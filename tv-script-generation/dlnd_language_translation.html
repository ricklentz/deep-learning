<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />
<title>dlnd_language_translation</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    color: #000 !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.2.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.2.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.2.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.2.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.2.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.2.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=1);
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2);
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=3);
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1);
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1);
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
@media (max-width: 991px) {
  #ipython_notebook {
    margin-left: 10px;
  }
}
[dir="rtl"] #ipython_notebook {
  float: right !important;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#login_widget {
  float: right;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  text-align: center;
  vertical-align: middle;
  display: inline;
  opacity: 0;
  z-index: 2;
  width: 12ex;
  margin-right: -12ex;
}
.alternate_upload .btn-upload {
  height: 22px;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
[dir="rtl"] #tabs li {
  float: right;
}
ul#tabs {
  margin-bottom: 4px;
}
[dir="rtl"] ul#tabs {
  margin-right: 0px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons {
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-right {
  padding-top: 1px;
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-left {
  float: right !important;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: baseline;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
#tree-selector {
  padding-right: 0px;
}
[dir="rtl"] #tree-selector a {
  float: right;
}
#button-select-all {
  min-width: 50px;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
[dir="rtl"] #new-menu {
  text-align: right;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
[dir="rtl"] #running .col-sm-8 {
  float: right !important;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI colors. */
.ansibold {
  font-weight: bold;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  border-left-width: 1px;
  padding-left: 5px;
  background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%);
}
div.cell.jupyter-soft-selected {
  border-left-color: #90CAF9;
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected {
  border-color: #ababab;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%);
}
@media print {
  div.cell.selected {
    border-color: transparent;
  }
}
div.cell.selected.jupyter-soft-selected {
  border-left-width: 0;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%);
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%);
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  padding: 0.4em;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */
  /* .CodeMirror-lines */
  padding: 0;
  border: 0;
  border-radius: 0;
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul {
  list-style: disc;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ul ul {
  list-style: square;
  margin: 0em 2em;
}
.rendered_html ul ul ul {
  list-style: circle;
  margin: 0em 2em;
}
.rendered_html ol {
  list-style: decimal;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
  margin: 0em 2em;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  background-color: #fff;
  color: #000;
  font-size: 100%;
  padding: 0px;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: 1px solid black;
  border-collapse: collapse;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  border: 1px solid black;
  border-collapse: collapse;
  margin: 1em 2em;
}
.rendered_html td,
.rendered_html th {
  text-align: left;
  vertical-align: middle;
  padding: 4px;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget {
  float: right !important;
  float: right;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  margin-top: 6px;
}
span.save_widget span.filename {
  height: 1em;
  line-height: 1em;
  padding: 3px;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  display: none;
}
.command-shortcut:before {
  content: "(command)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>
<style type="text/css">
    
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }

    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}

@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Language-Translation">Language Translation<a class="anchor-link" href="#Language-Translation">&#182;</a></h1><p>In this project, youre going to take a peek into the realm of neural network machine translation.  Youll be training a sequence to sequence model on a dataset of English and French sentences that can translate new sentences from English to French.</p>
<h2 id="Get-the-Data">Get the Data<a class="anchor-link" href="#Get-the-Data">&#182;</a></h2><p>Since translating the whole language of English to French will take lots of time to train, we have provided you with a small portion of the English corpus.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">helper</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="k">as</span> <span class="nn">tests</span>

<span class="n">source_path</span> <span class="o">=</span> <span class="s1">&#39;data/small_vocab_en&#39;</span>
<span class="n">target_path</span> <span class="o">=</span> <span class="s1">&#39;data/small_vocab_fr&#39;</span>
<span class="n">source_text</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">source_path</span><span class="p">)</span>
<span class="n">target_text</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">target_path</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Explore-the-Data">Explore the Data<a class="anchor-link" href="#Explore-the-Data">&#182;</a></h2><p>Play around with view_sentence_range to view different parts of the data.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">view_sentence_range</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Dataset Stats&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Roughly the number of unique words: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">({</span><span class="n">word</span><span class="p">:</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">source_text</span><span class="o">.</span><span class="n">split</span><span class="p">()})))</span>

<span class="n">sentences</span> <span class="o">=</span> <span class="n">source_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">word_counts</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">())</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Number of sentences: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sentences</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Average number of words in a sentence: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">word_counts</span><span class="p">)))</span>

<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;English sentences </span><span class="si">{}</span><span class="s1"> to </span><span class="si">{}</span><span class="s1">:&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">view_sentence_range</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">source_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)[</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]]))</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;French sentences </span><span class="si">{}</span><span class="s1"> to </span><span class="si">{}</span><span class="s1">:&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">view_sentence_range</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">target_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)[</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]]))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Dataset Stats
Roughly the number of unique words: 227
Number of sentences: 137861
Average number of words in a sentence: 13.225277634719028

English sentences 0 to 10:
new jersey is sometimes quiet during autumn , and it is snowy in april .
the united states is usually chilly during july , and it is usually freezing in november .
california is usually quiet during march , and it is usually hot in june .
the united states is sometimes mild during june , and it is cold in september .
your least liked fruit is the grape , but my least liked is the apple .
his favorite fruit is the orange , but my favorite is the grape .
paris is relaxing during december , but it is usually chilly in july .
new jersey is busy during spring , and it is never hot in march .
our least liked fruit is the lemon , but my least liked is the grape .
the united states is sometimes busy during january , and it is sometimes warm in november .

French sentences 0 to 10:
new jersey est parfois calme pendant l&#39; automne , et il est neigeux en avril .
les tats-unis est gnralement froid en juillet , et il gle habituellement en novembre .
california est gnralement calme en mars , et il est gnralement chaud en juin .
les tats-unis est parfois lgre en juin , et il fait froid en septembre .
votre moins aim fruit est le raisin , mais mon moins aim est la pomme .
son fruit prfr est l&#39;orange , mais mon prfr est le raisin .
paris est relaxant en dcembre , mais il est gnralement froid en juillet .
new jersey est occup au printemps , et il est jamais chaude en mars .
notre fruit est moins aim le citron , mais mon moins aim est le raisin .
les tats-unis est parfois occup en janvier , et il est parfois chaud en novembre .
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Implement-Preprocessing-Function">Implement Preprocessing Function<a class="anchor-link" href="#Implement-Preprocessing-Function">&#182;</a></h2><h3 id="Text-to-Word-Ids">Text to Word Ids<a class="anchor-link" href="#Text-to-Word-Ids">&#182;</a></h3><p>As you did with other RNNs, you must turn the text into a number so the computer can understand it. In the function <code>text_to_ids()</code>, you'll turn <code>source_text</code> and <code>target_text</code> from words to ids.  However, you need to add the <code>&lt;EOS&gt;</code> word id at the end of <code>target_text</code>.  This will help the neural network predict when the sentence should end.</p>
<p>You can get the <code>&lt;EOS&gt;</code> word id by doing:</p>
<div class="highlight"><pre><span></span><span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;EOS&gt;&#39;</span><span class="p">]</span>
</pre></div>
<p>You can get other word ids using <code>source_vocab_to_int</code> and <code>target_vocab_to_int</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">text_to_ids</span><span class="p">(</span><span class="n">source_text</span><span class="p">,</span> <span class="n">target_text</span><span class="p">,</span> <span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert source and target text to proper word ids</span>
<span class="sd">    :param source_text: String that contains all the source text.</span>
<span class="sd">    :param target_text: String that contains all the target text.</span>
<span class="sd">    :param source_vocab_to_int: Dictionary to go from the source words to an id</span>
<span class="sd">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span>
<span class="sd">    :return: A tuple of lists (source_id_text, target_id_text)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="n">source_id_text</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
    <span class="n">target_id_text</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
    
    <span class="c1"># convert the source text</span>
    <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">source_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">):</span>
        <span class="n">source_sentence_numbers</span> <span class="o">=</span> <span class="p">[</span><span class="n">source_vocab_to_int</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span>
        <span class="n">source_id_text</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">source_sentence_numbers</span><span class="p">)</span>
    
    <span class="c1"># convert the target text</span>
    <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">target_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">):</span>
        <span class="n">target_sentence_numbers</span> <span class="o">=</span> <span class="p">[</span><span class="n">target_vocab_to_int</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span>
        <span class="n">target_sentence_numbers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;EOS&gt;&#39;</span><span class="p">])</span>
        <span class="n">target_id_text</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">target_sentence_numbers</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="p">(</span><span class="n">source_id_text</span><span class="p">,</span> <span class="n">target_id_text</span><span class="p">)</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_text_to_ids</span><span class="p">(</span><span class="n">text_to_ids</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Preprocess-all-the-data-and-save-it">Preprocess all the data and save it<a class="anchor-link" href="#Preprocess-all-the-data-and-save-it">&#182;</a></h3><p>Running the code cell below will preprocess all the data and save it to file.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">helper</span><span class="o">.</span><span class="n">preprocess_and_save_data</span><span class="p">(</span><span class="n">source_path</span><span class="p">,</span> <span class="n">target_path</span><span class="p">,</span> <span class="n">text_to_ids</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Check-Point">Check Point<a class="anchor-link" href="#Check-Point">&#182;</a></h1><p>This is your first checkpoint. If you ever decide to come back to this notebook or have to restart the notebook, you can start from here. The preprocessed data has been saved to disk.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">helper</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="k">as</span> <span class="nn">tests</span>

<span class="p">(</span><span class="n">source_int_text</span><span class="p">,</span> <span class="n">target_int_text</span><span class="p">),</span> <span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">),</span> <span class="n">_</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Check-the-Version-of-TensorFlow-and-Access-to-GPU">Check the Version of TensorFlow and Access to GPU<a class="anchor-link" href="#Check-the-Version-of-TensorFlow-and-Access-to-GPU">&#182;</a></h3><p>This will check to make sure you have the correct version of TensorFlow and access to a GPU</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">distutils.version</span> <span class="k">import</span> <span class="n">LooseVersion</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.layers.core</span> <span class="k">import</span> <span class="n">Dense</span>

<span class="c1"># Check TensorFlow Version</span>
<span class="k">assert</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="s1">&#39;1.1&#39;</span><span class="p">),</span> <span class="s1">&#39;Please use TensorFlow version 1.1 or newer&#39;</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;TensorFlow Version: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">))</span>

<span class="c1"># Check for a GPU</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">gpu_device_name</span><span class="p">():</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;No GPU found. Please use a GPU to train your neural network.&#39;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Default GPU Device: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">gpu_device_name</span><span class="p">()))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>TensorFlow Version: 1.3.0
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/cbios/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: No GPU found. Please use a GPU to train your neural network.
  from ipykernel import kernelapp as app
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Build-the-Neural-Network">Build the Neural Network<a class="anchor-link" href="#Build-the-Neural-Network">&#182;</a></h2><p>You'll build the components necessary to build a Sequence-to-Sequence model by implementing the following functions below:</p>
<ul>
<li><code>model_inputs</code></li>
<li><code>process_decoder_input</code></li>
<li><code>encoding_layer</code></li>
<li><code>decoding_layer_train</code></li>
<li><code>decoding_layer_infer</code></li>
<li><code>decoding_layer</code></li>
<li><code>seq2seq_model</code></li>
</ul>
<h3 id="Input">Input<a class="anchor-link" href="#Input">&#182;</a></h3><p>Implement the <code>model_inputs()</code> function to create TF Placeholders for the Neural Network. It should create the following placeholders:</p>
<ul>
<li>Input text placeholder named "input" using the TF Placeholder name parameter with rank 2.</li>
<li>Targets placeholder with rank 2.</li>
<li>Learning rate placeholder with rank 0.</li>
<li>Keep probability placeholder named "keep_prob" using the TF Placeholder name parameter with rank 0.</li>
<li>Target sequence length placeholder named "target_sequence_length" with rank 1</li>
<li>Max target sequence length tensor named "max_target_len" getting its value from applying tf.reduce_max on the target_sequence_length placeholder. Rank 0.</li>
<li>Source sequence length placeholder named "source_sequence_length" with rank 1</li>
</ul>
<p>Return the placeholders in the following the tuple (input, targets, learning rate, keep probability, target sequence length, max target sequence length, source sequence length)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">model_inputs</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create TF Placeholders for input, targets, learning rate, and lengths of source and target sequences.</span>
<span class="sd">    :return: Tuple (input, targets, learning rate, keep probability, target sequence length,</span>
<span class="sd">    max target sequence length, source sequence length)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="n">_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span><span class="kc">None</span><span class="p">],</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;input&quot;</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">_targets</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span><span class="kc">None</span><span class="p">],</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;targets&quot;</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">_learning_rate</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">_keep_probability</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;keep_prob&quot;</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">_target_sequence_length</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;target_sequence_length&quot;</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">_max_target_sequence_length</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">_target_sequence_length</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;max_target_len&quot;</span><span class="p">)</span>
    <span class="n">_source_sequence_length</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;source_sequence_length&quot;</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="p">(</span><span class="n">_input</span><span class="p">,</span> <span class="n">_targets</span><span class="p">,</span> <span class="n">_learning_rate</span><span class="p">,</span> <span class="n">_keep_probability</span><span class="p">,</span> <span class="n">_target_sequence_length</span><span class="p">,</span> <span class="n">_max_target_sequence_length</span><span class="p">,</span> <span class="n">_source_sequence_length</span><span class="p">)</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_model_inputs</span><span class="p">(</span><span class="n">model_inputs</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>ERROR:tensorflow:==================================
Object was never used (type &lt;class &#39;tensorflow.python.framework.ops.Operation&#39;&gt;):
&lt;tf.Operation &#39;assert_rank_2/Assert/Assert&#39; type=Assert&gt;
If you want to mark it as used call its &#34;mark_used()&#34; method.
It was originally created here:
[&#39;File &#34;/home/cbios/anaconda3/lib/python3.6/runpy.py&#34;, line 193, in _run_module_as_main\n    &#34;__main__&#34;, mod_spec)&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/runpy.py&#34;, line 85, in _run_code\n    exec(code, run_globals)&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py&#34;, line 16, in &lt;module&gt;\n    app.launch_new_instance()&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py&#34;, line 658, in launch_instance\n    app.start()&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py&#34;, line 477, in start\n    ioloop.IOLoop.instance().start()&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py&#34;, line 177, in start\n    super(ZMQIOLoop, self).start()&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py&#34;, line 888, in start\n    handler_func(fd_obj, events)&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py&#34;, line 277, in null_wrapper\n    return fn(*args, **kwargs)&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py&#34;, line 440, in _handle_events\n    self._handle_recv()&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py&#34;, line 472, in _handle_recv\n    self._run_callback(callback, msg)&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py&#34;, line 414, in _run_callback\n    callback(*args, **kwargs)&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py&#34;, line 277, in null_wrapper\n    return fn(*args, **kwargs)&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py&#34;, line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py&#34;, line 235, in dispatch_shell\n    handler(stream, idents, msg)&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py&#34;, line 399, in execute_request\n    user_expressions, allow_stdin)&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py&#34;, line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py&#34;, line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py&#34;, line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py&#34;, line 2827, in run_ast_nodes\n    if self.run_code(code, result):&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py&#34;, line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)&#39;, &#39;File &#34;&lt;ipython-input-7-eef553aea72c&gt;&#34;, line 22, in &lt;module&gt;\n    tests.test_model_inputs(model_inputs)&#39;, &#39;File &#34;/home/cbios/github/deep-learning/language-translation/problem_unittests.py&#34;, line 106, in test_model_inputs\n    assert tf.assert_rank(lr, 0, message=\&#39;Learning Rate has wrong rank\&#39;)&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/check_ops.py&#34;, line 617, in assert_rank\n    dynamic_condition, data, summarize)&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/check_ops.py&#34;, line 571, in _assert_rank_condition\n    return control_flow_ops.Assert(condition, data, summarize=summarize)&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py&#34;, line 175, in wrapped\n    return _add_should_use_warning(fn(*args, **kwargs))&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py&#34;, line 144, in _add_should_use_warning\n    wrapped = TFShouldUseWarningWrapper(x)&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py&#34;, line 101, in __init__\n    stack = [s.strip() for s in traceback.format_stack()]&#39;]
==================================
ERROR:tensorflow:==================================
Object was never used (type &lt;class &#39;tensorflow.python.framework.ops.Operation&#39;&gt;):
&lt;tf.Operation &#39;assert_rank_3/Assert/Assert&#39; type=Assert&gt;
If you want to mark it as used call its &#34;mark_used()&#34; method.
It was originally created here:
[&#39;File &#34;/home/cbios/anaconda3/lib/python3.6/runpy.py&#34;, line 193, in _run_module_as_main\n    &#34;__main__&#34;, mod_spec)&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/runpy.py&#34;, line 85, in _run_code\n    exec(code, run_globals)&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py&#34;, line 16, in &lt;module&gt;\n    app.launch_new_instance()&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py&#34;, line 658, in launch_instance\n    app.start()&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py&#34;, line 477, in start\n    ioloop.IOLoop.instance().start()&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py&#34;, line 177, in start\n    super(ZMQIOLoop, self).start()&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py&#34;, line 888, in start\n    handler_func(fd_obj, events)&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py&#34;, line 277, in null_wrapper\n    return fn(*args, **kwargs)&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py&#34;, line 440, in _handle_events\n    self._handle_recv()&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py&#34;, line 472, in _handle_recv\n    self._run_callback(callback, msg)&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py&#34;, line 414, in _run_callback\n    callback(*args, **kwargs)&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py&#34;, line 277, in null_wrapper\n    return fn(*args, **kwargs)&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py&#34;, line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py&#34;, line 235, in dispatch_shell\n    handler(stream, idents, msg)&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py&#34;, line 399, in execute_request\n    user_expressions, allow_stdin)&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py&#34;, line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py&#34;, line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py&#34;, line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py&#34;, line 2827, in run_ast_nodes\n    if self.run_code(code, result):&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py&#34;, line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)&#39;, &#39;File &#34;&lt;ipython-input-7-eef553aea72c&gt;&#34;, line 22, in &lt;module&gt;\n    tests.test_model_inputs(model_inputs)&#39;, &#39;File &#34;/home/cbios/github/deep-learning/language-translation/problem_unittests.py&#34;, line 107, in test_model_inputs\n    assert tf.assert_rank(keep_prob, 0, message=\&#39;Keep Probability has wrong rank\&#39;)&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/check_ops.py&#34;, line 617, in assert_rank\n    dynamic_condition, data, summarize)&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/check_ops.py&#34;, line 571, in _assert_rank_condition\n    return control_flow_ops.Assert(condition, data, summarize=summarize)&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py&#34;, line 175, in wrapped\n    return _add_should_use_warning(fn(*args, **kwargs))&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py&#34;, line 144, in _add_should_use_warning\n    wrapped = TFShouldUseWarningWrapper(x)&#39;, &#39;File &#34;/home/cbios/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py&#34;, line 101, in __init__\n    stack = [s.strip() for s in traceback.format_stack()]&#39;]
==================================
Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Process-Decoder-Input">Process Decoder Input<a class="anchor-link" href="#Process-Decoder-Input">&#182;</a></h3><p>Implement <code>process_decoder_input</code> by removing the last word id from each batch in <code>target_data</code> and concat the GO ID to the begining of each batch.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">process_decoder_input</span><span class="p">(</span><span class="n">target_data</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Preprocess target data for encoding</span>
<span class="sd">    :param target_data: Target Placehoder</span>
<span class="sd">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span>
<span class="sd">    :param batch_size: Batch Size</span>
<span class="sd">    :return: Preprocessed target data</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="c1"># remove the last word id from each batch in target_data</span>
    <span class="n">strided_slice</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">strided_slice</span><span class="p">(</span><span class="n">target_data</span><span class="p">,</span>
                                     <span class="n">begin</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span>
                                     <span class="n">end</span><span class="o">=</span><span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                                     <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
    
    <span class="c1"># concatenate the GO ID to the begining of each batch</span>
    <span class="n">concat_values</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="n">dims</span><span class="o">=</span><span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
                    <span class="n">value</span><span class="o">=</span><span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;GO&gt;&#39;</span><span class="p">])</span>
    <span class="n">decoded_target_data</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="n">concat_values</span><span class="p">,</span><span class="n">strided_slice</span><span class="p">],</span>
                                   <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    
    <span class="k">return</span> <span class="n">decoded_target_data</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_process_encoding_input</span><span class="p">(</span><span class="n">process_decoder_input</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Encoding">Encoding<a class="anchor-link" href="#Encoding">&#182;</a></h3><p>Implement <code>encoding_layer()</code> to create a Encoder RNN layer:</p>
<ul>
<li>Embed the encoder input using <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/layers/embed_sequence"><code>tf.contrib.layers.embed_sequence</code></a></li>
<li>Construct a <a href="https://github.com/tensorflow/tensorflow/blob/6947f65a374ebf29e74bb71e36fd82760056d82c/tensorflow/docs_src/tutorials/recurrent.md#stacking-multiple-lstms">stacked</a> <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/LSTMCell"><code>tf.contrib.rnn.LSTMCell</code></a> wrapped in a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/DropoutWrapper"><code>tf.contrib.rnn.DropoutWrapper</code></a></li>
<li>Pass cell and embedded input to <a href="https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn"><code>tf.nn.dynamic_rnn()</code></a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">imp</span> <span class="k">import</span> <span class="n">reload</span>
<span class="n">reload</span><span class="p">(</span><span class="n">tests</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">encoding_layer</span><span class="p">(</span><span class="n">rnn_inputs</span><span class="p">,</span> <span class="n">rnn_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> 
                   <span class="n">source_sequence_length</span><span class="p">,</span> <span class="n">source_vocab_size</span><span class="p">,</span> 
                   <span class="n">encoding_embedding_size</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create encoding layer</span>
<span class="sd">    :param rnn_inputs: Inputs for the RNN</span>
<span class="sd">    :param rnn_size: RNN Size</span>
<span class="sd">    :param num_layers: Number of layers</span>
<span class="sd">    :param keep_prob: Dropout keep probability</span>
<span class="sd">    :param source_sequence_length: a list of the lengths of each sequence in the batch</span>
<span class="sd">    :param source_vocab_size: vocabulary size of source data</span>
<span class="sd">    :param encoding_embedding_size: embedding size of source data</span>
<span class="sd">    :return: tuple (RNN output, RNN state)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># embed the encoder input using tf.contrib.layers.embed_sequence</span>
    <span class="n">embed</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">embed_sequence</span><span class="p">(</span><span class="n">rnn_inputs</span><span class="p">,</span> <span class="n">source_vocab_size</span><span class="p">,</span> <span class="n">encoding_embedding_size</span><span class="p">)</span>
    
    <span class="c1"># construct a stacked tf.contrib.rnn.LSTMCell wrapped in a tf.contrib.rnn.DropoutWrapper using the num_layers</span>
    <span class="n">lstm_layers</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">):</span>
        <span class="n">lstm_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">))</span>
        
    <span class="n">cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">DropoutWrapper</span><span class="p">(</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">MultiRNNCell</span><span class="p">(</span><span class="n">lstm_layers</span><span class="p">),</span> <span class="n">keep_prob</span><span class="p">)</span>
    
    <span class="c1"># pass cell and embedded input to tf.nn.dynamic_rnn()</span>
    <span class="n">rnn_output</span><span class="p">,</span> <span class="n">rnn_state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dynamic_rnn</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">embed</span><span class="p">,</span> <span class="n">sequence_length</span><span class="o">=</span><span class="n">source_sequence_length</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">rnn_output</span><span class="p">,</span> <span class="n">rnn_state</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_encoding_layer</span><span class="p">(</span><span class="n">encoding_layer</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Decoding---Training">Decoding - Training<a class="anchor-link" href="#Decoding---Training">&#182;</a></h3><p>Create a training decoding layer:</p>
<ul>
<li>Create a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/TrainingHelper"><code>tf.contrib.seq2seq.TrainingHelper</code></a> </li>
<li>Create a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/BasicDecoder"><code>tf.contrib.seq2seq.BasicDecoder</code></a></li>
<li>Obtain the decoder outputs from <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_decode"><code>tf.contrib.seq2seq.dynamic_decode</code></a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">decoding_layer_train</span><span class="p">(</span><span class="n">encoder_state</span><span class="p">,</span> <span class="n">dec_cell</span><span class="p">,</span> <span class="n">dec_embed_input</span><span class="p">,</span> 
                         <span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_summary_length</span><span class="p">,</span> 
                         <span class="n">output_layer</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a decoding layer for training</span>
<span class="sd">    :param encoder_state: Encoder State</span>
<span class="sd">    :param dec_cell: Decoder RNN Cell</span>
<span class="sd">    :param dec_embed_input: Decoder embedded input</span>
<span class="sd">    :param target_sequence_length: The lengths of each sequence in the target batch</span>
<span class="sd">    :param max_summary_length: The length of the longest sequence in the batch</span>
<span class="sd">    :param output_layer: Function to apply the output layer</span>
<span class="sd">    :param keep_prob: Dropout keep probability</span>
<span class="sd">    :return: BasicDecoderOutput containing training logits and sample_id</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="c1"># create a decoding layer using the training helper</span>
    <span class="n">decoding_layer_helper</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">TrainingHelper</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">dec_embed_input</span><span class="p">,</span>
                                                       <span class="n">sequence_length</span><span class="o">=</span><span class="n">target_sequence_length</span><span class="p">)</span>
    
    <span class="c1"># create a basic decoder </span>
    <span class="n">basic_decoder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">BasicDecoder</span><span class="p">(</span><span class="n">cell</span><span class="o">=</span><span class="n">dec_cell</span><span class="p">,</span>
                                                    <span class="n">helper</span><span class="o">=</span><span class="n">decoding_layer_helper</span><span class="p">,</span> 
                                                    <span class="n">initial_state</span><span class="o">=</span><span class="n">encoder_state</span><span class="p">,</span> 
                                                    <span class="n">output_layer</span><span class="o">=</span><span class="n">output_layer</span><span class="p">)</span>
    
    <span class="c1"># obtain the decoder outputs from tf.contrib.seq2seq.dynamic_decode</span>
    <span class="n">decoder_outputs</span><span class="p">,</span> <span class="n">decoder_state</span><span class="p">,</span> <span class="n">decoder_sequence_lengths</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">dynamic_decode</span><span class="p">(</span><span class="n">decoder</span><span class="o">=</span><span class="n">basic_decoder</span><span class="p">,</span> 
                                                                                                 <span class="n">maximum_iterations</span><span class="o">=</span><span class="n">max_summary_length</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">decoder_outputs</span>



<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_decoding_layer_train</span><span class="p">(</span><span class="n">decoding_layer_train</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Decoding---Inference">Decoding - Inference<a class="anchor-link" href="#Decoding---Inference">&#182;</a></h3><p>Create inference decoder:</p>
<ul>
<li>Create a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/GreedyEmbeddingHelper"><code>tf.contrib.seq2seq.GreedyEmbeddingHelper</code></a></li>
<li>Create a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/BasicDecoder"><code>tf.contrib.seq2seq.BasicDecoder</code></a></li>
<li>Obtain the decoder outputs from <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_decode"><code>tf.contrib.seq2seq.dynamic_decode</code></a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">decoding_layer_infer</span><span class="p">(</span><span class="n">encoder_state</span><span class="p">,</span> <span class="n">dec_cell</span><span class="p">,</span> <span class="n">dec_embeddings</span><span class="p">,</span> <span class="n">start_of_sequence_id</span><span class="p">,</span>
                         <span class="n">end_of_sequence_id</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span>
                         <span class="n">vocab_size</span><span class="p">,</span> <span class="n">output_layer</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a decoding layer for inference</span>
<span class="sd">    x:param encoder_state: Encoder state</span>
<span class="sd">    x:param dec_cell: Decoder RNN Cell</span>
<span class="sd">    x:param dec_embeddings: Decoder embeddings</span>
<span class="sd">    x:param start_of_sequence_id: GO ID</span>
<span class="sd">    x:param end_of_sequence_id: EOS Id</span>
<span class="sd">    :param max_target_sequence_length: Maximum length of target sequences</span>
<span class="sd">    :param vocab_size: Size of decoder/target vocabulary</span>
<span class="sd">    :param decoding_scope: TenorFlow Variable Scope for decoding</span>
<span class="sd">    x:param output_layer: Function to apply the output layer</span>
<span class="sd">    :param batch_size: Batch size</span>
<span class="sd">    :param keep_prob: Dropout keep probability</span>
<span class="sd">    :return: BasicDecoderOutput containing inference logits and sample_id</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="c1"># find the start_tokens and end tokens   </span>
    <span class="c1"># per the project slack channel/forums, tf.tile can help replicate the input multiples times.</span>
    <span class="n">start_tokens</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="n">start_of_sequence_id</span><span class="p">],</span><span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
                           <span class="n">multiples</span><span class="o">=</span><span class="p">[</span><span class="n">batch_size</span><span class="p">])</span>
    
    
    
    <span class="c1"># create a tf.contrib.seq2seq.GreedyEmbeddingHelper</span>
    <span class="n">greedy_embedding_helper</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">GreedyEmbeddingHelper</span><span class="p">(</span><span class="n">embedding</span><span class="o">=</span><span class="n">dec_embeddings</span><span class="p">,</span>
                                                                      <span class="n">start_tokens</span><span class="o">=</span><span class="n">start_tokens</span><span class="p">,</span>
                                                                      <span class="n">end_token</span><span class="o">=</span><span class="n">end_of_sequence_id</span><span class="p">)</span>
    
    <span class="c1"># create a tf.contrib.seq2seq.BasicDecoder</span>
    <span class="n">basic_decoder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">BasicDecoder</span><span class="p">(</span><span class="n">cell</span><span class="o">=</span><span class="n">dec_cell</span><span class="p">,</span>
                                                    <span class="n">helper</span><span class="o">=</span><span class="n">greedy_embedding_helper</span><span class="p">,</span>
                                                    <span class="n">initial_state</span><span class="o">=</span><span class="n">encoder_state</span><span class="p">,</span>
                                                    <span class="n">output_layer</span><span class="o">=</span><span class="n">output_layer</span><span class="p">)</span>
    
    <span class="c1"># create the decoder outputs from tf.contrib.seq2seq.dynamic_decode</span>
    <span class="n">basic_decoder_outputs</span><span class="p">,</span> <span class="n">final_state</span><span class="p">,</span> <span class="n">final_sequence_lengths</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">dynamic_decode</span><span class="p">(</span><span class="n">decoder</span><span class="o">=</span><span class="n">basic_decoder</span><span class="p">,</span>
                                                                                                  <span class="n">output_time_major</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                                                                                  <span class="n">impute_finished</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                                                                                  <span class="n">maximum_iterations</span><span class="o">=</span><span class="n">max_target_sequence_length</span><span class="p">,</span>
                                                                                                  <span class="n">parallel_iterations</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
                                                                                                  <span class="n">swap_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                                                                                  <span class="n">scope</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">basic_decoder_outputs</span>



<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_decoding_layer_infer</span><span class="p">(</span><span class="n">decoding_layer_infer</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Build-the-Decoding-Layer">Build the Decoding Layer<a class="anchor-link" href="#Build-the-Decoding-Layer">&#182;</a></h3><p>Implement <code>decoding_layer()</code> to create a Decoder RNN layer.</p>
<ul>
<li>Embed the target sequences</li>
<li>Construct the decoder LSTM cell (just like you constructed the encoder cell above)</li>
<li>Create an output layer to map the outputs of the decoder to the elements of our vocabulary</li>
<li>Use the your <code>decoding_layer_train(encoder_state, dec_cell, dec_embed_input, target_sequence_length, max_target_sequence_length, output_layer, keep_prob)</code> function to get the training logits.</li>
<li>Use your <code>decoding_layer_infer(encoder_state, dec_cell, dec_embeddings, start_of_sequence_id, end_of_sequence_id, max_target_sequence_length, vocab_size, output_layer, batch_size, keep_prob)</code> function to get the inference logits.</li>
</ul>
<p>Note: You'll need to use <a href="https://www.tensorflow.org/api_docs/python/tf/variable_scope">tf.variable_scope</a> to share variables between training and inference.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">decoding_layer</span><span class="p">(</span><span class="n">dec_input</span><span class="p">,</span> <span class="n">encoder_state</span><span class="p">,</span>
                   <span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span>
                   <span class="n">rnn_size</span><span class="p">,</span>
                   <span class="n">num_layers</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span>
                   <span class="n">batch_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">decoding_embedding_size</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create decoding layer</span>
<span class="sd">    x:param dec_input: Decoder input</span>
<span class="sd">    x:param encoder_state: Encoder state</span>
<span class="sd">    :param target_sequence_length: The lengths of each sequence in the target batch</span>
<span class="sd">    :param max_target_sequence_length: Maximum length of target sequences</span>
<span class="sd">    x:param rnn_size: RNN Size</span>
<span class="sd">    x:param num_layers: Number of layers</span>
<span class="sd">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span>
<span class="sd">    x:param target_vocab_size: Size of target vocabulary</span>
<span class="sd">    :param batch_size: The size of the batch</span>
<span class="sd">    x:param keep_prob: Dropout keep probability</span>
<span class="sd">    x:param decoding_embedding_size: Decoding embedding size</span>
<span class="sd">    :return: Tuple of (Training BasicDecoderOutput, Inference BasicDecoderOutput)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="n">start_of_sequence_id</span> <span class="o">=</span> <span class="n">source_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;GO&gt;&#39;</span><span class="p">]</span>
    <span class="n">end_of_sequence_id</span> <span class="o">=</span> <span class="n">source_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;EOS&gt;&#39;</span><span class="p">]</span>
    
    <span class="c1"># embed the target sequences using tf.contrib.layers.embed_sequence</span>
    <span class="n">dec_embeddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_uniform</span><span class="p">([</span><span class="n">target_vocab_size</span><span class="p">,</span> <span class="n">decoding_embedding_size</span><span class="p">]))</span>
    <span class="c1"># looks up ids in a give tensor </span>
    <span class="n">dec_embed_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">embedding_lookup</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">dec_embeddings</span><span class="p">,</span> 
                                             <span class="n">ids</span><span class="o">=</span><span class="n">dec_input</span><span class="p">)</span>

    
    <span class="c1"># construct a stacked tf.contrib.rnn.LSTMCell wrapped in a tf.contrib.rnn.DropoutWrapper using the num_layers</span>
    <span class="n">lstm_layers</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">):</span>
        <span class="n">lstm_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">))</span>    
    <span class="n">dec_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">DropoutWrapper</span><span class="p">(</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">MultiRNNCell</span><span class="p">(</span><span class="n">lstm_layers</span><span class="p">),</span> <span class="n">keep_prob</span><span class="p">)</span>
    
    <span class="c1"># per the project 4 Slack channel, use dense with truncated normal init</span>
    <span class="n">output_layer</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">target_vocab_size</span><span class="p">,</span>
                         <span class="n">kernel_initializer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal_initializer</span><span class="p">(</span><span class="n">mean</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span>
     
    <span class="c1"># use tf.variable_scope to share variables between training and inference.</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s1">&#39;decoding&#39;</span><span class="p">,</span> <span class="n">reuse</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">as</span> <span class="n">decoding_scope</span><span class="p">:</span>
   
        <span class="c1"># get the training logits</span>
        <span class="n">training_basic_decoder_output</span> <span class="o">=</span>  <span class="n">decoding_layer_train</span><span class="p">(</span><span class="n">encoder_state</span><span class="p">,</span> <span class="n">dec_cell</span><span class="p">,</span> <span class="n">dec_embed_input</span><span class="p">,</span> <span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span> <span class="n">output_layer</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>
    
        <span class="c1"># get the inference logits</span>
        <span class="n">inference_basic_decoder_output</span> <span class="o">=</span> <span class="n">decoding_layer_infer</span><span class="p">(</span><span class="n">encoder_state</span><span class="p">,</span> <span class="n">dec_cell</span><span class="p">,</span> <span class="n">dec_embeddings</span><span class="p">,</span> <span class="n">start_of_sequence_id</span><span class="p">,</span> <span class="n">end_of_sequence_id</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span> <span class="n">output_layer</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">training_basic_decoder_output</span><span class="p">,</span> <span class="n">inference_basic_decoder_output</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_decoding_layer</span><span class="p">(</span><span class="n">decoding_layer</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Build-the-Neural-Network">Build the Neural Network<a class="anchor-link" href="#Build-the-Neural-Network">&#182;</a></h3><p>Apply the functions you implemented above to:</p>
<ul>
<li>Encode the input using your <code>encoding_layer(rnn_inputs, rnn_size, num_layers, keep_prob,  source_sequence_length, source_vocab_size, encoding_embedding_size)</code>.</li>
<li>Process target data using your <code>process_decoder_input(target_data, target_vocab_to_int, batch_size)</code> function.</li>
<li>Decode the encoded input using your <code>decoding_layer(dec_input, enc_state, target_sequence_length, max_target_sentence_length, rnn_size, num_layers, target_vocab_to_int, target_vocab_size, batch_size, keep_prob, dec_embedding_size)</code> function.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">seq2seq_model</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="n">target_data</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span>
                  <span class="n">source_sequence_length</span><span class="p">,</span> <span class="n">target_sequence_length</span><span class="p">,</span>
                  <span class="n">max_target_sentence_length</span><span class="p">,</span>
                  <span class="n">source_vocab_size</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span>
                  <span class="n">enc_embedding_size</span><span class="p">,</span> <span class="n">dec_embedding_size</span><span class="p">,</span>
                  <span class="n">rnn_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Build the Sequence-to-Sequence part of the neural network</span>
<span class="sd">    :param input_data: Input placeholder</span>
<span class="sd">    :param target_data: Target placeholder</span>
<span class="sd">    :param keep_prob: Dropout keep probability placeholder</span>
<span class="sd">    :param batch_size: Batch Size</span>
<span class="sd">    :param source_sequence_length: Sequence Lengths of source sequences in the batch</span>
<span class="sd">    :param target_sequence_length: Sequence Lengths of target sequences in the batch</span>
<span class="sd">    :param source_vocab_size: Source vocabulary size</span>
<span class="sd">    :param target_vocab_size: Target vocabulary size</span>
<span class="sd">    :param enc_embedding_size: Decoder embedding size</span>
<span class="sd">    :param dec_embedding_size: Encoder embedding size</span>
<span class="sd">    :param rnn_size: RNN Size</span>
<span class="sd">    :param num_layers: Number of layers</span>
<span class="sd">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span>
<span class="sd">    :return: Tuple of (Training BasicDecoderOutput, Inference BasicDecoderOutput)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># encode the input using your encoding_layer</span>
    <span class="n">enc_embed_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">embed_sequence</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="n">source_vocab_size</span><span class="p">,</span> <span class="n">enc_embedding_size</span><span class="p">)</span> 
    <span class="n">rnn_output</span><span class="p">,</span> <span class="n">enc_state</span> <span class="o">=</span> <span class="n">encoding_layer</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="n">rnn_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">source_sequence_length</span><span class="p">,</span> <span class="n">source_vocab_size</span><span class="p">,</span> <span class="n">enc_embedding_size</span><span class="p">)</span> 
    
    <span class="c1"># process target data using process_decoder_input()</span>
    <span class="n">dec_input</span> <span class="o">=</span> <span class="n">process_decoder_input</span><span class="p">(</span><span class="n">target_data</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>

    <span class="c1"># decode in encoded input using decoding_layer()</span>
    <span class="n">training_basic_decoder_output</span><span class="p">,</span> <span class="n">inference_basic_decoder_output</span> <span class="o">=</span> <span class="n">decoding_layer</span><span class="p">(</span><span class="n">dec_input</span><span class="p">,</span> <span class="n">enc_state</span><span class="p">,</span> <span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_target_sentence_length</span><span class="p">,</span> <span class="n">rnn_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">dec_embedding_size</span><span class="p">)</span>
     
    <span class="k">return</span> <span class="n">training_basic_decoder_output</span><span class="p">,</span> <span class="n">inference_basic_decoder_output</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_seq2seq_model</span><span class="p">(</span><span class="n">seq2seq_model</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Neural-Network-Training">Neural Network Training<a class="anchor-link" href="#Neural-Network-Training">&#182;</a></h2><h3 id="Hyperparameters">Hyperparameters<a class="anchor-link" href="#Hyperparameters">&#182;</a></h3><p>Tune the following parameters:</p>
<ul>
<li>Set <code>epochs</code> to the number of epochs.</li>
<li>Set <code>batch_size</code> to the batch size.</li>
<li>Set <code>rnn_size</code> to the size of the RNNs.</li>
<li>Set <code>num_layers</code> to the number of layers.</li>
<li>Set <code>encoding_embedding_size</code> to the size of the embedding for the encoder.</li>
<li>Set <code>decoding_embedding_size</code> to the size of the embedding for the decoder.</li>
<li>Set <code>learning_rate</code> to the learning rate.</li>
<li>Set <code>keep_probability</code> to the Dropout keep probability</li>
<li>Set <code>display_step</code> to state how many steps between each debug output statement</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Number of Epochs</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">300</span>
<span class="c1"># Batch Size</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">512</span>
<span class="c1"># RNN Size</span>
<span class="n">rnn_size</span> <span class="o">=</span> <span class="mi">25</span>
<span class="c1"># Number of Layers</span>
<span class="n">num_layers</span> <span class="o">=</span> <span class="mi">2</span>
<span class="c1"># Embedding Size</span>
<span class="n">encoding_embedding_size</span> <span class="o">=</span> <span class="mi">13</span>
<span class="n">decoding_embedding_size</span> <span class="o">=</span> <span class="mi">13</span>
<span class="c1"># Learning Rate</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="c1"># Dropout Keep Probability</span>
<span class="n">keep_probability</span> <span class="o">=</span> <span class="o">.</span><span class="mi">5</span>
<span class="n">display_step</span> <span class="o">=</span> <span class="mi">10</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Build-the-Graph">Build the Graph<a class="anchor-link" href="#Build-the-Graph">&#182;</a></h3><p>Build the graph using the neural network you implemented.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[15]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">save_path</span> <span class="o">=</span> <span class="s1">&#39;checkpoints/dev&#39;</span>
<span class="p">(</span><span class="n">source_int_text</span><span class="p">,</span> <span class="n">target_int_text</span><span class="p">),</span> <span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">),</span> <span class="n">_</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess</span><span class="p">()</span>
<span class="n">max_target_sentence_length</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">source_int_text</span><span class="p">])</span>

<span class="n">train_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="k">with</span> <span class="n">train_graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
    <span class="n">input_data</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span> <span class="n">source_sequence_length</span> <span class="o">=</span> <span class="n">model_inputs</span><span class="p">()</span>

    <span class="c1">#sequence_length = tf.placeholder_with_default(max_target_sentence_length, None, name=&#39;sequence_length&#39;)</span>
    <span class="n">input_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>

    <span class="n">train_logits</span><span class="p">,</span> <span class="n">inference_logits</span> <span class="o">=</span> <span class="n">seq2seq_model</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reverse</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span>
                                                   <span class="n">targets</span><span class="p">,</span>
                                                   <span class="n">keep_prob</span><span class="p">,</span>
                                                   <span class="n">batch_size</span><span class="p">,</span>
                                                   <span class="n">source_sequence_length</span><span class="p">,</span>
                                                   <span class="n">target_sequence_length</span><span class="p">,</span>
                                                   <span class="n">max_target_sequence_length</span><span class="p">,</span>
                                                   <span class="nb">len</span><span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">),</span>
                                                   <span class="nb">len</span><span class="p">(</span><span class="n">target_vocab_to_int</span><span class="p">),</span>
                                                   <span class="n">encoding_embedding_size</span><span class="p">,</span>
                                                   <span class="n">decoding_embedding_size</span><span class="p">,</span>
                                                   <span class="n">rnn_size</span><span class="p">,</span>
                                                   <span class="n">num_layers</span><span class="p">,</span>
                                                   <span class="n">target_vocab_to_int</span><span class="p">)</span>


    <span class="n">training_logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">train_logits</span><span class="o">.</span><span class="n">rnn_output</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;logits&#39;</span><span class="p">)</span>
    <span class="n">inference_logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">inference_logits</span><span class="o">.</span><span class="n">sample_id</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;predictions&#39;</span><span class="p">)</span>

    <span class="n">masks</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sequence_mask</span><span class="p">(</span><span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;masks&#39;</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s2">&quot;optimization&quot;</span><span class="p">):</span>
        <span class="c1"># Loss function</span>
        <span class="n">cost</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">sequence_loss</span><span class="p">(</span>
            <span class="n">training_logits</span><span class="p">,</span>
            <span class="n">targets</span><span class="p">,</span>
            <span class="n">masks</span><span class="p">)</span>

        <span class="c1"># Optimizer</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span>

        <span class="c1"># Gradient Clipping</span>
        <span class="n">gradients</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">compute_gradients</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
        <span class="n">capped_gradients</span> <span class="o">=</span> <span class="p">[(</span><span class="n">tf</span><span class="o">.</span><span class="n">clip_by_value</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">),</span> <span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">grad</span><span class="p">,</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">gradients</span> <span class="k">if</span> <span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">]</span>
        <span class="n">train_op</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="n">capped_gradients</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Batch and pad the source and target sequences</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[16]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="k">def</span> <span class="nf">pad_sentence_batch</span><span class="p">(</span><span class="n">sentence_batch</span><span class="p">,</span> <span class="n">pad_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Pad sentences with &lt;PAD&gt; so that each sentence of a batch has the same length&quot;&quot;&quot;</span>
    <span class="n">max_sentence</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentence_batch</span><span class="p">])</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">sentence</span> <span class="o">+</span> <span class="p">[</span><span class="n">pad_int</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">max_sentence</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">))</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentence_batch</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">get_batches</span><span class="p">(</span><span class="n">sources</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">source_pad_int</span><span class="p">,</span> <span class="n">target_pad_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Batch targets, sources, and the lengths of their sentences together&quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">batch_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">sources</span><span class="p">)</span><span class="o">//</span><span class="n">batch_size</span><span class="p">):</span>
        <span class="n">start_i</span> <span class="o">=</span> <span class="n">batch_i</span> <span class="o">*</span> <span class="n">batch_size</span>

        <span class="c1"># Slice the right amount for the batch</span>
        <span class="n">sources_batch</span> <span class="o">=</span> <span class="n">sources</span><span class="p">[</span><span class="n">start_i</span><span class="p">:</span><span class="n">start_i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>
        <span class="n">targets_batch</span> <span class="o">=</span> <span class="n">targets</span><span class="p">[</span><span class="n">start_i</span><span class="p">:</span><span class="n">start_i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>

        <span class="c1"># Pad</span>
        <span class="n">pad_sources_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">pad_sentence_batch</span><span class="p">(</span><span class="n">sources_batch</span><span class="p">,</span> <span class="n">source_pad_int</span><span class="p">))</span>
        <span class="n">pad_targets_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">pad_sentence_batch</span><span class="p">(</span><span class="n">targets_batch</span><span class="p">,</span> <span class="n">target_pad_int</span><span class="p">))</span>

        <span class="c1"># Need the lengths for the _lengths parameters</span>
        <span class="n">pad_targets_lengths</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">pad_targets_batch</span><span class="p">:</span>
            <span class="n">pad_targets_lengths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">target</span><span class="p">))</span>

        <span class="n">pad_source_lengths</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">source</span> <span class="ow">in</span> <span class="n">pad_sources_batch</span><span class="p">:</span>
            <span class="n">pad_source_lengths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">source</span><span class="p">))</span>

        <span class="k">yield</span> <span class="n">pad_sources_batch</span><span class="p">,</span> <span class="n">pad_targets_batch</span><span class="p">,</span> <span class="n">pad_source_lengths</span><span class="p">,</span> <span class="n">pad_targets_lengths</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Train">Train<a class="anchor-link" href="#Train">&#182;</a></h3><p>Train the neural network on the preprocessed data. If you have a hard time getting a good loss, check the forms to see if anyone is having the same problem.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[17]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="k">def</span> <span class="nf">get_accuracy</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">logits</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate accuracy</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">max_seq</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">max_seq</span> <span class="o">-</span> <span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
            <span class="n">target</span><span class="p">,</span>
            <span class="p">[(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="n">max_seq</span> <span class="o">-</span> <span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])],</span>
            <span class="s1">&#39;constant&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">max_seq</span> <span class="o">-</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
            <span class="n">logits</span><span class="p">,</span>
            <span class="p">[(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="n">max_seq</span> <span class="o">-</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])],</span>
            <span class="s1">&#39;constant&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">logits</span><span class="p">))</span>

<span class="c1"># Split data to training and validation sets</span>
<span class="n">train_source</span> <span class="o">=</span> <span class="n">source_int_text</span><span class="p">[</span><span class="n">batch_size</span><span class="p">:]</span>
<span class="n">train_target</span> <span class="o">=</span> <span class="n">target_int_text</span><span class="p">[</span><span class="n">batch_size</span><span class="p">:]</span>
<span class="n">valid_source</span> <span class="o">=</span> <span class="n">source_int_text</span><span class="p">[:</span><span class="n">batch_size</span><span class="p">]</span>
<span class="n">valid_target</span> <span class="o">=</span> <span class="n">target_int_text</span><span class="p">[:</span><span class="n">batch_size</span><span class="p">]</span>
<span class="p">(</span><span class="n">valid_sources_batch</span><span class="p">,</span> <span class="n">valid_targets_batch</span><span class="p">,</span> <span class="n">valid_sources_lengths</span><span class="p">,</span> <span class="n">valid_targets_lengths</span> <span class="p">)</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">get_batches</span><span class="p">(</span><span class="n">valid_source</span><span class="p">,</span>
                                                                                                             <span class="n">valid_target</span><span class="p">,</span>
                                                                                                             <span class="n">batch_size</span><span class="p">,</span>
                                                                                                             <span class="n">source_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;PAD&gt;&#39;</span><span class="p">],</span>
                                                                                                             <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;PAD&gt;&#39;</span><span class="p">]))</span>                                                                                                  
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">train_graph</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>

    <span class="k">for</span> <span class="n">epoch_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">batch_i</span><span class="p">,</span> <span class="p">(</span><span class="n">source_batch</span><span class="p">,</span> <span class="n">target_batch</span><span class="p">,</span> <span class="n">sources_lengths</span><span class="p">,</span> <span class="n">targets_lengths</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
                <span class="n">get_batches</span><span class="p">(</span><span class="n">train_source</span><span class="p">,</span> <span class="n">train_target</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span>
                            <span class="n">source_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;PAD&gt;&#39;</span><span class="p">],</span>
                            <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;PAD&gt;&#39;</span><span class="p">])):</span>

            <span class="n">_</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                <span class="p">[</span><span class="n">train_op</span><span class="p">,</span> <span class="n">cost</span><span class="p">],</span>
                <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="n">source_batch</span><span class="p">,</span>
                 <span class="n">targets</span><span class="p">:</span> <span class="n">target_batch</span><span class="p">,</span>
                 <span class="n">lr</span><span class="p">:</span> <span class="n">learning_rate</span><span class="p">,</span>
                 <span class="n">target_sequence_length</span><span class="p">:</span> <span class="n">targets_lengths</span><span class="p">,</span>
                 <span class="n">source_sequence_length</span><span class="p">:</span> <span class="n">sources_lengths</span><span class="p">,</span>
                 <span class="n">keep_prob</span><span class="p">:</span> <span class="n">keep_probability</span><span class="p">})</span>


            <span class="k">if</span> <span class="n">batch_i</span> <span class="o">%</span> <span class="n">display_step</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">batch_i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>


                <span class="n">batch_train_logits</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                    <span class="n">inference_logits</span><span class="p">,</span>
                    <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="n">source_batch</span><span class="p">,</span>
                     <span class="n">source_sequence_length</span><span class="p">:</span> <span class="n">sources_lengths</span><span class="p">,</span>
                     <span class="n">target_sequence_length</span><span class="p">:</span> <span class="n">targets_lengths</span><span class="p">,</span>
                     <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})</span>


                <span class="n">batch_valid_logits</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                    <span class="n">inference_logits</span><span class="p">,</span>
                    <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="n">valid_sources_batch</span><span class="p">,</span>
                     <span class="n">source_sequence_length</span><span class="p">:</span> <span class="n">valid_sources_lengths</span><span class="p">,</span>
                     <span class="n">target_sequence_length</span><span class="p">:</span> <span class="n">valid_targets_lengths</span><span class="p">,</span>
                     <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})</span>

                <span class="n">train_acc</span> <span class="o">=</span> <span class="n">get_accuracy</span><span class="p">(</span><span class="n">target_batch</span><span class="p">,</span> <span class="n">batch_train_logits</span><span class="p">)</span>

                <span class="n">valid_acc</span> <span class="o">=</span> <span class="n">get_accuracy</span><span class="p">(</span><span class="n">valid_targets_batch</span><span class="p">,</span> <span class="n">batch_valid_logits</span><span class="p">)</span>

                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch </span><span class="si">{:&gt;3}</span><span class="s1"> Batch </span><span class="si">{:&gt;4}</span><span class="s1">/</span><span class="si">{}</span><span class="s1"> - Train Accuracy: </span><span class="si">{:&gt;6.4f}</span><span class="s1">, Validation Accuracy: </span><span class="si">{:&gt;6.4f}</span><span class="s1">, Loss: </span><span class="si">{:&gt;6.4f}</span><span class="s1">&#39;</span>
                      <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch_i</span><span class="p">,</span> <span class="n">batch_i</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">source_int_text</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">train_acc</span><span class="p">,</span> <span class="n">valid_acc</span><span class="p">,</span> <span class="n">loss</span><span class="p">))</span>

    <span class="c1"># Save Model</span>
    <span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>
    <span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">save_path</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Model Trained and Saved&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch   0 Batch   10/269 - Train Accuracy: 0.2327, Validation Accuracy: 0.3096, Loss: 5.7543
Epoch   0 Batch   20/269 - Train Accuracy: 0.2386, Validation Accuracy: 0.3099, Loss: 5.5265
Epoch   0 Batch   30/269 - Train Accuracy: 0.2665, Validation Accuracy: 0.3096, Loss: 5.0690
Epoch   0 Batch   40/269 - Train Accuracy: 0.2437, Validation Accuracy: 0.3123, Loss: 4.6585
Epoch   0 Batch   50/269 - Train Accuracy: 0.2521, Validation Accuracy: 0.3123, Loss: 4.2811
Epoch   0 Batch   60/269 - Train Accuracy: 0.2920, Validation Accuracy: 0.3096, Loss: 3.8967
Epoch   0 Batch   70/269 - Train Accuracy: 0.2948, Validation Accuracy: 0.3220, Loss: 3.7458
Epoch   0 Batch   80/269 - Train Accuracy: 0.3157, Validation Accuracy: 0.3399, Loss: 3.6191
Epoch   0 Batch   90/269 - Train Accuracy: 0.2644, Validation Accuracy: 0.3410, Loss: 3.7033
Epoch   0 Batch  100/269 - Train Accuracy: 0.3199, Validation Accuracy: 0.3410, Loss: 3.4725
Epoch   0 Batch  110/269 - Train Accuracy: 0.3075, Validation Accuracy: 0.3419, Loss: 3.4691
Epoch   0 Batch  120/269 - Train Accuracy: 0.2681, Validation Accuracy: 0.3410, Loss: 3.5390
Epoch   0 Batch  130/269 - Train Accuracy: 0.2649, Validation Accuracy: 0.3410, Loss: 3.5138
Epoch   0 Batch  140/269 - Train Accuracy: 0.3046, Validation Accuracy: 0.3411, Loss: 3.3315
Epoch   0 Batch  150/269 - Train Accuracy: 0.3187, Validation Accuracy: 0.3470, Loss: 3.2923
Epoch   0 Batch  160/269 - Train Accuracy: 0.3161, Validation Accuracy: 0.3470, Loss: 3.2607
Epoch   0 Batch  170/269 - Train Accuracy: 0.3178, Validation Accuracy: 0.3479, Loss: 3.2321
Epoch   0 Batch  180/269 - Train Accuracy: 0.3145, Validation Accuracy: 0.3479, Loss: 3.2093
Epoch   0 Batch  190/269 - Train Accuracy: 0.3129, Validation Accuracy: 0.3477, Loss: 3.1763
Epoch   0 Batch  200/269 - Train Accuracy: 0.2870, Validation Accuracy: 0.3477, Loss: 3.2515
Epoch   0 Batch  210/269 - Train Accuracy: 0.3213, Validation Accuracy: 0.3477, Loss: 3.1199
Epoch   0 Batch  220/269 - Train Accuracy: 0.3381, Validation Accuracy: 0.3475, Loss: 3.0299
Epoch   0 Batch  230/269 - Train Accuracy: 0.3130, Validation Accuracy: 0.3480, Loss: 3.1004
Epoch   0 Batch  240/269 - Train Accuracy: 0.3670, Validation Accuracy: 0.3448, Loss: 2.8849
Epoch   0 Batch  250/269 - Train Accuracy: 0.2899, Validation Accuracy: 0.3466, Loss: 3.1345
Epoch   0 Batch  260/269 - Train Accuracy: 0.2846, Validation Accuracy: 0.3481, Loss: 3.1276
Epoch   1 Batch   10/269 - Train Accuracy: 0.2770, Validation Accuracy: 0.3480, Loss: 3.0806
Epoch   1 Batch   20/269 - Train Accuracy: 0.2815, Validation Accuracy: 0.3482, Loss: 3.0522
Epoch   1 Batch   30/269 - Train Accuracy: 0.3080, Validation Accuracy: 0.3483, Loss: 2.9522
Epoch   1 Batch   40/269 - Train Accuracy: 0.2829, Validation Accuracy: 0.3490, Loss: 3.0194
Epoch   1 Batch   50/269 - Train Accuracy: 0.2900, Validation Accuracy: 0.3488, Loss: 2.9959
Epoch   1 Batch   60/269 - Train Accuracy: 0.3328, Validation Accuracy: 0.3493, Loss: 2.8116
Epoch   1 Batch   70/269 - Train Accuracy: 0.3297, Validation Accuracy: 0.3521, Loss: 2.8337
Epoch   1 Batch   80/269 - Train Accuracy: 0.3570, Validation Accuracy: 0.3796, Loss: 2.7957
Epoch   1 Batch   90/269 - Train Accuracy: 0.3114, Validation Accuracy: 0.3825, Loss: 2.9646
Epoch   1 Batch  100/269 - Train Accuracy: 0.3668, Validation Accuracy: 0.3840, Loss: 2.7414
Epoch   1 Batch  110/269 - Train Accuracy: 0.3584, Validation Accuracy: 0.3892, Loss: 2.7843
Epoch   1 Batch  120/269 - Train Accuracy: 0.3229, Validation Accuracy: 0.3902, Loss: 2.8857
Epoch   1 Batch  130/269 - Train Accuracy: 0.3200, Validation Accuracy: 0.3912, Loss: 2.9060
Epoch   1 Batch  140/269 - Train Accuracy: 0.3576, Validation Accuracy: 0.3909, Loss: 2.7353
Epoch   1 Batch  150/269 - Train Accuracy: 0.3703, Validation Accuracy: 0.3979, Loss: 2.7112
Epoch   1 Batch  160/269 - Train Accuracy: 0.3650, Validation Accuracy: 0.3960, Loss: 2.7009
Epoch   1 Batch  170/269 - Train Accuracy: 0.3734, Validation Accuracy: 0.4046, Loss: 2.6803
Epoch   1 Batch  180/269 - Train Accuracy: 0.3743, Validation Accuracy: 0.4071, Loss: 2.6702
Epoch   1 Batch  190/269 - Train Accuracy: 0.3809, Validation Accuracy: 0.4116, Loss: 2.6399
Epoch   1 Batch  200/269 - Train Accuracy: 0.3568, Validation Accuracy: 0.4137, Loss: 2.7207
Epoch   1 Batch  210/269 - Train Accuracy: 0.3884, Validation Accuracy: 0.4148, Loss: 2.6016
Epoch   1 Batch  220/269 - Train Accuracy: 0.4068, Validation Accuracy: 0.4175, Loss: 2.5167
Epoch   1 Batch  230/269 - Train Accuracy: 0.3846, Validation Accuracy: 0.4210, Loss: 2.6038
Epoch   1 Batch  240/269 - Train Accuracy: 0.4426, Validation Accuracy: 0.4266, Loss: 2.3959
Epoch   1 Batch  250/269 - Train Accuracy: 0.3766, Validation Accuracy: 0.4272, Loss: 2.6302
Epoch   1 Batch  260/269 - Train Accuracy: 0.3700, Validation Accuracy: 0.4275, Loss: 2.6378
Epoch   2 Batch   10/269 - Train Accuracy: 0.3720, Validation Accuracy: 0.4329, Loss: 2.6096
Epoch   2 Batch   20/269 - Train Accuracy: 0.3771, Validation Accuracy: 0.4337, Loss: 2.5869
Epoch   2 Batch   30/269 - Train Accuracy: 0.3978, Validation Accuracy: 0.4359, Loss: 2.5030
Epoch   2 Batch   40/269 - Train Accuracy: 0.3746, Validation Accuracy: 0.4344, Loss: 2.5639
Epoch   2 Batch   50/269 - Train Accuracy: 0.3843, Validation Accuracy: 0.4368, Loss: 2.5389
Epoch   2 Batch   60/269 - Train Accuracy: 0.4213, Validation Accuracy: 0.4402, Loss: 2.3866
Epoch   2 Batch   70/269 - Train Accuracy: 0.4222, Validation Accuracy: 0.4429, Loss: 2.3985
Epoch   2 Batch   80/269 - Train Accuracy: 0.4275, Validation Accuracy: 0.4461, Loss: 2.3579
Epoch   2 Batch   90/269 - Train Accuracy: 0.3798, Validation Accuracy: 0.4475, Loss: 2.5345
Epoch   2 Batch  100/269 - Train Accuracy: 0.4390, Validation Accuracy: 0.4480, Loss: 2.3305
Epoch   2 Batch  110/269 - Train Accuracy: 0.4234, Validation Accuracy: 0.4524, Loss: 2.3735
Epoch   2 Batch  120/269 - Train Accuracy: 0.4019, Validation Accuracy: 0.4577, Loss: 2.4750
Epoch   2 Batch  130/269 - Train Accuracy: 0.3925, Validation Accuracy: 0.4570, Loss: 2.5025
Epoch   2 Batch  140/269 - Train Accuracy: 0.4352, Validation Accuracy: 0.4607, Loss: 2.3458
Epoch   2 Batch  150/269 - Train Accuracy: 0.4389, Validation Accuracy: 0.4640, Loss: 2.3264
Epoch   2 Batch  160/269 - Train Accuracy: 0.4422, Validation Accuracy: 0.4671, Loss: 2.3279
Epoch   2 Batch  170/269 - Train Accuracy: 0.4422, Validation Accuracy: 0.4666, Loss: 2.3056
Epoch   2 Batch  180/269 - Train Accuracy: 0.4376, Validation Accuracy: 0.4635, Loss: 2.2973
Epoch   2 Batch  190/269 - Train Accuracy: 0.4459, Validation Accuracy: 0.4680, Loss: 2.2736
Epoch   2 Batch  200/269 - Train Accuracy: 0.4255, Validation Accuracy: 0.4675, Loss: 2.3584
Epoch   2 Batch  210/269 - Train Accuracy: 0.4489, Validation Accuracy: 0.4705, Loss: 2.2547
Epoch   2 Batch  220/269 - Train Accuracy: 0.4662, Validation Accuracy: 0.4719, Loss: 2.1732
Epoch   2 Batch  230/269 - Train Accuracy: 0.4409, Validation Accuracy: 0.4711, Loss: 2.2637
Epoch   2 Batch  240/269 - Train Accuracy: 0.4924, Validation Accuracy: 0.4749, Loss: 2.0754
Epoch   2 Batch  250/269 - Train Accuracy: 0.4352, Validation Accuracy: 0.4739, Loss: 2.2841
Epoch   2 Batch  260/269 - Train Accuracy: 0.4300, Validation Accuracy: 0.4775, Loss: 2.2898
Epoch   3 Batch   10/269 - Train Accuracy: 0.4365, Validation Accuracy: 0.4846, Loss: 2.2402
Epoch   3 Batch   20/269 - Train Accuracy: 0.4474, Validation Accuracy: 0.4890, Loss: 2.2215
Epoch   3 Batch   30/269 - Train Accuracy: 0.4624, Validation Accuracy: 0.4896, Loss: 2.1420
Epoch   3 Batch   40/269 - Train Accuracy: 0.4412, Validation Accuracy: 0.4884, Loss: 2.1955
Epoch   3 Batch   50/269 - Train Accuracy: 0.4430, Validation Accuracy: 0.4894, Loss: 2.1693
Epoch   3 Batch   60/269 - Train Accuracy: 0.4806, Validation Accuracy: 0.4925, Loss: 2.0342
Epoch   3 Batch   70/269 - Train Accuracy: 0.4723, Validation Accuracy: 0.4895, Loss: 2.0450
Epoch   3 Batch   80/269 - Train Accuracy: 0.4807, Validation Accuracy: 0.4918, Loss: 2.0141
Epoch   3 Batch   90/269 - Train Accuracy: 0.4295, Validation Accuracy: 0.4908, Loss: 2.1709
Epoch   3 Batch  100/269 - Train Accuracy: 0.4820, Validation Accuracy: 0.4917, Loss: 1.9875
Epoch   3 Batch  110/269 - Train Accuracy: 0.4646, Validation Accuracy: 0.4940, Loss: 2.0222
Epoch   3 Batch  120/269 - Train Accuracy: 0.4509, Validation Accuracy: 0.4994, Loss: 2.1087
Epoch   3 Batch  130/269 - Train Accuracy: 0.4473, Validation Accuracy: 0.5049, Loss: 2.1278
Epoch   3 Batch  140/269 - Train Accuracy: 0.4866, Validation Accuracy: 0.5067, Loss: 1.9991
Epoch   3 Batch  150/269 - Train Accuracy: 0.4817, Validation Accuracy: 0.5065, Loss: 1.9845
Epoch   3 Batch  160/269 - Train Accuracy: 0.4883, Validation Accuracy: 0.5075, Loss: 1.9753
Epoch   3 Batch  170/269 - Train Accuracy: 0.4847, Validation Accuracy: 0.5060, Loss: 1.9547
Epoch   3 Batch  180/269 - Train Accuracy: 0.4844, Validation Accuracy: 0.5071, Loss: 1.9448
Epoch   3 Batch  190/269 - Train Accuracy: 0.4803, Validation Accuracy: 0.5044, Loss: 1.9242
Epoch   3 Batch  200/269 - Train Accuracy: 0.4645, Validation Accuracy: 0.5035, Loss: 1.9940
Epoch   3 Batch  210/269 - Train Accuracy: 0.4859, Validation Accuracy: 0.5062, Loss: 1.8970
Epoch   3 Batch  220/269 - Train Accuracy: 0.4982, Validation Accuracy: 0.5043, Loss: 1.8303
Epoch   3 Batch  230/269 - Train Accuracy: 0.4704, Validation Accuracy: 0.5027, Loss: 1.9063
Epoch   3 Batch  240/269 - Train Accuracy: 0.5179, Validation Accuracy: 0.5003, Loss: 1.7382
Epoch   3 Batch  250/269 - Train Accuracy: 0.4639, Validation Accuracy: 0.5023, Loss: 1.9105
Epoch   3 Batch  260/269 - Train Accuracy: 0.4434, Validation Accuracy: 0.4972, Loss: 1.9296
Epoch   4 Batch   10/269 - Train Accuracy: 0.4560, Validation Accuracy: 0.4995, Loss: 1.8866
Epoch   4 Batch   20/269 - Train Accuracy: 0.4525, Validation Accuracy: 0.4946, Loss: 1.8744
Epoch   4 Batch   30/269 - Train Accuracy: 0.4767, Validation Accuracy: 0.5013, Loss: 1.7968
Epoch   4 Batch   40/269 - Train Accuracy: 0.4568, Validation Accuracy: 0.5007, Loss: 1.8342
Epoch   4 Batch   50/269 - Train Accuracy: 0.4583, Validation Accuracy: 0.5057, Loss: 1.8060
Epoch   4 Batch   60/269 - Train Accuracy: 0.5032, Validation Accuracy: 0.5102, Loss: 1.6819
Epoch   4 Batch   70/269 - Train Accuracy: 0.4862, Validation Accuracy: 0.5075, Loss: 1.6883
Epoch   4 Batch   80/269 - Train Accuracy: 0.4824, Validation Accuracy: 0.5075, Loss: 1.6496
Epoch   4 Batch   90/269 - Train Accuracy: 0.4465, Validation Accuracy: 0.5057, Loss: 1.7714
Epoch   4 Batch  100/269 - Train Accuracy: 0.4887, Validation Accuracy: 0.5071, Loss: 1.6164
Epoch   4 Batch  110/269 - Train Accuracy: 0.4666, Validation Accuracy: 0.4959, Loss: 1.6342
Epoch   4 Batch  120/269 - Train Accuracy: 0.4318, Validation Accuracy: 0.4862, Loss: 1.6950
Epoch   4 Batch  130/269 - Train Accuracy: 0.4019, Validation Accuracy: 0.4494, Loss: 1.7147
Epoch   4 Batch  140/269 - Train Accuracy: 0.4154, Validation Accuracy: 0.4331, Loss: 1.5932
Epoch   4 Batch  150/269 - Train Accuracy: 0.3741, Validation Accuracy: 0.4111, Loss: 1.5875
Epoch   4 Batch  160/269 - Train Accuracy: 0.4257, Validation Accuracy: 0.4462, Loss: 1.5749
Epoch   4 Batch  170/269 - Train Accuracy: 0.3622, Validation Accuracy: 0.3747, Loss: 1.5521
Epoch   4 Batch  180/269 - Train Accuracy: 0.3767, Validation Accuracy: 0.4092, Loss: 1.5368
Epoch   4 Batch  190/269 - Train Accuracy: 0.3373, Validation Accuracy: 0.3657, Loss: 1.5194
Epoch   4 Batch  200/269 - Train Accuracy: 0.3370, Validation Accuracy: 0.3621, Loss: 1.5720
Epoch   4 Batch  210/269 - Train Accuracy: 0.3577, Validation Accuracy: 0.3626, Loss: 1.4984
Epoch   4 Batch  220/269 - Train Accuracy: 0.3358, Validation Accuracy: 0.3231, Loss: 1.4431
Epoch   4 Batch  230/269 - Train Accuracy: 0.3049, Validation Accuracy: 0.3256, Loss: 1.5017
Epoch   4 Batch  240/269 - Train Accuracy: 0.3494, Validation Accuracy: 0.3297, Loss: 1.3732
Epoch   4 Batch  250/269 - Train Accuracy: 0.3261, Validation Accuracy: 0.3200, Loss: 1.5030
Epoch   4 Batch  260/269 - Train Accuracy: 0.3015, Validation Accuracy: 0.3157, Loss: 1.5175
Epoch   5 Batch   10/269 - Train Accuracy: 0.2810, Validation Accuracy: 0.3164, Loss: 1.4742
Epoch   5 Batch   20/269 - Train Accuracy: 0.3036, Validation Accuracy: 0.3211, Loss: 1.4663
Epoch   5 Batch   30/269 - Train Accuracy: 0.3132, Validation Accuracy: 0.3283, Loss: 1.4123
Epoch   5 Batch   40/269 - Train Accuracy: 0.2968, Validation Accuracy: 0.3311, Loss: 1.4460
Epoch   5 Batch   50/269 - Train Accuracy: 0.3251, Validation Accuracy: 0.3596, Loss: 1.4412
Epoch   5 Batch   60/269 - Train Accuracy: 0.3394, Validation Accuracy: 0.3638, Loss: 1.3306
Epoch   5 Batch   70/269 - Train Accuracy: 0.3269, Validation Accuracy: 0.3417, Loss: 1.3521
Epoch   5 Batch   80/269 - Train Accuracy: 0.3181, Validation Accuracy: 0.3469, Loss: 1.3230
Epoch   5 Batch   90/269 - Train Accuracy: 0.2906, Validation Accuracy: 0.3303, Loss: 1.4226
Epoch   5 Batch  100/269 - Train Accuracy: 0.3295, Validation Accuracy: 0.3353, Loss: 1.3050
Epoch   5 Batch  110/269 - Train Accuracy: 0.3301, Validation Accuracy: 0.3248, Loss: 1.3272
Epoch   5 Batch  120/269 - Train Accuracy: 0.3053, Validation Accuracy: 0.3283, Loss: 1.3746
Epoch   5 Batch  130/269 - Train Accuracy: 0.3095, Validation Accuracy: 0.3255, Loss: 1.3997
Epoch   5 Batch  140/269 - Train Accuracy: 0.3158, Validation Accuracy: 0.3283, Loss: 1.3026
Epoch   5 Batch  150/269 - Train Accuracy: 0.3097, Validation Accuracy: 0.3255, Loss: 1.3016
Epoch   5 Batch  160/269 - Train Accuracy: 0.3382, Validation Accuracy: 0.3267, Loss: 1.2931
Epoch   5 Batch  170/269 - Train Accuracy: 0.3254, Validation Accuracy: 0.3276, Loss: 1.2783
Epoch   5 Batch  180/269 - Train Accuracy: 0.3171, Validation Accuracy: 0.3335, Loss: 1.2604
Epoch   5 Batch  190/269 - Train Accuracy: 0.3153, Validation Accuracy: 0.3262, Loss: 1.2462
Epoch   5 Batch  200/269 - Train Accuracy: 0.3124, Validation Accuracy: 0.3277, Loss: 1.2972
Epoch   5 Batch  210/269 - Train Accuracy: 0.3246, Validation Accuracy: 0.3291, Loss: 1.2341
Epoch   5 Batch  220/269 - Train Accuracy: 0.3321, Validation Accuracy: 0.3244, Loss: 1.1909
Epoch   5 Batch  230/269 - Train Accuracy: 0.3098, Validation Accuracy: 0.3260, Loss: 1.2377
Epoch   5 Batch  240/269 - Train Accuracy: 0.3519, Validation Accuracy: 0.3264, Loss: 1.1319
Epoch   5 Batch  250/269 - Train Accuracy: 0.3204, Validation Accuracy: 0.3169, Loss: 1.2473
Epoch   5 Batch  260/269 - Train Accuracy: 0.3141, Validation Accuracy: 0.3231, Loss: 1.2643
Epoch   6 Batch   10/269 - Train Accuracy: 0.2850, Validation Accuracy: 0.3092, Loss: 1.2291
Epoch   6 Batch   20/269 - Train Accuracy: 0.3002, Validation Accuracy: 0.3098, Loss: 1.2292
Epoch   6 Batch   30/269 - Train Accuracy: 0.3076, Validation Accuracy: 0.3155, Loss: 1.1736
Epoch   6 Batch   40/269 - Train Accuracy: 0.2954, Validation Accuracy: 0.3124, Loss: 1.2156
Epoch   6 Batch   50/269 - Train Accuracy: 0.3171, Validation Accuracy: 0.3256, Loss: 1.2136
Epoch   6 Batch   60/269 - Train Accuracy: 0.3350, Validation Accuracy: 0.3414, Loss: 1.1228
Epoch   6 Batch   70/269 - Train Accuracy: 0.3276, Validation Accuracy: 0.3461, Loss: 1.1466
Epoch   6 Batch   80/269 - Train Accuracy: 0.3243, Validation Accuracy: 0.3496, Loss: 1.1226
Epoch   6 Batch   90/269 - Train Accuracy: 0.3100, Validation Accuracy: 0.3509, Loss: 1.2086
Epoch   6 Batch  100/269 - Train Accuracy: 0.3452, Validation Accuracy: 0.3723, Loss: 1.1040
Epoch   6 Batch  110/269 - Train Accuracy: 0.3579, Validation Accuracy: 0.3808, Loss: 1.1226
Epoch   6 Batch  120/269 - Train Accuracy: 0.3185, Validation Accuracy: 0.3867, Loss: 1.1599
Epoch   6 Batch  130/269 - Train Accuracy: 0.3225, Validation Accuracy: 0.3894, Loss: 1.1879
Epoch   6 Batch  140/269 - Train Accuracy: 0.3624, Validation Accuracy: 0.3956, Loss: 1.1131
Epoch   6 Batch  150/269 - Train Accuracy: 0.3672, Validation Accuracy: 0.3941, Loss: 1.1173
Epoch   6 Batch  160/269 - Train Accuracy: 0.3762, Validation Accuracy: 0.3979, Loss: 1.1029
Epoch   6 Batch  170/269 - Train Accuracy: 0.3596, Validation Accuracy: 0.3931, Loss: 1.0954
Epoch   6 Batch  180/269 - Train Accuracy: 0.3650, Validation Accuracy: 0.3984, Loss: 1.0767
Epoch   6 Batch  190/269 - Train Accuracy: 0.3859, Validation Accuracy: 0.4024, Loss: 1.0678
Epoch   6 Batch  200/269 - Train Accuracy: 0.3420, Validation Accuracy: 0.3999, Loss: 1.1144
Epoch   6 Batch  210/269 - Train Accuracy: 0.3759, Validation Accuracy: 0.4049, Loss: 1.0625
Epoch   6 Batch  220/269 - Train Accuracy: 0.4042, Validation Accuracy: 0.3997, Loss: 1.0239
Epoch   6 Batch  230/269 - Train Accuracy: 0.3905, Validation Accuracy: 0.4256, Loss: 1.0697
Epoch   6 Batch  240/269 - Train Accuracy: 0.4658, Validation Accuracy: 0.4369, Loss: 0.9817
Epoch   6 Batch  250/269 - Train Accuracy: 0.4336, Validation Accuracy: 0.4776, Loss: 1.0821
Epoch   6 Batch  260/269 - Train Accuracy: 0.4196, Validation Accuracy: 0.4695, Loss: 1.0974
Epoch   7 Batch   10/269 - Train Accuracy: 0.4434, Validation Accuracy: 0.4721, Loss: 1.0677
Epoch   7 Batch   20/269 - Train Accuracy: 0.4154, Validation Accuracy: 0.4664, Loss: 1.0771
Epoch   7 Batch   30/269 - Train Accuracy: 0.4507, Validation Accuracy: 0.4743, Loss: 1.0199
Epoch   7 Batch   40/269 - Train Accuracy: 0.4618, Validation Accuracy: 0.4856, Loss: 1.0640
Epoch   7 Batch   50/269 - Train Accuracy: 0.4482, Validation Accuracy: 0.4885, Loss: 1.0643
Epoch   7 Batch   60/269 - Train Accuracy: 0.4893, Validation Accuracy: 0.4826, Loss: 0.9817
Epoch   7 Batch   70/269 - Train Accuracy: 0.4596, Validation Accuracy: 0.4761, Loss: 1.0088
Epoch   7 Batch   80/269 - Train Accuracy: 0.4914, Validation Accuracy: 0.4842, Loss: 0.9886
Epoch   7 Batch   90/269 - Train Accuracy: 0.4292, Validation Accuracy: 0.4817, Loss: 1.0609
Epoch   7 Batch  100/269 - Train Accuracy: 0.4908, Validation Accuracy: 0.4890, Loss: 0.9780
Epoch   7 Batch  110/269 - Train Accuracy: 0.4620, Validation Accuracy: 0.4919, Loss: 0.9901
Epoch   7 Batch  120/269 - Train Accuracy: 0.4396, Validation Accuracy: 0.4828, Loss: 1.0242
Epoch   7 Batch  130/269 - Train Accuracy: 0.4276, Validation Accuracy: 0.4887, Loss: 1.0463
Epoch   7 Batch  140/269 - Train Accuracy: 0.4851, Validation Accuracy: 0.4888, Loss: 0.9902
Epoch   7 Batch  150/269 - Train Accuracy: 0.4811, Validation Accuracy: 0.4913, Loss: 0.9918
Epoch   7 Batch  160/269 - Train Accuracy: 0.4641, Validation Accuracy: 0.4889, Loss: 0.9780
Epoch   7 Batch  170/269 - Train Accuracy: 0.4677, Validation Accuracy: 0.4891, Loss: 0.9777
Epoch   7 Batch  180/269 - Train Accuracy: 0.4793, Validation Accuracy: 0.4873, Loss: 0.9623
Epoch   7 Batch  190/269 - Train Accuracy: 0.4871, Validation Accuracy: 0.4907, Loss: 0.9574
Epoch   7 Batch  200/269 - Train Accuracy: 0.4687, Validation Accuracy: 0.4906, Loss: 0.9947
Epoch   7 Batch  210/269 - Train Accuracy: 0.4777, Validation Accuracy: 0.4903, Loss: 0.9470
Epoch   7 Batch  220/269 - Train Accuracy: 0.4986, Validation Accuracy: 0.4901, Loss: 0.9189
Epoch   7 Batch  230/269 - Train Accuracy: 0.4838, Validation Accuracy: 0.4941, Loss: 0.9618
Epoch   7 Batch  240/269 - Train Accuracy: 0.4984, Validation Accuracy: 0.4923, Loss: 0.8902
Epoch   7 Batch  250/269 - Train Accuracy: 0.4763, Validation Accuracy: 0.4944, Loss: 0.9832
Epoch   7 Batch  260/269 - Train Accuracy: 0.4476, Validation Accuracy: 0.4968, Loss: 0.9973
Epoch   8 Batch   10/269 - Train Accuracy: 0.4764, Validation Accuracy: 0.4975, Loss: 0.9673
Epoch   8 Batch   20/269 - Train Accuracy: 0.4682, Validation Accuracy: 0.4940, Loss: 0.9682
Epoch   8 Batch   30/269 - Train Accuracy: 0.4881, Validation Accuracy: 0.4964, Loss: 0.9247
Epoch   8 Batch   40/269 - Train Accuracy: 0.4795, Validation Accuracy: 0.4991, Loss: 0.9713
Epoch   8 Batch   50/269 - Train Accuracy: 0.4635, Validation Accuracy: 0.5026, Loss: 0.9697
Epoch   8 Batch   60/269 - Train Accuracy: 0.5019, Validation Accuracy: 0.4948, Loss: 0.8937
Epoch   8 Batch   70/269 - Train Accuracy: 0.4808, Validation Accuracy: 0.4962, Loss: 0.9237
Epoch   8 Batch   80/269 - Train Accuracy: 0.4986, Validation Accuracy: 0.4954, Loss: 0.9050
Epoch   8 Batch   90/269 - Train Accuracy: 0.4533, Validation Accuracy: 0.4991, Loss: 0.9679
Epoch   8 Batch  100/269 - Train Accuracy: 0.5046, Validation Accuracy: 0.5018, Loss: 0.8963
Epoch   8 Batch  110/269 - Train Accuracy: 0.4718, Validation Accuracy: 0.4988, Loss: 0.9005
Epoch   8 Batch  120/269 - Train Accuracy: 0.4587, Validation Accuracy: 0.5066, Loss: 0.9381
Epoch   8 Batch  130/269 - Train Accuracy: 0.4498, Validation Accuracy: 0.5026, Loss: 0.9613
Epoch   8 Batch  140/269 - Train Accuracy: 0.4908, Validation Accuracy: 0.5028, Loss: 0.9129
Epoch   8 Batch  150/269 - Train Accuracy: 0.4880, Validation Accuracy: 0.5083, Loss: 0.9131
Epoch   8 Batch  160/269 - Train Accuracy: 0.4838, Validation Accuracy: 0.5106, Loss: 0.9010
Epoch   8 Batch  170/269 - Train Accuracy: 0.4808, Validation Accuracy: 0.5030, Loss: 0.8971
Epoch   8 Batch  180/269 - Train Accuracy: 0.4840, Validation Accuracy: 0.5022, Loss: 0.8850
Epoch   8 Batch  190/269 - Train Accuracy: 0.4986, Validation Accuracy: 0.5127, Loss: 0.8769
Epoch   8 Batch  200/269 - Train Accuracy: 0.4946, Validation Accuracy: 0.5101, Loss: 0.9176
Epoch   8 Batch  210/269 - Train Accuracy: 0.4980, Validation Accuracy: 0.5102, Loss: 0.8740
Epoch   8 Batch  220/269 - Train Accuracy: 0.5186, Validation Accuracy: 0.5150, Loss: 0.8466
Epoch   8 Batch  230/269 - Train Accuracy: 0.5034, Validation Accuracy: 0.5179, Loss: 0.8885
Epoch   8 Batch  240/269 - Train Accuracy: 0.5298, Validation Accuracy: 0.5158, Loss: 0.8138
Epoch   8 Batch  250/269 - Train Accuracy: 0.4894, Validation Accuracy: 0.5134, Loss: 0.9044
Epoch   8 Batch  260/269 - Train Accuracy: 0.4689, Validation Accuracy: 0.5197, Loss: 0.9240
Epoch   9 Batch   10/269 - Train Accuracy: 0.4956, Validation Accuracy: 0.5326, Loss: 0.8990
Epoch   9 Batch   20/269 - Train Accuracy: 0.4914, Validation Accuracy: 0.5352, Loss: 0.9000
Epoch   9 Batch   30/269 - Train Accuracy: 0.5106, Validation Accuracy: 0.5328, Loss: 0.8589
Epoch   9 Batch   40/269 - Train Accuracy: 0.5017, Validation Accuracy: 0.5299, Loss: 0.9020
Epoch   9 Batch   50/269 - Train Accuracy: 0.4776, Validation Accuracy: 0.5167, Loss: 0.8994
Epoch   9 Batch   60/269 - Train Accuracy: 0.5266, Validation Accuracy: 0.5331, Loss: 0.8262
Epoch   9 Batch   70/269 - Train Accuracy: 0.5044, Validation Accuracy: 0.5317, Loss: 0.8619
Epoch   9 Batch   80/269 - Train Accuracy: 0.5171, Validation Accuracy: 0.5257, Loss: 0.8404
Epoch   9 Batch   90/269 - Train Accuracy: 0.4658, Validation Accuracy: 0.5291, Loss: 0.9028
Epoch   9 Batch  100/269 - Train Accuracy: 0.5338, Validation Accuracy: 0.5294, Loss: 0.8320
Epoch   9 Batch  110/269 - Train Accuracy: 0.5059, Validation Accuracy: 0.5356, Loss: 0.8394
Epoch   9 Batch  120/269 - Train Accuracy: 0.4896, Validation Accuracy: 0.5318, Loss: 0.8742
Epoch   9 Batch  130/269 - Train Accuracy: 0.4822, Validation Accuracy: 0.5412, Loss: 0.8925
Epoch   9 Batch  140/269 - Train Accuracy: 0.5233, Validation Accuracy: 0.5378, Loss: 0.8503
Epoch   9 Batch  150/269 - Train Accuracy: 0.5209, Validation Accuracy: 0.5417, Loss: 0.8519
Epoch   9 Batch  160/269 - Train Accuracy: 0.5203, Validation Accuracy: 0.5342, Loss: 0.8373
Epoch   9 Batch  170/269 - Train Accuracy: 0.5318, Validation Accuracy: 0.5418, Loss: 0.8375
Epoch   9 Batch  180/269 - Train Accuracy: 0.5411, Validation Accuracy: 0.5494, Loss: 0.8240
Epoch   9 Batch  190/269 - Train Accuracy: 0.5358, Validation Accuracy: 0.5460, Loss: 0.8220
Epoch   9 Batch  200/269 - Train Accuracy: 0.5261, Validation Accuracy: 0.5423, Loss: 0.8573
Epoch   9 Batch  210/269 - Train Accuracy: 0.5417, Validation Accuracy: 0.5421, Loss: 0.8200
Epoch   9 Batch  220/269 - Train Accuracy: 0.5462, Validation Accuracy: 0.5350, Loss: 0.7919
Epoch   9 Batch  230/269 - Train Accuracy: 0.5339, Validation Accuracy: 0.5483, Loss: 0.8309
Epoch   9 Batch  240/269 - Train Accuracy: 0.5638, Validation Accuracy: 0.5505, Loss: 0.7617
Epoch   9 Batch  250/269 - Train Accuracy: 0.5350, Validation Accuracy: 0.5598, Loss: 0.8534
Epoch   9 Batch  260/269 - Train Accuracy: 0.5144, Validation Accuracy: 0.5528, Loss: 0.8681
Epoch  10 Batch   10/269 - Train Accuracy: 0.5345, Validation Accuracy: 0.5669, Loss: 0.8405
Epoch  10 Batch   20/269 - Train Accuracy: 0.5372, Validation Accuracy: 0.5631, Loss: 0.8439
Epoch  10 Batch   30/269 - Train Accuracy: 0.5566, Validation Accuracy: 0.5654, Loss: 0.8032
Epoch  10 Batch   40/269 - Train Accuracy: 0.5471, Validation Accuracy: 0.5633, Loss: 0.8442
Epoch  10 Batch   50/269 - Train Accuracy: 0.5360, Validation Accuracy: 0.5666, Loss: 0.8442
Epoch  10 Batch   60/269 - Train Accuracy: 0.5629, Validation Accuracy: 0.5659, Loss: 0.7751
Epoch  10 Batch   70/269 - Train Accuracy: 0.5497, Validation Accuracy: 0.5576, Loss: 0.8102
Epoch  10 Batch   80/269 - Train Accuracy: 0.5608, Validation Accuracy: 0.5616, Loss: 0.7901
Epoch  10 Batch   90/269 - Train Accuracy: 0.5346, Validation Accuracy: 0.5722, Loss: 0.8459
Epoch  10 Batch  100/269 - Train Accuracy: 0.5759, Validation Accuracy: 0.5727, Loss: 0.7820
Epoch  10 Batch  110/269 - Train Accuracy: 0.5582, Validation Accuracy: 0.5720, Loss: 0.7898
Epoch  10 Batch  120/269 - Train Accuracy: 0.5288, Validation Accuracy: 0.5674, Loss: 0.8156
Epoch  10 Batch  130/269 - Train Accuracy: 0.5256, Validation Accuracy: 0.5668, Loss: 0.8365
Epoch  10 Batch  140/269 - Train Accuracy: 0.5635, Validation Accuracy: 0.5697, Loss: 0.8022
Epoch  10 Batch  150/269 - Train Accuracy: 0.5479, Validation Accuracy: 0.5724, Loss: 0.8026
Epoch  10 Batch  160/269 - Train Accuracy: 0.5685, Validation Accuracy: 0.5726, Loss: 0.7896
Epoch  10 Batch  170/269 - Train Accuracy: 0.5764, Validation Accuracy: 0.5760, Loss: 0.7865
Epoch  10 Batch  180/269 - Train Accuracy: 0.5710, Validation Accuracy: 0.5699, Loss: 0.7776
Epoch  10 Batch  190/269 - Train Accuracy: 0.5528, Validation Accuracy: 0.5702, Loss: 0.7726
Epoch  10 Batch  200/269 - Train Accuracy: 0.5647, Validation Accuracy: 0.5681, Loss: 0.8105
Epoch  10 Batch  210/269 - Train Accuracy: 0.5809, Validation Accuracy: 0.5639, Loss: 0.7712
Epoch  10 Batch  220/269 - Train Accuracy: 0.5694, Validation Accuracy: 0.5628, Loss: 0.7445
Epoch  10 Batch  230/269 - Train Accuracy: 0.5627, Validation Accuracy: 0.5732, Loss: 0.7814
Epoch  10 Batch  240/269 - Train Accuracy: 0.5960, Validation Accuracy: 0.5769, Loss: 0.7178
Epoch  10 Batch  250/269 - Train Accuracy: 0.5613, Validation Accuracy: 0.5744, Loss: 0.8007
Epoch  10 Batch  260/269 - Train Accuracy: 0.5404, Validation Accuracy: 0.5763, Loss: 0.8168
Epoch  11 Batch   10/269 - Train Accuracy: 0.5386, Validation Accuracy: 0.5746, Loss: 0.7972
Epoch  11 Batch   20/269 - Train Accuracy: 0.5577, Validation Accuracy: 0.5745, Loss: 0.8035
Epoch  11 Batch   30/269 - Train Accuracy: 0.5677, Validation Accuracy: 0.5794, Loss: 0.7583
Epoch  11 Batch   40/269 - Train Accuracy: 0.5548, Validation Accuracy: 0.5770, Loss: 0.8019
Epoch  11 Batch   50/269 - Train Accuracy: 0.5529, Validation Accuracy: 0.5751, Loss: 0.7995
Epoch  11 Batch   60/269 - Train Accuracy: 0.5651, Validation Accuracy: 0.5724, Loss: 0.7335
Epoch  11 Batch   70/269 - Train Accuracy: 0.5681, Validation Accuracy: 0.5684, Loss: 0.7672
Epoch  11 Batch   80/269 - Train Accuracy: 0.5632, Validation Accuracy: 0.5619, Loss: 0.7543
Epoch  11 Batch   90/269 - Train Accuracy: 0.5271, Validation Accuracy: 0.5698, Loss: 0.7995
Epoch  11 Batch  100/269 - Train Accuracy: 0.5871, Validation Accuracy: 0.5695, Loss: 0.7462
Epoch  11 Batch  110/269 - Train Accuracy: 0.5593, Validation Accuracy: 0.5684, Loss: 0.7469
Epoch  11 Batch  120/269 - Train Accuracy: 0.5467, Validation Accuracy: 0.5697, Loss: 0.7767
Epoch  11 Batch  130/269 - Train Accuracy: 0.5389, Validation Accuracy: 0.5696, Loss: 0.7971
Epoch  11 Batch  140/269 - Train Accuracy: 0.5674, Validation Accuracy: 0.5676, Loss: 0.7622
Epoch  11 Batch  150/269 - Train Accuracy: 0.5680, Validation Accuracy: 0.5748, Loss: 0.7606
Epoch  11 Batch  160/269 - Train Accuracy: 0.5751, Validation Accuracy: 0.5779, Loss: 0.7530
Epoch  11 Batch  170/269 - Train Accuracy: 0.5796, Validation Accuracy: 0.5743, Loss: 0.7482
Epoch  11 Batch  180/269 - Train Accuracy: 0.5770, Validation Accuracy: 0.5730, Loss: 0.7412
Epoch  11 Batch  190/269 - Train Accuracy: 0.5803, Validation Accuracy: 0.5727, Loss: 0.7268
Epoch  11 Batch  200/269 - Train Accuracy: 0.5816, Validation Accuracy: 0.5798, Loss: 0.7703
Epoch  11 Batch  210/269 - Train Accuracy: 0.5842, Validation Accuracy: 0.5782, Loss: 0.7374
Epoch  11 Batch  220/269 - Train Accuracy: 0.5811, Validation Accuracy: 0.5743, Loss: 0.7133
Epoch  11 Batch  230/269 - Train Accuracy: 0.5821, Validation Accuracy: 0.5756, Loss: 0.7453
Epoch  11 Batch  240/269 - Train Accuracy: 0.6087, Validation Accuracy: 0.5866, Loss: 0.6883
Epoch  11 Batch  250/269 - Train Accuracy: 0.5751, Validation Accuracy: 0.5862, Loss: 0.7646
Epoch  11 Batch  260/269 - Train Accuracy: 0.5512, Validation Accuracy: 0.5861, Loss: 0.7804
Epoch  12 Batch   10/269 - Train Accuracy: 0.5574, Validation Accuracy: 0.5859, Loss: 0.7567
Epoch  12 Batch   20/269 - Train Accuracy: 0.5659, Validation Accuracy: 0.5807, Loss: 0.7625
Epoch  12 Batch   30/269 - Train Accuracy: 0.5864, Validation Accuracy: 0.5885, Loss: 0.7248
Epoch  12 Batch   40/269 - Train Accuracy: 0.5813, Validation Accuracy: 0.5963, Loss: 0.7679
Epoch  12 Batch   50/269 - Train Accuracy: 0.5817, Validation Accuracy: 0.5844, Loss: 0.7585
Epoch  12 Batch   60/269 - Train Accuracy: 0.5960, Validation Accuracy: 0.5916, Loss: 0.7010
Epoch  12 Batch   70/269 - Train Accuracy: 0.5869, Validation Accuracy: 0.5872, Loss: 0.7349
Epoch  12 Batch   80/269 - Train Accuracy: 0.5930, Validation Accuracy: 0.5839, Loss: 0.7181
Epoch  12 Batch   90/269 - Train Accuracy: 0.5629, Validation Accuracy: 0.5898, Loss: 0.7663
Epoch  12 Batch  100/269 - Train Accuracy: 0.6068, Validation Accuracy: 0.5857, Loss: 0.7086
Epoch  12 Batch  110/269 - Train Accuracy: 0.5819, Validation Accuracy: 0.5894, Loss: 0.7147
Epoch  12 Batch  120/269 - Train Accuracy: 0.5770, Validation Accuracy: 0.5890, Loss: 0.7421
Epoch  12 Batch  130/269 - Train Accuracy: 0.5640, Validation Accuracy: 0.5925, Loss: 0.7566
Epoch  12 Batch  140/269 - Train Accuracy: 0.5977, Validation Accuracy: 0.5961, Loss: 0.7304
Epoch  12 Batch  150/269 - Train Accuracy: 0.6020, Validation Accuracy: 0.5993, Loss: 0.7263
Epoch  12 Batch  160/269 - Train Accuracy: 0.5982, Validation Accuracy: 0.6040, Loss: 0.7203
Epoch  12 Batch  170/269 - Train Accuracy: 0.6020, Validation Accuracy: 0.5990, Loss: 0.7074
Epoch  12 Batch  180/269 - Train Accuracy: 0.5897, Validation Accuracy: 0.5922, Loss: 0.7053
Epoch  12 Batch  190/269 - Train Accuracy: 0.6123, Validation Accuracy: 0.6072, Loss: 0.6981
Epoch  12 Batch  200/269 - Train Accuracy: 0.5970, Validation Accuracy: 0.5983, Loss: 0.7369
Epoch  12 Batch  210/269 - Train Accuracy: 0.5967, Validation Accuracy: 0.5975, Loss: 0.7063
Epoch  12 Batch  220/269 - Train Accuracy: 0.6109, Validation Accuracy: 0.5956, Loss: 0.6753
Epoch  12 Batch  230/269 - Train Accuracy: 0.5963, Validation Accuracy: 0.5998, Loss: 0.7170
Epoch  12 Batch  240/269 - Train Accuracy: 0.6218, Validation Accuracy: 0.6014, Loss: 0.6536
Epoch  12 Batch  250/269 - Train Accuracy: 0.5757, Validation Accuracy: 0.6009, Loss: 0.7297
Epoch  12 Batch  260/269 - Train Accuracy: 0.5711, Validation Accuracy: 0.6123, Loss: 0.7522
Epoch  13 Batch   10/269 - Train Accuracy: 0.5808, Validation Accuracy: 0.6048, Loss: 0.7276
Epoch  13 Batch   20/269 - Train Accuracy: 0.5891, Validation Accuracy: 0.6056, Loss: 0.7322
Epoch  13 Batch   30/269 - Train Accuracy: 0.6017, Validation Accuracy: 0.5993, Loss: 0.6946
Epoch  13 Batch   40/269 - Train Accuracy: 0.5893, Validation Accuracy: 0.6045, Loss: 0.7300
Epoch  13 Batch   50/269 - Train Accuracy: 0.5936, Validation Accuracy: 0.5981, Loss: 0.7307
Epoch  13 Batch   60/269 - Train Accuracy: 0.6027, Validation Accuracy: 0.6077, Loss: 0.6726
Epoch  13 Batch   70/269 - Train Accuracy: 0.6076, Validation Accuracy: 0.6050, Loss: 0.7019
Epoch  13 Batch   80/269 - Train Accuracy: 0.5985, Validation Accuracy: 0.5980, Loss: 0.6958
Epoch  13 Batch   90/269 - Train Accuracy: 0.5771, Validation Accuracy: 0.6053, Loss: 0.7345
Epoch  13 Batch  100/269 - Train Accuracy: 0.6196, Validation Accuracy: 0.6009, Loss: 0.6819
Epoch  13 Batch  110/269 - Train Accuracy: 0.6004, Validation Accuracy: 0.6046, Loss: 0.6889
Epoch  13 Batch  120/269 - Train Accuracy: 0.5883, Validation Accuracy: 0.5980, Loss: 0.7104
Epoch  13 Batch  130/269 - Train Accuracy: 0.5718, Validation Accuracy: 0.6087, Loss: 0.7253
Epoch  13 Batch  140/269 - Train Accuracy: 0.5998, Validation Accuracy: 0.6025, Loss: 0.7018
Epoch  13 Batch  150/269 - Train Accuracy: 0.6044, Validation Accuracy: 0.6032, Loss: 0.7004
Epoch  13 Batch  160/269 - Train Accuracy: 0.5980, Validation Accuracy: 0.6128, Loss: 0.6924
Epoch  13 Batch  170/269 - Train Accuracy: 0.5972, Validation Accuracy: 0.6043, Loss: 0.6792
Epoch  13 Batch  180/269 - Train Accuracy: 0.5972, Validation Accuracy: 0.6056, Loss: 0.6795
Epoch  13 Batch  190/269 - Train Accuracy: 0.6057, Validation Accuracy: 0.6029, Loss: 0.6751
Epoch  13 Batch  200/269 - Train Accuracy: 0.5938, Validation Accuracy: 0.6022, Loss: 0.7099
Epoch  13 Batch  210/269 - Train Accuracy: 0.6059, Validation Accuracy: 0.6066, Loss: 0.6741
Epoch  13 Batch  220/269 - Train Accuracy: 0.6063, Validation Accuracy: 0.6024, Loss: 0.6499
Epoch  13 Batch  230/269 - Train Accuracy: 0.5995, Validation Accuracy: 0.6040, Loss: 0.6843
Epoch  13 Batch  240/269 - Train Accuracy: 0.6361, Validation Accuracy: 0.6126, Loss: 0.6302
Epoch  13 Batch  250/269 - Train Accuracy: 0.5752, Validation Accuracy: 0.6050, Loss: 0.7035
Epoch  13 Batch  260/269 - Train Accuracy: 0.5736, Validation Accuracy: 0.6143, Loss: 0.7217
Epoch  14 Batch   10/269 - Train Accuracy: 0.5924, Validation Accuracy: 0.6155, Loss: 0.7021
Epoch  14 Batch   20/269 - Train Accuracy: 0.5945, Validation Accuracy: 0.6015, Loss: 0.7023
Epoch  14 Batch   30/269 - Train Accuracy: 0.6118, Validation Accuracy: 0.6096, Loss: 0.6689
Epoch  14 Batch   40/269 - Train Accuracy: 0.5914, Validation Accuracy: 0.6019, Loss: 0.7087
Epoch  14 Batch   50/269 - Train Accuracy: 0.5922, Validation Accuracy: 0.6020, Loss: 0.7060
Epoch  14 Batch   60/269 - Train Accuracy: 0.6143, Validation Accuracy: 0.6096, Loss: 0.6460
Epoch  14 Batch   70/269 - Train Accuracy: 0.6124, Validation Accuracy: 0.6052, Loss: 0.6763
Epoch  14 Batch   80/269 - Train Accuracy: 0.6057, Validation Accuracy: 0.6033, Loss: 0.6651
Epoch  14 Batch   90/269 - Train Accuracy: 0.5814, Validation Accuracy: 0.6012, Loss: 0.7063
Epoch  14 Batch  100/269 - Train Accuracy: 0.6200, Validation Accuracy: 0.6029, Loss: 0.6555
Epoch  14 Batch  110/269 - Train Accuracy: 0.5964, Validation Accuracy: 0.5994, Loss: 0.6617
Epoch  14 Batch  120/269 - Train Accuracy: 0.6000, Validation Accuracy: 0.6088, Loss: 0.6850
Epoch  14 Batch  130/269 - Train Accuracy: 0.5722, Validation Accuracy: 0.6087, Loss: 0.7023
Epoch  14 Batch  140/269 - Train Accuracy: 0.6070, Validation Accuracy: 0.6074, Loss: 0.6778
Epoch  14 Batch  150/269 - Train Accuracy: 0.6177, Validation Accuracy: 0.6110, Loss: 0.6715
Epoch  14 Batch  160/269 - Train Accuracy: 0.5968, Validation Accuracy: 0.6115, Loss: 0.6604
Epoch  14 Batch  170/269 - Train Accuracy: 0.6061, Validation Accuracy: 0.6089, Loss: 0.6572
Epoch  14 Batch  180/269 - Train Accuracy: 0.5969, Validation Accuracy: 0.6004, Loss: 0.6552
Epoch  14 Batch  190/269 - Train Accuracy: 0.6119, Validation Accuracy: 0.6060, Loss: 0.6423
Epoch  14 Batch  200/269 - Train Accuracy: 0.6093, Validation Accuracy: 0.6096, Loss: 0.6799
Epoch  14 Batch  210/269 - Train Accuracy: 0.6119, Validation Accuracy: 0.6011, Loss: 0.6477
Epoch  14 Batch  220/269 - Train Accuracy: 0.6201, Validation Accuracy: 0.6022, Loss: 0.6284
Epoch  14 Batch  230/269 - Train Accuracy: 0.6068, Validation Accuracy: 0.6025, Loss: 0.6587
Epoch  14 Batch  240/269 - Train Accuracy: 0.6382, Validation Accuracy: 0.6142, Loss: 0.6058
Epoch  14 Batch  250/269 - Train Accuracy: 0.5902, Validation Accuracy: 0.6049, Loss: 0.6798
Epoch  14 Batch  260/269 - Train Accuracy: 0.5748, Validation Accuracy: 0.6067, Loss: 0.6907
Epoch  15 Batch   10/269 - Train Accuracy: 0.5885, Validation Accuracy: 0.6169, Loss: 0.6773
Epoch  15 Batch   20/269 - Train Accuracy: 0.6080, Validation Accuracy: 0.6110, Loss: 0.6765
Epoch  15 Batch   30/269 - Train Accuracy: 0.6170, Validation Accuracy: 0.6049, Loss: 0.6487
Epoch  15 Batch   40/269 - Train Accuracy: 0.6106, Validation Accuracy: 0.6191, Loss: 0.6807
Epoch  15 Batch   50/269 - Train Accuracy: 0.6031, Validation Accuracy: 0.6099, Loss: 0.6783
Epoch  15 Batch   60/269 - Train Accuracy: 0.6218, Validation Accuracy: 0.6142, Loss: 0.6208
Epoch  15 Batch   70/269 - Train Accuracy: 0.6118, Validation Accuracy: 0.6057, Loss: 0.6559
Epoch  15 Batch   80/269 - Train Accuracy: 0.6084, Validation Accuracy: 0.6080, Loss: 0.6434
Epoch  15 Batch   90/269 - Train Accuracy: 0.5844, Validation Accuracy: 0.6121, Loss: 0.6818
Epoch  15 Batch  100/269 - Train Accuracy: 0.6228, Validation Accuracy: 0.6107, Loss: 0.6334
Epoch  15 Batch  110/269 - Train Accuracy: 0.6171, Validation Accuracy: 0.6175, Loss: 0.6365
Epoch  15 Batch  120/269 - Train Accuracy: 0.5975, Validation Accuracy: 0.6148, Loss: 0.6603
Epoch  15 Batch  130/269 - Train Accuracy: 0.5734, Validation Accuracy: 0.6117, Loss: 0.6729
Epoch  15 Batch  140/269 - Train Accuracy: 0.6139, Validation Accuracy: 0.6188, Loss: 0.6532
Epoch  15 Batch  150/269 - Train Accuracy: 0.6229, Validation Accuracy: 0.6096, Loss: 0.6429
Epoch  15 Batch  160/269 - Train Accuracy: 0.6122, Validation Accuracy: 0.6157, Loss: 0.6400
Epoch  15 Batch  170/269 - Train Accuracy: 0.6035, Validation Accuracy: 0.6071, Loss: 0.6342
Epoch  15 Batch  180/269 - Train Accuracy: 0.6059, Validation Accuracy: 0.6094, Loss: 0.6340
Epoch  15 Batch  190/269 - Train Accuracy: 0.6181, Validation Accuracy: 0.6136, Loss: 0.6227
Epoch  15 Batch  200/269 - Train Accuracy: 0.6064, Validation Accuracy: 0.6145, Loss: 0.6649
Epoch  15 Batch  210/269 - Train Accuracy: 0.6271, Validation Accuracy: 0.6153, Loss: 0.6266
Epoch  15 Batch  220/269 - Train Accuracy: 0.6285, Validation Accuracy: 0.6122, Loss: 0.6033
Epoch  15 Batch  230/269 - Train Accuracy: 0.6135, Validation Accuracy: 0.6080, Loss: 0.6368
Epoch  15 Batch  240/269 - Train Accuracy: 0.6412, Validation Accuracy: 0.6188, Loss: 0.5899
Epoch  15 Batch  250/269 - Train Accuracy: 0.5953, Validation Accuracy: 0.6082, Loss: 0.6535
Epoch  15 Batch  260/269 - Train Accuracy: 0.5835, Validation Accuracy: 0.6221, Loss: 0.6676
Epoch  16 Batch   10/269 - Train Accuracy: 0.6024, Validation Accuracy: 0.6210, Loss: 0.6524
Epoch  16 Batch   20/269 - Train Accuracy: 0.6068, Validation Accuracy: 0.6114, Loss: 0.6546
Epoch  16 Batch   30/269 - Train Accuracy: 0.6263, Validation Accuracy: 0.6200, Loss: 0.6258
Epoch  16 Batch   40/269 - Train Accuracy: 0.6086, Validation Accuracy: 0.6227, Loss: 0.6572
Epoch  16 Batch   50/269 - Train Accuracy: 0.6051, Validation Accuracy: 0.6142, Loss: 0.6531
Epoch  16 Batch   60/269 - Train Accuracy: 0.6217, Validation Accuracy: 0.6152, Loss: 0.6001
Epoch  16 Batch   70/269 - Train Accuracy: 0.6199, Validation Accuracy: 0.6152, Loss: 0.6305
Epoch  16 Batch   80/269 - Train Accuracy: 0.6174, Validation Accuracy: 0.6146, Loss: 0.6211
Epoch  16 Batch   90/269 - Train Accuracy: 0.5988, Validation Accuracy: 0.6202, Loss: 0.6556
Epoch  16 Batch  100/269 - Train Accuracy: 0.6288, Validation Accuracy: 0.6176, Loss: 0.6102
Epoch  16 Batch  110/269 - Train Accuracy: 0.6125, Validation Accuracy: 0.6177, Loss: 0.6127
Epoch  16 Batch  120/269 - Train Accuracy: 0.6075, Validation Accuracy: 0.6222, Loss: 0.6354
Epoch  16 Batch  130/269 - Train Accuracy: 0.5813, Validation Accuracy: 0.6201, Loss: 0.6473
Epoch  16 Batch  140/269 - Train Accuracy: 0.6166, Validation Accuracy: 0.6214, Loss: 0.6320
Epoch  16 Batch  150/269 - Train Accuracy: 0.6396, Validation Accuracy: 0.6219, Loss: 0.6189
Epoch  16 Batch  160/269 - Train Accuracy: 0.6198, Validation Accuracy: 0.6197, Loss: 0.6169
Epoch  16 Batch  170/269 - Train Accuracy: 0.6188, Validation Accuracy: 0.6207, Loss: 0.6090
Epoch  16 Batch  180/269 - Train Accuracy: 0.6209, Validation Accuracy: 0.6199, Loss: 0.6065
Epoch  16 Batch  190/269 - Train Accuracy: 0.6235, Validation Accuracy: 0.6264, Loss: 0.5986
Epoch  16 Batch  200/269 - Train Accuracy: 0.6093, Validation Accuracy: 0.6217, Loss: 0.6329
Epoch  16 Batch  210/269 - Train Accuracy: 0.6271, Validation Accuracy: 0.6230, Loss: 0.6026
Epoch  16 Batch  220/269 - Train Accuracy: 0.6409, Validation Accuracy: 0.6180, Loss: 0.5801
Epoch  16 Batch  230/269 - Train Accuracy: 0.6231, Validation Accuracy: 0.6213, Loss: 0.6187
Epoch  16 Batch  240/269 - Train Accuracy: 0.6588, Validation Accuracy: 0.6273, Loss: 0.5629
Epoch  16 Batch  250/269 - Train Accuracy: 0.6209, Validation Accuracy: 0.6227, Loss: 0.6186
Epoch  16 Batch  260/269 - Train Accuracy: 0.5934, Validation Accuracy: 0.6252, Loss: 0.6405
Epoch  17 Batch   10/269 - Train Accuracy: 0.6179, Validation Accuracy: 0.6298, Loss: 0.6293
Epoch  17 Batch   20/269 - Train Accuracy: 0.6211, Validation Accuracy: 0.6225, Loss: 0.6285
Epoch  17 Batch   30/269 - Train Accuracy: 0.6421, Validation Accuracy: 0.6299, Loss: 0.6061
Epoch  17 Batch   40/269 - Train Accuracy: 0.6139, Validation Accuracy: 0.6311, Loss: 0.6324
Epoch  17 Batch   50/269 - Train Accuracy: 0.6090, Validation Accuracy: 0.6196, Loss: 0.6260
Epoch  17 Batch   60/269 - Train Accuracy: 0.6341, Validation Accuracy: 0.6222, Loss: 0.5700
Epoch  17 Batch   70/269 - Train Accuracy: 0.6265, Validation Accuracy: 0.6294, Loss: 0.6004
Epoch  17 Batch   80/269 - Train Accuracy: 0.6293, Validation Accuracy: 0.6232, Loss: 0.5959
Epoch  17 Batch   90/269 - Train Accuracy: 0.5999, Validation Accuracy: 0.6276, Loss: 0.6294
Epoch  17 Batch  100/269 - Train Accuracy: 0.6390, Validation Accuracy: 0.6238, Loss: 0.5855
Epoch  17 Batch  110/269 - Train Accuracy: 0.6251, Validation Accuracy: 0.6309, Loss: 0.5913
Epoch  17 Batch  120/269 - Train Accuracy: 0.6218, Validation Accuracy: 0.6311, Loss: 0.6070
Epoch  17 Batch  130/269 - Train Accuracy: 0.5914, Validation Accuracy: 0.6273, Loss: 0.6219
Epoch  17 Batch  140/269 - Train Accuracy: 0.6315, Validation Accuracy: 0.6274, Loss: 0.5993
Epoch  17 Batch  150/269 - Train Accuracy: 0.6407, Validation Accuracy: 0.6230, Loss: 0.5896
Epoch  17 Batch  160/269 - Train Accuracy: 0.6326, Validation Accuracy: 0.6256, Loss: 0.5912
Epoch  17 Batch  170/269 - Train Accuracy: 0.6358, Validation Accuracy: 0.6406, Loss: 0.5825
Epoch  17 Batch  180/269 - Train Accuracy: 0.6277, Validation Accuracy: 0.6234, Loss: 0.5830
Epoch  17 Batch  190/269 - Train Accuracy: 0.6295, Validation Accuracy: 0.6441, Loss: 0.5709
Epoch  17 Batch  200/269 - Train Accuracy: 0.6275, Validation Accuracy: 0.6314, Loss: 0.6053
Epoch  17 Batch  210/269 - Train Accuracy: 0.6521, Validation Accuracy: 0.6365, Loss: 0.5808
Epoch  17 Batch  220/269 - Train Accuracy: 0.6595, Validation Accuracy: 0.6270, Loss: 0.5524
Epoch  17 Batch  230/269 - Train Accuracy: 0.6525, Validation Accuracy: 0.6362, Loss: 0.5847
Epoch  17 Batch  240/269 - Train Accuracy: 0.6596, Validation Accuracy: 0.6401, Loss: 0.5421
Epoch  17 Batch  250/269 - Train Accuracy: 0.6275, Validation Accuracy: 0.6364, Loss: 0.5943
Epoch  17 Batch  260/269 - Train Accuracy: 0.6117, Validation Accuracy: 0.6403, Loss: 0.6278
Epoch  18 Batch   10/269 - Train Accuracy: 0.6247, Validation Accuracy: 0.6333, Loss: 0.6008
Epoch  18 Batch   20/269 - Train Accuracy: 0.6435, Validation Accuracy: 0.6392, Loss: 0.6116
Epoch  18 Batch   30/269 - Train Accuracy: 0.6573, Validation Accuracy: 0.6472, Loss: 0.5723
Epoch  18 Batch   40/269 - Train Accuracy: 0.6415, Validation Accuracy: 0.6436, Loss: 0.6034
Epoch  18 Batch   50/269 - Train Accuracy: 0.6252, Validation Accuracy: 0.6367, Loss: 0.6016
Epoch  18 Batch   60/269 - Train Accuracy: 0.6491, Validation Accuracy: 0.6420, Loss: 0.5495
Epoch  18 Batch   70/269 - Train Accuracy: 0.6469, Validation Accuracy: 0.6406, Loss: 0.5801
Epoch  18 Batch   80/269 - Train Accuracy: 0.6378, Validation Accuracy: 0.6426, Loss: 0.5775
Epoch  18 Batch   90/269 - Train Accuracy: 0.6279, Validation Accuracy: 0.6445, Loss: 0.6024
Epoch  18 Batch  100/269 - Train Accuracy: 0.6562, Validation Accuracy: 0.6467, Loss: 0.5650
Epoch  18 Batch  110/269 - Train Accuracy: 0.6441, Validation Accuracy: 0.6433, Loss: 0.5713
Epoch  18 Batch  120/269 - Train Accuracy: 0.6274, Validation Accuracy: 0.6455, Loss: 0.5873
Epoch  18 Batch  130/269 - Train Accuracy: 0.6144, Validation Accuracy: 0.6490, Loss: 0.5965
Epoch  18 Batch  140/269 - Train Accuracy: 0.6431, Validation Accuracy: 0.6403, Loss: 0.5818
Epoch  18 Batch  150/269 - Train Accuracy: 0.6492, Validation Accuracy: 0.6462, Loss: 0.5709
Epoch  18 Batch  160/269 - Train Accuracy: 0.6509, Validation Accuracy: 0.6453, Loss: 0.5738
Epoch  18 Batch  170/269 - Train Accuracy: 0.6433, Validation Accuracy: 0.6541, Loss: 0.5633
Epoch  18 Batch  180/269 - Train Accuracy: 0.6440, Validation Accuracy: 0.6456, Loss: 0.5634
Epoch  18 Batch  190/269 - Train Accuracy: 0.6425, Validation Accuracy: 0.6466, Loss: 0.5523
Epoch  18 Batch  200/269 - Train Accuracy: 0.6429, Validation Accuracy: 0.6555, Loss: 0.5821
Epoch  18 Batch  210/269 - Train Accuracy: 0.6581, Validation Accuracy: 0.6505, Loss: 0.5596
Epoch  18 Batch  220/269 - Train Accuracy: 0.6626, Validation Accuracy: 0.6480, Loss: 0.5347
Epoch  18 Batch  230/269 - Train Accuracy: 0.6657, Validation Accuracy: 0.6551, Loss: 0.5672
Epoch  18 Batch  240/269 - Train Accuracy: 0.6744, Validation Accuracy: 0.6548, Loss: 0.5201
Epoch  18 Batch  250/269 - Train Accuracy: 0.6336, Validation Accuracy: 0.6480, Loss: 0.5839
Epoch  18 Batch  260/269 - Train Accuracy: 0.6312, Validation Accuracy: 0.6574, Loss: 0.5926
Epoch  19 Batch   10/269 - Train Accuracy: 0.6376, Validation Accuracy: 0.6619, Loss: 0.5822
Epoch  19 Batch   20/269 - Train Accuracy: 0.6531, Validation Accuracy: 0.6493, Loss: 0.5839
Epoch  19 Batch   30/269 - Train Accuracy: 0.6582, Validation Accuracy: 0.6530, Loss: 0.5590
Epoch  19 Batch   40/269 - Train Accuracy: 0.6505, Validation Accuracy: 0.6552, Loss: 0.5846
Epoch  19 Batch   50/269 - Train Accuracy: 0.6289, Validation Accuracy: 0.6430, Loss: 0.5896
Epoch  19 Batch   60/269 - Train Accuracy: 0.6644, Validation Accuracy: 0.6595, Loss: 0.5391
Epoch  19 Batch   70/269 - Train Accuracy: 0.6483, Validation Accuracy: 0.6504, Loss: 0.5627
Epoch  19 Batch   80/269 - Train Accuracy: 0.6462, Validation Accuracy: 0.6498, Loss: 0.5587
Epoch  19 Batch   90/269 - Train Accuracy: 0.6295, Validation Accuracy: 0.6628, Loss: 0.5828
Epoch  19 Batch  100/269 - Train Accuracy: 0.6647, Validation Accuracy: 0.6586, Loss: 0.5460
Epoch  19 Batch  110/269 - Train Accuracy: 0.6480, Validation Accuracy: 0.6607, Loss: 0.5575
Epoch  19 Batch  120/269 - Train Accuracy: 0.6394, Validation Accuracy: 0.6606, Loss: 0.5672
Epoch  19 Batch  130/269 - Train Accuracy: 0.6223, Validation Accuracy: 0.6612, Loss: 0.5809
Epoch  19 Batch  140/269 - Train Accuracy: 0.6553, Validation Accuracy: 0.6578, Loss: 0.5623
Epoch  19 Batch  150/269 - Train Accuracy: 0.6601, Validation Accuracy: 0.6583, Loss: 0.5530
Epoch  19 Batch  160/269 - Train Accuracy: 0.6634, Validation Accuracy: 0.6613, Loss: 0.5513
Epoch  19 Batch  170/269 - Train Accuracy: 0.6485, Validation Accuracy: 0.6598, Loss: 0.5456
Epoch  19 Batch  180/269 - Train Accuracy: 0.6493, Validation Accuracy: 0.6585, Loss: 0.5469
Epoch  19 Batch  190/269 - Train Accuracy: 0.6453, Validation Accuracy: 0.6640, Loss: 0.5396
Epoch  19 Batch  200/269 - Train Accuracy: 0.6447, Validation Accuracy: 0.6625, Loss: 0.5621
Epoch  19 Batch  210/269 - Train Accuracy: 0.6613, Validation Accuracy: 0.6633, Loss: 0.5384
Epoch  19 Batch  220/269 - Train Accuracy: 0.6673, Validation Accuracy: 0.6567, Loss: 0.5146
Epoch  19 Batch  230/269 - Train Accuracy: 0.6627, Validation Accuracy: 0.6646, Loss: 0.5438
Epoch  19 Batch  240/269 - Train Accuracy: 0.6786, Validation Accuracy: 0.6686, Loss: 0.5003
Epoch  19 Batch  250/269 - Train Accuracy: 0.6478, Validation Accuracy: 0.6503, Loss: 0.5612
Epoch  19 Batch  260/269 - Train Accuracy: 0.6396, Validation Accuracy: 0.6689, Loss: 0.5758
Epoch  20 Batch   10/269 - Train Accuracy: 0.6495, Validation Accuracy: 0.6629, Loss: 0.5668
Epoch  20 Batch   20/269 - Train Accuracy: 0.6550, Validation Accuracy: 0.6674, Loss: 0.5683
Epoch  20 Batch   30/269 - Train Accuracy: 0.6624, Validation Accuracy: 0.6685, Loss: 0.5393
Epoch  20 Batch   40/269 - Train Accuracy: 0.6493, Validation Accuracy: 0.6696, Loss: 0.5797
Epoch  20 Batch   50/269 - Train Accuracy: 0.6436, Validation Accuracy: 0.6696, Loss: 0.5676
Epoch  20 Batch   60/269 - Train Accuracy: 0.6633, Validation Accuracy: 0.6668, Loss: 0.5160
Epoch  20 Batch   70/269 - Train Accuracy: 0.6644, Validation Accuracy: 0.6687, Loss: 0.5472
Epoch  20 Batch   80/269 - Train Accuracy: 0.6521, Validation Accuracy: 0.6680, Loss: 0.5396
Epoch  20 Batch   90/269 - Train Accuracy: 0.6393, Validation Accuracy: 0.6745, Loss: 0.5692
Epoch  20 Batch  100/269 - Train Accuracy: 0.6692, Validation Accuracy: 0.6649, Loss: 0.5361
Epoch  20 Batch  110/269 - Train Accuracy: 0.6563, Validation Accuracy: 0.6677, Loss: 0.5376
Epoch  20 Batch  120/269 - Train Accuracy: 0.6475, Validation Accuracy: 0.6677, Loss: 0.5536
Epoch  20 Batch  130/269 - Train Accuracy: 0.6291, Validation Accuracy: 0.6639, Loss: 0.5618
Epoch  20 Batch  140/269 - Train Accuracy: 0.6530, Validation Accuracy: 0.6582, Loss: 0.5447
Epoch  20 Batch  150/269 - Train Accuracy: 0.6625, Validation Accuracy: 0.6697, Loss: 0.5418
Epoch  20 Batch  160/269 - Train Accuracy: 0.6603, Validation Accuracy: 0.6638, Loss: 0.5382
Epoch  20 Batch  170/269 - Train Accuracy: 0.6557, Validation Accuracy: 0.6622, Loss: 0.5335
Epoch  20 Batch  180/269 - Train Accuracy: 0.6488, Validation Accuracy: 0.6688, Loss: 0.5308
Epoch  20 Batch  190/269 - Train Accuracy: 0.6514, Validation Accuracy: 0.6661, Loss: 0.5209
Epoch  20 Batch  200/269 - Train Accuracy: 0.6548, Validation Accuracy: 0.6683, Loss: 0.5487
Epoch  20 Batch  210/269 - Train Accuracy: 0.6615, Validation Accuracy: 0.6656, Loss: 0.5265
Epoch  20 Batch  220/269 - Train Accuracy: 0.6726, Validation Accuracy: 0.6754, Loss: 0.5089
Epoch  20 Batch  230/269 - Train Accuracy: 0.6765, Validation Accuracy: 0.6702, Loss: 0.5304
Epoch  20 Batch  240/269 - Train Accuracy: 0.6915, Validation Accuracy: 0.6761, Loss: 0.4895
Epoch  20 Batch  250/269 - Train Accuracy: 0.6686, Validation Accuracy: 0.6813, Loss: 0.5452
Epoch  20 Batch  260/269 - Train Accuracy: 0.6423, Validation Accuracy: 0.6722, Loss: 0.5584
Epoch  21 Batch   10/269 - Train Accuracy: 0.6504, Validation Accuracy: 0.6722, Loss: 0.5538
Epoch  21 Batch   20/269 - Train Accuracy: 0.6622, Validation Accuracy: 0.6725, Loss: 0.5538
Epoch  21 Batch   30/269 - Train Accuracy: 0.6656, Validation Accuracy: 0.6694, Loss: 0.5233
Epoch  21 Batch   40/269 - Train Accuracy: 0.6678, Validation Accuracy: 0.6764, Loss: 0.5540
Epoch  21 Batch   50/269 - Train Accuracy: 0.6523, Validation Accuracy: 0.6733, Loss: 0.5539
Epoch  21 Batch   60/269 - Train Accuracy: 0.6690, Validation Accuracy: 0.6757, Loss: 0.5039
Epoch  21 Batch   70/269 - Train Accuracy: 0.6836, Validation Accuracy: 0.6820, Loss: 0.5314
Epoch  21 Batch   80/269 - Train Accuracy: 0.6545, Validation Accuracy: 0.6732, Loss: 0.5347
Epoch  21 Batch   90/269 - Train Accuracy: 0.6622, Validation Accuracy: 0.6777, Loss: 0.5569
Epoch  21 Batch  100/269 - Train Accuracy: 0.6806, Validation Accuracy: 0.6831, Loss: 0.5184
Epoch  21 Batch  110/269 - Train Accuracy: 0.6702, Validation Accuracy: 0.6802, Loss: 0.5267
Epoch  21 Batch  120/269 - Train Accuracy: 0.6586, Validation Accuracy: 0.6820, Loss: 0.5374
Epoch  21 Batch  130/269 - Train Accuracy: 0.6502, Validation Accuracy: 0.6875, Loss: 0.5534
Epoch  21 Batch  140/269 - Train Accuracy: 0.6783, Validation Accuracy: 0.6828, Loss: 0.5377
Epoch  21 Batch  150/269 - Train Accuracy: 0.6791, Validation Accuracy: 0.6870, Loss: 0.5199
Epoch  21 Batch  160/269 - Train Accuracy: 0.6817, Validation Accuracy: 0.6831, Loss: 0.5218
Epoch  21 Batch  170/269 - Train Accuracy: 0.6797, Validation Accuracy: 0.6894, Loss: 0.5128
Epoch  21 Batch  180/269 - Train Accuracy: 0.6737, Validation Accuracy: 0.6827, Loss: 0.5173
Epoch  21 Batch  190/269 - Train Accuracy: 0.6692, Validation Accuracy: 0.6845, Loss: 0.5072
Epoch  21 Batch  200/269 - Train Accuracy: 0.6755, Validation Accuracy: 0.6849, Loss: 0.5315
Epoch  21 Batch  210/269 - Train Accuracy: 0.6889, Validation Accuracy: 0.6896, Loss: 0.5158
Epoch  21 Batch  220/269 - Train Accuracy: 0.6901, Validation Accuracy: 0.6891, Loss: 0.4911
Epoch  21 Batch  230/269 - Train Accuracy: 0.6970, Validation Accuracy: 0.6853, Loss: 0.5167
Epoch  21 Batch  240/269 - Train Accuracy: 0.7063, Validation Accuracy: 0.6903, Loss: 0.4765
Epoch  21 Batch  250/269 - Train Accuracy: 0.6812, Validation Accuracy: 0.6926, Loss: 0.5265
Epoch  21 Batch  260/269 - Train Accuracy: 0.6677, Validation Accuracy: 0.6895, Loss: 0.5426
Epoch  22 Batch   10/269 - Train Accuracy: 0.6692, Validation Accuracy: 0.6929, Loss: 0.5354
Epoch  22 Batch   20/269 - Train Accuracy: 0.6796, Validation Accuracy: 0.6900, Loss: 0.5335
Epoch  22 Batch   30/269 - Train Accuracy: 0.6908, Validation Accuracy: 0.6923, Loss: 0.5112
Epoch  22 Batch   40/269 - Train Accuracy: 0.6799, Validation Accuracy: 0.6925, Loss: 0.5421
Epoch  22 Batch   50/269 - Train Accuracy: 0.6635, Validation Accuracy: 0.6868, Loss: 0.5389
Epoch  22 Batch   60/269 - Train Accuracy: 0.6862, Validation Accuracy: 0.6959, Loss: 0.4895
Epoch  22 Batch   70/269 - Train Accuracy: 0.7068, Validation Accuracy: 0.6938, Loss: 0.5138
Epoch  22 Batch   80/269 - Train Accuracy: 0.6853, Validation Accuracy: 0.6920, Loss: 0.5160
Epoch  22 Batch   90/269 - Train Accuracy: 0.6725, Validation Accuracy: 0.6968, Loss: 0.5416
Epoch  22 Batch  100/269 - Train Accuracy: 0.7058, Validation Accuracy: 0.6962, Loss: 0.5022
Epoch  22 Batch  110/269 - Train Accuracy: 0.6841, Validation Accuracy: 0.6957, Loss: 0.5061
Epoch  22 Batch  120/269 - Train Accuracy: 0.6743, Validation Accuracy: 0.6937, Loss: 0.5198
Epoch  22 Batch  130/269 - Train Accuracy: 0.6606, Validation Accuracy: 0.6956, Loss: 0.5352
Epoch  22 Batch  140/269 - Train Accuracy: 0.6939, Validation Accuracy: 0.7006, Loss: 0.5183
Epoch  22 Batch  150/269 - Train Accuracy: 0.6858, Validation Accuracy: 0.6988, Loss: 0.5091
Epoch  22 Batch  160/269 - Train Accuracy: 0.6930, Validation Accuracy: 0.7027, Loss: 0.5070
Epoch  22 Batch  170/269 - Train Accuracy: 0.6846, Validation Accuracy: 0.6979, Loss: 0.5033
Epoch  22 Batch  180/269 - Train Accuracy: 0.6862, Validation Accuracy: 0.6992, Loss: 0.5042
Epoch  22 Batch  190/269 - Train Accuracy: 0.6881, Validation Accuracy: 0.7033, Loss: 0.4935
Epoch  22 Batch  200/269 - Train Accuracy: 0.6853, Validation Accuracy: 0.7020, Loss: 0.5245
Epoch  22 Batch  210/269 - Train Accuracy: 0.6945, Validation Accuracy: 0.6971, Loss: 0.5003
Epoch  22 Batch  220/269 - Train Accuracy: 0.6914, Validation Accuracy: 0.7006, Loss: 0.4773
Epoch  22 Batch  230/269 - Train Accuracy: 0.7105, Validation Accuracy: 0.7080, Loss: 0.5097
Epoch  22 Batch  240/269 - Train Accuracy: 0.7267, Validation Accuracy: 0.7069, Loss: 0.4648
Epoch  22 Batch  250/269 - Train Accuracy: 0.6864, Validation Accuracy: 0.6958, Loss: 0.5116
Epoch  22 Batch  260/269 - Train Accuracy: 0.6780, Validation Accuracy: 0.7037, Loss: 0.5303
Epoch  23 Batch   10/269 - Train Accuracy: 0.6890, Validation Accuracy: 0.7061, Loss: 0.5221
Epoch  23 Batch   20/269 - Train Accuracy: 0.6884, Validation Accuracy: 0.7010, Loss: 0.5225
Epoch  23 Batch   30/269 - Train Accuracy: 0.6981, Validation Accuracy: 0.7062, Loss: 0.5013
Epoch  23 Batch   40/269 - Train Accuracy: 0.6949, Validation Accuracy: 0.7087, Loss: 0.5258
Epoch  23 Batch   50/269 - Train Accuracy: 0.6769, Validation Accuracy: 0.7037, Loss: 0.5277
Epoch  23 Batch   60/269 - Train Accuracy: 0.7026, Validation Accuracy: 0.7090, Loss: 0.4768
Epoch  23 Batch   70/269 - Train Accuracy: 0.7146, Validation Accuracy: 0.7023, Loss: 0.5047
Epoch  23 Batch   80/269 - Train Accuracy: 0.6959, Validation Accuracy: 0.7045, Loss: 0.4975
Epoch  23 Batch   90/269 - Train Accuracy: 0.6761, Validation Accuracy: 0.6982, Loss: 0.5255
Epoch  23 Batch  100/269 - Train Accuracy: 0.7042, Validation Accuracy: 0.7047, Loss: 0.4916
Epoch  23 Batch  110/269 - Train Accuracy: 0.6978, Validation Accuracy: 0.7087, Loss: 0.4983
Epoch  23 Batch  120/269 - Train Accuracy: 0.6883, Validation Accuracy: 0.7108, Loss: 0.5111
Epoch  23 Batch  130/269 - Train Accuracy: 0.6678, Validation Accuracy: 0.7025, Loss: 0.5281
Epoch  23 Batch  140/269 - Train Accuracy: 0.6997, Validation Accuracy: 0.7076, Loss: 0.5077
Epoch  23 Batch  150/269 - Train Accuracy: 0.6919, Validation Accuracy: 0.7072, Loss: 0.4922
Epoch  23 Batch  160/269 - Train Accuracy: 0.6977, Validation Accuracy: 0.7062, Loss: 0.4928
Epoch  23 Batch  170/269 - Train Accuracy: 0.6949, Validation Accuracy: 0.7116, Loss: 0.4915
Epoch  23 Batch  180/269 - Train Accuracy: 0.6924, Validation Accuracy: 0.7058, Loss: 0.4844
Epoch  23 Batch  190/269 - Train Accuracy: 0.6969, Validation Accuracy: 0.7096, Loss: 0.4837
Epoch  23 Batch  200/269 - Train Accuracy: 0.6855, Validation Accuracy: 0.7042, Loss: 0.5094
Epoch  23 Batch  210/269 - Train Accuracy: 0.7051, Validation Accuracy: 0.7068, Loss: 0.4893
Epoch  23 Batch  220/269 - Train Accuracy: 0.7010, Validation Accuracy: 0.7091, Loss: 0.4647
Epoch  23 Batch  230/269 - Train Accuracy: 0.7106, Validation Accuracy: 0.7101, Loss: 0.4909
Epoch  23 Batch  240/269 - Train Accuracy: 0.7345, Validation Accuracy: 0.7133, Loss: 0.4496
Epoch  23 Batch  250/269 - Train Accuracy: 0.6955, Validation Accuracy: 0.7043, Loss: 0.4990
Epoch  23 Batch  260/269 - Train Accuracy: 0.6800, Validation Accuracy: 0.7033, Loss: 0.5262
Epoch  24 Batch   10/269 - Train Accuracy: 0.6914, Validation Accuracy: 0.7108, Loss: 0.5135
Epoch  24 Batch   20/269 - Train Accuracy: 0.6940, Validation Accuracy: 0.7076, Loss: 0.5101
Epoch  24 Batch   30/269 - Train Accuracy: 0.7003, Validation Accuracy: 0.7075, Loss: 0.4890
Epoch  24 Batch   40/269 - Train Accuracy: 0.6979, Validation Accuracy: 0.7172, Loss: 0.5140
Epoch  24 Batch   50/269 - Train Accuracy: 0.6878, Validation Accuracy: 0.7096, Loss: 0.5133
Epoch  24 Batch   60/269 - Train Accuracy: 0.7057, Validation Accuracy: 0.7121, Loss: 0.4647
Epoch  24 Batch   70/269 - Train Accuracy: 0.7188, Validation Accuracy: 0.7179, Loss: 0.4899
Epoch  24 Batch   80/269 - Train Accuracy: 0.7008, Validation Accuracy: 0.7068, Loss: 0.4879
Epoch  24 Batch   90/269 - Train Accuracy: 0.6901, Validation Accuracy: 0.7133, Loss: 0.5103
Epoch  24 Batch  100/269 - Train Accuracy: 0.7127, Validation Accuracy: 0.7170, Loss: 0.4813
Epoch  24 Batch  110/269 - Train Accuracy: 0.7024, Validation Accuracy: 0.7097, Loss: 0.4827
Epoch  24 Batch  120/269 - Train Accuracy: 0.6967, Validation Accuracy: 0.7149, Loss: 0.4953
Epoch  24 Batch  130/269 - Train Accuracy: 0.6873, Validation Accuracy: 0.7178, Loss: 0.5044
Epoch  24 Batch  140/269 - Train Accuracy: 0.7020, Validation Accuracy: 0.7118, Loss: 0.5025
Epoch  24 Batch  150/269 - Train Accuracy: 0.6965, Validation Accuracy: 0.7142, Loss: 0.4843
Epoch  24 Batch  160/269 - Train Accuracy: 0.7028, Validation Accuracy: 0.7134, Loss: 0.4860
Epoch  24 Batch  170/269 - Train Accuracy: 0.7018, Validation Accuracy: 0.7150, Loss: 0.4763
Epoch  24 Batch  180/269 - Train Accuracy: 0.7072, Validation Accuracy: 0.7117, Loss: 0.4741
Epoch  24 Batch  190/269 - Train Accuracy: 0.7054, Validation Accuracy: 0.7140, Loss: 0.4652
Epoch  24 Batch  200/269 - Train Accuracy: 0.6926, Validation Accuracy: 0.7128, Loss: 0.4955
Epoch  24 Batch  210/269 - Train Accuracy: 0.7066, Validation Accuracy: 0.7111, Loss: 0.4763
Epoch  24 Batch  220/269 - Train Accuracy: 0.7095, Validation Accuracy: 0.7115, Loss: 0.4554
Epoch  24 Batch  230/269 - Train Accuracy: 0.7164, Validation Accuracy: 0.7156, Loss: 0.4774
Epoch  24 Batch  240/269 - Train Accuracy: 0.7417, Validation Accuracy: 0.7170, Loss: 0.4351
Epoch  24 Batch  250/269 - Train Accuracy: 0.6989, Validation Accuracy: 0.7117, Loss: 0.4904
Epoch  24 Batch  260/269 - Train Accuracy: 0.6841, Validation Accuracy: 0.7117, Loss: 0.5020
Epoch  25 Batch   10/269 - Train Accuracy: 0.7014, Validation Accuracy: 0.7150, Loss: 0.4916
Epoch  25 Batch   20/269 - Train Accuracy: 0.7021, Validation Accuracy: 0.7132, Loss: 0.4948
Epoch  25 Batch   30/269 - Train Accuracy: 0.7118, Validation Accuracy: 0.7143, Loss: 0.4787
Epoch  25 Batch   40/269 - Train Accuracy: 0.7047, Validation Accuracy: 0.7111, Loss: 0.5033
Epoch  25 Batch   50/269 - Train Accuracy: 0.6926, Validation Accuracy: 0.7183, Loss: 0.5025
Epoch  25 Batch   60/269 - Train Accuracy: 0.7140, Validation Accuracy: 0.7186, Loss: 0.4531
Epoch  25 Batch   70/269 - Train Accuracy: 0.7216, Validation Accuracy: 0.7193, Loss: 0.4761
Epoch  25 Batch   80/269 - Train Accuracy: 0.7077, Validation Accuracy: 0.7123, Loss: 0.4730
Epoch  25 Batch   90/269 - Train Accuracy: 0.6879, Validation Accuracy: 0.7129, Loss: 0.4986
Epoch  25 Batch  100/269 - Train Accuracy: 0.7190, Validation Accuracy: 0.7195, Loss: 0.4652
Epoch  25 Batch  110/269 - Train Accuracy: 0.7044, Validation Accuracy: 0.7191, Loss: 0.4779
Epoch  25 Batch  120/269 - Train Accuracy: 0.7049, Validation Accuracy: 0.7179, Loss: 0.4840
Epoch  25 Batch  130/269 - Train Accuracy: 0.6950, Validation Accuracy: 0.7198, Loss: 0.4916
Epoch  25 Batch  140/269 - Train Accuracy: 0.7099, Validation Accuracy: 0.7157, Loss: 0.4858
Epoch  25 Batch  150/269 - Train Accuracy: 0.7031, Validation Accuracy: 0.7185, Loss: 0.4789
Epoch  25 Batch  160/269 - Train Accuracy: 0.7097, Validation Accuracy: 0.7184, Loss: 0.4704
Epoch  25 Batch  170/269 - Train Accuracy: 0.7046, Validation Accuracy: 0.7203, Loss: 0.4651
Epoch  25 Batch  180/269 - Train Accuracy: 0.7077, Validation Accuracy: 0.7165, Loss: 0.4664
Epoch  25 Batch  190/269 - Train Accuracy: 0.7015, Validation Accuracy: 0.7173, Loss: 0.4608
Epoch  25 Batch  200/269 - Train Accuracy: 0.6948, Validation Accuracy: 0.7164, Loss: 0.4851
Epoch  25 Batch  210/269 - Train Accuracy: 0.7138, Validation Accuracy: 0.7206, Loss: 0.4636
Epoch  25 Batch  220/269 - Train Accuracy: 0.7124, Validation Accuracy: 0.7179, Loss: 0.4434
Epoch  25 Batch  230/269 - Train Accuracy: 0.7165, Validation Accuracy: 0.7207, Loss: 0.4654
Epoch  25 Batch  240/269 - Train Accuracy: 0.7412, Validation Accuracy: 0.7149, Loss: 0.4283
Epoch  25 Batch  250/269 - Train Accuracy: 0.7074, Validation Accuracy: 0.7105, Loss: 0.4769
Epoch  25 Batch  260/269 - Train Accuracy: 0.6845, Validation Accuracy: 0.7168, Loss: 0.4927
Epoch  26 Batch   10/269 - Train Accuracy: 0.7061, Validation Accuracy: 0.7188, Loss: 0.4831
Epoch  26 Batch   20/269 - Train Accuracy: 0.7107, Validation Accuracy: 0.7165, Loss: 0.4832
Epoch  26 Batch   30/269 - Train Accuracy: 0.7145, Validation Accuracy: 0.7163, Loss: 0.4663
Epoch  26 Batch   40/269 - Train Accuracy: 0.7104, Validation Accuracy: 0.7203, Loss: 0.4905
Epoch  26 Batch   50/269 - Train Accuracy: 0.6900, Validation Accuracy: 0.7211, Loss: 0.4921
Epoch  26 Batch   60/269 - Train Accuracy: 0.7139, Validation Accuracy: 0.7143, Loss: 0.4427
Epoch  26 Batch   70/269 - Train Accuracy: 0.7252, Validation Accuracy: 0.7251, Loss: 0.4624
Epoch  26 Batch   80/269 - Train Accuracy: 0.7179, Validation Accuracy: 0.7194, Loss: 0.4655
Epoch  26 Batch   90/269 - Train Accuracy: 0.6913, Validation Accuracy: 0.7197, Loss: 0.4858
Epoch  26 Batch  100/269 - Train Accuracy: 0.7223, Validation Accuracy: 0.7224, Loss: 0.4550
Epoch  26 Batch  110/269 - Train Accuracy: 0.7143, Validation Accuracy: 0.7206, Loss: 0.4633
Epoch  26 Batch  120/269 - Train Accuracy: 0.7045, Validation Accuracy: 0.7247, Loss: 0.4720
Epoch  26 Batch  130/269 - Train Accuracy: 0.6953, Validation Accuracy: 0.7191, Loss: 0.4806
Epoch  26 Batch  140/269 - Train Accuracy: 0.7129, Validation Accuracy: 0.7220, Loss: 0.4755
Epoch  26 Batch  150/269 - Train Accuracy: 0.7030, Validation Accuracy: 0.7162, Loss: 0.4608
Epoch  26 Batch  160/269 - Train Accuracy: 0.7121, Validation Accuracy: 0.7200, Loss: 0.4586
Epoch  26 Batch  170/269 - Train Accuracy: 0.7010, Validation Accuracy: 0.7183, Loss: 0.4500
Epoch  26 Batch  180/269 - Train Accuracy: 0.7136, Validation Accuracy: 0.7225, Loss: 0.4540
Epoch  26 Batch  190/269 - Train Accuracy: 0.7040, Validation Accuracy: 0.7187, Loss: 0.4465
Epoch  26 Batch  200/269 - Train Accuracy: 0.7013, Validation Accuracy: 0.7150, Loss: 0.4695
Epoch  26 Batch  210/269 - Train Accuracy: 0.7136, Validation Accuracy: 0.7201, Loss: 0.4485
Epoch  26 Batch  220/269 - Train Accuracy: 0.7133, Validation Accuracy: 0.7229, Loss: 0.4365
Epoch  26 Batch  230/269 - Train Accuracy: 0.7214, Validation Accuracy: 0.7201, Loss: 0.4531
Epoch  26 Batch  240/269 - Train Accuracy: 0.7384, Validation Accuracy: 0.7227, Loss: 0.4181
Epoch  26 Batch  250/269 - Train Accuracy: 0.7089, Validation Accuracy: 0.7124, Loss: 0.4608
Epoch  26 Batch  260/269 - Train Accuracy: 0.6853, Validation Accuracy: 0.7188, Loss: 0.4824
Epoch  27 Batch   10/269 - Train Accuracy: 0.7109, Validation Accuracy: 0.7208, Loss: 0.4703
Epoch  27 Batch   20/269 - Train Accuracy: 0.7169, Validation Accuracy: 0.7264, Loss: 0.4735
Epoch  27 Batch   30/269 - Train Accuracy: 0.7139, Validation Accuracy: 0.7207, Loss: 0.4496
Epoch  27 Batch   40/269 - Train Accuracy: 0.7054, Validation Accuracy: 0.7201, Loss: 0.4778
Epoch  27 Batch   50/269 - Train Accuracy: 0.7018, Validation Accuracy: 0.7197, Loss: 0.4784
Epoch  27 Batch   60/269 - Train Accuracy: 0.7202, Validation Accuracy: 0.7238, Loss: 0.4292
Epoch  27 Batch   70/269 - Train Accuracy: 0.7283, Validation Accuracy: 0.7246, Loss: 0.4546
Epoch  27 Batch   80/269 - Train Accuracy: 0.7199, Validation Accuracy: 0.7266, Loss: 0.4517
Epoch  27 Batch   90/269 - Train Accuracy: 0.6937, Validation Accuracy: 0.7235, Loss: 0.4717
Epoch  27 Batch  100/269 - Train Accuracy: 0.7205, Validation Accuracy: 0.7233, Loss: 0.4459
Epoch  27 Batch  110/269 - Train Accuracy: 0.7087, Validation Accuracy: 0.7230, Loss: 0.4489
Epoch  27 Batch  120/269 - Train Accuracy: 0.7010, Validation Accuracy: 0.7257, Loss: 0.4600
Epoch  27 Batch  130/269 - Train Accuracy: 0.6988, Validation Accuracy: 0.7224, Loss: 0.4687
Epoch  27 Batch  140/269 - Train Accuracy: 0.7194, Validation Accuracy: 0.7286, Loss: 0.4639
Epoch  27 Batch  150/269 - Train Accuracy: 0.7099, Validation Accuracy: 0.7211, Loss: 0.4478
Epoch  27 Batch  160/269 - Train Accuracy: 0.7149, Validation Accuracy: 0.7238, Loss: 0.4523
Epoch  27 Batch  170/269 - Train Accuracy: 0.7040, Validation Accuracy: 0.7161, Loss: 0.4435
Epoch  27 Batch  180/269 - Train Accuracy: 0.7174, Validation Accuracy: 0.7235, Loss: 0.4396
Epoch  27 Batch  190/269 - Train Accuracy: 0.7075, Validation Accuracy: 0.7177, Loss: 0.4376
Epoch  27 Batch  200/269 - Train Accuracy: 0.7039, Validation Accuracy: 0.7232, Loss: 0.4568
Epoch  27 Batch  210/269 - Train Accuracy: 0.7188, Validation Accuracy: 0.7169, Loss: 0.4402
Epoch  27 Batch  220/269 - Train Accuracy: 0.7177, Validation Accuracy: 0.7243, Loss: 0.4201
Epoch  27 Batch  230/269 - Train Accuracy: 0.7196, Validation Accuracy: 0.7208, Loss: 0.4449
Epoch  27 Batch  240/269 - Train Accuracy: 0.7409, Validation Accuracy: 0.7245, Loss: 0.4096
Epoch  27 Batch  250/269 - Train Accuracy: 0.7191, Validation Accuracy: 0.7228, Loss: 0.4501
Epoch  27 Batch  260/269 - Train Accuracy: 0.6931, Validation Accuracy: 0.7205, Loss: 0.4728
Epoch  28 Batch   10/269 - Train Accuracy: 0.7079, Validation Accuracy: 0.7235, Loss: 0.4610
Epoch  28 Batch   20/269 - Train Accuracy: 0.7188, Validation Accuracy: 0.7266, Loss: 0.4648
Epoch  28 Batch   30/269 - Train Accuracy: 0.7165, Validation Accuracy: 0.7243, Loss: 0.4384
Epoch  28 Batch   40/269 - Train Accuracy: 0.7111, Validation Accuracy: 0.7261, Loss: 0.4693
Epoch  28 Batch   50/269 - Train Accuracy: 0.6992, Validation Accuracy: 0.7273, Loss: 0.4707
Epoch  28 Batch   60/269 - Train Accuracy: 0.7281, Validation Accuracy: 0.7281, Loss: 0.4231
Epoch  28 Batch   70/269 - Train Accuracy: 0.7295, Validation Accuracy: 0.7255, Loss: 0.4437
Epoch  28 Batch   80/269 - Train Accuracy: 0.7248, Validation Accuracy: 0.7226, Loss: 0.4423
Epoch  28 Batch   90/269 - Train Accuracy: 0.6988, Validation Accuracy: 0.7249, Loss: 0.4681
Epoch  28 Batch  100/269 - Train Accuracy: 0.7286, Validation Accuracy: 0.7271, Loss: 0.4339
Epoch  28 Batch  110/269 - Train Accuracy: 0.7119, Validation Accuracy: 0.7211, Loss: 0.4407
Epoch  28 Batch  120/269 - Train Accuracy: 0.7048, Validation Accuracy: 0.7239, Loss: 0.4545
Epoch  28 Batch  130/269 - Train Accuracy: 0.7022, Validation Accuracy: 0.7264, Loss: 0.4623
Epoch  28 Batch  140/269 - Train Accuracy: 0.7161, Validation Accuracy: 0.7231, Loss: 0.4616
Epoch  28 Batch  150/269 - Train Accuracy: 0.7093, Validation Accuracy: 0.7250, Loss: 0.4431
Epoch  28 Batch  160/269 - Train Accuracy: 0.7202, Validation Accuracy: 0.7246, Loss: 0.4407
Epoch  28 Batch  170/269 - Train Accuracy: 0.7058, Validation Accuracy: 0.7268, Loss: 0.4334
Epoch  28 Batch  180/269 - Train Accuracy: 0.7230, Validation Accuracy: 0.7249, Loss: 0.4321
Epoch  28 Batch  190/269 - Train Accuracy: 0.7129, Validation Accuracy: 0.7275, Loss: 0.4273
Epoch  28 Batch  200/269 - Train Accuracy: 0.7122, Validation Accuracy: 0.7242, Loss: 0.4490
Epoch  28 Batch  210/269 - Train Accuracy: 0.7202, Validation Accuracy: 0.7229, Loss: 0.4340
Epoch  28 Batch  220/269 - Train Accuracy: 0.7218, Validation Accuracy: 0.7302, Loss: 0.4099
Epoch  28 Batch  230/269 - Train Accuracy: 0.7248, Validation Accuracy: 0.7297, Loss: 0.4318
Epoch  28 Batch  240/269 - Train Accuracy: 0.7426, Validation Accuracy: 0.7245, Loss: 0.4006
Epoch  28 Batch  250/269 - Train Accuracy: 0.7207, Validation Accuracy: 0.7232, Loss: 0.4389
Epoch  28 Batch  260/269 - Train Accuracy: 0.6928, Validation Accuracy: 0.7280, Loss: 0.4622
Epoch  29 Batch   10/269 - Train Accuracy: 0.7147, Validation Accuracy: 0.7290, Loss: 0.4519
Epoch  29 Batch   20/269 - Train Accuracy: 0.7257, Validation Accuracy: 0.7292, Loss: 0.4534
Epoch  29 Batch   30/269 - Train Accuracy: 0.7236, Validation Accuracy: 0.7275, Loss: 0.4293
Epoch  29 Batch   40/269 - Train Accuracy: 0.7076, Validation Accuracy: 0.7275, Loss: 0.4607
Epoch  29 Batch   50/269 - Train Accuracy: 0.7013, Validation Accuracy: 0.7275, Loss: 0.4567
Epoch  29 Batch   60/269 - Train Accuracy: 0.7280, Validation Accuracy: 0.7314, Loss: 0.4128
Epoch  29 Batch   70/269 - Train Accuracy: 0.7340, Validation Accuracy: 0.7321, Loss: 0.4331
Epoch  29 Batch   80/269 - Train Accuracy: 0.7274, Validation Accuracy: 0.7266, Loss: 0.4352
Epoch  29 Batch   90/269 - Train Accuracy: 0.7021, Validation Accuracy: 0.7343, Loss: 0.4538
Epoch  29 Batch  100/269 - Train Accuracy: 0.7258, Validation Accuracy: 0.7286, Loss: 0.4225
Epoch  29 Batch  110/269 - Train Accuracy: 0.7197, Validation Accuracy: 0.7307, Loss: 0.4339
Epoch  29 Batch  120/269 - Train Accuracy: 0.7061, Validation Accuracy: 0.7321, Loss: 0.4426
Epoch  29 Batch  130/269 - Train Accuracy: 0.7133, Validation Accuracy: 0.7305, Loss: 0.4477
Epoch  29 Batch  140/269 - Train Accuracy: 0.7214, Validation Accuracy: 0.7268, Loss: 0.4441
Epoch  29 Batch  150/269 - Train Accuracy: 0.7155, Validation Accuracy: 0.7290, Loss: 0.4312
Epoch  29 Batch  160/269 - Train Accuracy: 0.7219, Validation Accuracy: 0.7301, Loss: 0.4313
Epoch  29 Batch  170/269 - Train Accuracy: 0.7068, Validation Accuracy: 0.7316, Loss: 0.4212
Epoch  29 Batch  180/269 - Train Accuracy: 0.7296, Validation Accuracy: 0.7296, Loss: 0.4193
Epoch  29 Batch  190/269 - Train Accuracy: 0.7186, Validation Accuracy: 0.7298, Loss: 0.4169
Epoch  29 Batch  200/269 - Train Accuracy: 0.7120, Validation Accuracy: 0.7266, Loss: 0.4357
Epoch  29 Batch  210/269 - Train Accuracy: 0.7207, Validation Accuracy: 0.7287, Loss: 0.4237
Epoch  29 Batch  220/269 - Train Accuracy: 0.7250, Validation Accuracy: 0.7326, Loss: 0.4081
Epoch  29 Batch  230/269 - Train Accuracy: 0.7263, Validation Accuracy: 0.7303, Loss: 0.4183
Epoch  29 Batch  240/269 - Train Accuracy: 0.7448, Validation Accuracy: 0.7291, Loss: 0.3907
Epoch  29 Batch  250/269 - Train Accuracy: 0.7212, Validation Accuracy: 0.7291, Loss: 0.4371
Epoch  29 Batch  260/269 - Train Accuracy: 0.6961, Validation Accuracy: 0.7298, Loss: 0.4519
Epoch  30 Batch   10/269 - Train Accuracy: 0.7146, Validation Accuracy: 0.7309, Loss: 0.4374
Epoch  30 Batch   20/269 - Train Accuracy: 0.7229, Validation Accuracy: 0.7355, Loss: 0.4349
Epoch  30 Batch   30/269 - Train Accuracy: 0.7224, Validation Accuracy: 0.7367, Loss: 0.4200
Epoch  30 Batch   40/269 - Train Accuracy: 0.7170, Validation Accuracy: 0.7361, Loss: 0.4462
Epoch  30 Batch   50/269 - Train Accuracy: 0.7022, Validation Accuracy: 0.7397, Loss: 0.4504
Epoch  30 Batch   60/269 - Train Accuracy: 0.7291, Validation Accuracy: 0.7346, Loss: 0.4045
Epoch  30 Batch   70/269 - Train Accuracy: 0.7398, Validation Accuracy: 0.7334, Loss: 0.4264
Epoch  30 Batch   80/269 - Train Accuracy: 0.7348, Validation Accuracy: 0.7306, Loss: 0.4241
Epoch  30 Batch   90/269 - Train Accuracy: 0.7061, Validation Accuracy: 0.7278, Loss: 0.4385
Epoch  30 Batch  100/269 - Train Accuracy: 0.7316, Validation Accuracy: 0.7365, Loss: 0.4135
Epoch  30 Batch  110/269 - Train Accuracy: 0.7199, Validation Accuracy: 0.7277, Loss: 0.4201
Epoch  30 Batch  120/269 - Train Accuracy: 0.7172, Validation Accuracy: 0.7352, Loss: 0.4318
Epoch  30 Batch  130/269 - Train Accuracy: 0.7166, Validation Accuracy: 0.7359, Loss: 0.4398
Epoch  30 Batch  140/269 - Train Accuracy: 0.7288, Validation Accuracy: 0.7351, Loss: 0.4314
Epoch  30 Batch  150/269 - Train Accuracy: 0.7258, Validation Accuracy: 0.7346, Loss: 0.4187
Epoch  30 Batch  160/269 - Train Accuracy: 0.7244, Validation Accuracy: 0.7365, Loss: 0.4205
Epoch  30 Batch  170/269 - Train Accuracy: 0.7176, Validation Accuracy: 0.7333, Loss: 0.4152
Epoch  30 Batch  180/269 - Train Accuracy: 0.7334, Validation Accuracy: 0.7323, Loss: 0.4125
Epoch  30 Batch  190/269 - Train Accuracy: 0.7206, Validation Accuracy: 0.7336, Loss: 0.4080
Epoch  30 Batch  200/269 - Train Accuracy: 0.7115, Validation Accuracy: 0.7288, Loss: 0.4251
Epoch  30 Batch  210/269 - Train Accuracy: 0.7275, Validation Accuracy: 0.7313, Loss: 0.4109
Epoch  30 Batch  220/269 - Train Accuracy: 0.7279, Validation Accuracy: 0.7338, Loss: 0.4010
Epoch  30 Batch  230/269 - Train Accuracy: 0.7319, Validation Accuracy: 0.7313, Loss: 0.4145
Epoch  30 Batch  240/269 - Train Accuracy: 0.7492, Validation Accuracy: 0.7262, Loss: 0.3855
Epoch  30 Batch  250/269 - Train Accuracy: 0.7273, Validation Accuracy: 0.7346, Loss: 0.4301
Epoch  30 Batch  260/269 - Train Accuracy: 0.6976, Validation Accuracy: 0.7379, Loss: 0.4435
Epoch  31 Batch   10/269 - Train Accuracy: 0.7168, Validation Accuracy: 0.7323, Loss: 0.4245
Epoch  31 Batch   20/269 - Train Accuracy: 0.7202, Validation Accuracy: 0.7405, Loss: 0.4299
Epoch  31 Batch   30/269 - Train Accuracy: 0.7248, Validation Accuracy: 0.7383, Loss: 0.4086
Epoch  31 Batch   40/269 - Train Accuracy: 0.7211, Validation Accuracy: 0.7385, Loss: 0.4409
Epoch  31 Batch   50/269 - Train Accuracy: 0.7065, Validation Accuracy: 0.7379, Loss: 0.4403
Epoch  31 Batch   60/269 - Train Accuracy: 0.7395, Validation Accuracy: 0.7338, Loss: 0.3914
Epoch  31 Batch   70/269 - Train Accuracy: 0.7493, Validation Accuracy: 0.7346, Loss: 0.4133
Epoch  31 Batch   80/269 - Train Accuracy: 0.7317, Validation Accuracy: 0.7366, Loss: 0.4153
Epoch  31 Batch   90/269 - Train Accuracy: 0.7083, Validation Accuracy: 0.7385, Loss: 0.4322
Epoch  31 Batch  100/269 - Train Accuracy: 0.7344, Validation Accuracy: 0.7362, Loss: 0.4028
Epoch  31 Batch  110/269 - Train Accuracy: 0.7242, Validation Accuracy: 0.7310, Loss: 0.4093
Epoch  31 Batch  120/269 - Train Accuracy: 0.7203, Validation Accuracy: 0.7404, Loss: 0.4167
Epoch  31 Batch  130/269 - Train Accuracy: 0.7226, Validation Accuracy: 0.7432, Loss: 0.4286
Epoch  31 Batch  140/269 - Train Accuracy: 0.7294, Validation Accuracy: 0.7343, Loss: 0.4285
Epoch  31 Batch  150/269 - Train Accuracy: 0.7208, Validation Accuracy: 0.7387, Loss: 0.4118
Epoch  31 Batch  160/269 - Train Accuracy: 0.7313, Validation Accuracy: 0.7405, Loss: 0.4110
Epoch  31 Batch  170/269 - Train Accuracy: 0.7175, Validation Accuracy: 0.7358, Loss: 0.4133
Epoch  31 Batch  180/269 - Train Accuracy: 0.7347, Validation Accuracy: 0.7425, Loss: 0.4042
Epoch  31 Batch  190/269 - Train Accuracy: 0.7243, Validation Accuracy: 0.7330, Loss: 0.3942
Epoch  31 Batch  200/269 - Train Accuracy: 0.7137, Validation Accuracy: 0.7318, Loss: 0.4191
Epoch  31 Batch  210/269 - Train Accuracy: 0.7260, Validation Accuracy: 0.7362, Loss: 0.3958
Epoch  31 Batch  220/269 - Train Accuracy: 0.7265, Validation Accuracy: 0.7400, Loss: 0.3846
Epoch  31 Batch  230/269 - Train Accuracy: 0.7350, Validation Accuracy: 0.7396, Loss: 0.4125
Epoch  31 Batch  240/269 - Train Accuracy: 0.7517, Validation Accuracy: 0.7345, Loss: 0.3784
Epoch  31 Batch  250/269 - Train Accuracy: 0.7304, Validation Accuracy: 0.7378, Loss: 0.4164
Epoch  31 Batch  260/269 - Train Accuracy: 0.7081, Validation Accuracy: 0.7408, Loss: 0.4361
Epoch  32 Batch   10/269 - Train Accuracy: 0.7256, Validation Accuracy: 0.7411, Loss: 0.4205
Epoch  32 Batch   20/269 - Train Accuracy: 0.7280, Validation Accuracy: 0.7437, Loss: 0.4245
Epoch  32 Batch   30/269 - Train Accuracy: 0.7247, Validation Accuracy: 0.7395, Loss: 0.4035
Epoch  32 Batch   40/269 - Train Accuracy: 0.7257, Validation Accuracy: 0.7451, Loss: 0.4253
Epoch  32 Batch   50/269 - Train Accuracy: 0.7082, Validation Accuracy: 0.7399, Loss: 0.4283
Epoch  32 Batch   60/269 - Train Accuracy: 0.7352, Validation Accuracy: 0.7373, Loss: 0.3842
Epoch  32 Batch   70/269 - Train Accuracy: 0.7428, Validation Accuracy: 0.7462, Loss: 0.4041
Epoch  32 Batch   80/269 - Train Accuracy: 0.7347, Validation Accuracy: 0.7427, Loss: 0.4007
Epoch  32 Batch   90/269 - Train Accuracy: 0.7065, Validation Accuracy: 0.7338, Loss: 0.4251
Epoch  32 Batch  100/269 - Train Accuracy: 0.7358, Validation Accuracy: 0.7405, Loss: 0.4010
Epoch  32 Batch  110/269 - Train Accuracy: 0.7342, Validation Accuracy: 0.7374, Loss: 0.4113
Epoch  32 Batch  120/269 - Train Accuracy: 0.7153, Validation Accuracy: 0.7363, Loss: 0.4113
Epoch  32 Batch  130/269 - Train Accuracy: 0.7245, Validation Accuracy: 0.7427, Loss: 0.4198
Epoch  32 Batch  140/269 - Train Accuracy: 0.7328, Validation Accuracy: 0.7395, Loss: 0.4223
Epoch  32 Batch  150/269 - Train Accuracy: 0.7329, Validation Accuracy: 0.7445, Loss: 0.4001
Epoch  32 Batch  160/269 - Train Accuracy: 0.7338, Validation Accuracy: 0.7389, Loss: 0.3987
Epoch  32 Batch  170/269 - Train Accuracy: 0.7123, Validation Accuracy: 0.7392, Loss: 0.3953
Epoch  32 Batch  180/269 - Train Accuracy: 0.7398, Validation Accuracy: 0.7473, Loss: 0.3959
Epoch  32 Batch  190/269 - Train Accuracy: 0.7320, Validation Accuracy: 0.7418, Loss: 0.3944
Epoch  32 Batch  200/269 - Train Accuracy: 0.7210, Validation Accuracy: 0.7375, Loss: 0.4143
Epoch  32 Batch  210/269 - Train Accuracy: 0.7244, Validation Accuracy: 0.7368, Loss: 0.3953
Epoch  32 Batch  220/269 - Train Accuracy: 0.7331, Validation Accuracy: 0.7339, Loss: 0.3791
Epoch  32 Batch  230/269 - Train Accuracy: 0.7403, Validation Accuracy: 0.7416, Loss: 0.3942
Epoch  32 Batch  240/269 - Train Accuracy: 0.7594, Validation Accuracy: 0.7382, Loss: 0.3685
Epoch  32 Batch  250/269 - Train Accuracy: 0.7337, Validation Accuracy: 0.7385, Loss: 0.4051
Epoch  32 Batch  260/269 - Train Accuracy: 0.7093, Validation Accuracy: 0.7324, Loss: 0.4226
Epoch  33 Batch   10/269 - Train Accuracy: 0.7261, Validation Accuracy: 0.7357, Loss: 0.4097
Epoch  33 Batch   20/269 - Train Accuracy: 0.7355, Validation Accuracy: 0.7398, Loss: 0.4106
Epoch  33 Batch   30/269 - Train Accuracy: 0.7320, Validation Accuracy: 0.7355, Loss: 0.3959
Epoch  33 Batch   40/269 - Train Accuracy: 0.7335, Validation Accuracy: 0.7476, Loss: 0.4260
Epoch  33 Batch   50/269 - Train Accuracy: 0.7162, Validation Accuracy: 0.7415, Loss: 0.4236
Epoch  33 Batch   60/269 - Train Accuracy: 0.7426, Validation Accuracy: 0.7392, Loss: 0.3746
Epoch  33 Batch   70/269 - Train Accuracy: 0.7493, Validation Accuracy: 0.7383, Loss: 0.3918
Epoch  33 Batch   80/269 - Train Accuracy: 0.7416, Validation Accuracy: 0.7396, Loss: 0.3970
Epoch  33 Batch   90/269 - Train Accuracy: 0.7044, Validation Accuracy: 0.7338, Loss: 0.4175
Epoch  33 Batch  100/269 - Train Accuracy: 0.7460, Validation Accuracy: 0.7391, Loss: 0.3936
Epoch  33 Batch  110/269 - Train Accuracy: 0.7366, Validation Accuracy: 0.7333, Loss: 0.3977
Epoch  33 Batch  120/269 - Train Accuracy: 0.7240, Validation Accuracy: 0.7427, Loss: 0.4042
Epoch  33 Batch  130/269 - Train Accuracy: 0.7333, Validation Accuracy: 0.7419, Loss: 0.4136
Epoch  33 Batch  140/269 - Train Accuracy: 0.7375, Validation Accuracy: 0.7377, Loss: 0.4084
Epoch  33 Batch  150/269 - Train Accuracy: 0.7293, Validation Accuracy: 0.7401, Loss: 0.3899
Epoch  33 Batch  160/269 - Train Accuracy: 0.7352, Validation Accuracy: 0.7437, Loss: 0.3978
Epoch  33 Batch  170/269 - Train Accuracy: 0.7225, Validation Accuracy: 0.7423, Loss: 0.3923
Epoch  33 Batch  180/269 - Train Accuracy: 0.7374, Validation Accuracy: 0.7431, Loss: 0.3830
Epoch  33 Batch  190/269 - Train Accuracy: 0.7384, Validation Accuracy: 0.7433, Loss: 0.3824
Epoch  33 Batch  200/269 - Train Accuracy: 0.7228, Validation Accuracy: 0.7362, Loss: 0.4005
Epoch  33 Batch  210/269 - Train Accuracy: 0.7255, Validation Accuracy: 0.7360, Loss: 0.3832
Epoch  33 Batch  220/269 - Train Accuracy: 0.7396, Validation Accuracy: 0.7377, Loss: 0.3743
Epoch  33 Batch  230/269 - Train Accuracy: 0.7415, Validation Accuracy: 0.7428, Loss: 0.3846
Epoch  33 Batch  240/269 - Train Accuracy: 0.7566, Validation Accuracy: 0.7398, Loss: 0.3583
Epoch  33 Batch  250/269 - Train Accuracy: 0.7393, Validation Accuracy: 0.7367, Loss: 0.3951
Epoch  33 Batch  260/269 - Train Accuracy: 0.7093, Validation Accuracy: 0.7396, Loss: 0.4197
Epoch  34 Batch   10/269 - Train Accuracy: 0.7349, Validation Accuracy: 0.7409, Loss: 0.4014
Epoch  34 Batch   20/269 - Train Accuracy: 0.7407, Validation Accuracy: 0.7401, Loss: 0.4077
Epoch  34 Batch   30/269 - Train Accuracy: 0.7400, Validation Accuracy: 0.7392, Loss: 0.3859
Epoch  34 Batch   40/269 - Train Accuracy: 0.7330, Validation Accuracy: 0.7401, Loss: 0.4142
Epoch  34 Batch   50/269 - Train Accuracy: 0.7134, Validation Accuracy: 0.7400, Loss: 0.4082
Epoch  34 Batch   60/269 - Train Accuracy: 0.7430, Validation Accuracy: 0.7425, Loss: 0.3726
Epoch  34 Batch   70/269 - Train Accuracy: 0.7434, Validation Accuracy: 0.7355, Loss: 0.3911
Epoch  34 Batch   80/269 - Train Accuracy: 0.7450, Validation Accuracy: 0.7401, Loss: 0.3943
Epoch  34 Batch   90/269 - Train Accuracy: 0.7111, Validation Accuracy: 0.7363, Loss: 0.4123
Epoch  34 Batch  100/269 - Train Accuracy: 0.7527, Validation Accuracy: 0.7431, Loss: 0.3819
Epoch  34 Batch  110/269 - Train Accuracy: 0.7413, Validation Accuracy: 0.7417, Loss: 0.3870
Epoch  34 Batch  120/269 - Train Accuracy: 0.7259, Validation Accuracy: 0.7437, Loss: 0.3967
Epoch  34 Batch  130/269 - Train Accuracy: 0.7362, Validation Accuracy: 0.7457, Loss: 0.4049
Epoch  34 Batch  140/269 - Train Accuracy: 0.7427, Validation Accuracy: 0.7383, Loss: 0.3954
Epoch  34 Batch  150/269 - Train Accuracy: 0.7363, Validation Accuracy: 0.7387, Loss: 0.3823
Epoch  34 Batch  160/269 - Train Accuracy: 0.7424, Validation Accuracy: 0.7418, Loss: 0.3889
Epoch  34 Batch  170/269 - Train Accuracy: 0.7229, Validation Accuracy: 0.7464, Loss: 0.3913
Epoch  34 Batch  180/269 - Train Accuracy: 0.7459, Validation Accuracy: 0.7471, Loss: 0.3891
Epoch  34 Batch  190/269 - Train Accuracy: 0.7414, Validation Accuracy: 0.7404, Loss: 0.3767
Epoch  34 Batch  200/269 - Train Accuracy: 0.7211, Validation Accuracy: 0.7380, Loss: 0.3912
Epoch  34 Batch  210/269 - Train Accuracy: 0.7290, Validation Accuracy: 0.7418, Loss: 0.3812
Epoch  34 Batch  220/269 - Train Accuracy: 0.7456, Validation Accuracy: 0.7430, Loss: 0.3643
Epoch  34 Batch  230/269 - Train Accuracy: 0.7428, Validation Accuracy: 0.7397, Loss: 0.3819
Epoch  34 Batch  240/269 - Train Accuracy: 0.7634, Validation Accuracy: 0.7403, Loss: 0.3498
Epoch  34 Batch  250/269 - Train Accuracy: 0.7430, Validation Accuracy: 0.7444, Loss: 0.3873
Epoch  34 Batch  260/269 - Train Accuracy: 0.7133, Validation Accuracy: 0.7397, Loss: 0.4058
Epoch  35 Batch   10/269 - Train Accuracy: 0.7312, Validation Accuracy: 0.7400, Loss: 0.3927
Epoch  35 Batch   20/269 - Train Accuracy: 0.7378, Validation Accuracy: 0.7456, Loss: 0.3940
Epoch  35 Batch   30/269 - Train Accuracy: 0.7435, Validation Accuracy: 0.7400, Loss: 0.3826
Epoch  35 Batch   40/269 - Train Accuracy: 0.7383, Validation Accuracy: 0.7440, Loss: 0.4106
Epoch  35 Batch   50/269 - Train Accuracy: 0.7197, Validation Accuracy: 0.7443, Loss: 0.4101
Epoch  35 Batch   60/269 - Train Accuracy: 0.7463, Validation Accuracy: 0.7449, Loss: 0.3638
Epoch  35 Batch   70/269 - Train Accuracy: 0.7550, Validation Accuracy: 0.7414, Loss: 0.3819
Epoch  35 Batch   80/269 - Train Accuracy: 0.7497, Validation Accuracy: 0.7485, Loss: 0.3810
Epoch  35 Batch   90/269 - Train Accuracy: 0.7238, Validation Accuracy: 0.7396, Loss: 0.4014
Epoch  35 Batch  100/269 - Train Accuracy: 0.7507, Validation Accuracy: 0.7421, Loss: 0.3796
Epoch  35 Batch  110/269 - Train Accuracy: 0.7461, Validation Accuracy: 0.7431, Loss: 0.3851
Epoch  35 Batch  120/269 - Train Accuracy: 0.7302, Validation Accuracy: 0.7438, Loss: 0.3874
Epoch  35 Batch  130/269 - Train Accuracy: 0.7409, Validation Accuracy: 0.7479, Loss: 0.4019
Epoch  35 Batch  140/269 - Train Accuracy: 0.7478, Validation Accuracy: 0.7431, Loss: 0.3967
Epoch  35 Batch  150/269 - Train Accuracy: 0.7395, Validation Accuracy: 0.7461, Loss: 0.3767
Epoch  35 Batch  160/269 - Train Accuracy: 0.7373, Validation Accuracy: 0.7406, Loss: 0.3822
Epoch  35 Batch  170/269 - Train Accuracy: 0.7254, Validation Accuracy: 0.7476, Loss: 0.3722
Epoch  35 Batch  180/269 - Train Accuracy: 0.7495, Validation Accuracy: 0.7498, Loss: 0.3720
Epoch  35 Batch  190/269 - Train Accuracy: 0.7420, Validation Accuracy: 0.7420, Loss: 0.3698
Epoch  35 Batch  200/269 - Train Accuracy: 0.7258, Validation Accuracy: 0.7436, Loss: 0.3891
Epoch  35 Batch  210/269 - Train Accuracy: 0.7341, Validation Accuracy: 0.7441, Loss: 0.3735
Epoch  35 Batch  220/269 - Train Accuracy: 0.7456, Validation Accuracy: 0.7443, Loss: 0.3576
Epoch  35 Batch  230/269 - Train Accuracy: 0.7492, Validation Accuracy: 0.7442, Loss: 0.3787
Epoch  35 Batch  240/269 - Train Accuracy: 0.7662, Validation Accuracy: 0.7427, Loss: 0.3455
Epoch  35 Batch  250/269 - Train Accuracy: 0.7481, Validation Accuracy: 0.7420, Loss: 0.3840
Epoch  35 Batch  260/269 - Train Accuracy: 0.7196, Validation Accuracy: 0.7449, Loss: 0.4014
Epoch  36 Batch   10/269 - Train Accuracy: 0.7448, Validation Accuracy: 0.7456, Loss: 0.3861
Epoch  36 Batch   20/269 - Train Accuracy: 0.7438, Validation Accuracy: 0.7472, Loss: 0.3901
Epoch  36 Batch   30/269 - Train Accuracy: 0.7514, Validation Accuracy: 0.7394, Loss: 0.3745
Epoch  36 Batch   40/269 - Train Accuracy: 0.7491, Validation Accuracy: 0.7448, Loss: 0.4010
Epoch  36 Batch   50/269 - Train Accuracy: 0.7285, Validation Accuracy: 0.7491, Loss: 0.3965
Epoch  36 Batch   60/269 - Train Accuracy: 0.7528, Validation Accuracy: 0.7480, Loss: 0.3540
Epoch  36 Batch   70/269 - Train Accuracy: 0.7614, Validation Accuracy: 0.7471, Loss: 0.3759
Epoch  36 Batch   80/269 - Train Accuracy: 0.7526, Validation Accuracy: 0.7449, Loss: 0.3769
Epoch  36 Batch   90/269 - Train Accuracy: 0.7296, Validation Accuracy: 0.7417, Loss: 0.3906
Epoch  36 Batch  100/269 - Train Accuracy: 0.7601, Validation Accuracy: 0.7496, Loss: 0.3708
Epoch  36 Batch  110/269 - Train Accuracy: 0.7511, Validation Accuracy: 0.7429, Loss: 0.3720
Epoch  36 Batch  120/269 - Train Accuracy: 0.7333, Validation Accuracy: 0.7492, Loss: 0.3790
Epoch  36 Batch  130/269 - Train Accuracy: 0.7424, Validation Accuracy: 0.7500, Loss: 0.3914
Epoch  36 Batch  140/269 - Train Accuracy: 0.7455, Validation Accuracy: 0.7442, Loss: 0.3893
Epoch  36 Batch  150/269 - Train Accuracy: 0.7481, Validation Accuracy: 0.7476, Loss: 0.3693
Epoch  36 Batch  160/269 - Train Accuracy: 0.7433, Validation Accuracy: 0.7442, Loss: 0.3769
Epoch  36 Batch  170/269 - Train Accuracy: 0.7357, Validation Accuracy: 0.7449, Loss: 0.3631
Epoch  36 Batch  180/269 - Train Accuracy: 0.7520, Validation Accuracy: 0.7527, Loss: 0.3705
Epoch  36 Batch  190/269 - Train Accuracy: 0.7500, Validation Accuracy: 0.7472, Loss: 0.3640
Epoch  36 Batch  200/269 - Train Accuracy: 0.7306, Validation Accuracy: 0.7429, Loss: 0.3775
Epoch  36 Batch  210/269 - Train Accuracy: 0.7414, Validation Accuracy: 0.7505, Loss: 0.3724
Epoch  36 Batch  220/269 - Train Accuracy: 0.7517, Validation Accuracy: 0.7491, Loss: 0.3504
Epoch  36 Batch  230/269 - Train Accuracy: 0.7481, Validation Accuracy: 0.7510, Loss: 0.3629
Epoch  36 Batch  240/269 - Train Accuracy: 0.7671, Validation Accuracy: 0.7464, Loss: 0.3304
Epoch  36 Batch  250/269 - Train Accuracy: 0.7459, Validation Accuracy: 0.7472, Loss: 0.3725
Epoch  36 Batch  260/269 - Train Accuracy: 0.7190, Validation Accuracy: 0.7449, Loss: 0.3936
Epoch  37 Batch   10/269 - Train Accuracy: 0.7537, Validation Accuracy: 0.7468, Loss: 0.3845
Epoch  37 Batch   20/269 - Train Accuracy: 0.7406, Validation Accuracy: 0.7500, Loss: 0.3804
Epoch  37 Batch   30/269 - Train Accuracy: 0.7510, Validation Accuracy: 0.7454, Loss: 0.3728
Epoch  37 Batch   40/269 - Train Accuracy: 0.7497, Validation Accuracy: 0.7500, Loss: 0.3962
Epoch  37 Batch   50/269 - Train Accuracy: 0.7275, Validation Accuracy: 0.7481, Loss: 0.3896
Epoch  37 Batch   60/269 - Train Accuracy: 0.7555, Validation Accuracy: 0.7528, Loss: 0.3485
Epoch  37 Batch   70/269 - Train Accuracy: 0.7623, Validation Accuracy: 0.7520, Loss: 0.3622
Epoch  37 Batch   80/269 - Train Accuracy: 0.7576, Validation Accuracy: 0.7486, Loss: 0.3634
Epoch  37 Batch   90/269 - Train Accuracy: 0.7376, Validation Accuracy: 0.7477, Loss: 0.3841
Epoch  37 Batch  100/269 - Train Accuracy: 0.7643, Validation Accuracy: 0.7491, Loss: 0.3598
Epoch  37 Batch  110/269 - Train Accuracy: 0.7560, Validation Accuracy: 0.7514, Loss: 0.3742
Epoch  37 Batch  120/269 - Train Accuracy: 0.7382, Validation Accuracy: 0.7513, Loss: 0.3835
Epoch  37 Batch  130/269 - Train Accuracy: 0.7503, Validation Accuracy: 0.7506, Loss: 0.3837
Epoch  37 Batch  140/269 - Train Accuracy: 0.7484, Validation Accuracy: 0.7446, Loss: 0.3771
Epoch  37 Batch  150/269 - Train Accuracy: 0.7524, Validation Accuracy: 0.7529, Loss: 0.3596
Epoch  37 Batch  160/269 - Train Accuracy: 0.7452, Validation Accuracy: 0.7471, Loss: 0.3665
Epoch  37 Batch  170/269 - Train Accuracy: 0.7302, Validation Accuracy: 0.7546, Loss: 0.3634
Epoch  37 Batch  180/269 - Train Accuracy: 0.7599, Validation Accuracy: 0.7547, Loss: 0.3632
Epoch  37 Batch  190/269 - Train Accuracy: 0.7543, Validation Accuracy: 0.7513, Loss: 0.3574
Epoch  37 Batch  200/269 - Train Accuracy: 0.7288, Validation Accuracy: 0.7473, Loss: 0.3799
Epoch  37 Batch  210/269 - Train Accuracy: 0.7455, Validation Accuracy: 0.7472, Loss: 0.3619
Epoch  37 Batch  220/269 - Train Accuracy: 0.7585, Validation Accuracy: 0.7519, Loss: 0.3397
Epoch  37 Batch  230/269 - Train Accuracy: 0.7537, Validation Accuracy: 0.7559, Loss: 0.3605
Epoch  37 Batch  240/269 - Train Accuracy: 0.7712, Validation Accuracy: 0.7519, Loss: 0.3298
Epoch  37 Batch  250/269 - Train Accuracy: 0.7478, Validation Accuracy: 0.7535, Loss: 0.3683
Epoch  37 Batch  260/269 - Train Accuracy: 0.7243, Validation Accuracy: 0.7509, Loss: 0.3839
Epoch  38 Batch   10/269 - Train Accuracy: 0.7576, Validation Accuracy: 0.7495, Loss: 0.3648
Epoch  38 Batch   20/269 - Train Accuracy: 0.7538, Validation Accuracy: 0.7542, Loss: 0.3760
Epoch  38 Batch   30/269 - Train Accuracy: 0.7622, Validation Accuracy: 0.7512, Loss: 0.3618
Epoch  38 Batch   40/269 - Train Accuracy: 0.7537, Validation Accuracy: 0.7555, Loss: 0.3834
Epoch  38 Batch   50/269 - Train Accuracy: 0.7325, Validation Accuracy: 0.7538, Loss: 0.3836
Epoch  38 Batch   60/269 - Train Accuracy: 0.7533, Validation Accuracy: 0.7548, Loss: 0.3446
Epoch  38 Batch   70/269 - Train Accuracy: 0.7657, Validation Accuracy: 0.7506, Loss: 0.3598
Epoch  38 Batch   80/269 - Train Accuracy: 0.7572, Validation Accuracy: 0.7521, Loss: 0.3661
Epoch  38 Batch   90/269 - Train Accuracy: 0.7423, Validation Accuracy: 0.7464, Loss: 0.3844
Epoch  38 Batch  100/269 - Train Accuracy: 0.7639, Validation Accuracy: 0.7531, Loss: 0.3529
Epoch  38 Batch  110/269 - Train Accuracy: 0.7582, Validation Accuracy: 0.7526, Loss: 0.3625
Epoch  38 Batch  120/269 - Train Accuracy: 0.7366, Validation Accuracy: 0.7584, Loss: 0.3750
Epoch  38 Batch  130/269 - Train Accuracy: 0.7527, Validation Accuracy: 0.7575, Loss: 0.3815
Epoch  38 Batch  140/269 - Train Accuracy: 0.7509, Validation Accuracy: 0.7479, Loss: 0.3695
Epoch  38 Batch  150/269 - Train Accuracy: 0.7568, Validation Accuracy: 0.7555, Loss: 0.3527
Epoch  38 Batch  160/269 - Train Accuracy: 0.7463, Validation Accuracy: 0.7525, Loss: 0.3633
Epoch  38 Batch  170/269 - Train Accuracy: 0.7369, Validation Accuracy: 0.7591, Loss: 0.3539
Epoch  38 Batch  180/269 - Train Accuracy: 0.7617, Validation Accuracy: 0.7582, Loss: 0.3543
Epoch  38 Batch  190/269 - Train Accuracy: 0.7523, Validation Accuracy: 0.7591, Loss: 0.3536
Epoch  38 Batch  200/269 - Train Accuracy: 0.7297, Validation Accuracy: 0.7468, Loss: 0.3674
Epoch  38 Batch  210/269 - Train Accuracy: 0.7495, Validation Accuracy: 0.7511, Loss: 0.3611
Epoch  38 Batch  220/269 - Train Accuracy: 0.7579, Validation Accuracy: 0.7559, Loss: 0.3369
Epoch  38 Batch  230/269 - Train Accuracy: 0.7585, Validation Accuracy: 0.7579, Loss: 0.3515
Epoch  38 Batch  240/269 - Train Accuracy: 0.7760, Validation Accuracy: 0.7587, Loss: 0.3238
Epoch  38 Batch  250/269 - Train Accuracy: 0.7546, Validation Accuracy: 0.7551, Loss: 0.3585
Epoch  38 Batch  260/269 - Train Accuracy: 0.7294, Validation Accuracy: 0.7558, Loss: 0.3854
Epoch  39 Batch   10/269 - Train Accuracy: 0.7627, Validation Accuracy: 0.7566, Loss: 0.3632
Epoch  39 Batch   20/269 - Train Accuracy: 0.7518, Validation Accuracy: 0.7562, Loss: 0.3750
Epoch  39 Batch   30/269 - Train Accuracy: 0.7599, Validation Accuracy: 0.7543, Loss: 0.3617
Epoch  39 Batch   40/269 - Train Accuracy: 0.7541, Validation Accuracy: 0.7601, Loss: 0.3758
Epoch  39 Batch   50/269 - Train Accuracy: 0.7298, Validation Accuracy: 0.7528, Loss: 0.3797
Epoch  39 Batch   60/269 - Train Accuracy: 0.7557, Validation Accuracy: 0.7575, Loss: 0.3451
Epoch  39 Batch   70/269 - Train Accuracy: 0.7691, Validation Accuracy: 0.7500, Loss: 0.3557
Epoch  39 Batch   80/269 - Train Accuracy: 0.7590, Validation Accuracy: 0.7529, Loss: 0.3598
Epoch  39 Batch   90/269 - Train Accuracy: 0.7453, Validation Accuracy: 0.7536, Loss: 0.3758
Epoch  39 Batch  100/269 - Train Accuracy: 0.7733, Validation Accuracy: 0.7600, Loss: 0.3579
Epoch  39 Batch  110/269 - Train Accuracy: 0.7546, Validation Accuracy: 0.7542, Loss: 0.3563
Epoch  39 Batch  120/269 - Train Accuracy: 0.7403, Validation Accuracy: 0.7595, Loss: 0.3628
Epoch  39 Batch  130/269 - Train Accuracy: 0.7555, Validation Accuracy: 0.7558, Loss: 0.3699
Epoch  39 Batch  140/269 - Train Accuracy: 0.7548, Validation Accuracy: 0.7555, Loss: 0.3661
Epoch  39 Batch  150/269 - Train Accuracy: 0.7603, Validation Accuracy: 0.7566, Loss: 0.3572
Epoch  39 Batch  160/269 - Train Accuracy: 0.7578, Validation Accuracy: 0.7558, Loss: 0.3542
Epoch  39 Batch  170/269 - Train Accuracy: 0.7415, Validation Accuracy: 0.7561, Loss: 0.3509
Epoch  39 Batch  180/269 - Train Accuracy: 0.7684, Validation Accuracy: 0.7646, Loss: 0.3437
Epoch  39 Batch  190/269 - Train Accuracy: 0.7580, Validation Accuracy: 0.7593, Loss: 0.3473
Epoch  39 Batch  200/269 - Train Accuracy: 0.7385, Validation Accuracy: 0.7567, Loss: 0.3562
Epoch  39 Batch  210/269 - Train Accuracy: 0.7524, Validation Accuracy: 0.7479, Loss: 0.3519
Epoch  39 Batch  220/269 - Train Accuracy: 0.7646, Validation Accuracy: 0.7578, Loss: 0.3317
Epoch  39 Batch  230/269 - Train Accuracy: 0.7581, Validation Accuracy: 0.7608, Loss: 0.3489
Epoch  39 Batch  240/269 - Train Accuracy: 0.7779, Validation Accuracy: 0.7597, Loss: 0.3200
Epoch  39 Batch  250/269 - Train Accuracy: 0.7552, Validation Accuracy: 0.7579, Loss: 0.3542
Epoch  39 Batch  260/269 - Train Accuracy: 0.7275, Validation Accuracy: 0.7529, Loss: 0.3792
Epoch  40 Batch   10/269 - Train Accuracy: 0.7634, Validation Accuracy: 0.7553, Loss: 0.3604
Epoch  40 Batch   20/269 - Train Accuracy: 0.7543, Validation Accuracy: 0.7569, Loss: 0.3647
Epoch  40 Batch   30/269 - Train Accuracy: 0.7662, Validation Accuracy: 0.7593, Loss: 0.3481
Epoch  40 Batch   40/269 - Train Accuracy: 0.7587, Validation Accuracy: 0.7604, Loss: 0.3739
Epoch  40 Batch   50/269 - Train Accuracy: 0.7342, Validation Accuracy: 0.7553, Loss: 0.3674
Epoch  40 Batch   60/269 - Train Accuracy: 0.7564, Validation Accuracy: 0.7599, Loss: 0.3294
Epoch  40 Batch   70/269 - Train Accuracy: 0.7746, Validation Accuracy: 0.7562, Loss: 0.3494
Epoch  40 Batch   80/269 - Train Accuracy: 0.7593, Validation Accuracy: 0.7595, Loss: 0.3455
Epoch  40 Batch   90/269 - Train Accuracy: 0.7480, Validation Accuracy: 0.7573, Loss: 0.3697
Epoch  40 Batch  100/269 - Train Accuracy: 0.7799, Validation Accuracy: 0.7634, Loss: 0.3407
Epoch  40 Batch  110/269 - Train Accuracy: 0.7560, Validation Accuracy: 0.7560, Loss: 0.3510
Epoch  40 Batch  120/269 - Train Accuracy: 0.7500, Validation Accuracy: 0.7622, Loss: 0.3538
Epoch  40 Batch  130/269 - Train Accuracy: 0.7656, Validation Accuracy: 0.7606, Loss: 0.3624
Epoch  40 Batch  140/269 - Train Accuracy: 0.7609, Validation Accuracy: 0.7595, Loss: 0.3593
Epoch  40 Batch  150/269 - Train Accuracy: 0.7640, Validation Accuracy: 0.7612, Loss: 0.3635
Epoch  40 Batch  160/269 - Train Accuracy: 0.7528, Validation Accuracy: 0.7586, Loss: 0.3478
Epoch  40 Batch  170/269 - Train Accuracy: 0.7431, Validation Accuracy: 0.7623, Loss: 0.3389
Epoch  40 Batch  180/269 - Train Accuracy: 0.7716, Validation Accuracy: 0.7641, Loss: 0.3416
Epoch  40 Batch  190/269 - Train Accuracy: 0.7631, Validation Accuracy: 0.7639, Loss: 0.3435
Epoch  40 Batch  200/269 - Train Accuracy: 0.7420, Validation Accuracy: 0.7569, Loss: 0.3492
Epoch  40 Batch  210/269 - Train Accuracy: 0.7604, Validation Accuracy: 0.7552, Loss: 0.3476
Epoch  40 Batch  220/269 - Train Accuracy: 0.7696, Validation Accuracy: 0.7581, Loss: 0.3318
Epoch  40 Batch  230/269 - Train Accuracy: 0.7571, Validation Accuracy: 0.7647, Loss: 0.3329
Epoch  40 Batch  240/269 - Train Accuracy: 0.7796, Validation Accuracy: 0.7620, Loss: 0.3244
Epoch  40 Batch  250/269 - Train Accuracy: 0.7619, Validation Accuracy: 0.7596, Loss: 0.3538
Epoch  40 Batch  260/269 - Train Accuracy: 0.7380, Validation Accuracy: 0.7621, Loss: 0.3680
Epoch  41 Batch   10/269 - Train Accuracy: 0.7734, Validation Accuracy: 0.7615, Loss: 0.3496
Epoch  41 Batch   20/269 - Train Accuracy: 0.7565, Validation Accuracy: 0.7612, Loss: 0.3651
Epoch  41 Batch   30/269 - Train Accuracy: 0.7657, Validation Accuracy: 0.7645, Loss: 0.3459
Epoch  41 Batch   40/269 - Train Accuracy: 0.7661, Validation Accuracy: 0.7667, Loss: 0.3618
Epoch  41 Batch   50/269 - Train Accuracy: 0.7414, Validation Accuracy: 0.7651, Loss: 0.3635
Epoch  41 Batch   60/269 - Train Accuracy: 0.7636, Validation Accuracy: 0.7649, Loss: 0.3295
Epoch  41 Batch   70/269 - Train Accuracy: 0.7808, Validation Accuracy: 0.7627, Loss: 0.3447
Epoch  41 Batch   80/269 - Train Accuracy: 0.7656, Validation Accuracy: 0.7638, Loss: 0.3417
Epoch  41 Batch   90/269 - Train Accuracy: 0.7563, Validation Accuracy: 0.7623, Loss: 0.3638
Epoch  41 Batch  100/269 - Train Accuracy: 0.7848, Validation Accuracy: 0.7637, Loss: 0.3346
Epoch  41 Batch  110/269 - Train Accuracy: 0.7662, Validation Accuracy: 0.7636, Loss: 0.3415
Epoch  41 Batch  120/269 - Train Accuracy: 0.7559, Validation Accuracy: 0.7686, Loss: 0.3520
Epoch  41 Batch  130/269 - Train Accuracy: 0.7583, Validation Accuracy: 0.7707, Loss: 0.3664
Epoch  41 Batch  140/269 - Train Accuracy: 0.7601, Validation Accuracy: 0.7695, Loss: 0.3493
Epoch  41 Batch  150/269 - Train Accuracy: 0.7618, Validation Accuracy: 0.7707, Loss: 0.3422
Epoch  41 Batch  160/269 - Train Accuracy: 0.7584, Validation Accuracy: 0.7652, Loss: 0.3497
Epoch  41 Batch  170/269 - Train Accuracy: 0.7559, Validation Accuracy: 0.7682, Loss: 0.3387
Epoch  41 Batch  180/269 - Train Accuracy: 0.7746, Validation Accuracy: 0.7640, Loss: 0.3333
Epoch  41 Batch  190/269 - Train Accuracy: 0.7668, Validation Accuracy: 0.7715, Loss: 0.3285
Epoch  41 Batch  200/269 - Train Accuracy: 0.7428, Validation Accuracy: 0.7647, Loss: 0.3477
Epoch  41 Batch  210/269 - Train Accuracy: 0.7603, Validation Accuracy: 0.7624, Loss: 0.3358
Epoch  41 Batch  220/269 - Train Accuracy: 0.7762, Validation Accuracy: 0.7655, Loss: 0.3230
Epoch  41 Batch  230/269 - Train Accuracy: 0.7672, Validation Accuracy: 0.7655, Loss: 0.3333
Epoch  41 Batch  240/269 - Train Accuracy: 0.7882, Validation Accuracy: 0.7653, Loss: 0.3104
Epoch  41 Batch  250/269 - Train Accuracy: 0.7701, Validation Accuracy: 0.7684, Loss: 0.3428
Epoch  41 Batch  260/269 - Train Accuracy: 0.7450, Validation Accuracy: 0.7682, Loss: 0.3640
Epoch  42 Batch   10/269 - Train Accuracy: 0.7803, Validation Accuracy: 0.7656, Loss: 0.3403
Epoch  42 Batch   20/269 - Train Accuracy: 0.7634, Validation Accuracy: 0.7717, Loss: 0.3503
Epoch  42 Batch   30/269 - Train Accuracy: 0.7742, Validation Accuracy: 0.7725, Loss: 0.3411
Epoch  42 Batch   40/269 - Train Accuracy: 0.7706, Validation Accuracy: 0.7702, Loss: 0.3530
Epoch  42 Batch   50/269 - Train Accuracy: 0.7439, Validation Accuracy: 0.7695, Loss: 0.3610
Epoch  42 Batch   60/269 - Train Accuracy: 0.7684, Validation Accuracy: 0.7656, Loss: 0.3166
Epoch  42 Batch   70/269 - Train Accuracy: 0.7812, Validation Accuracy: 0.7708, Loss: 0.3372
Epoch  42 Batch   80/269 - Train Accuracy: 0.7740, Validation Accuracy: 0.7672, Loss: 0.3330
Epoch  42 Batch   90/269 - Train Accuracy: 0.7588, Validation Accuracy: 0.7670, Loss: 0.3544
Epoch  42 Batch  100/269 - Train Accuracy: 0.7866, Validation Accuracy: 0.7641, Loss: 0.3274
Epoch  42 Batch  110/269 - Train Accuracy: 0.7745, Validation Accuracy: 0.7678, Loss: 0.3398
Epoch  42 Batch  120/269 - Train Accuracy: 0.7580, Validation Accuracy: 0.7718, Loss: 0.3486
Epoch  42 Batch  130/269 - Train Accuracy: 0.7698, Validation Accuracy: 0.7725, Loss: 0.3475
Epoch  42 Batch  140/269 - Train Accuracy: 0.7614, Validation Accuracy: 0.7635, Loss: 0.3482
Epoch  42 Batch  150/269 - Train Accuracy: 0.7659, Validation Accuracy: 0.7722, Loss: 0.3364
Epoch  42 Batch  160/269 - Train Accuracy: 0.7706, Validation Accuracy: 0.7762, Loss: 0.3378
Epoch  42 Batch  170/269 - Train Accuracy: 0.7582, Validation Accuracy: 0.7721, Loss: 0.3308
Epoch  42 Batch  180/269 - Train Accuracy: 0.7822, Validation Accuracy: 0.7761, Loss: 0.3251
Epoch  42 Batch  190/269 - Train Accuracy: 0.7725, Validation Accuracy: 0.7749, Loss: 0.3318
Epoch  42 Batch  200/269 - Train Accuracy: 0.7485, Validation Accuracy: 0.7725, Loss: 0.3435
Epoch  42 Batch  210/269 - Train Accuracy: 0.7674, Validation Accuracy: 0.7705, Loss: 0.3372
Epoch  42 Batch  220/269 - Train Accuracy: 0.7849, Validation Accuracy: 0.7760, Loss: 0.3125
Epoch  42 Batch  230/269 - Train Accuracy: 0.7690, Validation Accuracy: 0.7700, Loss: 0.3336
Epoch  42 Batch  240/269 - Train Accuracy: 0.7879, Validation Accuracy: 0.7738, Loss: 0.3127
Epoch  42 Batch  250/269 - Train Accuracy: 0.7782, Validation Accuracy: 0.7705, Loss: 0.3373
Epoch  42 Batch  260/269 - Train Accuracy: 0.7445, Validation Accuracy: 0.7718, Loss: 0.3546
Epoch  43 Batch   10/269 - Train Accuracy: 0.7827, Validation Accuracy: 0.7778, Loss: 0.3335
Epoch  43 Batch   20/269 - Train Accuracy: 0.7695, Validation Accuracy: 0.7709, Loss: 0.3443
Epoch  43 Batch   30/269 - Train Accuracy: 0.7763, Validation Accuracy: 0.7743, Loss: 0.3303
Epoch  43 Batch   40/269 - Train Accuracy: 0.7742, Validation Accuracy: 0.7754, Loss: 0.3565
Epoch  43 Batch   50/269 - Train Accuracy: 0.7527, Validation Accuracy: 0.7804, Loss: 0.3475
Epoch  43 Batch   60/269 - Train Accuracy: 0.7686, Validation Accuracy: 0.7733, Loss: 0.3203
Epoch  43 Batch   70/269 - Train Accuracy: 0.7831, Validation Accuracy: 0.7755, Loss: 0.3286
Epoch  43 Batch   80/269 - Train Accuracy: 0.7805, Validation Accuracy: 0.7710, Loss: 0.3319
Epoch  43 Batch   90/269 - Train Accuracy: 0.7691, Validation Accuracy: 0.7709, Loss: 0.3484
Epoch  43 Batch  100/269 - Train Accuracy: 0.7867, Validation Accuracy: 0.7765, Loss: 0.3215
Epoch  43 Batch  110/269 - Train Accuracy: 0.7788, Validation Accuracy: 0.7785, Loss: 0.3310
Epoch  43 Batch  120/269 - Train Accuracy: 0.7688, Validation Accuracy: 0.7804, Loss: 0.3362
Epoch  43 Batch  130/269 - Train Accuracy: 0.7722, Validation Accuracy: 0.7764, Loss: 0.3500
Epoch  43 Batch  140/269 - Train Accuracy: 0.7736, Validation Accuracy: 0.7710, Loss: 0.3394
Epoch  43 Batch  150/269 - Train Accuracy: 0.7652, Validation Accuracy: 0.7759, Loss: 0.3215
Epoch  43 Batch  160/269 - Train Accuracy: 0.7719, Validation Accuracy: 0.7773, Loss: 0.3330
Epoch  43 Batch  170/269 - Train Accuracy: 0.7620, Validation Accuracy: 0.7765, Loss: 0.3353
Epoch  43 Batch  180/269 - Train Accuracy: 0.7810, Validation Accuracy: 0.7774, Loss: 0.3281
Epoch  43 Batch  190/269 - Train Accuracy: 0.7784, Validation Accuracy: 0.7741, Loss: 0.3168
Epoch  43 Batch  200/269 - Train Accuracy: 0.7483, Validation Accuracy: 0.7709, Loss: 0.3359
Epoch  43 Batch  210/269 - Train Accuracy: 0.7798, Validation Accuracy: 0.7783, Loss: 0.3250
Epoch  43 Batch  220/269 - Train Accuracy: 0.7895, Validation Accuracy: 0.7838, Loss: 0.3093
Epoch  43 Batch  230/269 - Train Accuracy: 0.7692, Validation Accuracy: 0.7761, Loss: 0.3243
Epoch  43 Batch  240/269 - Train Accuracy: 0.7949, Validation Accuracy: 0.7770, Loss: 0.2951
Epoch  43 Batch  250/269 - Train Accuracy: 0.7841, Validation Accuracy: 0.7738, Loss: 0.3349
Epoch  43 Batch  260/269 - Train Accuracy: 0.7547, Validation Accuracy: 0.7770, Loss: 0.3524
Epoch  44 Batch   10/269 - Train Accuracy: 0.7896, Validation Accuracy: 0.7792, Loss: 0.3307
Epoch  44 Batch   20/269 - Train Accuracy: 0.7744, Validation Accuracy: 0.7808, Loss: 0.3397
Epoch  44 Batch   30/269 - Train Accuracy: 0.7794, Validation Accuracy: 0.7784, Loss: 0.3348
Epoch  44 Batch   40/269 - Train Accuracy: 0.7784, Validation Accuracy: 0.7756, Loss: 0.3463
Epoch  44 Batch   50/269 - Train Accuracy: 0.7615, Validation Accuracy: 0.7798, Loss: 0.3450
Epoch  44 Batch   60/269 - Train Accuracy: 0.7742, Validation Accuracy: 0.7737, Loss: 0.3076
Epoch  44 Batch   70/269 - Train Accuracy: 0.7879, Validation Accuracy: 0.7763, Loss: 0.3220
Epoch  44 Batch   80/269 - Train Accuracy: 0.7794, Validation Accuracy: 0.7790, Loss: 0.3211
Epoch  44 Batch   90/269 - Train Accuracy: 0.7781, Validation Accuracy: 0.7760, Loss: 0.3442
Epoch  44 Batch  100/269 - Train Accuracy: 0.7919, Validation Accuracy: 0.7831, Loss: 0.3194
Epoch  44 Batch  110/269 - Train Accuracy: 0.7862, Validation Accuracy: 0.7827, Loss: 0.3229
Epoch  44 Batch  120/269 - Train Accuracy: 0.7694, Validation Accuracy: 0.7811, Loss: 0.3367
Epoch  44 Batch  130/269 - Train Accuracy: 0.7753, Validation Accuracy: 0.7812, Loss: 0.3327
Epoch  44 Batch  140/269 - Train Accuracy: 0.7746, Validation Accuracy: 0.7803, Loss: 0.3325
Epoch  44 Batch  150/269 - Train Accuracy: 0.7716, Validation Accuracy: 0.7840, Loss: 0.3229
Epoch  44 Batch  160/269 - Train Accuracy: 0.7809, Validation Accuracy: 0.7832, Loss: 0.3297
Epoch  44 Batch  170/269 - Train Accuracy: 0.7680, Validation Accuracy: 0.7867, Loss: 0.3170
Epoch  44 Batch  180/269 - Train Accuracy: 0.7845, Validation Accuracy: 0.7836, Loss: 0.3147
Epoch  44 Batch  190/269 - Train Accuracy: 0.7760, Validation Accuracy: 0.7762, Loss: 0.3242
Epoch  44 Batch  200/269 - Train Accuracy: 0.7539, Validation Accuracy: 0.7805, Loss: 0.3323
Epoch  44 Batch  210/269 - Train Accuracy: 0.7799, Validation Accuracy: 0.7810, Loss: 0.3177
Epoch  44 Batch  220/269 - Train Accuracy: 0.7876, Validation Accuracy: 0.7796, Loss: 0.3072
Epoch  44 Batch  230/269 - Train Accuracy: 0.7754, Validation Accuracy: 0.7789, Loss: 0.3241
Epoch  44 Batch  240/269 - Train Accuracy: 0.8048, Validation Accuracy: 0.7738, Loss: 0.2953
Epoch  44 Batch  250/269 - Train Accuracy: 0.7874, Validation Accuracy: 0.7818, Loss: 0.3290
Epoch  44 Batch  260/269 - Train Accuracy: 0.7546, Validation Accuracy: 0.7802, Loss: 0.3510
Epoch  45 Batch   10/269 - Train Accuracy: 0.7849, Validation Accuracy: 0.7828, Loss: 0.3268
Epoch  45 Batch   20/269 - Train Accuracy: 0.7783, Validation Accuracy: 0.7807, Loss: 0.3308
Epoch  45 Batch   30/269 - Train Accuracy: 0.7835, Validation Accuracy: 0.7784, Loss: 0.3274
Epoch  45 Batch   40/269 - Train Accuracy: 0.7851, Validation Accuracy: 0.7868, Loss: 0.3412
Epoch  45 Batch   50/269 - Train Accuracy: 0.7625, Validation Accuracy: 0.7794, Loss: 0.3484
Epoch  45 Batch   60/269 - Train Accuracy: 0.7763, Validation Accuracy: 0.7781, Loss: 0.3067
Epoch  45 Batch   70/269 - Train Accuracy: 0.7959, Validation Accuracy: 0.7765, Loss: 0.3246
Epoch  45 Batch   80/269 - Train Accuracy: 0.7817, Validation Accuracy: 0.7832, Loss: 0.3216
Epoch  45 Batch   90/269 - Train Accuracy: 0.7767, Validation Accuracy: 0.7811, Loss: 0.3369
Epoch  45 Batch  100/269 - Train Accuracy: 0.7949, Validation Accuracy: 0.7844, Loss: 0.3139
Epoch  45 Batch  110/269 - Train Accuracy: 0.7906, Validation Accuracy: 0.7800, Loss: 0.3265
Epoch  45 Batch  120/269 - Train Accuracy: 0.7751, Validation Accuracy: 0.7856, Loss: 0.3236
Epoch  45 Batch  130/269 - Train Accuracy: 0.7723, Validation Accuracy: 0.7809, Loss: 0.3334
Epoch  45 Batch  140/269 - Train Accuracy: 0.7758, Validation Accuracy: 0.7817, Loss: 0.3405
Epoch  45 Batch  150/269 - Train Accuracy: 0.7772, Validation Accuracy: 0.7858, Loss: 0.3167
Epoch  45 Batch  160/269 - Train Accuracy: 0.7737, Validation Accuracy: 0.7811, Loss: 0.3229
Epoch  45 Batch  170/269 - Train Accuracy: 0.7731, Validation Accuracy: 0.7860, Loss: 0.3105
Epoch  45 Batch  180/269 - Train Accuracy: 0.7907, Validation Accuracy: 0.7812, Loss: 0.3102
Epoch  45 Batch  190/269 - Train Accuracy: 0.7722, Validation Accuracy: 0.7769, Loss: 0.3160
Epoch  45 Batch  200/269 - Train Accuracy: 0.7579, Validation Accuracy: 0.7768, Loss: 0.3250
Epoch  45 Batch  210/269 - Train Accuracy: 0.7887, Validation Accuracy: 0.7796, Loss: 0.3112
Epoch  45 Batch  220/269 - Train Accuracy: 0.7906, Validation Accuracy: 0.7813, Loss: 0.2918
Epoch  45 Batch  230/269 - Train Accuracy: 0.7824, Validation Accuracy: 0.7840, Loss: 0.3112
Epoch  45 Batch  240/269 - Train Accuracy: 0.8066, Validation Accuracy: 0.7866, Loss: 0.2888
Epoch  45 Batch  250/269 - Train Accuracy: 0.7910, Validation Accuracy: 0.7798, Loss: 0.3219
Epoch  45 Batch  260/269 - Train Accuracy: 0.7604, Validation Accuracy: 0.7789, Loss: 0.3412
Epoch  46 Batch   10/269 - Train Accuracy: 0.7968, Validation Accuracy: 0.7866, Loss: 0.3211
Epoch  46 Batch   20/269 - Train Accuracy: 0.7765, Validation Accuracy: 0.7813, Loss: 0.3277
Epoch  46 Batch   30/269 - Train Accuracy: 0.7908, Validation Accuracy: 0.7853, Loss: 0.3217
Epoch  46 Batch   40/269 - Train Accuracy: 0.7878, Validation Accuracy: 0.7846, Loss: 0.3256
Epoch  46 Batch   50/269 - Train Accuracy: 0.7682, Validation Accuracy: 0.7868, Loss: 0.3328
Epoch  46 Batch   60/269 - Train Accuracy: 0.7794, Validation Accuracy: 0.7795, Loss: 0.3003
Epoch  46 Batch   70/269 - Train Accuracy: 0.7940, Validation Accuracy: 0.7814, Loss: 0.3113
Epoch  46 Batch   80/269 - Train Accuracy: 0.7852, Validation Accuracy: 0.7813, Loss: 0.3129
Epoch  46 Batch   90/269 - Train Accuracy: 0.7836, Validation Accuracy: 0.7875, Loss: 0.3273
Epoch  46 Batch  100/269 - Train Accuracy: 0.8032, Validation Accuracy: 0.7859, Loss: 0.3057
Epoch  46 Batch  110/269 - Train Accuracy: 0.7879, Validation Accuracy: 0.7823, Loss: 0.3165
Epoch  46 Batch  120/269 - Train Accuracy: 0.7803, Validation Accuracy: 0.7902, Loss: 0.3200
Epoch  46 Batch  130/269 - Train Accuracy: 0.7784, Validation Accuracy: 0.7862, Loss: 0.3267
Epoch  46 Batch  140/269 - Train Accuracy: 0.7788, Validation Accuracy: 0.7860, Loss: 0.3306
Epoch  46 Batch  150/269 - Train Accuracy: 0.7768, Validation Accuracy: 0.7887, Loss: 0.3084
Epoch  46 Batch  160/269 - Train Accuracy: 0.7802, Validation Accuracy: 0.7903, Loss: 0.3149
Epoch  46 Batch  170/269 - Train Accuracy: 0.7740, Validation Accuracy: 0.7900, Loss: 0.3114
Epoch  46 Batch  180/269 - Train Accuracy: 0.7975, Validation Accuracy: 0.7803, Loss: 0.3037
Epoch  46 Batch  190/269 - Train Accuracy: 0.7868, Validation Accuracy: 0.7836, Loss: 0.3077
Epoch  46 Batch  200/269 - Train Accuracy: 0.7618, Validation Accuracy: 0.7827, Loss: 0.3172
Epoch  46 Batch  210/269 - Train Accuracy: 0.7831, Validation Accuracy: 0.7838, Loss: 0.3138
Epoch  46 Batch  220/269 - Train Accuracy: 0.7928, Validation Accuracy: 0.7819, Loss: 0.2968
Epoch  46 Batch  230/269 - Train Accuracy: 0.7852, Validation Accuracy: 0.7838, Loss: 0.3093
Epoch  46 Batch  240/269 - Train Accuracy: 0.8105, Validation Accuracy: 0.7835, Loss: 0.2807
Epoch  46 Batch  250/269 - Train Accuracy: 0.7937, Validation Accuracy: 0.7869, Loss: 0.3211
Epoch  46 Batch  260/269 - Train Accuracy: 0.7633, Validation Accuracy: 0.7860, Loss: 0.3290
Epoch  47 Batch   10/269 - Train Accuracy: 0.7950, Validation Accuracy: 0.7871, Loss: 0.3100
Epoch  47 Batch   20/269 - Train Accuracy: 0.7826, Validation Accuracy: 0.7857, Loss: 0.3203
Epoch  47 Batch   30/269 - Train Accuracy: 0.7936, Validation Accuracy: 0.7931, Loss: 0.3157
Epoch  47 Batch   40/269 - Train Accuracy: 0.7881, Validation Accuracy: 0.7950, Loss: 0.3268
Epoch  47 Batch   50/269 - Train Accuracy: 0.7644, Validation Accuracy: 0.7924, Loss: 0.3337
Epoch  47 Batch   60/269 - Train Accuracy: 0.7874, Validation Accuracy: 0.7867, Loss: 0.2884
Epoch  47 Batch   70/269 - Train Accuracy: 0.7972, Validation Accuracy: 0.7847, Loss: 0.3189
Epoch  47 Batch   80/269 - Train Accuracy: 0.7891, Validation Accuracy: 0.7843, Loss: 0.3101
Epoch  47 Batch   90/269 - Train Accuracy: 0.7839, Validation Accuracy: 0.7886, Loss: 0.3252
Epoch  47 Batch  100/269 - Train Accuracy: 0.8032, Validation Accuracy: 0.7868, Loss: 0.2991
Epoch  47 Batch  110/269 - Train Accuracy: 0.7890, Validation Accuracy: 0.7887, Loss: 0.3202
Epoch  47 Batch  120/269 - Train Accuracy: 0.7829, Validation Accuracy: 0.7865, Loss: 0.3224
Epoch  47 Batch  130/269 - Train Accuracy: 0.7771, Validation Accuracy: 0.7899, Loss: 0.3240
Epoch  47 Batch  140/269 - Train Accuracy: 0.7802, Validation Accuracy: 0.7824, Loss: 0.3268
Epoch  47 Batch  150/269 - Train Accuracy: 0.7825, Validation Accuracy: 0.7919, Loss: 0.3146
Epoch  47 Batch  160/269 - Train Accuracy: 0.7852, Validation Accuracy: 0.7936, Loss: 0.3155
Epoch  47 Batch  170/269 - Train Accuracy: 0.7811, Validation Accuracy: 0.7879, Loss: 0.3061
Epoch  47 Batch  180/269 - Train Accuracy: 0.7959, Validation Accuracy: 0.7872, Loss: 0.3006
Epoch  47 Batch  190/269 - Train Accuracy: 0.7851, Validation Accuracy: 0.7861, Loss: 0.2953
Epoch  47 Batch  200/269 - Train Accuracy: 0.7609, Validation Accuracy: 0.7847, Loss: 0.3231
Epoch  47 Batch  210/269 - Train Accuracy: 0.7938, Validation Accuracy: 0.7821, Loss: 0.3068
Epoch  47 Batch  220/269 - Train Accuracy: 0.7936, Validation Accuracy: 0.7860, Loss: 0.2879
Epoch  47 Batch  230/269 - Train Accuracy: 0.7882, Validation Accuracy: 0.7818, Loss: 0.3001
Epoch  47 Batch  240/269 - Train Accuracy: 0.8079, Validation Accuracy: 0.7832, Loss: 0.2793
Epoch  47 Batch  250/269 - Train Accuracy: 0.7914, Validation Accuracy: 0.7851, Loss: 0.3190
Epoch  47 Batch  260/269 - Train Accuracy: 0.7669, Validation Accuracy: 0.7858, Loss: 0.3323
Epoch  48 Batch   10/269 - Train Accuracy: 0.7997, Validation Accuracy: 0.7900, Loss: 0.3064
Epoch  48 Batch   20/269 - Train Accuracy: 0.7876, Validation Accuracy: 0.7898, Loss: 0.3188
Epoch  48 Batch   30/269 - Train Accuracy: 0.7959, Validation Accuracy: 0.7863, Loss: 0.3098
Epoch  48 Batch   40/269 - Train Accuracy: 0.7915, Validation Accuracy: 0.7923, Loss: 0.3246
Epoch  48 Batch   50/269 - Train Accuracy: 0.7669, Validation Accuracy: 0.7958, Loss: 0.3261
Epoch  48 Batch   60/269 - Train Accuracy: 0.7895, Validation Accuracy: 0.7853, Loss: 0.2930
Epoch  48 Batch   70/269 - Train Accuracy: 0.7973, Validation Accuracy: 0.7906, Loss: 0.3002
Epoch  48 Batch   80/269 - Train Accuracy: 0.7916, Validation Accuracy: 0.7878, Loss: 0.3051
Epoch  48 Batch   90/269 - Train Accuracy: 0.7869, Validation Accuracy: 0.7901, Loss: 0.3177
Epoch  48 Batch  100/269 - Train Accuracy: 0.8039, Validation Accuracy: 0.7945, Loss: 0.3080
Epoch  48 Batch  110/269 - Train Accuracy: 0.7920, Validation Accuracy: 0.7900, Loss: 0.3098
Epoch  48 Batch  120/269 - Train Accuracy: 0.7823, Validation Accuracy: 0.7939, Loss: 0.3158
Epoch  48 Batch  130/269 - Train Accuracy: 0.7812, Validation Accuracy: 0.7862, Loss: 0.3159
Epoch  48 Batch  140/269 - Train Accuracy: 0.7858, Validation Accuracy: 0.7874, Loss: 0.3234
Epoch  48 Batch  150/269 - Train Accuracy: 0.7873, Validation Accuracy: 0.7950, Loss: 0.2950
Epoch  48 Batch  160/269 - Train Accuracy: 0.7906, Validation Accuracy: 0.7873, Loss: 0.3045
Epoch  48 Batch  170/269 - Train Accuracy: 0.7878, Validation Accuracy: 0.7907, Loss: 0.3014
Epoch  48 Batch  180/269 - Train Accuracy: 0.7975, Validation Accuracy: 0.7869, Loss: 0.2942
Epoch  48 Batch  190/269 - Train Accuracy: 0.7845, Validation Accuracy: 0.7867, Loss: 0.2950
Epoch  48 Batch  200/269 - Train Accuracy: 0.7676, Validation Accuracy: 0.7851, Loss: 0.3140
Epoch  48 Batch  210/269 - Train Accuracy: 0.7935, Validation Accuracy: 0.7854, Loss: 0.3042
Epoch  48 Batch  220/269 - Train Accuracy: 0.8030, Validation Accuracy: 0.7901, Loss: 0.2872
Epoch  48 Batch  230/269 - Train Accuracy: 0.7907, Validation Accuracy: 0.7888, Loss: 0.2976
Epoch  48 Batch  240/269 - Train Accuracy: 0.8167, Validation Accuracy: 0.7933, Loss: 0.2758
Epoch  48 Batch  250/269 - Train Accuracy: 0.7934, Validation Accuracy: 0.7847, Loss: 0.3068
Epoch  48 Batch  260/269 - Train Accuracy: 0.7707, Validation Accuracy: 0.7893, Loss: 0.3254
Epoch  49 Batch   10/269 - Train Accuracy: 0.7983, Validation Accuracy: 0.7931, Loss: 0.3072
Epoch  49 Batch   20/269 - Train Accuracy: 0.7877, Validation Accuracy: 0.7894, Loss: 0.3130
Epoch  49 Batch   30/269 - Train Accuracy: 0.7984, Validation Accuracy: 0.7899, Loss: 0.3058
Epoch  49 Batch   40/269 - Train Accuracy: 0.7863, Validation Accuracy: 0.7979, Loss: 0.3231
Epoch  49 Batch   50/269 - Train Accuracy: 0.7656, Validation Accuracy: 0.7931, Loss: 0.3258
Epoch  49 Batch   60/269 - Train Accuracy: 0.7904, Validation Accuracy: 0.7897, Loss: 0.2902
Epoch  49 Batch   70/269 - Train Accuracy: 0.8017, Validation Accuracy: 0.7931, Loss: 0.3031
Epoch  49 Batch   80/269 - Train Accuracy: 0.7954, Validation Accuracy: 0.7921, Loss: 0.2983
Epoch  49 Batch   90/269 - Train Accuracy: 0.7909, Validation Accuracy: 0.7923, Loss: 0.3126
Epoch  49 Batch  100/269 - Train Accuracy: 0.8105, Validation Accuracy: 0.8032, Loss: 0.2975
Epoch  49 Batch  110/269 - Train Accuracy: 0.7960, Validation Accuracy: 0.7989, Loss: 0.3036
Epoch  49 Batch  120/269 - Train Accuracy: 0.7867, Validation Accuracy: 0.7994, Loss: 0.3040
Epoch  49 Batch  130/269 - Train Accuracy: 0.7838, Validation Accuracy: 0.7915, Loss: 0.3127
Epoch  49 Batch  140/269 - Train Accuracy: 0.7850, Validation Accuracy: 0.7854, Loss: 0.3144
Epoch  49 Batch  150/269 - Train Accuracy: 0.7814, Validation Accuracy: 0.7908, Loss: 0.2947
Epoch  49 Batch  160/269 - Train Accuracy: 0.7945, Validation Accuracy: 0.7938, Loss: 0.3061
Epoch  49 Batch  170/269 - Train Accuracy: 0.7840, Validation Accuracy: 0.7960, Loss: 0.2985
Epoch  49 Batch  180/269 - Train Accuracy: 0.8062, Validation Accuracy: 0.7884, Loss: 0.2923
Epoch  49 Batch  190/269 - Train Accuracy: 0.7857, Validation Accuracy: 0.7907, Loss: 0.3073
Epoch  49 Batch  200/269 - Train Accuracy: 0.7715, Validation Accuracy: 0.7846, Loss: 0.3032
Epoch  49 Batch  210/269 - Train Accuracy: 0.7910, Validation Accuracy: 0.7844, Loss: 0.2903
Epoch  49 Batch  220/269 - Train Accuracy: 0.8102, Validation Accuracy: 0.7905, Loss: 0.2808
Epoch  49 Batch  230/269 - Train Accuracy: 0.7896, Validation Accuracy: 0.7897, Loss: 0.2949
Epoch  49 Batch  240/269 - Train Accuracy: 0.8168, Validation Accuracy: 0.7924, Loss: 0.2652
Epoch  49 Batch  250/269 - Train Accuracy: 0.7996, Validation Accuracy: 0.7890, Loss: 0.3033
Epoch  49 Batch  260/269 - Train Accuracy: 0.7720, Validation Accuracy: 0.7894, Loss: 0.3230
Epoch  50 Batch   10/269 - Train Accuracy: 0.7983, Validation Accuracy: 0.7957, Loss: 0.2997
Epoch  50 Batch   20/269 - Train Accuracy: 0.7886, Validation Accuracy: 0.7861, Loss: 0.3090
Epoch  50 Batch   30/269 - Train Accuracy: 0.8033, Validation Accuracy: 0.7885, Loss: 0.2955
Epoch  50 Batch   40/269 - Train Accuracy: 0.7980, Validation Accuracy: 0.7897, Loss: 0.3183
Epoch  50 Batch   50/269 - Train Accuracy: 0.7718, Validation Accuracy: 0.7941, Loss: 0.3202
Epoch  50 Batch   60/269 - Train Accuracy: 0.7850, Validation Accuracy: 0.7902, Loss: 0.2814
Epoch  50 Batch   70/269 - Train Accuracy: 0.8079, Validation Accuracy: 0.7868, Loss: 0.2945
Epoch  50 Batch   80/269 - Train Accuracy: 0.7962, Validation Accuracy: 0.7900, Loss: 0.3005
Epoch  50 Batch   90/269 - Train Accuracy: 0.7909, Validation Accuracy: 0.7920, Loss: 0.3172
Epoch  50 Batch  100/269 - Train Accuracy: 0.8082, Validation Accuracy: 0.8040, Loss: 0.2866
Epoch  50 Batch  110/269 - Train Accuracy: 0.7927, Validation Accuracy: 0.7972, Loss: 0.3010
Epoch  50 Batch  120/269 - Train Accuracy: 0.7858, Validation Accuracy: 0.7977, Loss: 0.3053
Epoch  50 Batch  130/269 - Train Accuracy: 0.7898, Validation Accuracy: 0.7944, Loss: 0.3221
Epoch  50 Batch  140/269 - Train Accuracy: 0.7897, Validation Accuracy: 0.7879, Loss: 0.3092
Epoch  50 Batch  150/269 - Train Accuracy: 0.7888, Validation Accuracy: 0.7946, Loss: 0.2882
Epoch  50 Batch  160/269 - Train Accuracy: 0.7947, Validation Accuracy: 0.7952, Loss: 0.2985
Epoch  50 Batch  170/269 - Train Accuracy: 0.7920, Validation Accuracy: 0.7992, Loss: 0.2896
Epoch  50 Batch  180/269 - Train Accuracy: 0.8033, Validation Accuracy: 0.7895, Loss: 0.2866
Epoch  50 Batch  190/269 - Train Accuracy: 0.7949, Validation Accuracy: 0.7942, Loss: 0.2873
Epoch  50 Batch  200/269 - Train Accuracy: 0.7709, Validation Accuracy: 0.7935, Loss: 0.3041
Epoch  50 Batch  210/269 - Train Accuracy: 0.7963, Validation Accuracy: 0.7953, Loss: 0.2914
Epoch  50 Batch  220/269 - Train Accuracy: 0.8025, Validation Accuracy: 0.7947, Loss: 0.2843
Epoch  50 Batch  230/269 - Train Accuracy: 0.7942, Validation Accuracy: 0.7949, Loss: 0.2907
Epoch  50 Batch  240/269 - Train Accuracy: 0.8163, Validation Accuracy: 0.7931, Loss: 0.2698
Epoch  50 Batch  250/269 - Train Accuracy: 0.8000, Validation Accuracy: 0.7945, Loss: 0.3074
Epoch  50 Batch  260/269 - Train Accuracy: 0.7677, Validation Accuracy: 0.7964, Loss: 0.3218
Epoch  51 Batch   10/269 - Train Accuracy: 0.8084, Validation Accuracy: 0.7994, Loss: 0.2951
Epoch  51 Batch   20/269 - Train Accuracy: 0.7979, Validation Accuracy: 0.7962, Loss: 0.3015
Epoch  51 Batch   30/269 - Train Accuracy: 0.8043, Validation Accuracy: 0.7858, Loss: 0.2939
Epoch  51 Batch   40/269 - Train Accuracy: 0.7981, Validation Accuracy: 0.7977, Loss: 0.3302
Epoch  51 Batch   50/269 - Train Accuracy: 0.7773, Validation Accuracy: 0.8015, Loss: 0.3129
Epoch  51 Batch   60/269 - Train Accuracy: 0.7990, Validation Accuracy: 0.7984, Loss: 0.2754
Epoch  51 Batch   70/269 - Train Accuracy: 0.8105, Validation Accuracy: 0.7978, Loss: 0.2921
Epoch  51 Batch   80/269 - Train Accuracy: 0.8002, Validation Accuracy: 0.7932, Loss: 0.2950
Epoch  51 Batch   90/269 - Train Accuracy: 0.7937, Validation Accuracy: 0.7987, Loss: 0.3032
Epoch  51 Batch  100/269 - Train Accuracy: 0.8129, Validation Accuracy: 0.8083, Loss: 0.2834
Epoch  51 Batch  110/269 - Train Accuracy: 0.7916, Validation Accuracy: 0.7924, Loss: 0.3002
Epoch  51 Batch  120/269 - Train Accuracy: 0.7912, Validation Accuracy: 0.8080, Loss: 0.3010
Epoch  51 Batch  130/269 - Train Accuracy: 0.7900, Validation Accuracy: 0.8006, Loss: 0.3142
Epoch  51 Batch  140/269 - Train Accuracy: 0.7951, Validation Accuracy: 0.7977, Loss: 0.3048
Epoch  51 Batch  150/269 - Train Accuracy: 0.7904, Validation Accuracy: 0.7969, Loss: 0.2862
Epoch  51 Batch  160/269 - Train Accuracy: 0.7990, Validation Accuracy: 0.7971, Loss: 0.3010
Epoch  51 Batch  170/269 - Train Accuracy: 0.7954, Validation Accuracy: 0.8028, Loss: 0.2807
Epoch  51 Batch  180/269 - Train Accuracy: 0.8065, Validation Accuracy: 0.7985, Loss: 0.2826
Epoch  51 Batch  190/269 - Train Accuracy: 0.7972, Validation Accuracy: 0.8016, Loss: 0.2802
Epoch  51 Batch  200/269 - Train Accuracy: 0.7755, Validation Accuracy: 0.7999, Loss: 0.2971
Epoch  51 Batch  210/269 - Train Accuracy: 0.8003, Validation Accuracy: 0.7948, Loss: 0.2862
Epoch  51 Batch  220/269 - Train Accuracy: 0.8110, Validation Accuracy: 0.7979, Loss: 0.2729
Epoch  51 Batch  230/269 - Train Accuracy: 0.7934, Validation Accuracy: 0.7950, Loss: 0.2901
Epoch  51 Batch  240/269 - Train Accuracy: 0.8156, Validation Accuracy: 0.7950, Loss: 0.2700
Epoch  51 Batch  250/269 - Train Accuracy: 0.8056, Validation Accuracy: 0.8002, Loss: 0.2893
Epoch  51 Batch  260/269 - Train Accuracy: 0.7711, Validation Accuracy: 0.7985, Loss: 0.3092
Epoch  52 Batch   10/269 - Train Accuracy: 0.8041, Validation Accuracy: 0.7968, Loss: 0.2943
Epoch  52 Batch   20/269 - Train Accuracy: 0.8007, Validation Accuracy: 0.8054, Loss: 0.2960
Epoch  52 Batch   30/269 - Train Accuracy: 0.8052, Validation Accuracy: 0.8008, Loss: 0.2905
Epoch  52 Batch   40/269 - Train Accuracy: 0.7992, Validation Accuracy: 0.8001, Loss: 0.3059
Epoch  52 Batch   50/269 - Train Accuracy: 0.7790, Validation Accuracy: 0.8055, Loss: 0.3075
Epoch  52 Batch   60/269 - Train Accuracy: 0.7960, Validation Accuracy: 0.7961, Loss: 0.2697
Epoch  52 Batch   70/269 - Train Accuracy: 0.8128, Validation Accuracy: 0.8042, Loss: 0.2916
Epoch  52 Batch   80/269 - Train Accuracy: 0.7972, Validation Accuracy: 0.7966, Loss: 0.3017
Epoch  52 Batch   90/269 - Train Accuracy: 0.7962, Validation Accuracy: 0.8001, Loss: 0.3132
Epoch  52 Batch  100/269 - Train Accuracy: 0.8108, Validation Accuracy: 0.8105, Loss: 0.2770
Epoch  52 Batch  110/269 - Train Accuracy: 0.8002, Validation Accuracy: 0.8010, Loss: 0.2959
Epoch  52 Batch  120/269 - Train Accuracy: 0.7940, Validation Accuracy: 0.8068, Loss: 0.2937
Epoch  52 Batch  130/269 - Train Accuracy: 0.7915, Validation Accuracy: 0.8017, Loss: 0.2985
Epoch  52 Batch  140/269 - Train Accuracy: 0.7974, Validation Accuracy: 0.7958, Loss: 0.3022
Epoch  52 Batch  150/269 - Train Accuracy: 0.7891, Validation Accuracy: 0.8019, Loss: 0.2867
Epoch  52 Batch  160/269 - Train Accuracy: 0.7997, Validation Accuracy: 0.8049, Loss: 0.2945
Epoch  52 Batch  170/269 - Train Accuracy: 0.7946, Validation Accuracy: 0.8064, Loss: 0.2803
Epoch  52 Batch  180/269 - Train Accuracy: 0.8063, Validation Accuracy: 0.8010, Loss: 0.2789
Epoch  52 Batch  190/269 - Train Accuracy: 0.8035, Validation Accuracy: 0.8007, Loss: 0.2750
Epoch  52 Batch  200/269 - Train Accuracy: 0.7789, Validation Accuracy: 0.8024, Loss: 0.2943
Epoch  52 Batch  210/269 - Train Accuracy: 0.8087, Validation Accuracy: 0.8012, Loss: 0.2834
Epoch  52 Batch  220/269 - Train Accuracy: 0.8136, Validation Accuracy: 0.7986, Loss: 0.2718
Epoch  52 Batch  230/269 - Train Accuracy: 0.7959, Validation Accuracy: 0.7963, Loss: 0.2795
Epoch  52 Batch  240/269 - Train Accuracy: 0.8200, Validation Accuracy: 0.8003, Loss: 0.2613
Epoch  52 Batch  250/269 - Train Accuracy: 0.8028, Validation Accuracy: 0.8006, Loss: 0.2900
Epoch  52 Batch  260/269 - Train Accuracy: 0.7803, Validation Accuracy: 0.8001, Loss: 0.2978
Epoch  53 Batch   10/269 - Train Accuracy: 0.8069, Validation Accuracy: 0.8026, Loss: 0.2853
Epoch  53 Batch   20/269 - Train Accuracy: 0.8018, Validation Accuracy: 0.8015, Loss: 0.3008
Epoch  53 Batch   30/269 - Train Accuracy: 0.8132, Validation Accuracy: 0.8070, Loss: 0.2809
Epoch  53 Batch   40/269 - Train Accuracy: 0.8051, Validation Accuracy: 0.8034, Loss: 0.3060
Epoch  53 Batch   50/269 - Train Accuracy: 0.7866, Validation Accuracy: 0.8075, Loss: 0.3003
Epoch  53 Batch   60/269 - Train Accuracy: 0.7969, Validation Accuracy: 0.7995, Loss: 0.2741
Epoch  53 Batch   70/269 - Train Accuracy: 0.8105, Validation Accuracy: 0.8041, Loss: 0.2803
Epoch  53 Batch   80/269 - Train Accuracy: 0.8012, Validation Accuracy: 0.8001, Loss: 0.2841
Epoch  53 Batch   90/269 - Train Accuracy: 0.7956, Validation Accuracy: 0.8053, Loss: 0.3048
Epoch  53 Batch  100/269 - Train Accuracy: 0.8196, Validation Accuracy: 0.8121, Loss: 0.2794
Epoch  53 Batch  110/269 - Train Accuracy: 0.7989, Validation Accuracy: 0.8061, Loss: 0.2851
Epoch  53 Batch  120/269 - Train Accuracy: 0.7968, Validation Accuracy: 0.8031, Loss: 0.2958
Epoch  53 Batch  130/269 - Train Accuracy: 0.7933, Validation Accuracy: 0.8043, Loss: 0.3056
Epoch  53 Batch  140/269 - Train Accuracy: 0.8013, Validation Accuracy: 0.8026, Loss: 0.3024
Epoch  53 Batch  150/269 - Train Accuracy: 0.7944, Validation Accuracy: 0.8022, Loss: 0.2855
Epoch  53 Batch  160/269 - Train Accuracy: 0.8012, Validation Accuracy: 0.8050, Loss: 0.2973
Epoch  53 Batch  170/269 - Train Accuracy: 0.8039, Validation Accuracy: 0.8081, Loss: 0.2850
Epoch  53 Batch  180/269 - Train Accuracy: 0.8122, Validation Accuracy: 0.8028, Loss: 0.2791
Epoch  53 Batch  190/269 - Train Accuracy: 0.8074, Validation Accuracy: 0.8089, Loss: 0.2809
Epoch  53 Batch  200/269 - Train Accuracy: 0.7851, Validation Accuracy: 0.8032, Loss: 0.2952
Epoch  53 Batch  210/269 - Train Accuracy: 0.8099, Validation Accuracy: 0.8000, Loss: 0.2786
Epoch  53 Batch  220/269 - Train Accuracy: 0.8129, Validation Accuracy: 0.7978, Loss: 0.2705
Epoch  53 Batch  230/269 - Train Accuracy: 0.7981, Validation Accuracy: 0.7995, Loss: 0.2831
Epoch  53 Batch  240/269 - Train Accuracy: 0.8201, Validation Accuracy: 0.8012, Loss: 0.2573
Epoch  53 Batch  250/269 - Train Accuracy: 0.8058, Validation Accuracy: 0.8073, Loss: 0.2860
Epoch  53 Batch  260/269 - Train Accuracy: 0.7755, Validation Accuracy: 0.8026, Loss: 0.3051
Epoch  54 Batch   10/269 - Train Accuracy: 0.8062, Validation Accuracy: 0.8051, Loss: 0.2848
Epoch  54 Batch   20/269 - Train Accuracy: 0.8067, Validation Accuracy: 0.8062, Loss: 0.2928
Epoch  54 Batch   30/269 - Train Accuracy: 0.8096, Validation Accuracy: 0.8041, Loss: 0.2846
Epoch  54 Batch   40/269 - Train Accuracy: 0.7981, Validation Accuracy: 0.8059, Loss: 0.3089
Epoch  54 Batch   50/269 - Train Accuracy: 0.7852, Validation Accuracy: 0.8095, Loss: 0.3024
Epoch  54 Batch   60/269 - Train Accuracy: 0.8050, Validation Accuracy: 0.8038, Loss: 0.2680
Epoch  54 Batch   70/269 - Train Accuracy: 0.8131, Validation Accuracy: 0.7979, Loss: 0.2874
Epoch  54 Batch   80/269 - Train Accuracy: 0.8043, Validation Accuracy: 0.8058, Loss: 0.2801
Epoch  54 Batch   90/269 - Train Accuracy: 0.8008, Validation Accuracy: 0.8160, Loss: 0.2901
Epoch  54 Batch  100/269 - Train Accuracy: 0.8259, Validation Accuracy: 0.8106, Loss: 0.2730
Epoch  54 Batch  110/269 - Train Accuracy: 0.8004, Validation Accuracy: 0.8068, Loss: 0.2871
Epoch  54 Batch  120/269 - Train Accuracy: 0.7937, Validation Accuracy: 0.8036, Loss: 0.2904
Epoch  54 Batch  130/269 - Train Accuracy: 0.7933, Validation Accuracy: 0.8043, Loss: 0.2994
Epoch  54 Batch  140/269 - Train Accuracy: 0.8023, Validation Accuracy: 0.8047, Loss: 0.2869
Epoch  54 Batch  150/269 - Train Accuracy: 0.7950, Validation Accuracy: 0.8089, Loss: 0.2767
Epoch  54 Batch  160/269 - Train Accuracy: 0.8062, Validation Accuracy: 0.8117, Loss: 0.2898
Epoch  54 Batch  170/269 - Train Accuracy: 0.8025, Validation Accuracy: 0.8088, Loss: 0.2782
Epoch  54 Batch  180/269 - Train Accuracy: 0.8108, Validation Accuracy: 0.8053, Loss: 0.2708
Epoch  54 Batch  190/269 - Train Accuracy: 0.8095, Validation Accuracy: 0.8051, Loss: 0.2828
Epoch  54 Batch  200/269 - Train Accuracy: 0.7869, Validation Accuracy: 0.7994, Loss: 0.2917
Epoch  54 Batch  210/269 - Train Accuracy: 0.8155, Validation Accuracy: 0.8072, Loss: 0.2800
Epoch  54 Batch  220/269 - Train Accuracy: 0.8186, Validation Accuracy: 0.8038, Loss: 0.2686
Epoch  54 Batch  230/269 - Train Accuracy: 0.7995, Validation Accuracy: 0.8063, Loss: 0.2789
Epoch  54 Batch  240/269 - Train Accuracy: 0.8226, Validation Accuracy: 0.8109, Loss: 0.2503
Epoch  54 Batch  250/269 - Train Accuracy: 0.8104, Validation Accuracy: 0.8055, Loss: 0.2811
Epoch  54 Batch  260/269 - Train Accuracy: 0.7729, Validation Accuracy: 0.8061, Loss: 0.2990
Epoch  55 Batch   10/269 - Train Accuracy: 0.8045, Validation Accuracy: 0.8077, Loss: 0.2796
Epoch  55 Batch   20/269 - Train Accuracy: 0.8059, Validation Accuracy: 0.8075, Loss: 0.2824
Epoch  55 Batch   30/269 - Train Accuracy: 0.8097, Validation Accuracy: 0.8059, Loss: 0.2754
Epoch  55 Batch   40/269 - Train Accuracy: 0.8081, Validation Accuracy: 0.8083, Loss: 0.2930
Epoch  55 Batch   50/269 - Train Accuracy: 0.7822, Validation Accuracy: 0.8072, Loss: 0.3015
Epoch  55 Batch   60/269 - Train Accuracy: 0.8078, Validation Accuracy: 0.8050, Loss: 0.2655
Epoch  55 Batch   70/269 - Train Accuracy: 0.8196, Validation Accuracy: 0.8108, Loss: 0.2806
Epoch  55 Batch   80/269 - Train Accuracy: 0.8015, Validation Accuracy: 0.8037, Loss: 0.2835
Epoch  55 Batch   90/269 - Train Accuracy: 0.7966, Validation Accuracy: 0.8085, Loss: 0.2978
Epoch  55 Batch  100/269 - Train Accuracy: 0.8155, Validation Accuracy: 0.8095, Loss: 0.2668
Epoch  55 Batch  110/269 - Train Accuracy: 0.8020, Validation Accuracy: 0.8073, Loss: 0.2851
Epoch  55 Batch  120/269 - Train Accuracy: 0.8072, Validation Accuracy: 0.8082, Loss: 0.2853
Epoch  55 Batch  130/269 - Train Accuracy: 0.8049, Validation Accuracy: 0.8099, Loss: 0.2875
Epoch  55 Batch  140/269 - Train Accuracy: 0.8083, Validation Accuracy: 0.8137, Loss: 0.2977
Epoch  55 Batch  150/269 - Train Accuracy: 0.7968, Validation Accuracy: 0.8134, Loss: 0.2768
Epoch  55 Batch  160/269 - Train Accuracy: 0.8056, Validation Accuracy: 0.8097, Loss: 0.2784
Epoch  55 Batch  170/269 - Train Accuracy: 0.8012, Validation Accuracy: 0.8047, Loss: 0.2757
Epoch  55 Batch  180/269 - Train Accuracy: 0.8117, Validation Accuracy: 0.8028, Loss: 0.2669
Epoch  55 Batch  190/269 - Train Accuracy: 0.8160, Validation Accuracy: 0.8099, Loss: 0.2741
Epoch  55 Batch  200/269 - Train Accuracy: 0.7854, Validation Accuracy: 0.8070, Loss: 0.2826
Epoch  55 Batch  210/269 - Train Accuracy: 0.8105, Validation Accuracy: 0.8072, Loss: 0.2697
Epoch  55 Batch  220/269 - Train Accuracy: 0.8200, Validation Accuracy: 0.8097, Loss: 0.2643
Epoch  55 Batch  230/269 - Train Accuracy: 0.8011, Validation Accuracy: 0.8070, Loss: 0.2774
Epoch  55 Batch  240/269 - Train Accuracy: 0.8197, Validation Accuracy: 0.8107, Loss: 0.2527
Epoch  55 Batch  250/269 - Train Accuracy: 0.8110, Validation Accuracy: 0.8058, Loss: 0.2740
Epoch  55 Batch  260/269 - Train Accuracy: 0.7796, Validation Accuracy: 0.8084, Loss: 0.2886
Epoch  56 Batch   10/269 - Train Accuracy: 0.8119, Validation Accuracy: 0.8105, Loss: 0.2714
Epoch  56 Batch   20/269 - Train Accuracy: 0.8140, Validation Accuracy: 0.8093, Loss: 0.2804
Epoch  56 Batch   30/269 - Train Accuracy: 0.8110, Validation Accuracy: 0.8038, Loss: 0.2784
Epoch  56 Batch   40/269 - Train Accuracy: 0.8062, Validation Accuracy: 0.8137, Loss: 0.2862
Epoch  56 Batch   50/269 - Train Accuracy: 0.7854, Validation Accuracy: 0.8076, Loss: 0.2948
Epoch  56 Batch   60/269 - Train Accuracy: 0.8055, Validation Accuracy: 0.8112, Loss: 0.2663
Epoch  56 Batch   70/269 - Train Accuracy: 0.8163, Validation Accuracy: 0.8131, Loss: 0.2742
Epoch  56 Batch   80/269 - Train Accuracy: 0.8029, Validation Accuracy: 0.8034, Loss: 0.2789
Epoch  56 Batch   90/269 - Train Accuracy: 0.8047, Validation Accuracy: 0.8141, Loss: 0.2925
Epoch  56 Batch  100/269 - Train Accuracy: 0.8246, Validation Accuracy: 0.8126, Loss: 0.2690
Epoch  56 Batch  110/269 - Train Accuracy: 0.8018, Validation Accuracy: 0.8102, Loss: 0.2804
Epoch  56 Batch  120/269 - Train Accuracy: 0.8003, Validation Accuracy: 0.8113, Loss: 0.2822
Epoch  56 Batch  130/269 - Train Accuracy: 0.8049, Validation Accuracy: 0.8113, Loss: 0.2904
Epoch  56 Batch  140/269 - Train Accuracy: 0.8062, Validation Accuracy: 0.8059, Loss: 0.2835
Epoch  56 Batch  150/269 - Train Accuracy: 0.7991, Validation Accuracy: 0.8200, Loss: 0.2696
Epoch  56 Batch  160/269 - Train Accuracy: 0.8096, Validation Accuracy: 0.8121, Loss: 0.2807
Epoch  56 Batch  170/269 - Train Accuracy: 0.8003, Validation Accuracy: 0.8158, Loss: 0.2704
Epoch  56 Batch  180/269 - Train Accuracy: 0.8164, Validation Accuracy: 0.8069, Loss: 0.2638
Epoch  56 Batch  190/269 - Train Accuracy: 0.8137, Validation Accuracy: 0.8141, Loss: 0.2710
Epoch  56 Batch  200/269 - Train Accuracy: 0.7922, Validation Accuracy: 0.8149, Loss: 0.2756
Epoch  56 Batch  210/269 - Train Accuracy: 0.8171, Validation Accuracy: 0.8176, Loss: 0.2719
Epoch  56 Batch  220/269 - Train Accuracy: 0.8197, Validation Accuracy: 0.8126, Loss: 0.2555
Epoch  56 Batch  230/269 - Train Accuracy: 0.8082, Validation Accuracy: 0.8058, Loss: 0.2608
Epoch  56 Batch  240/269 - Train Accuracy: 0.8227, Validation Accuracy: 0.8153, Loss: 0.2442
Epoch  56 Batch  250/269 - Train Accuracy: 0.8131, Validation Accuracy: 0.8151, Loss: 0.2760
Epoch  56 Batch  260/269 - Train Accuracy: 0.7830, Validation Accuracy: 0.8182, Loss: 0.2901
Epoch  57 Batch   10/269 - Train Accuracy: 0.8177, Validation Accuracy: 0.8093, Loss: 0.2703
Epoch  57 Batch   20/269 - Train Accuracy: 0.8117, Validation Accuracy: 0.8117, Loss: 0.2760
Epoch  57 Batch   30/269 - Train Accuracy: 0.8132, Validation Accuracy: 0.8113, Loss: 0.2677
Epoch  57 Batch   40/269 - Train Accuracy: 0.8128, Validation Accuracy: 0.8147, Loss: 0.2896
Epoch  57 Batch   50/269 - Train Accuracy: 0.7913, Validation Accuracy: 0.8127, Loss: 0.2872
Epoch  57 Batch   60/269 - Train Accuracy: 0.8154, Validation Accuracy: 0.8115, Loss: 0.2592
Epoch  57 Batch   70/269 - Train Accuracy: 0.8204, Validation Accuracy: 0.8138, Loss: 0.2678
Epoch  57 Batch   80/269 - Train Accuracy: 0.8076, Validation Accuracy: 0.8098, Loss: 0.2805
Epoch  57 Batch   90/269 - Train Accuracy: 0.8048, Validation Accuracy: 0.8124, Loss: 0.2784
Epoch  57 Batch  100/269 - Train Accuracy: 0.8260, Validation Accuracy: 0.8192, Loss: 0.2625
Epoch  57 Batch  110/269 - Train Accuracy: 0.8011, Validation Accuracy: 0.8162, Loss: 0.2749
Epoch  57 Batch  120/269 - Train Accuracy: 0.8101, Validation Accuracy: 0.8098, Loss: 0.2779
Epoch  57 Batch  130/269 - Train Accuracy: 0.8063, Validation Accuracy: 0.8058, Loss: 0.2880
Epoch  57 Batch  140/269 - Train Accuracy: 0.8134, Validation Accuracy: 0.8105, Loss: 0.2797
Epoch  57 Batch  150/269 - Train Accuracy: 0.7993, Validation Accuracy: 0.8171, Loss: 0.2643
Epoch  57 Batch  160/269 - Train Accuracy: 0.8152, Validation Accuracy: 0.8208, Loss: 0.2726
Epoch  57 Batch  170/269 - Train Accuracy: 0.8041, Validation Accuracy: 0.8121, Loss: 0.2596
Epoch  57 Batch  180/269 - Train Accuracy: 0.8205, Validation Accuracy: 0.8122, Loss: 0.2596
Epoch  57 Batch  190/269 - Train Accuracy: 0.8196, Validation Accuracy: 0.8172, Loss: 0.2689
Epoch  57 Batch  200/269 - Train Accuracy: 0.7907, Validation Accuracy: 0.8177, Loss: 0.2686
Epoch  57 Batch  210/269 - Train Accuracy: 0.8227, Validation Accuracy: 0.8126, Loss: 0.2615
Epoch  57 Batch  220/269 - Train Accuracy: 0.8081, Validation Accuracy: 0.8025, Loss: 0.2626
Epoch  57 Batch  230/269 - Train Accuracy: 0.8041, Validation Accuracy: 0.8039, Loss: 0.2775
Epoch  57 Batch  240/269 - Train Accuracy: 0.8240, Validation Accuracy: 0.8090, Loss: 0.2436
Epoch  57 Batch  250/269 - Train Accuracy: 0.8123, Validation Accuracy: 0.8093, Loss: 0.2823
Epoch  57 Batch  260/269 - Train Accuracy: 0.7800, Validation Accuracy: 0.8117, Loss: 0.2857
Epoch  58 Batch   10/269 - Train Accuracy: 0.8156, Validation Accuracy: 0.8104, Loss: 0.2688
Epoch  58 Batch   20/269 - Train Accuracy: 0.8128, Validation Accuracy: 0.8104, Loss: 0.2750
Epoch  58 Batch   30/269 - Train Accuracy: 0.8114, Validation Accuracy: 0.8074, Loss: 0.2671
Epoch  58 Batch   40/269 - Train Accuracy: 0.8152, Validation Accuracy: 0.8132, Loss: 0.2802
Epoch  58 Batch   50/269 - Train Accuracy: 0.7981, Validation Accuracy: 0.8206, Loss: 0.2869
Epoch  58 Batch   60/269 - Train Accuracy: 0.8070, Validation Accuracy: 0.8061, Loss: 0.2560
Epoch  58 Batch   70/269 - Train Accuracy: 0.8208, Validation Accuracy: 0.8133, Loss: 0.2678
Epoch  58 Batch   80/269 - Train Accuracy: 0.8078, Validation Accuracy: 0.8077, Loss: 0.2747
Epoch  58 Batch   90/269 - Train Accuracy: 0.8055, Validation Accuracy: 0.8175, Loss: 0.2837
Epoch  58 Batch  100/269 - Train Accuracy: 0.8244, Validation Accuracy: 0.8099, Loss: 0.2637
Epoch  58 Batch  110/269 - Train Accuracy: 0.8058, Validation Accuracy: 0.8219, Loss: 0.2710
Epoch  58 Batch  120/269 - Train Accuracy: 0.8030, Validation Accuracy: 0.8156, Loss: 0.2707
Epoch  58 Batch  130/269 - Train Accuracy: 0.8124, Validation Accuracy: 0.8130, Loss: 0.2774
Epoch  58 Batch  140/269 - Train Accuracy: 0.8048, Validation Accuracy: 0.8125, Loss: 0.2775
Epoch  58 Batch  150/269 - Train Accuracy: 0.8019, Validation Accuracy: 0.8165, Loss: 0.2680
Epoch  58 Batch  160/269 - Train Accuracy: 0.8176, Validation Accuracy: 0.8146, Loss: 0.2700
Epoch  58 Batch  170/269 - Train Accuracy: 0.7966, Validation Accuracy: 0.8178, Loss: 0.2589
Epoch  58 Batch  180/269 - Train Accuracy: 0.8189, Validation Accuracy: 0.8094, Loss: 0.2556
Epoch  58 Batch  190/269 - Train Accuracy: 0.8261, Validation Accuracy: 0.8205, Loss: 0.2669
Epoch  58 Batch  200/269 - Train Accuracy: 0.7942, Validation Accuracy: 0.8193, Loss: 0.2734
Epoch  58 Batch  210/269 - Train Accuracy: 0.8238, Validation Accuracy: 0.8106, Loss: 0.2642
Epoch  58 Batch  220/269 - Train Accuracy: 0.8199, Validation Accuracy: 0.8129, Loss: 0.2596
Epoch  58 Batch  230/269 - Train Accuracy: 0.8125, Validation Accuracy: 0.8059, Loss: 0.2653
Epoch  58 Batch  240/269 - Train Accuracy: 0.8308, Validation Accuracy: 0.8180, Loss: 0.2401
Epoch  58 Batch  250/269 - Train Accuracy: 0.8100, Validation Accuracy: 0.8148, Loss: 0.2724
Epoch  58 Batch  260/269 - Train Accuracy: 0.7838, Validation Accuracy: 0.8139, Loss: 0.2812
Epoch  59 Batch   10/269 - Train Accuracy: 0.8186, Validation Accuracy: 0.8110, Loss: 0.2658
Epoch  59 Batch   20/269 - Train Accuracy: 0.8249, Validation Accuracy: 0.8132, Loss: 0.2778
Epoch  59 Batch   30/269 - Train Accuracy: 0.8122, Validation Accuracy: 0.8122, Loss: 0.2676
Epoch  59 Batch   40/269 - Train Accuracy: 0.8151, Validation Accuracy: 0.8148, Loss: 0.2819
Epoch  59 Batch   50/269 - Train Accuracy: 0.7953, Validation Accuracy: 0.8145, Loss: 0.2879
Epoch  59 Batch   60/269 - Train Accuracy: 0.8160, Validation Accuracy: 0.8154, Loss: 0.2592
Epoch  59 Batch   70/269 - Train Accuracy: 0.8175, Validation Accuracy: 0.8123, Loss: 0.2584
Epoch  59 Batch   80/269 - Train Accuracy: 0.8057, Validation Accuracy: 0.8082, Loss: 0.2636
Epoch  59 Batch   90/269 - Train Accuracy: 0.8062, Validation Accuracy: 0.8146, Loss: 0.2769
Epoch  59 Batch  100/269 - Train Accuracy: 0.8274, Validation Accuracy: 0.8190, Loss: 0.2608
Epoch  59 Batch  110/269 - Train Accuracy: 0.8060, Validation Accuracy: 0.8173, Loss: 0.2742
Epoch  59 Batch  120/269 - Train Accuracy: 0.8047, Validation Accuracy: 0.8172, Loss: 0.2704
Epoch  59 Batch  130/269 - Train Accuracy: 0.8150, Validation Accuracy: 0.8211, Loss: 0.2776
Epoch  59 Batch  140/269 - Train Accuracy: 0.8091, Validation Accuracy: 0.8142, Loss: 0.2829
Epoch  59 Batch  150/269 - Train Accuracy: 0.8025, Validation Accuracy: 0.8220, Loss: 0.2629
Epoch  59 Batch  160/269 - Train Accuracy: 0.8108, Validation Accuracy: 0.8176, Loss: 0.2644
Epoch  59 Batch  170/269 - Train Accuracy: 0.8040, Validation Accuracy: 0.8148, Loss: 0.2626
Epoch  59 Batch  180/269 - Train Accuracy: 0.8165, Validation Accuracy: 0.8122, Loss: 0.2516
Epoch  59 Batch  190/269 - Train Accuracy: 0.8254, Validation Accuracy: 0.8201, Loss: 0.2540
Epoch  59 Batch  200/269 - Train Accuracy: 0.7906, Validation Accuracy: 0.8113, Loss: 0.2688
Epoch  59 Batch  210/269 - Train Accuracy: 0.8281, Validation Accuracy: 0.8189, Loss: 0.2589
Epoch  59 Batch  220/269 - Train Accuracy: 0.8202, Validation Accuracy: 0.8097, Loss: 0.2478
Epoch  59 Batch  230/269 - Train Accuracy: 0.8122, Validation Accuracy: 0.8130, Loss: 0.2505
Epoch  59 Batch  240/269 - Train Accuracy: 0.8310, Validation Accuracy: 0.8233, Loss: 0.2411
Epoch  59 Batch  250/269 - Train Accuracy: 0.8106, Validation Accuracy: 0.8184, Loss: 0.2659
Epoch  59 Batch  260/269 - Train Accuracy: 0.7854, Validation Accuracy: 0.8188, Loss: 0.2807
Epoch  60 Batch   10/269 - Train Accuracy: 0.8299, Validation Accuracy: 0.8146, Loss: 0.2760
Epoch  60 Batch   20/269 - Train Accuracy: 0.8139, Validation Accuracy: 0.8176, Loss: 0.2686
Epoch  60 Batch   30/269 - Train Accuracy: 0.8138, Validation Accuracy: 0.8156, Loss: 0.2628
Epoch  60 Batch   40/269 - Train Accuracy: 0.8159, Validation Accuracy: 0.8144, Loss: 0.2742
Epoch  60 Batch   50/269 - Train Accuracy: 0.7907, Validation Accuracy: 0.8198, Loss: 0.2803
Epoch  60 Batch   60/269 - Train Accuracy: 0.8105, Validation Accuracy: 0.8197, Loss: 0.2476
Epoch  60 Batch   70/269 - Train Accuracy: 0.8282, Validation Accuracy: 0.8184, Loss: 0.2555
Epoch  60 Batch   80/269 - Train Accuracy: 0.8071, Validation Accuracy: 0.8113, Loss: 0.2634
Epoch  60 Batch   90/269 - Train Accuracy: 0.8065, Validation Accuracy: 0.8143, Loss: 0.2756
Epoch  60 Batch  100/269 - Train Accuracy: 0.8245, Validation Accuracy: 0.8158, Loss: 0.2533
Epoch  60 Batch  110/269 - Train Accuracy: 0.8022, Validation Accuracy: 0.8182, Loss: 0.2619
Epoch  60 Batch  120/269 - Train Accuracy: 0.8155, Validation Accuracy: 0.8281, Loss: 0.2680
Epoch  60 Batch  130/269 - Train Accuracy: 0.8166, Validation Accuracy: 0.8159, Loss: 0.2752
Epoch  60 Batch  140/269 - Train Accuracy: 0.8148, Validation Accuracy: 0.8224, Loss: 0.2733
Epoch  60 Batch  150/269 - Train Accuracy: 0.8058, Validation Accuracy: 0.8145, Loss: 0.2620
Epoch  60 Batch  160/269 - Train Accuracy: 0.8169, Validation Accuracy: 0.8203, Loss: 0.2686
Epoch  60 Batch  170/269 - Train Accuracy: 0.8010, Validation Accuracy: 0.8250, Loss: 0.2555
Epoch  60 Batch  180/269 - Train Accuracy: 0.8200, Validation Accuracy: 0.8115, Loss: 0.2457
Epoch  60 Batch  190/269 - Train Accuracy: 0.8177, Validation Accuracy: 0.8184, Loss: 0.2478
Epoch  60 Batch  200/269 - Train Accuracy: 0.7928, Validation Accuracy: 0.8225, Loss: 0.2644
Epoch  60 Batch  210/269 - Train Accuracy: 0.8207, Validation Accuracy: 0.8224, Loss: 0.2561
Epoch  60 Batch  220/269 - Train Accuracy: 0.8244, Validation Accuracy: 0.8119, Loss: 0.2408
Epoch  60 Batch  230/269 - Train Accuracy: 0.8177, Validation Accuracy: 0.8137, Loss: 0.2492
Epoch  60 Batch  240/269 - Train Accuracy: 0.8367, Validation Accuracy: 0.8250, Loss: 0.2385
Epoch  60 Batch  250/269 - Train Accuracy: 0.8166, Validation Accuracy: 0.8139, Loss: 0.2642
Epoch  60 Batch  260/269 - Train Accuracy: 0.7854, Validation Accuracy: 0.8224, Loss: 0.2820
Epoch  61 Batch   10/269 - Train Accuracy: 0.8228, Validation Accuracy: 0.8232, Loss: 0.2558
Epoch  61 Batch   20/269 - Train Accuracy: 0.8239, Validation Accuracy: 0.8114, Loss: 0.2697
Epoch  61 Batch   30/269 - Train Accuracy: 0.8190, Validation Accuracy: 0.8156, Loss: 0.2513
Epoch  61 Batch   40/269 - Train Accuracy: 0.8144, Validation Accuracy: 0.8224, Loss: 0.2782
Epoch  61 Batch   50/269 - Train Accuracy: 0.7896, Validation Accuracy: 0.8209, Loss: 0.2725
Epoch  61 Batch   60/269 - Train Accuracy: 0.8139, Validation Accuracy: 0.8160, Loss: 0.2492
Epoch  61 Batch   70/269 - Train Accuracy: 0.8280, Validation Accuracy: 0.8240, Loss: 0.2601
Epoch  61 Batch   80/269 - Train Accuracy: 0.8096, Validation Accuracy: 0.8127, Loss: 0.2597
Epoch  61 Batch   90/269 - Train Accuracy: 0.8171, Validation Accuracy: 0.8255, Loss: 0.2729
Epoch  61 Batch  100/269 - Train Accuracy: 0.8232, Validation Accuracy: 0.8178, Loss: 0.2532
Epoch  61 Batch  110/269 - Train Accuracy: 0.8120, Validation Accuracy: 0.8226, Loss: 0.2585
Epoch  61 Batch  120/269 - Train Accuracy: 0.8121, Validation Accuracy: 0.8228, Loss: 0.2651
Epoch  61 Batch  130/269 - Train Accuracy: 0.8190, Validation Accuracy: 0.8201, Loss: 0.2727
Epoch  61 Batch  140/269 - Train Accuracy: 0.8114, Validation Accuracy: 0.8227, Loss: 0.2706
Epoch  61 Batch  150/269 - Train Accuracy: 0.8126, Validation Accuracy: 0.8204, Loss: 0.2532
Epoch  61 Batch  160/269 - Train Accuracy: 0.8198, Validation Accuracy: 0.8229, Loss: 0.2605
Epoch  61 Batch  170/269 - Train Accuracy: 0.8083, Validation Accuracy: 0.8237, Loss: 0.2448
Epoch  61 Batch  180/269 - Train Accuracy: 0.8275, Validation Accuracy: 0.8236, Loss: 0.2488
Epoch  61 Batch  190/269 - Train Accuracy: 0.8248, Validation Accuracy: 0.8206, Loss: 0.2547
Epoch  61 Batch  200/269 - Train Accuracy: 0.7991, Validation Accuracy: 0.8197, Loss: 0.2576
Epoch  61 Batch  210/269 - Train Accuracy: 0.8270, Validation Accuracy: 0.8178, Loss: 0.2517
Epoch  61 Batch  220/269 - Train Accuracy: 0.8228, Validation Accuracy: 0.8121, Loss: 0.2447
Epoch  61 Batch  230/269 - Train Accuracy: 0.8136, Validation Accuracy: 0.8152, Loss: 0.2518
Epoch  61 Batch  240/269 - Train Accuracy: 0.8377, Validation Accuracy: 0.8211, Loss: 0.2430
Epoch  61 Batch  250/269 - Train Accuracy: 0.8207, Validation Accuracy: 0.8208, Loss: 0.2646
Epoch  61 Batch  260/269 - Train Accuracy: 0.7979, Validation Accuracy: 0.8241, Loss: 0.2729
Epoch  62 Batch   10/269 - Train Accuracy: 0.8200, Validation Accuracy: 0.8160, Loss: 0.2598
Epoch  62 Batch   20/269 - Train Accuracy: 0.8224, Validation Accuracy: 0.8186, Loss: 0.2635
Epoch  62 Batch   30/269 - Train Accuracy: 0.8211, Validation Accuracy: 0.8208, Loss: 0.2539
Epoch  62 Batch   40/269 - Train Accuracy: 0.8151, Validation Accuracy: 0.8241, Loss: 0.2692
Epoch  62 Batch   50/269 - Train Accuracy: 0.7973, Validation Accuracy: 0.8207, Loss: 0.2686
Epoch  62 Batch   60/269 - Train Accuracy: 0.8181, Validation Accuracy: 0.8166, Loss: 0.2426
Epoch  62 Batch   70/269 - Train Accuracy: 0.8318, Validation Accuracy: 0.8176, Loss: 0.2535
Epoch  62 Batch   80/269 - Train Accuracy: 0.8110, Validation Accuracy: 0.8117, Loss: 0.2542
Epoch  62 Batch   90/269 - Train Accuracy: 0.8088, Validation Accuracy: 0.8210, Loss: 0.2711
Epoch  62 Batch  100/269 - Train Accuracy: 0.8269, Validation Accuracy: 0.8216, Loss: 0.2448
Epoch  62 Batch  110/269 - Train Accuracy: 0.8076, Validation Accuracy: 0.8232, Loss: 0.2547
Epoch  62 Batch  120/269 - Train Accuracy: 0.8127, Validation Accuracy: 0.8231, Loss: 0.2684
Epoch  62 Batch  130/269 - Train Accuracy: 0.8191, Validation Accuracy: 0.8281, Loss: 0.2693
Epoch  62 Batch  140/269 - Train Accuracy: 0.8176, Validation Accuracy: 0.8195, Loss: 0.2668
Epoch  62 Batch  150/269 - Train Accuracy: 0.8111, Validation Accuracy: 0.8215, Loss: 0.2471
Epoch  62 Batch  160/269 - Train Accuracy: 0.8171, Validation Accuracy: 0.8258, Loss: 0.2568
Epoch  62 Batch  170/269 - Train Accuracy: 0.8048, Validation Accuracy: 0.8130, Loss: 0.2460
Epoch  62 Batch  180/269 - Train Accuracy: 0.8276, Validation Accuracy: 0.8188, Loss: 0.2429
Epoch  62 Batch  190/269 - Train Accuracy: 0.8275, Validation Accuracy: 0.8208, Loss: 0.2432
Epoch  62 Batch  200/269 - Train Accuracy: 0.8034, Validation Accuracy: 0.8229, Loss: 0.2577
Epoch  62 Batch  210/269 - Train Accuracy: 0.8314, Validation Accuracy: 0.8227, Loss: 0.2547
Epoch  62 Batch  220/269 - Train Accuracy: 0.8219, Validation Accuracy: 0.8145, Loss: 0.2433
Epoch  62 Batch  230/269 - Train Accuracy: 0.8171, Validation Accuracy: 0.8167, Loss: 0.2505
Epoch  62 Batch  240/269 - Train Accuracy: 0.8369, Validation Accuracy: 0.8188, Loss: 0.2314
Epoch  62 Batch  250/269 - Train Accuracy: 0.8197, Validation Accuracy: 0.8176, Loss: 0.2569
Epoch  62 Batch  260/269 - Train Accuracy: 0.7887, Validation Accuracy: 0.8208, Loss: 0.2812
Epoch  63 Batch   10/269 - Train Accuracy: 0.8266, Validation Accuracy: 0.8176, Loss: 0.2509
Epoch  63 Batch   20/269 - Train Accuracy: 0.8284, Validation Accuracy: 0.8231, Loss: 0.2543
Epoch  63 Batch   30/269 - Train Accuracy: 0.8209, Validation Accuracy: 0.8207, Loss: 0.2553
Epoch  63 Batch   40/269 - Train Accuracy: 0.8133, Validation Accuracy: 0.8261, Loss: 0.2713
Epoch  63 Batch   50/269 - Train Accuracy: 0.7959, Validation Accuracy: 0.8246, Loss: 0.2781
Epoch  63 Batch   60/269 - Train Accuracy: 0.8169, Validation Accuracy: 0.8238, Loss: 0.2354
Epoch  63 Batch   70/269 - Train Accuracy: 0.8229, Validation Accuracy: 0.8204, Loss: 0.2506
Epoch  63 Batch   80/269 - Train Accuracy: 0.8145, Validation Accuracy: 0.8153, Loss: 0.2500
Epoch  63 Batch   90/269 - Train Accuracy: 0.8213, Validation Accuracy: 0.8232, Loss: 0.2676
Epoch  63 Batch  100/269 - Train Accuracy: 0.8288, Validation Accuracy: 0.8246, Loss: 0.2451
Epoch  63 Batch  110/269 - Train Accuracy: 0.8169, Validation Accuracy: 0.8239, Loss: 0.2591
Epoch  63 Batch  120/269 - Train Accuracy: 0.8145, Validation Accuracy: 0.8232, Loss: 0.2612
Epoch  63 Batch  130/269 - Train Accuracy: 0.8184, Validation Accuracy: 0.8243, Loss: 0.2676
Epoch  63 Batch  140/269 - Train Accuracy: 0.8177, Validation Accuracy: 0.8191, Loss: 0.2675
Epoch  63 Batch  150/269 - Train Accuracy: 0.8185, Validation Accuracy: 0.8282, Loss: 0.2435
Epoch  63 Batch  160/269 - Train Accuracy: 0.8185, Validation Accuracy: 0.8265, Loss: 0.2571
Epoch  63 Batch  170/269 - Train Accuracy: 0.8013, Validation Accuracy: 0.8169, Loss: 0.2450
Epoch  63 Batch  180/269 - Train Accuracy: 0.8318, Validation Accuracy: 0.8145, Loss: 0.2389
Epoch  63 Batch  190/269 - Train Accuracy: 0.8266, Validation Accuracy: 0.8291, Loss: 0.2451
Epoch  63 Batch  200/269 - Train Accuracy: 0.7988, Validation Accuracy: 0.8165, Loss: 0.2562
Epoch  63 Batch  210/269 - Train Accuracy: 0.8291, Validation Accuracy: 0.8229, Loss: 0.2529
Epoch  63 Batch  220/269 - Train Accuracy: 0.8312, Validation Accuracy: 0.8144, Loss: 0.2385
Epoch  63 Batch  230/269 - Train Accuracy: 0.8181, Validation Accuracy: 0.8201, Loss: 0.2502
Epoch  63 Batch  240/269 - Train Accuracy: 0.8376, Validation Accuracy: 0.8239, Loss: 0.2281
Epoch  63 Batch  250/269 - Train Accuracy: 0.8247, Validation Accuracy: 0.8233, Loss: 0.2525
Epoch  63 Batch  260/269 - Train Accuracy: 0.7954, Validation Accuracy: 0.8224, Loss: 0.2626
Epoch  64 Batch   10/269 - Train Accuracy: 0.8244, Validation Accuracy: 0.8219, Loss: 0.2572
Epoch  64 Batch   20/269 - Train Accuracy: 0.8271, Validation Accuracy: 0.8197, Loss: 0.2535
Epoch  64 Batch   30/269 - Train Accuracy: 0.8142, Validation Accuracy: 0.8220, Loss: 0.2451
Epoch  64 Batch   40/269 - Train Accuracy: 0.8177, Validation Accuracy: 0.8260, Loss: 0.2633
Epoch  64 Batch   50/269 - Train Accuracy: 0.7979, Validation Accuracy: 0.8294, Loss: 0.2723
Epoch  64 Batch   60/269 - Train Accuracy: 0.8178, Validation Accuracy: 0.8183, Loss: 0.2370
Epoch  64 Batch   70/269 - Train Accuracy: 0.8345, Validation Accuracy: 0.8201, Loss: 0.2453
Epoch  64 Batch   80/269 - Train Accuracy: 0.8105, Validation Accuracy: 0.8097, Loss: 0.2518
Epoch  64 Batch   90/269 - Train Accuracy: 0.8125, Validation Accuracy: 0.8240, Loss: 0.2580
Epoch  64 Batch  100/269 - Train Accuracy: 0.8256, Validation Accuracy: 0.8215, Loss: 0.2474
Epoch  64 Batch  110/269 - Train Accuracy: 0.8126, Validation Accuracy: 0.8224, Loss: 0.2561
Epoch  64 Batch  120/269 - Train Accuracy: 0.8168, Validation Accuracy: 0.8229, Loss: 0.2554
Epoch  64 Batch  130/269 - Train Accuracy: 0.8216, Validation Accuracy: 0.8283, Loss: 0.2623
Epoch  64 Batch  140/269 - Train Accuracy: 0.8183, Validation Accuracy: 0.8203, Loss: 0.2617
Epoch  64 Batch  150/269 - Train Accuracy: 0.8182, Validation Accuracy: 0.8287, Loss: 0.2478
Epoch  64 Batch  160/269 - Train Accuracy: 0.8153, Validation Accuracy: 0.8243, Loss: 0.2477
Epoch  64 Batch  170/269 - Train Accuracy: 0.8160, Validation Accuracy: 0.8205, Loss: 0.2472
Epoch  64 Batch  180/269 - Train Accuracy: 0.8324, Validation Accuracy: 0.8211, Loss: 0.2422
Epoch  64 Batch  190/269 - Train Accuracy: 0.8278, Validation Accuracy: 0.8289, Loss: 0.2434
Epoch  64 Batch  200/269 - Train Accuracy: 0.8022, Validation Accuracy: 0.8232, Loss: 0.2531
Epoch  64 Batch  210/269 - Train Accuracy: 0.8298, Validation Accuracy: 0.8237, Loss: 0.2460
Epoch  64 Batch  220/269 - Train Accuracy: 0.8295, Validation Accuracy: 0.8184, Loss: 0.2358
Epoch  64 Batch  230/269 - Train Accuracy: 0.8198, Validation Accuracy: 0.8264, Loss: 0.2518
Epoch  64 Batch  240/269 - Train Accuracy: 0.8379, Validation Accuracy: 0.8241, Loss: 0.2235
Epoch  64 Batch  250/269 - Train Accuracy: 0.8264, Validation Accuracy: 0.8263, Loss: 0.2470
Epoch  64 Batch  260/269 - Train Accuracy: 0.7952, Validation Accuracy: 0.8210, Loss: 0.2673
Epoch  65 Batch   10/269 - Train Accuracy: 0.8272, Validation Accuracy: 0.8264, Loss: 0.2478
Epoch  65 Batch   20/269 - Train Accuracy: 0.8271, Validation Accuracy: 0.8216, Loss: 0.2678
Epoch  65 Batch   30/269 - Train Accuracy: 0.8199, Validation Accuracy: 0.8237, Loss: 0.2397
Epoch  65 Batch   40/269 - Train Accuracy: 0.8135, Validation Accuracy: 0.8196, Loss: 0.2665
Epoch  65 Batch   50/269 - Train Accuracy: 0.7959, Validation Accuracy: 0.8244, Loss: 0.2739
Epoch  65 Batch   60/269 - Train Accuracy: 0.8165, Validation Accuracy: 0.8211, Loss: 0.2430
Epoch  65 Batch   70/269 - Train Accuracy: 0.8252, Validation Accuracy: 0.8250, Loss: 0.2507
Epoch  65 Batch   80/269 - Train Accuracy: 0.8145, Validation Accuracy: 0.8176, Loss: 0.2467
Epoch  65 Batch   90/269 - Train Accuracy: 0.8204, Validation Accuracy: 0.8267, Loss: 0.2564
Epoch  65 Batch  100/269 - Train Accuracy: 0.8259, Validation Accuracy: 0.8253, Loss: 0.2424
Epoch  65 Batch  110/269 - Train Accuracy: 0.8158, Validation Accuracy: 0.8232, Loss: 0.2521
Epoch  65 Batch  120/269 - Train Accuracy: 0.8159, Validation Accuracy: 0.8287, Loss: 0.2609
Epoch  65 Batch  130/269 - Train Accuracy: 0.8128, Validation Accuracy: 0.8306, Loss: 0.2659
Epoch  65 Batch  140/269 - Train Accuracy: 0.8210, Validation Accuracy: 0.8274, Loss: 0.2659
Epoch  65 Batch  150/269 - Train Accuracy: 0.8171, Validation Accuracy: 0.8308, Loss: 0.2442
Epoch  65 Batch  160/269 - Train Accuracy: 0.8182, Validation Accuracy: 0.8293, Loss: 0.2485
Epoch  65 Batch  170/269 - Train Accuracy: 0.8102, Validation Accuracy: 0.8299, Loss: 0.2414
Epoch  65 Batch  180/269 - Train Accuracy: 0.8311, Validation Accuracy: 0.8180, Loss: 0.2409
Epoch  65 Batch  190/269 - Train Accuracy: 0.8279, Validation Accuracy: 0.8239, Loss: 0.2384
Epoch  65 Batch  200/269 - Train Accuracy: 0.8049, Validation Accuracy: 0.8245, Loss: 0.2544
Epoch  65 Batch  210/269 - Train Accuracy: 0.8331, Validation Accuracy: 0.8299, Loss: 0.2437
Epoch  65 Batch  220/269 - Train Accuracy: 0.8267, Validation Accuracy: 0.8169, Loss: 0.2377
Epoch  65 Batch  230/269 - Train Accuracy: 0.8187, Validation Accuracy: 0.8182, Loss: 0.2455
Epoch  65 Batch  240/269 - Train Accuracy: 0.8410, Validation Accuracy: 0.8293, Loss: 0.2212
Epoch  65 Batch  250/269 - Train Accuracy: 0.8273, Validation Accuracy: 0.8256, Loss: 0.2483
Epoch  65 Batch  260/269 - Train Accuracy: 0.7980, Validation Accuracy: 0.8279, Loss: 0.2654
Epoch  66 Batch   10/269 - Train Accuracy: 0.8287, Validation Accuracy: 0.8273, Loss: 0.2437
Epoch  66 Batch   20/269 - Train Accuracy: 0.8339, Validation Accuracy: 0.8241, Loss: 0.2576
Epoch  66 Batch   30/269 - Train Accuracy: 0.8197, Validation Accuracy: 0.8182, Loss: 0.2403
Epoch  66 Batch   40/269 - Train Accuracy: 0.8204, Validation Accuracy: 0.8307, Loss: 0.2646
Epoch  66 Batch   50/269 - Train Accuracy: 0.8025, Validation Accuracy: 0.8379, Loss: 0.2612
Epoch  66 Batch   60/269 - Train Accuracy: 0.8171, Validation Accuracy: 0.8177, Loss: 0.2322
Epoch  66 Batch   70/269 - Train Accuracy: 0.8274, Validation Accuracy: 0.8294, Loss: 0.2408
Epoch  66 Batch   80/269 - Train Accuracy: 0.8172, Validation Accuracy: 0.8194, Loss: 0.2467
Epoch  66 Batch   90/269 - Train Accuracy: 0.8200, Validation Accuracy: 0.8190, Loss: 0.2545
Epoch  66 Batch  100/269 - Train Accuracy: 0.8278, Validation Accuracy: 0.8242, Loss: 0.2327
Epoch  66 Batch  110/269 - Train Accuracy: 0.8145, Validation Accuracy: 0.8297, Loss: 0.2476
Epoch  66 Batch  120/269 - Train Accuracy: 0.8195, Validation Accuracy: 0.8233, Loss: 0.2589
Epoch  66 Batch  130/269 - Train Accuracy: 0.8271, Validation Accuracy: 0.8321, Loss: 0.2726
Epoch  66 Batch  140/269 - Train Accuracy: 0.8166, Validation Accuracy: 0.8272, Loss: 0.2616
Epoch  66 Batch  150/269 - Train Accuracy: 0.8173, Validation Accuracy: 0.8280, Loss: 0.2417
Epoch  66 Batch  160/269 - Train Accuracy: 0.8172, Validation Accuracy: 0.8239, Loss: 0.2435
Epoch  66 Batch  170/269 - Train Accuracy: 0.8068, Validation Accuracy: 0.8226, Loss: 0.2399
Epoch  66 Batch  180/269 - Train Accuracy: 0.8313, Validation Accuracy: 0.8169, Loss: 0.2300
Epoch  66 Batch  190/269 - Train Accuracy: 0.8298, Validation Accuracy: 0.8262, Loss: 0.2374
Epoch  66 Batch  200/269 - Train Accuracy: 0.8072, Validation Accuracy: 0.8318, Loss: 0.2460
Epoch  66 Batch  210/269 - Train Accuracy: 0.8338, Validation Accuracy: 0.8306, Loss: 0.2442
Epoch  66 Batch  220/269 - Train Accuracy: 0.8303, Validation Accuracy: 0.8219, Loss: 0.2396
Epoch  66 Batch  230/269 - Train Accuracy: 0.8200, Validation Accuracy: 0.8198, Loss: 0.2432
Epoch  66 Batch  240/269 - Train Accuracy: 0.8375, Validation Accuracy: 0.8324, Loss: 0.2225
Epoch  66 Batch  250/269 - Train Accuracy: 0.8244, Validation Accuracy: 0.8242, Loss: 0.2402
Epoch  66 Batch  260/269 - Train Accuracy: 0.7976, Validation Accuracy: 0.8191, Loss: 0.2557
Epoch  67 Batch   10/269 - Train Accuracy: 0.8249, Validation Accuracy: 0.8253, Loss: 0.2409
Epoch  67 Batch   20/269 - Train Accuracy: 0.8292, Validation Accuracy: 0.8248, Loss: 0.2507
Epoch  67 Batch   30/269 - Train Accuracy: 0.8253, Validation Accuracy: 0.8239, Loss: 0.2523
Epoch  67 Batch   40/269 - Train Accuracy: 0.8155, Validation Accuracy: 0.8240, Loss: 0.2578
Epoch  67 Batch   50/269 - Train Accuracy: 0.8025, Validation Accuracy: 0.8206, Loss: 0.2631
Epoch  67 Batch   60/269 - Train Accuracy: 0.8222, Validation Accuracy: 0.8245, Loss: 0.2310
Epoch  67 Batch   70/269 - Train Accuracy: 0.8283, Validation Accuracy: 0.8246, Loss: 0.2474
Epoch  67 Batch   80/269 - Train Accuracy: 0.8195, Validation Accuracy: 0.8203, Loss: 0.2482
Epoch  67 Batch   90/269 - Train Accuracy: 0.8193, Validation Accuracy: 0.8283, Loss: 0.2585
Epoch  67 Batch  100/269 - Train Accuracy: 0.8296, Validation Accuracy: 0.8272, Loss: 0.2293
Epoch  67 Batch  110/269 - Train Accuracy: 0.8194, Validation Accuracy: 0.8285, Loss: 0.2446
Epoch  67 Batch  120/269 - Train Accuracy: 0.8147, Validation Accuracy: 0.8239, Loss: 0.2459
Epoch  67 Batch  130/269 - Train Accuracy: 0.8238, Validation Accuracy: 0.8318, Loss: 0.2599
Epoch  67 Batch  140/269 - Train Accuracy: 0.8204, Validation Accuracy: 0.8339, Loss: 0.2614
Epoch  67 Batch  150/269 - Train Accuracy: 0.8158, Validation Accuracy: 0.8277, Loss: 0.2349
Epoch  67 Batch  160/269 - Train Accuracy: 0.8195, Validation Accuracy: 0.8314, Loss: 0.2431
Epoch  67 Batch  170/269 - Train Accuracy: 0.8143, Validation Accuracy: 0.8241, Loss: 0.2393
Epoch  67 Batch  180/269 - Train Accuracy: 0.8319, Validation Accuracy: 0.8185, Loss: 0.2309
Epoch  67 Batch  190/269 - Train Accuracy: 0.8267, Validation Accuracy: 0.8255, Loss: 0.2316
Epoch  67 Batch  200/269 - Train Accuracy: 0.8054, Validation Accuracy: 0.8244, Loss: 0.2422
Epoch  67 Batch  210/269 - Train Accuracy: 0.8332, Validation Accuracy: 0.8290, Loss: 0.2360
Epoch  67 Batch  220/269 - Train Accuracy: 0.8462, Validation Accuracy: 0.8271, Loss: 0.2289
Epoch  67 Batch  230/269 - Train Accuracy: 0.8213, Validation Accuracy: 0.8227, Loss: 0.2333
Epoch  67 Batch  240/269 - Train Accuracy: 0.8434, Validation Accuracy: 0.8221, Loss: 0.2215
Epoch  67 Batch  250/269 - Train Accuracy: 0.8244, Validation Accuracy: 0.8236, Loss: 0.2403
Epoch  67 Batch  260/269 - Train Accuracy: 0.8021, Validation Accuracy: 0.8315, Loss: 0.2523
Epoch  68 Batch   10/269 - Train Accuracy: 0.8312, Validation Accuracy: 0.8305, Loss: 0.2402
Epoch  68 Batch   20/269 - Train Accuracy: 0.8285, Validation Accuracy: 0.8271, Loss: 0.2438
Epoch  68 Batch   30/269 - Train Accuracy: 0.8230, Validation Accuracy: 0.8298, Loss: 0.2402
Epoch  68 Batch   40/269 - Train Accuracy: 0.8181, Validation Accuracy: 0.8280, Loss: 0.2512
Epoch  68 Batch   50/269 - Train Accuracy: 0.8025, Validation Accuracy: 0.8279, Loss: 0.2553
Epoch  68 Batch   60/269 - Train Accuracy: 0.8236, Validation Accuracy: 0.8221, Loss: 0.2296
Epoch  68 Batch   70/269 - Train Accuracy: 0.8343, Validation Accuracy: 0.8250, Loss: 0.2347
Epoch  68 Batch   80/269 - Train Accuracy: 0.8211, Validation Accuracy: 0.8293, Loss: 0.2437
Epoch  68 Batch   90/269 - Train Accuracy: 0.8248, Validation Accuracy: 0.8319, Loss: 0.2536
Epoch  68 Batch  100/269 - Train Accuracy: 0.8311, Validation Accuracy: 0.8269, Loss: 0.2284
Epoch  68 Batch  110/269 - Train Accuracy: 0.8212, Validation Accuracy: 0.8326, Loss: 0.2410
Epoch  68 Batch  120/269 - Train Accuracy: 0.8250, Validation Accuracy: 0.8287, Loss: 0.2459
Epoch  68 Batch  130/269 - Train Accuracy: 0.8268, Validation Accuracy: 0.8276, Loss: 0.2550
Epoch  68 Batch  140/269 - Train Accuracy: 0.8211, Validation Accuracy: 0.8272, Loss: 0.2525
Epoch  68 Batch  150/269 - Train Accuracy: 0.8146, Validation Accuracy: 0.8240, Loss: 0.2407
Epoch  68 Batch  160/269 - Train Accuracy: 0.8143, Validation Accuracy: 0.8273, Loss: 0.2490
Epoch  68 Batch  170/269 - Train Accuracy: 0.8143, Validation Accuracy: 0.8306, Loss: 0.2289
Epoch  68 Batch  180/269 - Train Accuracy: 0.8359, Validation Accuracy: 0.8202, Loss: 0.2341
Epoch  68 Batch  190/269 - Train Accuracy: 0.8345, Validation Accuracy: 0.8239, Loss: 0.2302
Epoch  68 Batch  200/269 - Train Accuracy: 0.8083, Validation Accuracy: 0.8244, Loss: 0.2431
Epoch  68 Batch  210/269 - Train Accuracy: 0.8377, Validation Accuracy: 0.8300, Loss: 0.2312
Epoch  68 Batch  220/269 - Train Accuracy: 0.8329, Validation Accuracy: 0.8200, Loss: 0.2321
Epoch  68 Batch  230/269 - Train Accuracy: 0.8244, Validation Accuracy: 0.8267, Loss: 0.2358
Epoch  68 Batch  240/269 - Train Accuracy: 0.8418, Validation Accuracy: 0.8281, Loss: 0.2291
Epoch  68 Batch  250/269 - Train Accuracy: 0.8307, Validation Accuracy: 0.8255, Loss: 0.2330
Epoch  68 Batch  260/269 - Train Accuracy: 0.8001, Validation Accuracy: 0.8316, Loss: 0.2555
Epoch  69 Batch   10/269 - Train Accuracy: 0.8278, Validation Accuracy: 0.8257, Loss: 0.2320
Epoch  69 Batch   20/269 - Train Accuracy: 0.8366, Validation Accuracy: 0.8253, Loss: 0.2477
Epoch  69 Batch   30/269 - Train Accuracy: 0.8241, Validation Accuracy: 0.8246, Loss: 0.2280
Epoch  69 Batch   40/269 - Train Accuracy: 0.8200, Validation Accuracy: 0.8271, Loss: 0.2543
Epoch  69 Batch   50/269 - Train Accuracy: 0.8001, Validation Accuracy: 0.8263, Loss: 0.2507
Epoch  69 Batch   60/269 - Train Accuracy: 0.8234, Validation Accuracy: 0.8177, Loss: 0.2248
Epoch  69 Batch   70/269 - Train Accuracy: 0.8345, Validation Accuracy: 0.8208, Loss: 0.2332
Epoch  69 Batch   80/269 - Train Accuracy: 0.8214, Validation Accuracy: 0.8205, Loss: 0.2461
Epoch  69 Batch   90/269 - Train Accuracy: 0.8266, Validation Accuracy: 0.8337, Loss: 0.2442
Epoch  69 Batch  100/269 - Train Accuracy: 0.8327, Validation Accuracy: 0.8290, Loss: 0.2371
Epoch  69 Batch  110/269 - Train Accuracy: 0.8182, Validation Accuracy: 0.8285, Loss: 0.2414
Epoch  69 Batch  120/269 - Train Accuracy: 0.8243, Validation Accuracy: 0.8342, Loss: 0.2429
Epoch  69 Batch  130/269 - Train Accuracy: 0.8178, Validation Accuracy: 0.8327, Loss: 0.2509
Epoch  69 Batch  140/269 - Train Accuracy: 0.8187, Validation Accuracy: 0.8319, Loss: 0.2518
Epoch  69 Batch  150/269 - Train Accuracy: 0.8237, Validation Accuracy: 0.8289, Loss: 0.2408
Epoch  69 Batch  160/269 - Train Accuracy: 0.8232, Validation Accuracy: 0.8284, Loss: 0.2483
Epoch  69 Batch  170/269 - Train Accuracy: 0.8151, Validation Accuracy: 0.8280, Loss: 0.2323
Epoch  69 Batch  180/269 - Train Accuracy: 0.8341, Validation Accuracy: 0.8190, Loss: 0.2258
Epoch  69 Batch  190/269 - Train Accuracy: 0.8344, Validation Accuracy: 0.8295, Loss: 0.2261
Epoch  69 Batch  200/269 - Train Accuracy: 0.8087, Validation Accuracy: 0.8289, Loss: 0.2425
Epoch  69 Batch  210/269 - Train Accuracy: 0.8351, Validation Accuracy: 0.8260, Loss: 0.2370
Epoch  69 Batch  220/269 - Train Accuracy: 0.8305, Validation Accuracy: 0.8274, Loss: 0.2282
Epoch  69 Batch  230/269 - Train Accuracy: 0.8252, Validation Accuracy: 0.8239, Loss: 0.2291
Epoch  69 Batch  240/269 - Train Accuracy: 0.8467, Validation Accuracy: 0.8267, Loss: 0.2108
Epoch  69 Batch  250/269 - Train Accuracy: 0.8268, Validation Accuracy: 0.8211, Loss: 0.2428
Epoch  69 Batch  260/269 - Train Accuracy: 0.8041, Validation Accuracy: 0.8210, Loss: 0.2564
Epoch  70 Batch   10/269 - Train Accuracy: 0.8291, Validation Accuracy: 0.8317, Loss: 0.2341
Epoch  70 Batch   20/269 - Train Accuracy: 0.8299, Validation Accuracy: 0.8230, Loss: 0.2388
Epoch  70 Batch   30/269 - Train Accuracy: 0.8301, Validation Accuracy: 0.8258, Loss: 0.2312
Epoch  70 Batch   40/269 - Train Accuracy: 0.8170, Validation Accuracy: 0.8248, Loss: 0.2598
Epoch  70 Batch   50/269 - Train Accuracy: 0.8068, Validation Accuracy: 0.8301, Loss: 0.2508
Epoch  70 Batch   60/269 - Train Accuracy: 0.8245, Validation Accuracy: 0.8294, Loss: 0.2202
Epoch  70 Batch   70/269 - Train Accuracy: 0.8395, Validation Accuracy: 0.8234, Loss: 0.2319
Epoch  70 Batch   80/269 - Train Accuracy: 0.8160, Validation Accuracy: 0.8224, Loss: 0.2385
Epoch  70 Batch   90/269 - Train Accuracy: 0.8242, Validation Accuracy: 0.8292, Loss: 0.2478
Epoch  70 Batch  100/269 - Train Accuracy: 0.8238, Validation Accuracy: 0.8233, Loss: 0.2303
Epoch  70 Batch  110/269 - Train Accuracy: 0.8216, Validation Accuracy: 0.8321, Loss: 0.2437
Epoch  70 Batch  120/269 - Train Accuracy: 0.8225, Validation Accuracy: 0.8288, Loss: 0.2424
Epoch  70 Batch  130/269 - Train Accuracy: 0.8234, Validation Accuracy: 0.8345, Loss: 0.2443
Epoch  70 Batch  140/269 - Train Accuracy: 0.8259, Validation Accuracy: 0.8325, Loss: 0.2474
Epoch  70 Batch  150/269 - Train Accuracy: 0.8223, Validation Accuracy: 0.8269, Loss: 0.2451
Epoch  70 Batch  160/269 - Train Accuracy: 0.8157, Validation Accuracy: 0.8283, Loss: 0.2331
Epoch  70 Batch  170/269 - Train Accuracy: 0.8098, Validation Accuracy: 0.8235, Loss: 0.2269
Epoch  70 Batch  180/269 - Train Accuracy: 0.8390, Validation Accuracy: 0.8221, Loss: 0.2189
Epoch  70 Batch  190/269 - Train Accuracy: 0.8339, Validation Accuracy: 0.8262, Loss: 0.2287
Epoch  70 Batch  200/269 - Train Accuracy: 0.8090, Validation Accuracy: 0.8278, Loss: 0.2272
Epoch  70 Batch  210/269 - Train Accuracy: 0.8446, Validation Accuracy: 0.8253, Loss: 0.2305
Epoch  70 Batch  220/269 - Train Accuracy: 0.8404, Validation Accuracy: 0.8273, Loss: 0.2243
Epoch  70 Batch  230/269 - Train Accuracy: 0.8210, Validation Accuracy: 0.8279, Loss: 0.2247
Epoch  70 Batch  240/269 - Train Accuracy: 0.8446, Validation Accuracy: 0.8275, Loss: 0.2099
Epoch  70 Batch  250/269 - Train Accuracy: 0.8266, Validation Accuracy: 0.8220, Loss: 0.2317
Epoch  70 Batch  260/269 - Train Accuracy: 0.8051, Validation Accuracy: 0.8213, Loss: 0.2486
Epoch  71 Batch   10/269 - Train Accuracy: 0.8274, Validation Accuracy: 0.8271, Loss: 0.2329
Epoch  71 Batch   20/269 - Train Accuracy: 0.8313, Validation Accuracy: 0.8307, Loss: 0.2360
Epoch  71 Batch   30/269 - Train Accuracy: 0.8277, Validation Accuracy: 0.8271, Loss: 0.2409
Epoch  71 Batch   40/269 - Train Accuracy: 0.8221, Validation Accuracy: 0.8275, Loss: 0.2495
Epoch  71 Batch   50/269 - Train Accuracy: 0.8076, Validation Accuracy: 0.8319, Loss: 0.2604
Epoch  71 Batch   60/269 - Train Accuracy: 0.8262, Validation Accuracy: 0.8340, Loss: 0.2200
Epoch  71 Batch   70/269 - Train Accuracy: 0.8382, Validation Accuracy: 0.8230, Loss: 0.2283
Epoch  71 Batch   80/269 - Train Accuracy: 0.8226, Validation Accuracy: 0.8186, Loss: 0.2350
Epoch  71 Batch   90/269 - Train Accuracy: 0.8275, Validation Accuracy: 0.8335, Loss: 0.2508
Epoch  71 Batch  100/269 - Train Accuracy: 0.8291, Validation Accuracy: 0.8256, Loss: 0.2311
Epoch  71 Batch  110/269 - Train Accuracy: 0.8271, Validation Accuracy: 0.8354, Loss: 0.2360
Epoch  71 Batch  120/269 - Train Accuracy: 0.8277, Validation Accuracy: 0.8318, Loss: 0.2310
Epoch  71 Batch  130/269 - Train Accuracy: 0.8247, Validation Accuracy: 0.8343, Loss: 0.2439
Epoch  71 Batch  140/269 - Train Accuracy: 0.8269, Validation Accuracy: 0.8263, Loss: 0.2468
Epoch  71 Batch  150/269 - Train Accuracy: 0.8238, Validation Accuracy: 0.8290, Loss: 0.2415
Epoch  71 Batch  160/269 - Train Accuracy: 0.8262, Validation Accuracy: 0.8338, Loss: 0.2369
Epoch  71 Batch  170/269 - Train Accuracy: 0.8140, Validation Accuracy: 0.8276, Loss: 0.2275
Epoch  71 Batch  180/269 - Train Accuracy: 0.8330, Validation Accuracy: 0.8250, Loss: 0.2286
Epoch  71 Batch  190/269 - Train Accuracy: 0.8337, Validation Accuracy: 0.8264, Loss: 0.2255
Epoch  71 Batch  200/269 - Train Accuracy: 0.8064, Validation Accuracy: 0.8222, Loss: 0.2395
Epoch  71 Batch  210/269 - Train Accuracy: 0.8408, Validation Accuracy: 0.8241, Loss: 0.2227
Epoch  71 Batch  220/269 - Train Accuracy: 0.8314, Validation Accuracy: 0.8192, Loss: 0.2263
Epoch  71 Batch  230/269 - Train Accuracy: 0.8267, Validation Accuracy: 0.8319, Loss: 0.2276
Epoch  71 Batch  240/269 - Train Accuracy: 0.8440, Validation Accuracy: 0.8268, Loss: 0.2078
Epoch  71 Batch  250/269 - Train Accuracy: 0.8292, Validation Accuracy: 0.8265, Loss: 0.2344
Epoch  71 Batch  260/269 - Train Accuracy: 0.8073, Validation Accuracy: 0.8292, Loss: 0.2454
Epoch  72 Batch   10/269 - Train Accuracy: 0.8296, Validation Accuracy: 0.8348, Loss: 0.2245
Epoch  72 Batch   20/269 - Train Accuracy: 0.8344, Validation Accuracy: 0.8243, Loss: 0.2379
Epoch  72 Batch   30/269 - Train Accuracy: 0.8318, Validation Accuracy: 0.8290, Loss: 0.2310
Epoch  72 Batch   40/269 - Train Accuracy: 0.8263, Validation Accuracy: 0.8254, Loss: 0.2540
Epoch  72 Batch   50/269 - Train Accuracy: 0.8123, Validation Accuracy: 0.8315, Loss: 0.2425
Epoch  72 Batch   60/269 - Train Accuracy: 0.8260, Validation Accuracy: 0.8289, Loss: 0.2210
Epoch  72 Batch   70/269 - Train Accuracy: 0.8341, Validation Accuracy: 0.8322, Loss: 0.2341
Epoch  72 Batch   80/269 - Train Accuracy: 0.8299, Validation Accuracy: 0.8249, Loss: 0.2357
Epoch  72 Batch   90/269 - Train Accuracy: 0.8205, Validation Accuracy: 0.8310, Loss: 0.2424
Epoch  72 Batch  100/269 - Train Accuracy: 0.8323, Validation Accuracy: 0.8299, Loss: 0.2281
Epoch  72 Batch  110/269 - Train Accuracy: 0.8209, Validation Accuracy: 0.8318, Loss: 0.2306
Epoch  72 Batch  120/269 - Train Accuracy: 0.8228, Validation Accuracy: 0.8326, Loss: 0.2513
Epoch  72 Batch  130/269 - Train Accuracy: 0.8279, Validation Accuracy: 0.8282, Loss: 0.2406
Epoch  72 Batch  140/269 - Train Accuracy: 0.8234, Validation Accuracy: 0.8334, Loss: 0.2405
Epoch  72 Batch  150/269 - Train Accuracy: 0.8181, Validation Accuracy: 0.8321, Loss: 0.2341
Epoch  72 Batch  160/269 - Train Accuracy: 0.8263, Validation Accuracy: 0.8325, Loss: 0.2333
Epoch  72 Batch  170/269 - Train Accuracy: 0.8159, Validation Accuracy: 0.8296, Loss: 0.2224
Epoch  72 Batch  180/269 - Train Accuracy: 0.8370, Validation Accuracy: 0.8255, Loss: 0.2103
Epoch  72 Batch  190/269 - Train Accuracy: 0.8377, Validation Accuracy: 0.8248, Loss: 0.2170
Epoch  72 Batch  200/269 - Train Accuracy: 0.8142, Validation Accuracy: 0.8324, Loss: 0.2324
Epoch  72 Batch  210/269 - Train Accuracy: 0.8401, Validation Accuracy: 0.8268, Loss: 0.2311
Epoch  72 Batch  220/269 - Train Accuracy: 0.8280, Validation Accuracy: 0.8214, Loss: 0.2176
Epoch  72 Batch  230/269 - Train Accuracy: 0.8191, Validation Accuracy: 0.8253, Loss: 0.2268
Epoch  72 Batch  240/269 - Train Accuracy: 0.8458, Validation Accuracy: 0.8335, Loss: 0.2116
Epoch  72 Batch  250/269 - Train Accuracy: 0.8281, Validation Accuracy: 0.8311, Loss: 0.2276
Epoch  72 Batch  260/269 - Train Accuracy: 0.7995, Validation Accuracy: 0.8261, Loss: 0.2360
Epoch  73 Batch   10/269 - Train Accuracy: 0.8259, Validation Accuracy: 0.8319, Loss: 0.2239
Epoch  73 Batch   20/269 - Train Accuracy: 0.8279, Validation Accuracy: 0.8271, Loss: 0.2310
Epoch  73 Batch   30/269 - Train Accuracy: 0.8298, Validation Accuracy: 0.8319, Loss: 0.2280
Epoch  73 Batch   40/269 - Train Accuracy: 0.8208, Validation Accuracy: 0.8301, Loss: 0.2488
Epoch  73 Batch   50/269 - Train Accuracy: 0.8094, Validation Accuracy: 0.8335, Loss: 0.2429
Epoch  73 Batch   60/269 - Train Accuracy: 0.8235, Validation Accuracy: 0.8238, Loss: 0.2149
Epoch  73 Batch   70/269 - Train Accuracy: 0.8331, Validation Accuracy: 0.8240, Loss: 0.2260
Epoch  73 Batch   80/269 - Train Accuracy: 0.8281, Validation Accuracy: 0.8226, Loss: 0.2277
Epoch  73 Batch   90/269 - Train Accuracy: 0.8218, Validation Accuracy: 0.8335, Loss: 0.2499
Epoch  73 Batch  100/269 - Train Accuracy: 0.8318, Validation Accuracy: 0.8315, Loss: 0.2187
Epoch  73 Batch  110/269 - Train Accuracy: 0.8172, Validation Accuracy: 0.8320, Loss: 0.2291
Epoch  73 Batch  120/269 - Train Accuracy: 0.8241, Validation Accuracy: 0.8307, Loss: 0.2331
Epoch  73 Batch  130/269 - Train Accuracy: 0.8184, Validation Accuracy: 0.8295, Loss: 0.2371
Epoch  73 Batch  140/269 - Train Accuracy: 0.8197, Validation Accuracy: 0.8361, Loss: 0.2412
Epoch  73 Batch  150/269 - Train Accuracy: 0.8228, Validation Accuracy: 0.8302, Loss: 0.2338
Epoch  73 Batch  160/269 - Train Accuracy: 0.8236, Validation Accuracy: 0.8335, Loss: 0.2258
Epoch  73 Batch  170/269 - Train Accuracy: 0.8157, Validation Accuracy: 0.8324, Loss: 0.2234
Epoch  73 Batch  180/269 - Train Accuracy: 0.8362, Validation Accuracy: 0.8211, Loss: 0.2201
Epoch  73 Batch  190/269 - Train Accuracy: 0.8347, Validation Accuracy: 0.8287, Loss: 0.2210
Epoch  73 Batch  200/269 - Train Accuracy: 0.8118, Validation Accuracy: 0.8294, Loss: 0.2301
Epoch  73 Batch  210/269 - Train Accuracy: 0.8388, Validation Accuracy: 0.8213, Loss: 0.2258
Epoch  73 Batch  220/269 - Train Accuracy: 0.8359, Validation Accuracy: 0.8283, Loss: 0.2211
Epoch  73 Batch  230/269 - Train Accuracy: 0.8197, Validation Accuracy: 0.8212, Loss: 0.2192
Epoch  73 Batch  240/269 - Train Accuracy: 0.8424, Validation Accuracy: 0.8314, Loss: 0.2103
Epoch  73 Batch  250/269 - Train Accuracy: 0.8303, Validation Accuracy: 0.8256, Loss: 0.2345
Epoch  73 Batch  260/269 - Train Accuracy: 0.8054, Validation Accuracy: 0.8266, Loss: 0.2413
Epoch  74 Batch   10/269 - Train Accuracy: 0.8333, Validation Accuracy: 0.8269, Loss: 0.2253
Epoch  74 Batch   20/269 - Train Accuracy: 0.8316, Validation Accuracy: 0.8282, Loss: 0.2343
Epoch  74 Batch   30/269 - Train Accuracy: 0.8278, Validation Accuracy: 0.8234, Loss: 0.2250
Epoch  74 Batch   40/269 - Train Accuracy: 0.8155, Validation Accuracy: 0.8256, Loss: 0.2401
Epoch  74 Batch   50/269 - Train Accuracy: 0.8140, Validation Accuracy: 0.8361, Loss: 0.2594
Epoch  74 Batch   60/269 - Train Accuracy: 0.8275, Validation Accuracy: 0.8232, Loss: 0.2165
Epoch  74 Batch   70/269 - Train Accuracy: 0.8352, Validation Accuracy: 0.8244, Loss: 0.2212
Epoch  74 Batch   80/269 - Train Accuracy: 0.8211, Validation Accuracy: 0.8220, Loss: 0.2321
Epoch  74 Batch   90/269 - Train Accuracy: 0.8161, Validation Accuracy: 0.8302, Loss: 0.2366
Epoch  74 Batch  100/269 - Train Accuracy: 0.8324, Validation Accuracy: 0.8292, Loss: 0.2242
Epoch  74 Batch  110/269 - Train Accuracy: 0.8173, Validation Accuracy: 0.8263, Loss: 0.2277
Epoch  74 Batch  120/269 - Train Accuracy: 0.8268, Validation Accuracy: 0.8280, Loss: 0.2297
Epoch  74 Batch  130/269 - Train Accuracy: 0.8241, Validation Accuracy: 0.8333, Loss: 0.2499
Epoch  74 Batch  140/269 - Train Accuracy: 0.8248, Validation Accuracy: 0.8259, Loss: 0.2376
Epoch  74 Batch  150/269 - Train Accuracy: 0.8239, Validation Accuracy: 0.8293, Loss: 0.2247
Epoch  74 Batch  160/269 - Train Accuracy: 0.8257, Validation Accuracy: 0.8343, Loss: 0.2278
Epoch  74 Batch  170/269 - Train Accuracy: 0.8187, Validation Accuracy: 0.8315, Loss: 0.2264
Epoch  74 Batch  180/269 - Train Accuracy: 0.8401, Validation Accuracy: 0.8219, Loss: 0.2115
Epoch  74 Batch  190/269 - Train Accuracy: 0.8320, Validation Accuracy: 0.8277, Loss: 0.2193
Epoch  74 Batch  200/269 - Train Accuracy: 0.8099, Validation Accuracy: 0.8317, Loss: 0.2336
Epoch  74 Batch  210/269 - Train Accuracy: 0.8378, Validation Accuracy: 0.8288, Loss: 0.2256
Epoch  74 Batch  220/269 - Train Accuracy: 0.8262, Validation Accuracy: 0.8219, Loss: 0.2208
Epoch  74 Batch  230/269 - Train Accuracy: 0.8244, Validation Accuracy: 0.8285, Loss: 0.2235
Epoch  74 Batch  240/269 - Train Accuracy: 0.8450, Validation Accuracy: 0.8256, Loss: 0.2015
Epoch  74 Batch  250/269 - Train Accuracy: 0.8329, Validation Accuracy: 0.8201, Loss: 0.2329
Epoch  74 Batch  260/269 - Train Accuracy: 0.8058, Validation Accuracy: 0.8276, Loss: 0.2435
Epoch  75 Batch   10/269 - Train Accuracy: 0.8320, Validation Accuracy: 0.8319, Loss: 0.2192
Epoch  75 Batch   20/269 - Train Accuracy: 0.8262, Validation Accuracy: 0.8207, Loss: 0.2340
Epoch  75 Batch   30/269 - Train Accuracy: 0.8284, Validation Accuracy: 0.8333, Loss: 0.2297
Epoch  75 Batch   40/269 - Train Accuracy: 0.8178, Validation Accuracy: 0.8250, Loss: 0.2355
Epoch  75 Batch   50/269 - Train Accuracy: 0.8133, Validation Accuracy: 0.8306, Loss: 0.2405
Epoch  75 Batch   60/269 - Train Accuracy: 0.8229, Validation Accuracy: 0.8188, Loss: 0.2111
Epoch  75 Batch   70/269 - Train Accuracy: 0.8364, Validation Accuracy: 0.8217, Loss: 0.2217
Epoch  75 Batch   80/269 - Train Accuracy: 0.8197, Validation Accuracy: 0.8227, Loss: 0.2201
Epoch  75 Batch   90/269 - Train Accuracy: 0.8274, Validation Accuracy: 0.8310, Loss: 0.2347
Epoch  75 Batch  100/269 - Train Accuracy: 0.8335, Validation Accuracy: 0.8328, Loss: 0.2232
Epoch  75 Batch  110/269 - Train Accuracy: 0.8273, Validation Accuracy: 0.8336, Loss: 0.2282
Epoch  75 Batch  120/269 - Train Accuracy: 0.8234, Validation Accuracy: 0.8304, Loss: 0.2345
Epoch  75 Batch  130/269 - Train Accuracy: 0.8221, Validation Accuracy: 0.8270, Loss: 0.2345
Epoch  75 Batch  140/269 - Train Accuracy: 0.8205, Validation Accuracy: 0.8334, Loss: 0.2414
Epoch  75 Batch  150/269 - Train Accuracy: 0.8173, Validation Accuracy: 0.8277, Loss: 0.2203
Epoch  75 Batch  160/269 - Train Accuracy: 0.8223, Validation Accuracy: 0.8305, Loss: 0.2258
Epoch  75 Batch  170/269 - Train Accuracy: 0.8175, Validation Accuracy: 0.8281, Loss: 0.2177
Epoch  75 Batch  180/269 - Train Accuracy: 0.8386, Validation Accuracy: 0.8222, Loss: 0.2105
Epoch  75 Batch  190/269 - Train Accuracy: 0.8367, Validation Accuracy: 0.8327, Loss: 0.2061
Epoch  75 Batch  200/269 - Train Accuracy: 0.8170, Validation Accuracy: 0.8228, Loss: 0.2291
Epoch  75 Batch  210/269 - Train Accuracy: 0.8410, Validation Accuracy: 0.8217, Loss: 0.2188
Epoch  75 Batch  220/269 - Train Accuracy: 0.8313, Validation Accuracy: 0.8263, Loss: 0.2124
Epoch  75 Batch  230/269 - Train Accuracy: 0.8251, Validation Accuracy: 0.8234, Loss: 0.2164
Epoch  75 Batch  240/269 - Train Accuracy: 0.8455, Validation Accuracy: 0.8290, Loss: 0.2023
Epoch  75 Batch  250/269 - Train Accuracy: 0.8341, Validation Accuracy: 0.8290, Loss: 0.2252
Epoch  75 Batch  260/269 - Train Accuracy: 0.8062, Validation Accuracy: 0.8232, Loss: 0.2356
Epoch  76 Batch   10/269 - Train Accuracy: 0.8318, Validation Accuracy: 0.8310, Loss: 0.2177
Epoch  76 Batch   20/269 - Train Accuracy: 0.8297, Validation Accuracy: 0.8244, Loss: 0.2363
Epoch  76 Batch   30/269 - Train Accuracy: 0.8225, Validation Accuracy: 0.8270, Loss: 0.2190
Epoch  76 Batch   40/269 - Train Accuracy: 0.8245, Validation Accuracy: 0.8283, Loss: 0.2410
Epoch  76 Batch   50/269 - Train Accuracy: 0.8039, Validation Accuracy: 0.8256, Loss: 0.2529
Epoch  76 Batch   60/269 - Train Accuracy: 0.8259, Validation Accuracy: 0.8257, Loss: 0.2285
Epoch  76 Batch   70/269 - Train Accuracy: 0.8319, Validation Accuracy: 0.8241, Loss: 0.2348
Epoch  76 Batch   80/269 - Train Accuracy: 0.8166, Validation Accuracy: 0.8169, Loss: 0.2278
Epoch  76 Batch   90/269 - Train Accuracy: 0.8199, Validation Accuracy: 0.8282, Loss: 0.2335
Epoch  76 Batch  100/269 - Train Accuracy: 0.8280, Validation Accuracy: 0.8179, Loss: 0.2105
Epoch  76 Batch  110/269 - Train Accuracy: 0.8202, Validation Accuracy: 0.8300, Loss: 0.2232
Epoch  76 Batch  120/269 - Train Accuracy: 0.8160, Validation Accuracy: 0.8244, Loss: 0.2320
Epoch  76 Batch  130/269 - Train Accuracy: 0.8208, Validation Accuracy: 0.8305, Loss: 0.2320
Epoch  76 Batch  140/269 - Train Accuracy: 0.8232, Validation Accuracy: 0.8363, Loss: 0.2409
Epoch  76 Batch  150/269 - Train Accuracy: 0.8198, Validation Accuracy: 0.8250, Loss: 0.2276
Epoch  76 Batch  160/269 - Train Accuracy: 0.8175, Validation Accuracy: 0.8287, Loss: 0.2266
Epoch  76 Batch  170/269 - Train Accuracy: 0.8144, Validation Accuracy: 0.8312, Loss: 0.2201
Epoch  76 Batch  180/269 - Train Accuracy: 0.8402, Validation Accuracy: 0.8262, Loss: 0.2200
Epoch  76 Batch  190/269 - Train Accuracy: 0.8386, Validation Accuracy: 0.8256, Loss: 0.2131
Epoch  76 Batch  200/269 - Train Accuracy: 0.8073, Validation Accuracy: 0.8249, Loss: 0.2183
Epoch  76 Batch  210/269 - Train Accuracy: 0.8399, Validation Accuracy: 0.8267, Loss: 0.2107
Epoch  76 Batch  220/269 - Train Accuracy: 0.8353, Validation Accuracy: 0.8288, Loss: 0.2098
Epoch  76 Batch  230/269 - Train Accuracy: 0.8266, Validation Accuracy: 0.8280, Loss: 0.2083
Epoch  76 Batch  240/269 - Train Accuracy: 0.8448, Validation Accuracy: 0.8304, Loss: 0.2061
Epoch  76 Batch  250/269 - Train Accuracy: 0.8297, Validation Accuracy: 0.8226, Loss: 0.2176
Epoch  76 Batch  260/269 - Train Accuracy: 0.8114, Validation Accuracy: 0.8327, Loss: 0.2303
Epoch  77 Batch   10/269 - Train Accuracy: 0.8293, Validation Accuracy: 0.8311, Loss: 0.2156
Epoch  77 Batch   20/269 - Train Accuracy: 0.8315, Validation Accuracy: 0.8177, Loss: 0.2203
Epoch  77 Batch   30/269 - Train Accuracy: 0.8298, Validation Accuracy: 0.8306, Loss: 0.2130
Epoch  77 Batch   40/269 - Train Accuracy: 0.8232, Validation Accuracy: 0.8224, Loss: 0.2506
Epoch  77 Batch   50/269 - Train Accuracy: 0.8154, Validation Accuracy: 0.8344, Loss: 0.2372
Epoch  77 Batch   60/269 - Train Accuracy: 0.8232, Validation Accuracy: 0.8264, Loss: 0.2016
Epoch  77 Batch   70/269 - Train Accuracy: 0.8376, Validation Accuracy: 0.8232, Loss: 0.2215
Epoch  77 Batch   80/269 - Train Accuracy: 0.8157, Validation Accuracy: 0.8172, Loss: 0.2181
Epoch  77 Batch   90/269 - Train Accuracy: 0.8221, Validation Accuracy: 0.8328, Loss: 0.2328
Epoch  77 Batch  100/269 - Train Accuracy: 0.8341, Validation Accuracy: 0.8208, Loss: 0.2101
Epoch  77 Batch  110/269 - Train Accuracy: 0.8269, Validation Accuracy: 0.8360, Loss: 0.2191
Epoch  77 Batch  120/269 - Train Accuracy: 0.8205, Validation Accuracy: 0.8234, Loss: 0.2276
Epoch  77 Batch  130/269 - Train Accuracy: 0.8264, Validation Accuracy: 0.8308, Loss: 0.2341
Epoch  77 Batch  140/269 - Train Accuracy: 0.8267, Validation Accuracy: 0.8298, Loss: 0.2418
Epoch  77 Batch  150/269 - Train Accuracy: 0.8239, Validation Accuracy: 0.8309, Loss: 0.2194
Epoch  77 Batch  160/269 - Train Accuracy: 0.8193, Validation Accuracy: 0.8288, Loss: 0.2263
Epoch  77 Batch  170/269 - Train Accuracy: 0.8158, Validation Accuracy: 0.8326, Loss: 0.2097
Epoch  77 Batch  180/269 - Train Accuracy: 0.8349, Validation Accuracy: 0.8196, Loss: 0.2072
Epoch  77 Batch  190/269 - Train Accuracy: 0.8391, Validation Accuracy: 0.8287, Loss: 0.2144
Epoch  77 Batch  200/269 - Train Accuracy: 0.8149, Validation Accuracy: 0.8216, Loss: 0.2195
Epoch  77 Batch  210/269 - Train Accuracy: 0.8409, Validation Accuracy: 0.8277, Loss: 0.2156
Epoch  77 Batch  220/269 - Train Accuracy: 0.8327, Validation Accuracy: 0.8182, Loss: 0.2072
Epoch  77 Batch  230/269 - Train Accuracy: 0.8239, Validation Accuracy: 0.8271, Loss: 0.2135
Epoch  77 Batch  240/269 - Train Accuracy: 0.8459, Validation Accuracy: 0.8291, Loss: 0.1981
Epoch  77 Batch  250/269 - Train Accuracy: 0.8261, Validation Accuracy: 0.8266, Loss: 0.2145
Epoch  77 Batch  260/269 - Train Accuracy: 0.8001, Validation Accuracy: 0.8242, Loss: 0.2266
Epoch  78 Batch   10/269 - Train Accuracy: 0.8340, Validation Accuracy: 0.8299, Loss: 0.2127
Epoch  78 Batch   20/269 - Train Accuracy: 0.8320, Validation Accuracy: 0.8206, Loss: 0.2179
Epoch  78 Batch   30/269 - Train Accuracy: 0.8245, Validation Accuracy: 0.8278, Loss: 0.2170
Epoch  78 Batch   40/269 - Train Accuracy: 0.8195, Validation Accuracy: 0.8235, Loss: 0.2286
Epoch  78 Batch   50/269 - Train Accuracy: 0.8151, Validation Accuracy: 0.8294, Loss: 0.2310
Epoch  78 Batch   60/269 - Train Accuracy: 0.8319, Validation Accuracy: 0.8201, Loss: 0.1985
Epoch  78 Batch   70/269 - Train Accuracy: 0.8338, Validation Accuracy: 0.8288, Loss: 0.2167
Epoch  78 Batch   80/269 - Train Accuracy: 0.8179, Validation Accuracy: 0.8164, Loss: 0.2156
Epoch  78 Batch   90/269 - Train Accuracy: 0.8211, Validation Accuracy: 0.8335, Loss: 0.2257
Epoch  78 Batch  100/269 - Train Accuracy: 0.8413, Validation Accuracy: 0.8235, Loss: 0.2127
Epoch  78 Batch  110/269 - Train Accuracy: 0.8244, Validation Accuracy: 0.8274, Loss: 0.2271
Epoch  78 Batch  120/269 - Train Accuracy: 0.8177, Validation Accuracy: 0.8327, Loss: 0.2171
Epoch  78 Batch  130/269 - Train Accuracy: 0.8262, Validation Accuracy: 0.8296, Loss: 0.2234
Epoch  78 Batch  140/269 - Train Accuracy: 0.8280, Validation Accuracy: 0.8302, Loss: 0.2291
Epoch  78 Batch  150/269 - Train Accuracy: 0.8189, Validation Accuracy: 0.8275, Loss: 0.2141
Epoch  78 Batch  160/269 - Train Accuracy: 0.8200, Validation Accuracy: 0.8239, Loss: 0.2256
Epoch  78 Batch  170/269 - Train Accuracy: 0.8177, Validation Accuracy: 0.8393, Loss: 0.2170
Epoch  78 Batch  180/269 - Train Accuracy: 0.8408, Validation Accuracy: 0.8192, Loss: 0.2076
Epoch  78 Batch  190/269 - Train Accuracy: 0.8381, Validation Accuracy: 0.8263, Loss: 0.2112
Epoch  78 Batch  200/269 - Train Accuracy: 0.8221, Validation Accuracy: 0.8288, Loss: 0.2211
Epoch  78 Batch  210/269 - Train Accuracy: 0.8425, Validation Accuracy: 0.8279, Loss: 0.2117
Epoch  78 Batch  220/269 - Train Accuracy: 0.8368, Validation Accuracy: 0.8256, Loss: 0.2119
Epoch  78 Batch  230/269 - Train Accuracy: 0.8250, Validation Accuracy: 0.8185, Loss: 0.2140
Epoch  78 Batch  240/269 - Train Accuracy: 0.8474, Validation Accuracy: 0.8208, Loss: 0.1960
Epoch  78 Batch  250/269 - Train Accuracy: 0.8258, Validation Accuracy: 0.8236, Loss: 0.2098
Epoch  78 Batch  260/269 - Train Accuracy: 0.8063, Validation Accuracy: 0.8224, Loss: 0.2302
Epoch  79 Batch   10/269 - Train Accuracy: 0.8273, Validation Accuracy: 0.8208, Loss: 0.2101
Epoch  79 Batch   20/269 - Train Accuracy: 0.8313, Validation Accuracy: 0.8263, Loss: 0.2168
Epoch  79 Batch   30/269 - Train Accuracy: 0.8225, Validation Accuracy: 0.8264, Loss: 0.2122
Epoch  79 Batch   40/269 - Train Accuracy: 0.8237, Validation Accuracy: 0.8288, Loss: 0.2352
Epoch  79 Batch   50/269 - Train Accuracy: 0.8153, Validation Accuracy: 0.8320, Loss: 0.2310
Epoch  79 Batch   60/269 - Train Accuracy: 0.8267, Validation Accuracy: 0.8192, Loss: 0.2008
Epoch  79 Batch   70/269 - Train Accuracy: 0.8404, Validation Accuracy: 0.8235, Loss: 0.2155
Epoch  79 Batch   80/269 - Train Accuracy: 0.8241, Validation Accuracy: 0.8196, Loss: 0.2118
Epoch  79 Batch   90/269 - Train Accuracy: 0.8216, Validation Accuracy: 0.8248, Loss: 0.2243
Epoch  79 Batch  100/269 - Train Accuracy: 0.8390, Validation Accuracy: 0.8241, Loss: 0.2050
Epoch  79 Batch  110/269 - Train Accuracy: 0.8209, Validation Accuracy: 0.8285, Loss: 0.2109
Epoch  79 Batch  120/269 - Train Accuracy: 0.8201, Validation Accuracy: 0.8272, Loss: 0.2209
Epoch  79 Batch  130/269 - Train Accuracy: 0.8263, Validation Accuracy: 0.8259, Loss: 0.2271
Epoch  79 Batch  140/269 - Train Accuracy: 0.8295, Validation Accuracy: 0.8287, Loss: 0.2347
Epoch  79 Batch  150/269 - Train Accuracy: 0.8251, Validation Accuracy: 0.8344, Loss: 0.2143
Epoch  79 Batch  160/269 - Train Accuracy: 0.8200, Validation Accuracy: 0.8274, Loss: 0.2140
Epoch  79 Batch  170/269 - Train Accuracy: 0.8210, Validation Accuracy: 0.8318, Loss: 0.2182
Epoch  79 Batch  180/269 - Train Accuracy: 0.8412, Validation Accuracy: 0.8182, Loss: 0.2034
Epoch  79 Batch  190/269 - Train Accuracy: 0.8434, Validation Accuracy: 0.8273, Loss: 0.2108
Epoch  79 Batch  200/269 - Train Accuracy: 0.8155, Validation Accuracy: 0.8269, Loss: 0.2248
Epoch  79 Batch  210/269 - Train Accuracy: 0.8440, Validation Accuracy: 0.8270, Loss: 0.2075
Epoch  79 Batch  220/269 - Train Accuracy: 0.8343, Validation Accuracy: 0.8197, Loss: 0.2043
Epoch  79 Batch  230/269 - Train Accuracy: 0.8306, Validation Accuracy: 0.8297, Loss: 0.2118
Epoch  79 Batch  240/269 - Train Accuracy: 0.8491, Validation Accuracy: 0.8275, Loss: 0.1975
Epoch  79 Batch  250/269 - Train Accuracy: 0.8271, Validation Accuracy: 0.8246, Loss: 0.2219
Epoch  79 Batch  260/269 - Train Accuracy: 0.8066, Validation Accuracy: 0.8281, Loss: 0.2294
Epoch  80 Batch   10/269 - Train Accuracy: 0.8379, Validation Accuracy: 0.8287, Loss: 0.2132
Epoch  80 Batch   20/269 - Train Accuracy: 0.8322, Validation Accuracy: 0.8285, Loss: 0.2149
Epoch  80 Batch   30/269 - Train Accuracy: 0.8263, Validation Accuracy: 0.8283, Loss: 0.2108
Epoch  80 Batch   40/269 - Train Accuracy: 0.8238, Validation Accuracy: 0.8288, Loss: 0.2220
Epoch  80 Batch   50/269 - Train Accuracy: 0.8164, Validation Accuracy: 0.8348, Loss: 0.2252
Epoch  80 Batch   60/269 - Train Accuracy: 0.8317, Validation Accuracy: 0.8283, Loss: 0.1986
Epoch  80 Batch   70/269 - Train Accuracy: 0.8374, Validation Accuracy: 0.8187, Loss: 0.2109
Epoch  80 Batch   80/269 - Train Accuracy: 0.8217, Validation Accuracy: 0.8191, Loss: 0.2084
Epoch  80 Batch   90/269 - Train Accuracy: 0.8178, Validation Accuracy: 0.8267, Loss: 0.2270
Epoch  80 Batch  100/269 - Train Accuracy: 0.8345, Validation Accuracy: 0.8300, Loss: 0.2143
Epoch  80 Batch  110/269 - Train Accuracy: 0.8254, Validation Accuracy: 0.8293, Loss: 0.2189
Epoch  80 Batch  120/269 - Train Accuracy: 0.8278, Validation Accuracy: 0.8314, Loss: 0.2149
Epoch  80 Batch  130/269 - Train Accuracy: 0.8282, Validation Accuracy: 0.8274, Loss: 0.2212
Epoch  80 Batch  140/269 - Train Accuracy: 0.8268, Validation Accuracy: 0.8323, Loss: 0.2264
Epoch  80 Batch  150/269 - Train Accuracy: 0.8273, Validation Accuracy: 0.8282, Loss: 0.2120
Epoch  80 Batch  160/269 - Train Accuracy: 0.8169, Validation Accuracy: 0.8244, Loss: 0.2183
Epoch  80 Batch  170/269 - Train Accuracy: 0.8108, Validation Accuracy: 0.8287, Loss: 0.2085
Epoch  80 Batch  180/269 - Train Accuracy: 0.8430, Validation Accuracy: 0.8307, Loss: 0.2011
Epoch  80 Batch  190/269 - Train Accuracy: 0.8410, Validation Accuracy: 0.8240, Loss: 0.2087
Epoch  80 Batch  200/269 - Train Accuracy: 0.8227, Validation Accuracy: 0.8311, Loss: 0.2107
Epoch  80 Batch  210/269 - Train Accuracy: 0.8371, Validation Accuracy: 0.8299, Loss: 0.2108
Epoch  80 Batch  220/269 - Train Accuracy: 0.8283, Validation Accuracy: 0.8241, Loss: 0.1996
Epoch  80 Batch  230/269 - Train Accuracy: 0.8307, Validation Accuracy: 0.8215, Loss: 0.2129
Epoch  80 Batch  240/269 - Train Accuracy: 0.8503, Validation Accuracy: 0.8251, Loss: 0.1889
Epoch  80 Batch  250/269 - Train Accuracy: 0.8332, Validation Accuracy: 0.8281, Loss: 0.2162
Epoch  80 Batch  260/269 - Train Accuracy: 0.8013, Validation Accuracy: 0.8235, Loss: 0.2215
Epoch  81 Batch   10/269 - Train Accuracy: 0.8304, Validation Accuracy: 0.8287, Loss: 0.2114
Epoch  81 Batch   20/269 - Train Accuracy: 0.8385, Validation Accuracy: 0.8267, Loss: 0.2205
Epoch  81 Batch   30/269 - Train Accuracy: 0.8223, Validation Accuracy: 0.8279, Loss: 0.2229
Epoch  81 Batch   40/269 - Train Accuracy: 0.8188, Validation Accuracy: 0.8242, Loss: 0.2268
Epoch  81 Batch   50/269 - Train Accuracy: 0.8169, Validation Accuracy: 0.8307, Loss: 0.2258
Epoch  81 Batch   60/269 - Train Accuracy: 0.8256, Validation Accuracy: 0.8271, Loss: 0.2045
Epoch  81 Batch   70/269 - Train Accuracy: 0.8399, Validation Accuracy: 0.8267, Loss: 0.2077
Epoch  81 Batch   80/269 - Train Accuracy: 0.8251, Validation Accuracy: 0.8232, Loss: 0.2103
Epoch  81 Batch   90/269 - Train Accuracy: 0.8243, Validation Accuracy: 0.8299, Loss: 0.2170
Epoch  81 Batch  100/269 - Train Accuracy: 0.8346, Validation Accuracy: 0.8263, Loss: 0.2085
Epoch  81 Batch  110/269 - Train Accuracy: 0.8226, Validation Accuracy: 0.8312, Loss: 0.2182
Epoch  81 Batch  120/269 - Train Accuracy: 0.8179, Validation Accuracy: 0.8288, Loss: 0.2170
Epoch  81 Batch  130/269 - Train Accuracy: 0.8323, Validation Accuracy: 0.8290, Loss: 0.2243
Epoch  81 Batch  140/269 - Train Accuracy: 0.8317, Validation Accuracy: 0.8323, Loss: 0.2224
Epoch  81 Batch  150/269 - Train Accuracy: 0.8230, Validation Accuracy: 0.8302, Loss: 0.2036
Epoch  81 Batch  160/269 - Train Accuracy: 0.8254, Validation Accuracy: 0.8329, Loss: 0.2168
Epoch  81 Batch  170/269 - Train Accuracy: 0.8199, Validation Accuracy: 0.8310, Loss: 0.2066
Epoch  81 Batch  180/269 - Train Accuracy: 0.8417, Validation Accuracy: 0.8259, Loss: 0.1990
Epoch  81 Batch  190/269 - Train Accuracy: 0.8398, Validation Accuracy: 0.8327, Loss: 0.2043
Epoch  81 Batch  200/269 - Train Accuracy: 0.8215, Validation Accuracy: 0.8284, Loss: 0.2113
Epoch  81 Batch  210/269 - Train Accuracy: 0.8450, Validation Accuracy: 0.8295, Loss: 0.2030
Epoch  81 Batch  220/269 - Train Accuracy: 0.8392, Validation Accuracy: 0.8275, Loss: 0.2079
Epoch  81 Batch  230/269 - Train Accuracy: 0.8355, Validation Accuracy: 0.8342, Loss: 0.2048
Epoch  81 Batch  240/269 - Train Accuracy: 0.8466, Validation Accuracy: 0.8330, Loss: 0.1917
Epoch  81 Batch  250/269 - Train Accuracy: 0.8305, Validation Accuracy: 0.8251, Loss: 0.2123
Epoch  81 Batch  260/269 - Train Accuracy: 0.8039, Validation Accuracy: 0.8258, Loss: 0.2233
Epoch  82 Batch   10/269 - Train Accuracy: 0.8326, Validation Accuracy: 0.8287, Loss: 0.2033
Epoch  82 Batch   20/269 - Train Accuracy: 0.8336, Validation Accuracy: 0.8247, Loss: 0.2108
Epoch  82 Batch   30/269 - Train Accuracy: 0.8273, Validation Accuracy: 0.8328, Loss: 0.2051
Epoch  82 Batch   40/269 - Train Accuracy: 0.8220, Validation Accuracy: 0.8263, Loss: 0.2232
Epoch  82 Batch   50/269 - Train Accuracy: 0.8178, Validation Accuracy: 0.8356, Loss: 0.2229
Epoch  82 Batch   60/269 - Train Accuracy: 0.8357, Validation Accuracy: 0.8332, Loss: 0.1990
Epoch  82 Batch   70/269 - Train Accuracy: 0.8445, Validation Accuracy: 0.8259, Loss: 0.2091
Epoch  82 Batch   80/269 - Train Accuracy: 0.8285, Validation Accuracy: 0.8273, Loss: 0.2178
Epoch  82 Batch   90/269 - Train Accuracy: 0.8172, Validation Accuracy: 0.8282, Loss: 0.2180
Epoch  82 Batch  100/269 - Train Accuracy: 0.8349, Validation Accuracy: 0.8272, Loss: 0.2073
Epoch  82 Batch  110/269 - Train Accuracy: 0.8242, Validation Accuracy: 0.8311, Loss: 0.2089
Epoch  82 Batch  120/269 - Train Accuracy: 0.8234, Validation Accuracy: 0.8274, Loss: 0.2218
Epoch  82 Batch  130/269 - Train Accuracy: 0.8296, Validation Accuracy: 0.8307, Loss: 0.2227
Epoch  82 Batch  140/269 - Train Accuracy: 0.8299, Validation Accuracy: 0.8299, Loss: 0.2225
Epoch  82 Batch  150/269 - Train Accuracy: 0.8314, Validation Accuracy: 0.8275, Loss: 0.2118
Epoch  82 Batch  160/269 - Train Accuracy: 0.8265, Validation Accuracy: 0.8250, Loss: 0.2125
Epoch  82 Batch  170/269 - Train Accuracy: 0.8222, Validation Accuracy: 0.8268, Loss: 0.2018
Epoch  82 Batch  180/269 - Train Accuracy: 0.8430, Validation Accuracy: 0.8252, Loss: 0.2001
Epoch  82 Batch  190/269 - Train Accuracy: 0.8381, Validation Accuracy: 0.8319, Loss: 0.2067
Epoch  82 Batch  200/269 - Train Accuracy: 0.8236, Validation Accuracy: 0.8316, Loss: 0.2073
Epoch  82 Batch  210/269 - Train Accuracy: 0.8444, Validation Accuracy: 0.8279, Loss: 0.2088
Epoch  82 Batch  220/269 - Train Accuracy: 0.8358, Validation Accuracy: 0.8266, Loss: 0.1999
Epoch  82 Batch  230/269 - Train Accuracy: 0.8348, Validation Accuracy: 0.8303, Loss: 0.2077
Epoch  82 Batch  240/269 - Train Accuracy: 0.8497, Validation Accuracy: 0.8317, Loss: 0.1853
Epoch  82 Batch  250/269 - Train Accuracy: 0.8363, Validation Accuracy: 0.8329, Loss: 0.2115
Epoch  82 Batch  260/269 - Train Accuracy: 0.8096, Validation Accuracy: 0.8253, Loss: 0.2177
Epoch  83 Batch   10/269 - Train Accuracy: 0.8340, Validation Accuracy: 0.8273, Loss: 0.2044
Epoch  83 Batch   20/269 - Train Accuracy: 0.8379, Validation Accuracy: 0.8279, Loss: 0.2112
Epoch  83 Batch   30/269 - Train Accuracy: 0.8253, Validation Accuracy: 0.8248, Loss: 0.2039
Epoch  83 Batch   40/269 - Train Accuracy: 0.8268, Validation Accuracy: 0.8312, Loss: 0.2215
Epoch  83 Batch   50/269 - Train Accuracy: 0.8130, Validation Accuracy: 0.8303, Loss: 0.2253
Epoch  83 Batch   60/269 - Train Accuracy: 0.8346, Validation Accuracy: 0.8246, Loss: 0.1952
Epoch  83 Batch   70/269 - Train Accuracy: 0.8386, Validation Accuracy: 0.8240, Loss: 0.2100
Epoch  83 Batch   80/269 - Train Accuracy: 0.8289, Validation Accuracy: 0.8208, Loss: 0.2099
Epoch  83 Batch   90/269 - Train Accuracy: 0.8219, Validation Accuracy: 0.8229, Loss: 0.2122
Epoch  83 Batch  100/269 - Train Accuracy: 0.8384, Validation Accuracy: 0.8282, Loss: 0.2069
Epoch  83 Batch  110/269 - Train Accuracy: 0.8201, Validation Accuracy: 0.8254, Loss: 0.2049
Epoch  83 Batch  120/269 - Train Accuracy: 0.8234, Validation Accuracy: 0.8307, Loss: 0.2128
Epoch  83 Batch  130/269 - Train Accuracy: 0.8256, Validation Accuracy: 0.8262, Loss: 0.2122
Epoch  83 Batch  140/269 - Train Accuracy: 0.8312, Validation Accuracy: 0.8256, Loss: 0.2182
Epoch  83 Batch  150/269 - Train Accuracy: 0.8326, Validation Accuracy: 0.8298, Loss: 0.2063
Epoch  83 Batch  160/269 - Train Accuracy: 0.8190, Validation Accuracy: 0.8227, Loss: 0.2059
Epoch  83 Batch  170/269 - Train Accuracy: 0.8218, Validation Accuracy: 0.8282, Loss: 0.2036
Epoch  83 Batch  180/269 - Train Accuracy: 0.8445, Validation Accuracy: 0.8349, Loss: 0.2007
Epoch  83 Batch  190/269 - Train Accuracy: 0.8409, Validation Accuracy: 0.8310, Loss: 0.2001
Epoch  83 Batch  200/269 - Train Accuracy: 0.8213, Validation Accuracy: 0.8327, Loss: 0.2067
Epoch  83 Batch  210/269 - Train Accuracy: 0.8391, Validation Accuracy: 0.8237, Loss: 0.2086
Epoch  83 Batch  220/269 - Train Accuracy: 0.8350, Validation Accuracy: 0.8245, Loss: 0.1903
Epoch  83 Batch  230/269 - Train Accuracy: 0.8293, Validation Accuracy: 0.8284, Loss: 0.2093
Epoch  83 Batch  240/269 - Train Accuracy: 0.8483, Validation Accuracy: 0.8335, Loss: 0.1806
Epoch  83 Batch  250/269 - Train Accuracy: 0.8358, Validation Accuracy: 0.8297, Loss: 0.2103
Epoch  83 Batch  260/269 - Train Accuracy: 0.8094, Validation Accuracy: 0.8287, Loss: 0.2216
Epoch  84 Batch   10/269 - Train Accuracy: 0.8390, Validation Accuracy: 0.8282, Loss: 0.2017
Epoch  84 Batch   20/269 - Train Accuracy: 0.8351, Validation Accuracy: 0.8284, Loss: 0.2066
Epoch  84 Batch   30/269 - Train Accuracy: 0.8287, Validation Accuracy: 0.8317, Loss: 0.2036
Epoch  84 Batch   40/269 - Train Accuracy: 0.8201, Validation Accuracy: 0.8234, Loss: 0.2228
Epoch  84 Batch   50/269 - Train Accuracy: 0.8105, Validation Accuracy: 0.8298, Loss: 0.2255
Epoch  84 Batch   60/269 - Train Accuracy: 0.8265, Validation Accuracy: 0.8263, Loss: 0.1965
Epoch  84 Batch   70/269 - Train Accuracy: 0.8447, Validation Accuracy: 0.8268, Loss: 0.2026
Epoch  84 Batch   80/269 - Train Accuracy: 0.8358, Validation Accuracy: 0.8197, Loss: 0.2011
Epoch  84 Batch   90/269 - Train Accuracy: 0.8256, Validation Accuracy: 0.8303, Loss: 0.2104
Epoch  84 Batch  100/269 - Train Accuracy: 0.8358, Validation Accuracy: 0.8254, Loss: 0.1982
Epoch  84 Batch  110/269 - Train Accuracy: 0.8263, Validation Accuracy: 0.8298, Loss: 0.2117
Epoch  84 Batch  120/269 - Train Accuracy: 0.8266, Validation Accuracy: 0.8371, Loss: 0.2132
Epoch  84 Batch  130/269 - Train Accuracy: 0.8320, Validation Accuracy: 0.8334, Loss: 0.2150
Epoch  84 Batch  140/269 - Train Accuracy: 0.8324, Validation Accuracy: 0.8290, Loss: 0.2170
Epoch  84 Batch  150/269 - Train Accuracy: 0.8276, Validation Accuracy: 0.8316, Loss: 0.2045
Epoch  84 Batch  160/269 - Train Accuracy: 0.8265, Validation Accuracy: 0.8304, Loss: 0.2071
Epoch  84 Batch  170/269 - Train Accuracy: 0.8205, Validation Accuracy: 0.8263, Loss: 0.1980
Epoch  84 Batch  180/269 - Train Accuracy: 0.8451, Validation Accuracy: 0.8277, Loss: 0.1980
Epoch  84 Batch  190/269 - Train Accuracy: 0.8358, Validation Accuracy: 0.8312, Loss: 0.1952
Epoch  84 Batch  200/269 - Train Accuracy: 0.8187, Validation Accuracy: 0.8271, Loss: 0.2059
Epoch  84 Batch  210/269 - Train Accuracy: 0.8421, Validation Accuracy: 0.8278, Loss: 0.2031
Epoch  84 Batch  220/269 - Train Accuracy: 0.8366, Validation Accuracy: 0.8234, Loss: 0.1970
Epoch  84 Batch  230/269 - Train Accuracy: 0.8411, Validation Accuracy: 0.8380, Loss: 0.2046
Epoch  84 Batch  240/269 - Train Accuracy: 0.8499, Validation Accuracy: 0.8287, Loss: 0.1870
Epoch  84 Batch  250/269 - Train Accuracy: 0.8397, Validation Accuracy: 0.8333, Loss: 0.2083
Epoch  84 Batch  260/269 - Train Accuracy: 0.8090, Validation Accuracy: 0.8287, Loss: 0.2120
Epoch  85 Batch   10/269 - Train Accuracy: 0.8325, Validation Accuracy: 0.8288, Loss: 0.2011
Epoch  85 Batch   20/269 - Train Accuracy: 0.8383, Validation Accuracy: 0.8319, Loss: 0.2127
Epoch  85 Batch   30/269 - Train Accuracy: 0.8291, Validation Accuracy: 0.8296, Loss: 0.1992
Epoch  85 Batch   40/269 - Train Accuracy: 0.8256, Validation Accuracy: 0.8300, Loss: 0.2204
Epoch  85 Batch   50/269 - Train Accuracy: 0.8070, Validation Accuracy: 0.8359, Loss: 0.2210
Epoch  85 Batch   60/269 - Train Accuracy: 0.8300, Validation Accuracy: 0.8292, Loss: 0.1883
Epoch  85 Batch   70/269 - Train Accuracy: 0.8394, Validation Accuracy: 0.8191, Loss: 0.2020
Epoch  85 Batch   80/269 - Train Accuracy: 0.8303, Validation Accuracy: 0.8248, Loss: 0.2108
Epoch  85 Batch   90/269 - Train Accuracy: 0.8205, Validation Accuracy: 0.8279, Loss: 0.2103
Epoch  85 Batch  100/269 - Train Accuracy: 0.8413, Validation Accuracy: 0.8292, Loss: 0.2059
Epoch  85 Batch  110/269 - Train Accuracy: 0.8256, Validation Accuracy: 0.8315, Loss: 0.2022
Epoch  85 Batch  120/269 - Train Accuracy: 0.8283, Validation Accuracy: 0.8326, Loss: 0.2089
Epoch  85 Batch  130/269 - Train Accuracy: 0.8247, Validation Accuracy: 0.8271, Loss: 0.2158
Epoch  85 Batch  140/269 - Train Accuracy: 0.8309, Validation Accuracy: 0.8268, Loss: 0.2099
Epoch  85 Batch  150/269 - Train Accuracy: 0.8283, Validation Accuracy: 0.8355, Loss: 0.1973
Epoch  85 Batch  160/269 - Train Accuracy: 0.8273, Validation Accuracy: 0.8275, Loss: 0.2053
Epoch  85 Batch  170/269 - Train Accuracy: 0.8233, Validation Accuracy: 0.8316, Loss: 0.2003
Epoch  85 Batch  180/269 - Train Accuracy: 0.8437, Validation Accuracy: 0.8244, Loss: 0.1869
Epoch  85 Batch  190/269 - Train Accuracy: 0.8453, Validation Accuracy: 0.8302, Loss: 0.2048
Epoch  85 Batch  200/269 - Train Accuracy: 0.8174, Validation Accuracy: 0.8252, Loss: 0.2005
Epoch  85 Batch  210/269 - Train Accuracy: 0.8478, Validation Accuracy: 0.8303, Loss: 0.2001
Epoch  85 Batch  220/269 - Train Accuracy: 0.8384, Validation Accuracy: 0.8255, Loss: 0.1972
Epoch  85 Batch  230/269 - Train Accuracy: 0.8394, Validation Accuracy: 0.8305, Loss: 0.2011
Epoch  85 Batch  240/269 - Train Accuracy: 0.8519, Validation Accuracy: 0.8257, Loss: 0.1933
Epoch  85 Batch  250/269 - Train Accuracy: 0.8400, Validation Accuracy: 0.8316, Loss: 0.2007
Epoch  85 Batch  260/269 - Train Accuracy: 0.8084, Validation Accuracy: 0.8261, Loss: 0.2077
Epoch  86 Batch   10/269 - Train Accuracy: 0.8366, Validation Accuracy: 0.8286, Loss: 0.1987
Epoch  86 Batch   20/269 - Train Accuracy: 0.8357, Validation Accuracy: 0.8299, Loss: 0.2090
Epoch  86 Batch   30/269 - Train Accuracy: 0.8230, Validation Accuracy: 0.8298, Loss: 0.1995
Epoch  86 Batch   40/269 - Train Accuracy: 0.8239, Validation Accuracy: 0.8301, Loss: 0.2213
Epoch  86 Batch   50/269 - Train Accuracy: 0.8154, Validation Accuracy: 0.8293, Loss: 0.2195
Epoch  86 Batch   60/269 - Train Accuracy: 0.8312, Validation Accuracy: 0.8263, Loss: 0.1870
Epoch  86 Batch   70/269 - Train Accuracy: 0.8455, Validation Accuracy: 0.8271, Loss: 0.1977
Epoch  86 Batch   80/269 - Train Accuracy: 0.8404, Validation Accuracy: 0.8282, Loss: 0.2044
Epoch  86 Batch   90/269 - Train Accuracy: 0.8271, Validation Accuracy: 0.8279, Loss: 0.2100
Epoch  86 Batch  100/269 - Train Accuracy: 0.8381, Validation Accuracy: 0.8321, Loss: 0.1968
Epoch  86 Batch  110/269 - Train Accuracy: 0.8205, Validation Accuracy: 0.8297, Loss: 0.2044
Epoch  86 Batch  120/269 - Train Accuracy: 0.8251, Validation Accuracy: 0.8316, Loss: 0.2085
Epoch  86 Batch  130/269 - Train Accuracy: 0.8275, Validation Accuracy: 0.8295, Loss: 0.2126
Epoch  86 Batch  140/269 - Train Accuracy: 0.8341, Validation Accuracy: 0.8359, Loss: 0.2117
Epoch  86 Batch  150/269 - Train Accuracy: 0.8331, Validation Accuracy: 0.8272, Loss: 0.1969
Epoch  86 Batch  160/269 - Train Accuracy: 0.8302, Validation Accuracy: 0.8327, Loss: 0.2013
Epoch  86 Batch  170/269 - Train Accuracy: 0.8211, Validation Accuracy: 0.8318, Loss: 0.2042
Epoch  86 Batch  180/269 - Train Accuracy: 0.8413, Validation Accuracy: 0.8263, Loss: 0.1894
Epoch  86 Batch  190/269 - Train Accuracy: 0.8434, Validation Accuracy: 0.8349, Loss: 0.1966
Epoch  86 Batch  200/269 - Train Accuracy: 0.8283, Validation Accuracy: 0.8354, Loss: 0.2081
Epoch  86 Batch  210/269 - Train Accuracy: 0.8424, Validation Accuracy: 0.8288, Loss: 0.2000
Epoch  86 Batch  220/269 - Train Accuracy: 0.8430, Validation Accuracy: 0.8247, Loss: 0.1957
Epoch  86 Batch  230/269 - Train Accuracy: 0.8304, Validation Accuracy: 0.8266, Loss: 0.2008
Epoch  86 Batch  240/269 - Train Accuracy: 0.8578, Validation Accuracy: 0.8327, Loss: 0.1808
Epoch  86 Batch  250/269 - Train Accuracy: 0.8338, Validation Accuracy: 0.8255, Loss: 0.2021
Epoch  86 Batch  260/269 - Train Accuracy: 0.8063, Validation Accuracy: 0.8280, Loss: 0.2154
Epoch  87 Batch   10/269 - Train Accuracy: 0.8373, Validation Accuracy: 0.8248, Loss: 0.1991
Epoch  87 Batch   20/269 - Train Accuracy: 0.8379, Validation Accuracy: 0.8327, Loss: 0.1979
Epoch  87 Batch   30/269 - Train Accuracy: 0.8259, Validation Accuracy: 0.8268, Loss: 0.1936
Epoch  87 Batch   40/269 - Train Accuracy: 0.8262, Validation Accuracy: 0.8297, Loss: 0.2188
Epoch  87 Batch   50/269 - Train Accuracy: 0.8185, Validation Accuracy: 0.8317, Loss: 0.2185
Epoch  87 Batch   60/269 - Train Accuracy: 0.8314, Validation Accuracy: 0.8287, Loss: 0.1916
Epoch  87 Batch   70/269 - Train Accuracy: 0.8438, Validation Accuracy: 0.8322, Loss: 0.2053
Epoch  87 Batch   80/269 - Train Accuracy: 0.8412, Validation Accuracy: 0.8298, Loss: 0.1969
Epoch  87 Batch   90/269 - Train Accuracy: 0.8279, Validation Accuracy: 0.8284, Loss: 0.2127
Epoch  87 Batch  100/269 - Train Accuracy: 0.8415, Validation Accuracy: 0.8311, Loss: 0.1936
Epoch  87 Batch  110/269 - Train Accuracy: 0.8267, Validation Accuracy: 0.8283, Loss: 0.2026
Epoch  87 Batch  120/269 - Train Accuracy: 0.8284, Validation Accuracy: 0.8335, Loss: 0.2045
Epoch  87 Batch  130/269 - Train Accuracy: 0.8310, Validation Accuracy: 0.8284, Loss: 0.2135
Epoch  87 Batch  140/269 - Train Accuracy: 0.8296, Validation Accuracy: 0.8258, Loss: 0.2203
Epoch  87 Batch  150/269 - Train Accuracy: 0.8290, Validation Accuracy: 0.8287, Loss: 0.1986
Epoch  87 Batch  160/269 - Train Accuracy: 0.8287, Validation Accuracy: 0.8346, Loss: 0.1994
Epoch  87 Batch  170/269 - Train Accuracy: 0.8260, Validation Accuracy: 0.8271, Loss: 0.2038
Epoch  87 Batch  180/269 - Train Accuracy: 0.8432, Validation Accuracy: 0.8306, Loss: 0.1943
Epoch  87 Batch  190/269 - Train Accuracy: 0.8408, Validation Accuracy: 0.8361, Loss: 0.1972
Epoch  87 Batch  200/269 - Train Accuracy: 0.8230, Validation Accuracy: 0.8324, Loss: 0.2091
Epoch  87 Batch  210/269 - Train Accuracy: 0.8440, Validation Accuracy: 0.8306, Loss: 0.2005
Epoch  87 Batch  220/269 - Train Accuracy: 0.8440, Validation Accuracy: 0.8311, Loss: 0.1938
Epoch  87 Batch  230/269 - Train Accuracy: 0.8293, Validation Accuracy: 0.8288, Loss: 0.2055
Epoch  87 Batch  240/269 - Train Accuracy: 0.8513, Validation Accuracy: 0.8308, Loss: 0.1757
Epoch  87 Batch  250/269 - Train Accuracy: 0.8402, Validation Accuracy: 0.8359, Loss: 0.2015
Epoch  87 Batch  260/269 - Train Accuracy: 0.8116, Validation Accuracy: 0.8295, Loss: 0.2045
Epoch  88 Batch   10/269 - Train Accuracy: 0.8352, Validation Accuracy: 0.8358, Loss: 0.1991
Epoch  88 Batch   20/269 - Train Accuracy: 0.8391, Validation Accuracy: 0.8345, Loss: 0.2033
Epoch  88 Batch   30/269 - Train Accuracy: 0.8295, Validation Accuracy: 0.8336, Loss: 0.1938
Epoch  88 Batch   40/269 - Train Accuracy: 0.8212, Validation Accuracy: 0.8365, Loss: 0.2153
Epoch  88 Batch   50/269 - Train Accuracy: 0.8174, Validation Accuracy: 0.8366, Loss: 0.2085
Epoch  88 Batch   60/269 - Train Accuracy: 0.8289, Validation Accuracy: 0.8252, Loss: 0.1967
Epoch  88 Batch   70/269 - Train Accuracy: 0.8471, Validation Accuracy: 0.8314, Loss: 0.1949
Epoch  88 Batch   80/269 - Train Accuracy: 0.8378, Validation Accuracy: 0.8210, Loss: 0.1938
Epoch  88 Batch   90/269 - Train Accuracy: 0.8262, Validation Accuracy: 0.8292, Loss: 0.2083
Epoch  88 Batch  100/269 - Train Accuracy: 0.8456, Validation Accuracy: 0.8289, Loss: 0.1983
Epoch  88 Batch  110/269 - Train Accuracy: 0.8217, Validation Accuracy: 0.8352, Loss: 0.2129
Epoch  88 Batch  120/269 - Train Accuracy: 0.8318, Validation Accuracy: 0.8336, Loss: 0.2128
Epoch  88 Batch  130/269 - Train Accuracy: 0.8242, Validation Accuracy: 0.8319, Loss: 0.2085
Epoch  88 Batch  140/269 - Train Accuracy: 0.8344, Validation Accuracy: 0.8283, Loss: 0.2150
Epoch  88 Batch  150/269 - Train Accuracy: 0.8318, Validation Accuracy: 0.8364, Loss: 0.1909
Epoch  88 Batch  160/269 - Train Accuracy: 0.8303, Validation Accuracy: 0.8308, Loss: 0.1960
Epoch  88 Batch  170/269 - Train Accuracy: 0.8244, Validation Accuracy: 0.8303, Loss: 0.2039
Epoch  88 Batch  180/269 - Train Accuracy: 0.8477, Validation Accuracy: 0.8307, Loss: 0.1882
Epoch  88 Batch  190/269 - Train Accuracy: 0.8441, Validation Accuracy: 0.8358, Loss: 0.1955
Epoch  88 Batch  200/269 - Train Accuracy: 0.8242, Validation Accuracy: 0.8321, Loss: 0.2038
Epoch  88 Batch  210/269 - Train Accuracy: 0.8481, Validation Accuracy: 0.8303, Loss: 0.2004
Epoch  88 Batch  220/269 - Train Accuracy: 0.8335, Validation Accuracy: 0.8271, Loss: 0.1872
Epoch  88 Batch  230/269 - Train Accuracy: 0.8424, Validation Accuracy: 0.8327, Loss: 0.1921
Epoch  88 Batch  240/269 - Train Accuracy: 0.8485, Validation Accuracy: 0.8301, Loss: 0.1711
Epoch  88 Batch  250/269 - Train Accuracy: 0.8390, Validation Accuracy: 0.8327, Loss: 0.2036
Epoch  88 Batch  260/269 - Train Accuracy: 0.8181, Validation Accuracy: 0.8310, Loss: 0.2136
Epoch  89 Batch   10/269 - Train Accuracy: 0.8409, Validation Accuracy: 0.8293, Loss: 0.1981
Epoch  89 Batch   20/269 - Train Accuracy: 0.8380, Validation Accuracy: 0.8292, Loss: 0.2005
Epoch  89 Batch   30/269 - Train Accuracy: 0.8262, Validation Accuracy: 0.8291, Loss: 0.1980
Epoch  89 Batch   40/269 - Train Accuracy: 0.8250, Validation Accuracy: 0.8287, Loss: 0.2122
Epoch  89 Batch   50/269 - Train Accuracy: 0.8145, Validation Accuracy: 0.8335, Loss: 0.2155
Epoch  89 Batch   60/269 - Train Accuracy: 0.8360, Validation Accuracy: 0.8319, Loss: 0.1797
Epoch  89 Batch   70/269 - Train Accuracy: 0.8393, Validation Accuracy: 0.8258, Loss: 0.1935
Epoch  89 Batch   80/269 - Train Accuracy: 0.8384, Validation Accuracy: 0.8278, Loss: 0.2011
Epoch  89 Batch   90/269 - Train Accuracy: 0.8220, Validation Accuracy: 0.8245, Loss: 0.2088
Epoch  89 Batch  100/269 - Train Accuracy: 0.8439, Validation Accuracy: 0.8339, Loss: 0.1909
Epoch  89 Batch  110/269 - Train Accuracy: 0.8267, Validation Accuracy: 0.8342, Loss: 0.1994
Epoch  89 Batch  120/269 - Train Accuracy: 0.8233, Validation Accuracy: 0.8300, Loss: 0.2040
Epoch  89 Batch  130/269 - Train Accuracy: 0.8299, Validation Accuracy: 0.8303, Loss: 0.2063
Epoch  89 Batch  140/269 - Train Accuracy: 0.8331, Validation Accuracy: 0.8272, Loss: 0.2113
Epoch  89 Batch  150/269 - Train Accuracy: 0.8356, Validation Accuracy: 0.8322, Loss: 0.1953
Epoch  89 Batch  160/269 - Train Accuracy: 0.8282, Validation Accuracy: 0.8328, Loss: 0.1971
Epoch  89 Batch  170/269 - Train Accuracy: 0.8307, Validation Accuracy: 0.8370, Loss: 0.1906
Epoch  89 Batch  180/269 - Train Accuracy: 0.8459, Validation Accuracy: 0.8326, Loss: 0.1865
Epoch  89 Batch  190/269 - Train Accuracy: 0.8508, Validation Accuracy: 0.8342, Loss: 0.1905
Epoch  89 Batch  200/269 - Train Accuracy: 0.8290, Validation Accuracy: 0.8307, Loss: 0.1969
Epoch  89 Batch  210/269 - Train Accuracy: 0.8556, Validation Accuracy: 0.8271, Loss: 0.1910
Epoch  89 Batch  220/269 - Train Accuracy: 0.8461, Validation Accuracy: 0.8265, Loss: 0.1801
Epoch  89 Batch  230/269 - Train Accuracy: 0.8362, Validation Accuracy: 0.8375, Loss: 0.2002
Epoch  89 Batch  240/269 - Train Accuracy: 0.8466, Validation Accuracy: 0.8275, Loss: 0.1744
Epoch  89 Batch  250/269 - Train Accuracy: 0.8423, Validation Accuracy: 0.8365, Loss: 0.2006
Epoch  89 Batch  260/269 - Train Accuracy: 0.8112, Validation Accuracy: 0.8301, Loss: 0.2131
Epoch  90 Batch   10/269 - Train Accuracy: 0.8407, Validation Accuracy: 0.8327, Loss: 0.1950
Epoch  90 Batch   20/269 - Train Accuracy: 0.8384, Validation Accuracy: 0.8339, Loss: 0.2074
Epoch  90 Batch   30/269 - Train Accuracy: 0.8333, Validation Accuracy: 0.8329, Loss: 0.1889
Epoch  90 Batch   40/269 - Train Accuracy: 0.8248, Validation Accuracy: 0.8321, Loss: 0.2151
Epoch  90 Batch   50/269 - Train Accuracy: 0.8233, Validation Accuracy: 0.8396, Loss: 0.2188
Epoch  90 Batch   60/269 - Train Accuracy: 0.8350, Validation Accuracy: 0.8335, Loss: 0.1855
Epoch  90 Batch   70/269 - Train Accuracy: 0.8414, Validation Accuracy: 0.8305, Loss: 0.1891
Epoch  90 Batch   80/269 - Train Accuracy: 0.8460, Validation Accuracy: 0.8321, Loss: 0.2011
Epoch  90 Batch   90/269 - Train Accuracy: 0.8317, Validation Accuracy: 0.8278, Loss: 0.2031
Epoch  90 Batch  100/269 - Train Accuracy: 0.8483, Validation Accuracy: 0.8393, Loss: 0.1846
Epoch  90 Batch  110/269 - Train Accuracy: 0.8196, Validation Accuracy: 0.8293, Loss: 0.1967
Epoch  90 Batch  120/269 - Train Accuracy: 0.8333, Validation Accuracy: 0.8366, Loss: 0.2135
Epoch  90 Batch  130/269 - Train Accuracy: 0.8333, Validation Accuracy: 0.8291, Loss: 0.2176
Epoch  90 Batch  140/269 - Train Accuracy: 0.8394, Validation Accuracy: 0.8331, Loss: 0.2114
Epoch  90 Batch  150/269 - Train Accuracy: 0.8348, Validation Accuracy: 0.8298, Loss: 0.1906
Epoch  90 Batch  160/269 - Train Accuracy: 0.8309, Validation Accuracy: 0.8314, Loss: 0.1909
Epoch  90 Batch  170/269 - Train Accuracy: 0.8238, Validation Accuracy: 0.8364, Loss: 0.1922
Epoch  90 Batch  180/269 - Train Accuracy: 0.8452, Validation Accuracy: 0.8307, Loss: 0.1835
Epoch  90 Batch  190/269 - Train Accuracy: 0.8482, Validation Accuracy: 0.8311, Loss: 0.1943
Epoch  90 Batch  200/269 - Train Accuracy: 0.8258, Validation Accuracy: 0.8288, Loss: 0.2008
Epoch  90 Batch  210/269 - Train Accuracy: 0.8532, Validation Accuracy: 0.8357, Loss: 0.1914
Epoch  90 Batch  220/269 - Train Accuracy: 0.8450, Validation Accuracy: 0.8338, Loss: 0.1912
Epoch  90 Batch  230/269 - Train Accuracy: 0.8336, Validation Accuracy: 0.8355, Loss: 0.1914
Epoch  90 Batch  240/269 - Train Accuracy: 0.8556, Validation Accuracy: 0.8322, Loss: 0.1764
Epoch  90 Batch  250/269 - Train Accuracy: 0.8391, Validation Accuracy: 0.8350, Loss: 0.1922
Epoch  90 Batch  260/269 - Train Accuracy: 0.8139, Validation Accuracy: 0.8303, Loss: 0.2108
Epoch  91 Batch   10/269 - Train Accuracy: 0.8415, Validation Accuracy: 0.8299, Loss: 0.1849
Epoch  91 Batch   20/269 - Train Accuracy: 0.8365, Validation Accuracy: 0.8347, Loss: 0.1993
Epoch  91 Batch   30/269 - Train Accuracy: 0.8331, Validation Accuracy: 0.8277, Loss: 0.1882
Epoch  91 Batch   40/269 - Train Accuracy: 0.8294, Validation Accuracy: 0.8357, Loss: 0.2156
Epoch  91 Batch   50/269 - Train Accuracy: 0.8150, Validation Accuracy: 0.8380, Loss: 0.2064
Epoch  91 Batch   60/269 - Train Accuracy: 0.8318, Validation Accuracy: 0.8292, Loss: 0.1770
Epoch  91 Batch   70/269 - Train Accuracy: 0.8473, Validation Accuracy: 0.8313, Loss: 0.1890
Epoch  91 Batch   80/269 - Train Accuracy: 0.8446, Validation Accuracy: 0.8347, Loss: 0.1954
Epoch  91 Batch   90/269 - Train Accuracy: 0.8361, Validation Accuracy: 0.8356, Loss: 0.2069
Epoch  91 Batch  100/269 - Train Accuracy: 0.8441, Validation Accuracy: 0.8341, Loss: 0.1896
Epoch  91 Batch  110/269 - Train Accuracy: 0.8278, Validation Accuracy: 0.8304, Loss: 0.1988
Epoch  91 Batch  120/269 - Train Accuracy: 0.8317, Validation Accuracy: 0.8372, Loss: 0.1982
Epoch  91 Batch  130/269 - Train Accuracy: 0.8335, Validation Accuracy: 0.8345, Loss: 0.2054
Epoch  91 Batch  140/269 - Train Accuracy: 0.8342, Validation Accuracy: 0.8284, Loss: 0.2141
Epoch  91 Batch  150/269 - Train Accuracy: 0.8325, Validation Accuracy: 0.8369, Loss: 0.1929
Epoch  91 Batch  160/269 - Train Accuracy: 0.8280, Validation Accuracy: 0.8370, Loss: 0.1879
Epoch  91 Batch  170/269 - Train Accuracy: 0.8276, Validation Accuracy: 0.8307, Loss: 0.1909
Epoch  91 Batch  180/269 - Train Accuracy: 0.8506, Validation Accuracy: 0.8347, Loss: 0.1886
Epoch  91 Batch  190/269 - Train Accuracy: 0.8428, Validation Accuracy: 0.8350, Loss: 0.1908
Epoch  91 Batch  200/269 - Train Accuracy: 0.8354, Validation Accuracy: 0.8381, Loss: 0.1939
Epoch  91 Batch  210/269 - Train Accuracy: 0.8514, Validation Accuracy: 0.8290, Loss: 0.1903
Epoch  91 Batch  220/269 - Train Accuracy: 0.8391, Validation Accuracy: 0.8327, Loss: 0.1903
Epoch  91 Batch  230/269 - Train Accuracy: 0.8394, Validation Accuracy: 0.8363, Loss: 0.1942
Epoch  91 Batch  240/269 - Train Accuracy: 0.8558, Validation Accuracy: 0.8373, Loss: 0.1794
Epoch  91 Batch  250/269 - Train Accuracy: 0.8457, Validation Accuracy: 0.8303, Loss: 0.1845
Epoch  91 Batch  260/269 - Train Accuracy: 0.8170, Validation Accuracy: 0.8333, Loss: 0.1996
Epoch  92 Batch   10/269 - Train Accuracy: 0.8362, Validation Accuracy: 0.8273, Loss: 0.1874
Epoch  92 Batch   20/269 - Train Accuracy: 0.8337, Validation Accuracy: 0.8288, Loss: 0.1951
Epoch  92 Batch   30/269 - Train Accuracy: 0.8402, Validation Accuracy: 0.8361, Loss: 0.1927
Epoch  92 Batch   40/269 - Train Accuracy: 0.8345, Validation Accuracy: 0.8361, Loss: 0.2072
Epoch  92 Batch   50/269 - Train Accuracy: 0.8202, Validation Accuracy: 0.8383, Loss: 0.2101
Epoch  92 Batch   60/269 - Train Accuracy: 0.8320, Validation Accuracy: 0.8314, Loss: 0.1790
Epoch  92 Batch   70/269 - Train Accuracy: 0.8426, Validation Accuracy: 0.8366, Loss: 0.1847
Epoch  92 Batch   80/269 - Train Accuracy: 0.8451, Validation Accuracy: 0.8322, Loss: 0.1907
Epoch  92 Batch   90/269 - Train Accuracy: 0.8374, Validation Accuracy: 0.8351, Loss: 0.2005
Epoch  92 Batch  100/269 - Train Accuracy: 0.8463, Validation Accuracy: 0.8344, Loss: 0.1870
Epoch  92 Batch  110/269 - Train Accuracy: 0.8290, Validation Accuracy: 0.8314, Loss: 0.2000
Epoch  92 Batch  120/269 - Train Accuracy: 0.8296, Validation Accuracy: 0.8297, Loss: 0.1954
Epoch  92 Batch  130/269 - Train Accuracy: 0.8337, Validation Accuracy: 0.8347, Loss: 0.2034
Epoch  92 Batch  140/269 - Train Accuracy: 0.8380, Validation Accuracy: 0.8368, Loss: 0.2080
Epoch  92 Batch  150/269 - Train Accuracy: 0.8344, Validation Accuracy: 0.8345, Loss: 0.1903
Epoch  92 Batch  160/269 - Train Accuracy: 0.8304, Validation Accuracy: 0.8329, Loss: 0.1950
Epoch  92 Batch  170/269 - Train Accuracy: 0.8275, Validation Accuracy: 0.8388, Loss: 0.1957
Epoch  92 Batch  180/269 - Train Accuracy: 0.8578, Validation Accuracy: 0.8279, Loss: 0.1809
Epoch  92 Batch  190/269 - Train Accuracy: 0.8508, Validation Accuracy: 0.8351, Loss: 0.1897
Epoch  92 Batch  200/269 - Train Accuracy: 0.8274, Validation Accuracy: 0.8358, Loss: 0.1963
Epoch  92 Batch  210/269 - Train Accuracy: 0.8545, Validation Accuracy: 0.8345, Loss: 0.1856
Epoch  92 Batch  220/269 - Train Accuracy: 0.8409, Validation Accuracy: 0.8309, Loss: 0.1771
Epoch  92 Batch  230/269 - Train Accuracy: 0.8415, Validation Accuracy: 0.8395, Loss: 0.1905
Epoch  92 Batch  240/269 - Train Accuracy: 0.8587, Validation Accuracy: 0.8420, Loss: 0.1723
Epoch  92 Batch  250/269 - Train Accuracy: 0.8438, Validation Accuracy: 0.8353, Loss: 0.1944
Epoch  92 Batch  260/269 - Train Accuracy: 0.8216, Validation Accuracy: 0.8381, Loss: 0.1985
Epoch  93 Batch   10/269 - Train Accuracy: 0.8390, Validation Accuracy: 0.8368, Loss: 0.1828
Epoch  93 Batch   20/269 - Train Accuracy: 0.8351, Validation Accuracy: 0.8344, Loss: 0.1937
Epoch  93 Batch   30/269 - Train Accuracy: 0.8331, Validation Accuracy: 0.8343, Loss: 0.1949
Epoch  93 Batch   40/269 - Train Accuracy: 0.8233, Validation Accuracy: 0.8382, Loss: 0.2135
Epoch  93 Batch   50/269 - Train Accuracy: 0.8179, Validation Accuracy: 0.8425, Loss: 0.2142
Epoch  93 Batch   60/269 - Train Accuracy: 0.8303, Validation Accuracy: 0.8389, Loss: 0.1975
Epoch  93 Batch   70/269 - Train Accuracy: 0.8481, Validation Accuracy: 0.8327, Loss: 0.1871
Epoch  93 Batch   80/269 - Train Accuracy: 0.8471, Validation Accuracy: 0.8333, Loss: 0.2012
Epoch  93 Batch   90/269 - Train Accuracy: 0.8381, Validation Accuracy: 0.8370, Loss: 0.1947
Epoch  93 Batch  100/269 - Train Accuracy: 0.8387, Validation Accuracy: 0.8414, Loss: 0.1869
Epoch  93 Batch  110/269 - Train Accuracy: 0.8307, Validation Accuracy: 0.8347, Loss: 0.1925
Epoch  93 Batch  120/269 - Train Accuracy: 0.8231, Validation Accuracy: 0.8348, Loss: 0.1996
Epoch  93 Batch  130/269 - Train Accuracy: 0.8262, Validation Accuracy: 0.8337, Loss: 0.2023
Epoch  93 Batch  140/269 - Train Accuracy: 0.8390, Validation Accuracy: 0.8342, Loss: 0.2074
Epoch  93 Batch  150/269 - Train Accuracy: 0.8343, Validation Accuracy: 0.8340, Loss: 0.1870
Epoch  93 Batch  160/269 - Train Accuracy: 0.8290, Validation Accuracy: 0.8367, Loss: 0.1935
Epoch  93 Batch  170/269 - Train Accuracy: 0.8303, Validation Accuracy: 0.8387, Loss: 0.1889
Epoch  93 Batch  180/269 - Train Accuracy: 0.8536, Validation Accuracy: 0.8311, Loss: 0.1789
Epoch  93 Batch  190/269 - Train Accuracy: 0.8455, Validation Accuracy: 0.8317, Loss: 0.1885
Epoch  93 Batch  200/269 - Train Accuracy: 0.8277, Validation Accuracy: 0.8316, Loss: 0.1878
Epoch  93 Batch  210/269 - Train Accuracy: 0.8526, Validation Accuracy: 0.8339, Loss: 0.1859
Epoch  93 Batch  220/269 - Train Accuracy: 0.8478, Validation Accuracy: 0.8315, Loss: 0.1828
Epoch  93 Batch  230/269 - Train Accuracy: 0.8372, Validation Accuracy: 0.8354, Loss: 0.1794
Epoch  93 Batch  240/269 - Train Accuracy: 0.8585, Validation Accuracy: 0.8326, Loss: 0.1655
Epoch  93 Batch  250/269 - Train Accuracy: 0.8433, Validation Accuracy: 0.8388, Loss: 0.1875
Epoch  93 Batch  260/269 - Train Accuracy: 0.8130, Validation Accuracy: 0.8295, Loss: 0.2034
Epoch  94 Batch   10/269 - Train Accuracy: 0.8417, Validation Accuracy: 0.8412, Loss: 0.1841
Epoch  94 Batch   20/269 - Train Accuracy: 0.8373, Validation Accuracy: 0.8305, Loss: 0.1900
Epoch  94 Batch   30/269 - Train Accuracy: 0.8339, Validation Accuracy: 0.8330, Loss: 0.1834
Epoch  94 Batch   40/269 - Train Accuracy: 0.8271, Validation Accuracy: 0.8358, Loss: 0.2107
Epoch  94 Batch   50/269 - Train Accuracy: 0.8233, Validation Accuracy: 0.8381, Loss: 0.2043
Epoch  94 Batch   60/269 - Train Accuracy: 0.8341, Validation Accuracy: 0.8391, Loss: 0.1844
Epoch  94 Batch   70/269 - Train Accuracy: 0.8426, Validation Accuracy: 0.8325, Loss: 0.1909
Epoch  94 Batch   80/269 - Train Accuracy: 0.8502, Validation Accuracy: 0.8316, Loss: 0.1931
Epoch  94 Batch   90/269 - Train Accuracy: 0.8318, Validation Accuracy: 0.8299, Loss: 0.1988
Epoch  94 Batch  100/269 - Train Accuracy: 0.8438, Validation Accuracy: 0.8331, Loss: 0.1798
Epoch  94 Batch  110/269 - Train Accuracy: 0.8276, Validation Accuracy: 0.8349, Loss: 0.1969
Epoch  94 Batch  120/269 - Train Accuracy: 0.8353, Validation Accuracy: 0.8354, Loss: 0.1966
Epoch  94 Batch  130/269 - Train Accuracy: 0.8362, Validation Accuracy: 0.8337, Loss: 0.2030
Epoch  94 Batch  140/269 - Train Accuracy: 0.8344, Validation Accuracy: 0.8396, Loss: 0.2093
Epoch  94 Batch  150/269 - Train Accuracy: 0.8345, Validation Accuracy: 0.8300, Loss: 0.1842
Epoch  94 Batch  160/269 - Train Accuracy: 0.8362, Validation Accuracy: 0.8357, Loss: 0.2027
Epoch  94 Batch  170/269 - Train Accuracy: 0.8310, Validation Accuracy: 0.8349, Loss: 0.1842
Epoch  94 Batch  180/269 - Train Accuracy: 0.8567, Validation Accuracy: 0.8330, Loss: 0.1791
Epoch  94 Batch  190/269 - Train Accuracy: 0.8501, Validation Accuracy: 0.8397, Loss: 0.1830
Epoch  94 Batch  200/269 - Train Accuracy: 0.8326, Validation Accuracy: 0.8373, Loss: 0.1906
Epoch  94 Batch  210/269 - Train Accuracy: 0.8551, Validation Accuracy: 0.8360, Loss: 0.1874
Epoch  94 Batch  220/269 - Train Accuracy: 0.8443, Validation Accuracy: 0.8332, Loss: 0.1855
Epoch  94 Batch  230/269 - Train Accuracy: 0.8421, Validation Accuracy: 0.8354, Loss: 0.1906
Epoch  94 Batch  240/269 - Train Accuracy: 0.8546, Validation Accuracy: 0.8356, Loss: 0.1708
Epoch  94 Batch  250/269 - Train Accuracy: 0.8507, Validation Accuracy: 0.8399, Loss: 0.1930
Epoch  94 Batch  260/269 - Train Accuracy: 0.8218, Validation Accuracy: 0.8355, Loss: 0.2036
Epoch  95 Batch   10/269 - Train Accuracy: 0.8404, Validation Accuracy: 0.8416, Loss: 0.1773
Epoch  95 Batch   20/269 - Train Accuracy: 0.8413, Validation Accuracy: 0.8414, Loss: 0.1905
Epoch  95 Batch   30/269 - Train Accuracy: 0.8380, Validation Accuracy: 0.8358, Loss: 0.1833
Epoch  95 Batch   40/269 - Train Accuracy: 0.8271, Validation Accuracy: 0.8425, Loss: 0.2024
Epoch  95 Batch   50/269 - Train Accuracy: 0.8262, Validation Accuracy: 0.8437, Loss: 0.2098
Epoch  95 Batch   60/269 - Train Accuracy: 0.8267, Validation Accuracy: 0.8373, Loss: 0.1751
Epoch  95 Batch   70/269 - Train Accuracy: 0.8486, Validation Accuracy: 0.8384, Loss: 0.1842
Epoch  95 Batch   80/269 - Train Accuracy: 0.8462, Validation Accuracy: 0.8337, Loss: 0.1946
Epoch  95 Batch   90/269 - Train Accuracy: 0.8355, Validation Accuracy: 0.8379, Loss: 0.1975
Epoch  95 Batch  100/269 - Train Accuracy: 0.8482, Validation Accuracy: 0.8372, Loss: 0.1831
Epoch  95 Batch  110/269 - Train Accuracy: 0.8323, Validation Accuracy: 0.8379, Loss: 0.1952
Epoch  95 Batch  120/269 - Train Accuracy: 0.8293, Validation Accuracy: 0.8355, Loss: 0.2031
Epoch  95 Batch  130/269 - Train Accuracy: 0.8331, Validation Accuracy: 0.8400, Loss: 0.2001
Epoch  95 Batch  140/269 - Train Accuracy: 0.8377, Validation Accuracy: 0.8359, Loss: 0.1968
Epoch  95 Batch  150/269 - Train Accuracy: 0.8312, Validation Accuracy: 0.8402, Loss: 0.1896
Epoch  95 Batch  160/269 - Train Accuracy: 0.8317, Validation Accuracy: 0.8383, Loss: 0.1885
Epoch  95 Batch  170/269 - Train Accuracy: 0.8357, Validation Accuracy: 0.8341, Loss: 0.1831
Epoch  95 Batch  180/269 - Train Accuracy: 0.8498, Validation Accuracy: 0.8309, Loss: 0.1810
Epoch  95 Batch  190/269 - Train Accuracy: 0.8547, Validation Accuracy: 0.8371, Loss: 0.1827
Epoch  95 Batch  200/269 - Train Accuracy: 0.8321, Validation Accuracy: 0.8339, Loss: 0.1901
Epoch  95 Batch  210/269 - Train Accuracy: 0.8531, Validation Accuracy: 0.8331, Loss: 0.1963
Epoch  95 Batch  220/269 - Train Accuracy: 0.8431, Validation Accuracy: 0.8369, Loss: 0.1834
Epoch  95 Batch  230/269 - Train Accuracy: 0.8470, Validation Accuracy: 0.8424, Loss: 0.1866
Epoch  95 Batch  240/269 - Train Accuracy: 0.8528, Validation Accuracy: 0.8390, Loss: 0.1681
Epoch  95 Batch  250/269 - Train Accuracy: 0.8427, Validation Accuracy: 0.8394, Loss: 0.1900
Epoch  95 Batch  260/269 - Train Accuracy: 0.8202, Validation Accuracy: 0.8349, Loss: 0.1975
Epoch  96 Batch   10/269 - Train Accuracy: 0.8453, Validation Accuracy: 0.8378, Loss: 0.1899
Epoch  96 Batch   20/269 - Train Accuracy: 0.8416, Validation Accuracy: 0.8375, Loss: 0.1874
Epoch  96 Batch   30/269 - Train Accuracy: 0.8475, Validation Accuracy: 0.8423, Loss: 0.1812
Epoch  96 Batch   40/269 - Train Accuracy: 0.8326, Validation Accuracy: 0.8413, Loss: 0.1981
Epoch  96 Batch   50/269 - Train Accuracy: 0.8259, Validation Accuracy: 0.8463, Loss: 0.1996
Epoch  96 Batch   60/269 - Train Accuracy: 0.8377, Validation Accuracy: 0.8430, Loss: 0.1740
Epoch  96 Batch   70/269 - Train Accuracy: 0.8503, Validation Accuracy: 0.8383, Loss: 0.1859
Epoch  96 Batch   80/269 - Train Accuracy: 0.8497, Validation Accuracy: 0.8343, Loss: 0.1972
Epoch  96 Batch   90/269 - Train Accuracy: 0.8435, Validation Accuracy: 0.8388, Loss: 0.2028
Epoch  96 Batch  100/269 - Train Accuracy: 0.8495, Validation Accuracy: 0.8453, Loss: 0.1808
Epoch  96 Batch  110/269 - Train Accuracy: 0.8348, Validation Accuracy: 0.8446, Loss: 0.1916
Epoch  96 Batch  120/269 - Train Accuracy: 0.8317, Validation Accuracy: 0.8398, Loss: 0.1893
Epoch  96 Batch  130/269 - Train Accuracy: 0.8366, Validation Accuracy: 0.8398, Loss: 0.2029
Epoch  96 Batch  140/269 - Train Accuracy: 0.8434, Validation Accuracy: 0.8453, Loss: 0.2016
Epoch  96 Batch  150/269 - Train Accuracy: 0.8323, Validation Accuracy: 0.8327, Loss: 0.1857
Epoch  96 Batch  160/269 - Train Accuracy: 0.8337, Validation Accuracy: 0.8353, Loss: 0.1870
Epoch  96 Batch  170/269 - Train Accuracy: 0.8365, Validation Accuracy: 0.8468, Loss: 0.1808
Epoch  96 Batch  180/269 - Train Accuracy: 0.8520, Validation Accuracy: 0.8339, Loss: 0.1809
Epoch  96 Batch  190/269 - Train Accuracy: 0.8493, Validation Accuracy: 0.8436, Loss: 0.1819
Epoch  96 Batch  200/269 - Train Accuracy: 0.8315, Validation Accuracy: 0.8357, Loss: 0.1874
Epoch  96 Batch  210/269 - Train Accuracy: 0.8551, Validation Accuracy: 0.8363, Loss: 0.1861
Epoch  96 Batch  220/269 - Train Accuracy: 0.8407, Validation Accuracy: 0.8341, Loss: 0.1827
Epoch  96 Batch  230/269 - Train Accuracy: 0.8461, Validation Accuracy: 0.8442, Loss: 0.1857
Epoch  96 Batch  240/269 - Train Accuracy: 0.8588, Validation Accuracy: 0.8419, Loss: 0.1648
Epoch  96 Batch  250/269 - Train Accuracy: 0.8479, Validation Accuracy: 0.8477, Loss: 0.1873
Epoch  96 Batch  260/269 - Train Accuracy: 0.8141, Validation Accuracy: 0.8346, Loss: 0.1928
Epoch  97 Batch   10/269 - Train Accuracy: 0.8415, Validation Accuracy: 0.8390, Loss: 0.1816
Epoch  97 Batch   20/269 - Train Accuracy: 0.8418, Validation Accuracy: 0.8427, Loss: 0.1928
Epoch  97 Batch   30/269 - Train Accuracy: 0.8411, Validation Accuracy: 0.8475, Loss: 0.1822
Epoch  97 Batch   40/269 - Train Accuracy: 0.8305, Validation Accuracy: 0.8411, Loss: 0.2044
Epoch  97 Batch   50/269 - Train Accuracy: 0.8215, Validation Accuracy: 0.8425, Loss: 0.2034
Epoch  97 Batch   60/269 - Train Accuracy: 0.8355, Validation Accuracy: 0.8374, Loss: 0.1714
Epoch  97 Batch   70/269 - Train Accuracy: 0.8445, Validation Accuracy: 0.8344, Loss: 0.1870
Epoch  97 Batch   80/269 - Train Accuracy: 0.8449, Validation Accuracy: 0.8329, Loss: 0.1812
Epoch  97 Batch   90/269 - Train Accuracy: 0.8413, Validation Accuracy: 0.8398, Loss: 0.1957
Epoch  97 Batch  100/269 - Train Accuracy: 0.8527, Validation Accuracy: 0.8467, Loss: 0.1834
Epoch  97 Batch  110/269 - Train Accuracy: 0.8327, Validation Accuracy: 0.8460, Loss: 0.1889
Epoch  97 Batch  120/269 - Train Accuracy: 0.8313, Validation Accuracy: 0.8443, Loss: 0.1967
Epoch  97 Batch  130/269 - Train Accuracy: 0.8360, Validation Accuracy: 0.8423, Loss: 0.1957
Epoch  97 Batch  140/269 - Train Accuracy: 0.8415, Validation Accuracy: 0.8422, Loss: 0.2040
Epoch  97 Batch  150/269 - Train Accuracy: 0.8340, Validation Accuracy: 0.8404, Loss: 0.1817
Epoch  97 Batch  160/269 - Train Accuracy: 0.8375, Validation Accuracy: 0.8417, Loss: 0.1907
Epoch  97 Batch  170/269 - Train Accuracy: 0.8282, Validation Accuracy: 0.8405, Loss: 0.1903
Epoch  97 Batch  180/269 - Train Accuracy: 0.8506, Validation Accuracy: 0.8358, Loss: 0.1868
Epoch  97 Batch  190/269 - Train Accuracy: 0.8451, Validation Accuracy: 0.8362, Loss: 0.1885
Epoch  97 Batch  200/269 - Train Accuracy: 0.8305, Validation Accuracy: 0.8391, Loss: 0.1840
Epoch  97 Batch  210/269 - Train Accuracy: 0.8563, Validation Accuracy: 0.8418, Loss: 0.1841
Epoch  97 Batch  220/269 - Train Accuracy: 0.8440, Validation Accuracy: 0.8377, Loss: 0.1696
Epoch  97 Batch  230/269 - Train Accuracy: 0.8444, Validation Accuracy: 0.8431, Loss: 0.1897
Epoch  97 Batch  240/269 - Train Accuracy: 0.8596, Validation Accuracy: 0.8383, Loss: 0.1678
Epoch  97 Batch  250/269 - Train Accuracy: 0.8493, Validation Accuracy: 0.8351, Loss: 0.1802
Epoch  97 Batch  260/269 - Train Accuracy: 0.8225, Validation Accuracy: 0.8402, Loss: 0.1998
Epoch  98 Batch   10/269 - Train Accuracy: 0.8398, Validation Accuracy: 0.8347, Loss: 0.1861
Epoch  98 Batch   20/269 - Train Accuracy: 0.8360, Validation Accuracy: 0.8445, Loss: 0.1887
Epoch  98 Batch   30/269 - Train Accuracy: 0.8464, Validation Accuracy: 0.8421, Loss: 0.1868
Epoch  98 Batch   40/269 - Train Accuracy: 0.8369, Validation Accuracy: 0.8449, Loss: 0.2011
Epoch  98 Batch   50/269 - Train Accuracy: 0.8214, Validation Accuracy: 0.8476, Loss: 0.2022
Epoch  98 Batch   60/269 - Train Accuracy: 0.8347, Validation Accuracy: 0.8501, Loss: 0.1700
Epoch  98 Batch   70/269 - Train Accuracy: 0.8518, Validation Accuracy: 0.8450, Loss: 0.1798
Epoch  98 Batch   80/269 - Train Accuracy: 0.8457, Validation Accuracy: 0.8330, Loss: 0.1906
Epoch  98 Batch   90/269 - Train Accuracy: 0.8387, Validation Accuracy: 0.8396, Loss: 0.2023
Epoch  98 Batch  100/269 - Train Accuracy: 0.8480, Validation Accuracy: 0.8431, Loss: 0.1787
Epoch  98 Batch  110/269 - Train Accuracy: 0.8308, Validation Accuracy: 0.8479, Loss: 0.1842
Epoch  98 Batch  120/269 - Train Accuracy: 0.8371, Validation Accuracy: 0.8468, Loss: 0.2016
Epoch  98 Batch  130/269 - Train Accuracy: 0.8423, Validation Accuracy: 0.8447, Loss: 0.1951
Epoch  98 Batch  140/269 - Train Accuracy: 0.8397, Validation Accuracy: 0.8384, Loss: 0.1984
Epoch  98 Batch  150/269 - Train Accuracy: 0.8362, Validation Accuracy: 0.8467, Loss: 0.1848
Epoch  98 Batch  160/269 - Train Accuracy: 0.8363, Validation Accuracy: 0.8416, Loss: 0.1888
Epoch  98 Batch  170/269 - Train Accuracy: 0.8367, Validation Accuracy: 0.8453, Loss: 0.1882
Epoch  98 Batch  180/269 - Train Accuracy: 0.8605, Validation Accuracy: 0.8422, Loss: 0.1706
Epoch  98 Batch  190/269 - Train Accuracy: 0.8522, Validation Accuracy: 0.8359, Loss: 0.1809
Epoch  98 Batch  200/269 - Train Accuracy: 0.8354, Validation Accuracy: 0.8458, Loss: 0.1874
Epoch  98 Batch  210/269 - Train Accuracy: 0.8610, Validation Accuracy: 0.8421, Loss: 0.1857
Epoch  98 Batch  220/269 - Train Accuracy: 0.8532, Validation Accuracy: 0.8431, Loss: 0.1720
Epoch  98 Batch  230/269 - Train Accuracy: 0.8474, Validation Accuracy: 0.8414, Loss: 0.1895
Epoch  98 Batch  240/269 - Train Accuracy: 0.8594, Validation Accuracy: 0.8353, Loss: 0.1672
Epoch  98 Batch  250/269 - Train Accuracy: 0.8524, Validation Accuracy: 0.8487, Loss: 0.1867
Epoch  98 Batch  260/269 - Train Accuracy: 0.8256, Validation Accuracy: 0.8445, Loss: 0.1905
Epoch  99 Batch   10/269 - Train Accuracy: 0.8425, Validation Accuracy: 0.8412, Loss: 0.1863
Epoch  99 Batch   20/269 - Train Accuracy: 0.8372, Validation Accuracy: 0.8405, Loss: 0.1813
Epoch  99 Batch   30/269 - Train Accuracy: 0.8421, Validation Accuracy: 0.8486, Loss: 0.1762
Epoch  99 Batch   40/269 - Train Accuracy: 0.8271, Validation Accuracy: 0.8421, Loss: 0.2045
Epoch  99 Batch   50/269 - Train Accuracy: 0.8280, Validation Accuracy: 0.8449, Loss: 0.2091
Epoch  99 Batch   60/269 - Train Accuracy: 0.8354, Validation Accuracy: 0.8445, Loss: 0.1725
Epoch  99 Batch   70/269 - Train Accuracy: 0.8477, Validation Accuracy: 0.8454, Loss: 0.1813
Epoch  99 Batch   80/269 - Train Accuracy: 0.8421, Validation Accuracy: 0.8370, Loss: 0.1771
Epoch  99 Batch   90/269 - Train Accuracy: 0.8444, Validation Accuracy: 0.8397, Loss: 0.1979
Epoch  99 Batch  100/269 - Train Accuracy: 0.8496, Validation Accuracy: 0.8495, Loss: 0.1811
Epoch  99 Batch  110/269 - Train Accuracy: 0.8395, Validation Accuracy: 0.8498, Loss: 0.1895
Epoch  99 Batch  120/269 - Train Accuracy: 0.8391, Validation Accuracy: 0.8399, Loss: 0.2081
Epoch  99 Batch  130/269 - Train Accuracy: 0.8379, Validation Accuracy: 0.8486, Loss: 0.1924
Epoch  99 Batch  140/269 - Train Accuracy: 0.8366, Validation Accuracy: 0.8406, Loss: 0.1890
Epoch  99 Batch  150/269 - Train Accuracy: 0.8346, Validation Accuracy: 0.8428, Loss: 0.1890
Epoch  99 Batch  160/269 - Train Accuracy: 0.8357, Validation Accuracy: 0.8396, Loss: 0.1949
Epoch  99 Batch  170/269 - Train Accuracy: 0.8375, Validation Accuracy: 0.8406, Loss: 0.1828
Epoch  99 Batch  180/269 - Train Accuracy: 0.8594, Validation Accuracy: 0.8422, Loss: 0.1796
Epoch  99 Batch  190/269 - Train Accuracy: 0.8504, Validation Accuracy: 0.8436, Loss: 0.1867
Epoch  99 Batch  200/269 - Train Accuracy: 0.8389, Validation Accuracy: 0.8438, Loss: 0.1803
Epoch  99 Batch  210/269 - Train Accuracy: 0.8526, Validation Accuracy: 0.8435, Loss: 0.1818
Epoch  99 Batch  220/269 - Train Accuracy: 0.8353, Validation Accuracy: 0.8369, Loss: 0.1722
Epoch  99 Batch  230/269 - Train Accuracy: 0.8456, Validation Accuracy: 0.8469, Loss: 0.1855
Epoch  99 Batch  240/269 - Train Accuracy: 0.8590, Validation Accuracy: 0.8412, Loss: 0.1657
Epoch  99 Batch  250/269 - Train Accuracy: 0.8448, Validation Accuracy: 0.8449, Loss: 0.1881
Epoch  99 Batch  260/269 - Train Accuracy: 0.8265, Validation Accuracy: 0.8453, Loss: 0.1948
Epoch 100 Batch   10/269 - Train Accuracy: 0.8453, Validation Accuracy: 0.8381, Loss: 0.1823
Epoch 100 Batch   20/269 - Train Accuracy: 0.8453, Validation Accuracy: 0.8444, Loss: 0.1846
Epoch 100 Batch   30/269 - Train Accuracy: 0.8435, Validation Accuracy: 0.8461, Loss: 0.1769
Epoch 100 Batch   40/269 - Train Accuracy: 0.8280, Validation Accuracy: 0.8455, Loss: 0.2063
Epoch 100 Batch   50/269 - Train Accuracy: 0.8278, Validation Accuracy: 0.8549, Loss: 0.2024
Epoch 100 Batch   60/269 - Train Accuracy: 0.8382, Validation Accuracy: 0.8441, Loss: 0.1690
Epoch 100 Batch   70/269 - Train Accuracy: 0.8477, Validation Accuracy: 0.8439, Loss: 0.1845
Epoch 100 Batch   80/269 - Train Accuracy: 0.8466, Validation Accuracy: 0.8467, Loss: 0.1726
Epoch 100 Batch   90/269 - Train Accuracy: 0.8396, Validation Accuracy: 0.8434, Loss: 0.1916
Epoch 100 Batch  100/269 - Train Accuracy: 0.8502, Validation Accuracy: 0.8453, Loss: 0.1902
Epoch 100 Batch  110/269 - Train Accuracy: 0.8324, Validation Accuracy: 0.8485, Loss: 0.1823
Epoch 100 Batch  120/269 - Train Accuracy: 0.8305, Validation Accuracy: 0.8477, Loss: 0.1967
Epoch 100 Batch  130/269 - Train Accuracy: 0.8359, Validation Accuracy: 0.8462, Loss: 0.1922
Epoch 100 Batch  140/269 - Train Accuracy: 0.8435, Validation Accuracy: 0.8436, Loss: 0.2012
Epoch 100 Batch  150/269 - Train Accuracy: 0.8338, Validation Accuracy: 0.8401, Loss: 0.1816
Epoch 100 Batch  160/269 - Train Accuracy: 0.8372, Validation Accuracy: 0.8403, Loss: 0.1781
Epoch 100 Batch  170/269 - Train Accuracy: 0.8426, Validation Accuracy: 0.8438, Loss: 0.1775
Epoch 100 Batch  180/269 - Train Accuracy: 0.8565, Validation Accuracy: 0.8469, Loss: 0.1717
Epoch 100 Batch  190/269 - Train Accuracy: 0.8494, Validation Accuracy: 0.8471, Loss: 0.1766
Epoch 100 Batch  200/269 - Train Accuracy: 0.8401, Validation Accuracy: 0.8485, Loss: 0.1805
Epoch 100 Batch  210/269 - Train Accuracy: 0.8627, Validation Accuracy: 0.8461, Loss: 0.1847
Epoch 100 Batch  220/269 - Train Accuracy: 0.8404, Validation Accuracy: 0.8389, Loss: 0.1714
Epoch 100 Batch  230/269 - Train Accuracy: 0.8451, Validation Accuracy: 0.8426, Loss: 0.1788
Epoch 100 Batch  240/269 - Train Accuracy: 0.8584, Validation Accuracy: 0.8371, Loss: 0.1643
Epoch 100 Batch  250/269 - Train Accuracy: 0.8520, Validation Accuracy: 0.8429, Loss: 0.1865
Epoch 100 Batch  260/269 - Train Accuracy: 0.8269, Validation Accuracy: 0.8448, Loss: 0.1951
Epoch 101 Batch   10/269 - Train Accuracy: 0.8458, Validation Accuracy: 0.8390, Loss: 0.1778
Epoch 101 Batch   20/269 - Train Accuracy: 0.8423, Validation Accuracy: 0.8452, Loss: 0.1752
Epoch 101 Batch   30/269 - Train Accuracy: 0.8452, Validation Accuracy: 0.8435, Loss: 0.1807
Epoch 101 Batch   40/269 - Train Accuracy: 0.8307, Validation Accuracy: 0.8405, Loss: 0.1911
Epoch 101 Batch   50/269 - Train Accuracy: 0.8231, Validation Accuracy: 0.8493, Loss: 0.1964
Epoch 101 Batch   60/269 - Train Accuracy: 0.8319, Validation Accuracy: 0.8440, Loss: 0.1728
Epoch 101 Batch   70/269 - Train Accuracy: 0.8505, Validation Accuracy: 0.8500, Loss: 0.1826
Epoch 101 Batch   80/269 - Train Accuracy: 0.8462, Validation Accuracy: 0.8499, Loss: 0.1788
Epoch 101 Batch   90/269 - Train Accuracy: 0.8466, Validation Accuracy: 0.8505, Loss: 0.1991
Epoch 101 Batch  100/269 - Train Accuracy: 0.8560, Validation Accuracy: 0.8513, Loss: 0.1803
Epoch 101 Batch  110/269 - Train Accuracy: 0.8476, Validation Accuracy: 0.8494, Loss: 0.1907
Epoch 101 Batch  120/269 - Train Accuracy: 0.8365, Validation Accuracy: 0.8526, Loss: 0.1938
Epoch 101 Batch  130/269 - Train Accuracy: 0.8361, Validation Accuracy: 0.8478, Loss: 0.1798
Epoch 101 Batch  140/269 - Train Accuracy: 0.8434, Validation Accuracy: 0.8476, Loss: 0.1891
Epoch 101 Batch  150/269 - Train Accuracy: 0.8456, Validation Accuracy: 0.8528, Loss: 0.1764
Epoch 101 Batch  160/269 - Train Accuracy: 0.8370, Validation Accuracy: 0.8448, Loss: 0.1795
Epoch 101 Batch  170/269 - Train Accuracy: 0.8397, Validation Accuracy: 0.8446, Loss: 0.1744
Epoch 101 Batch  180/269 - Train Accuracy: 0.8569, Validation Accuracy: 0.8397, Loss: 0.1681
Epoch 101 Batch  190/269 - Train Accuracy: 0.8560, Validation Accuracy: 0.8481, Loss: 0.1812
Epoch 101 Batch  200/269 - Train Accuracy: 0.8381, Validation Accuracy: 0.8588, Loss: 0.1872
Epoch 101 Batch  210/269 - Train Accuracy: 0.8539, Validation Accuracy: 0.8482, Loss: 0.1763
Epoch 101 Batch  220/269 - Train Accuracy: 0.8418, Validation Accuracy: 0.8417, Loss: 0.1701
Epoch 101 Batch  230/269 - Train Accuracy: 0.8473, Validation Accuracy: 0.8520, Loss: 0.1749
Epoch 101 Batch  240/269 - Train Accuracy: 0.8638, Validation Accuracy: 0.8442, Loss: 0.1604
Epoch 101 Batch  250/269 - Train Accuracy: 0.8527, Validation Accuracy: 0.8443, Loss: 0.1953
Epoch 101 Batch  260/269 - Train Accuracy: 0.8327, Validation Accuracy: 0.8447, Loss: 0.1940
Epoch 102 Batch   10/269 - Train Accuracy: 0.8430, Validation Accuracy: 0.8432, Loss: 0.1759
Epoch 102 Batch   20/269 - Train Accuracy: 0.8446, Validation Accuracy: 0.8507, Loss: 0.1871
Epoch 102 Batch   30/269 - Train Accuracy: 0.8411, Validation Accuracy: 0.8507, Loss: 0.1739
Epoch 102 Batch   40/269 - Train Accuracy: 0.8329, Validation Accuracy: 0.8421, Loss: 0.1933
Epoch 102 Batch   50/269 - Train Accuracy: 0.8305, Validation Accuracy: 0.8546, Loss: 0.1910
Epoch 102 Batch   60/269 - Train Accuracy: 0.8331, Validation Accuracy: 0.8462, Loss: 0.1618
Epoch 102 Batch   70/269 - Train Accuracy: 0.8491, Validation Accuracy: 0.8427, Loss: 0.1819
Epoch 102 Batch   80/269 - Train Accuracy: 0.8479, Validation Accuracy: 0.8439, Loss: 0.1834
Epoch 102 Batch   90/269 - Train Accuracy: 0.8413, Validation Accuracy: 0.8478, Loss: 0.1934
Epoch 102 Batch  100/269 - Train Accuracy: 0.8525, Validation Accuracy: 0.8560, Loss: 0.1718
Epoch 102 Batch  110/269 - Train Accuracy: 0.8345, Validation Accuracy: 0.8481, Loss: 0.1808
Epoch 102 Batch  120/269 - Train Accuracy: 0.8324, Validation Accuracy: 0.8461, Loss: 0.1872
Epoch 102 Batch  130/269 - Train Accuracy: 0.8320, Validation Accuracy: 0.8447, Loss: 0.1975
Epoch 102 Batch  140/269 - Train Accuracy: 0.8489, Validation Accuracy: 0.8491, Loss: 0.1935
Epoch 102 Batch  150/269 - Train Accuracy: 0.8424, Validation Accuracy: 0.8506, Loss: 0.1790
Epoch 102 Batch  160/269 - Train Accuracy: 0.8385, Validation Accuracy: 0.8517, Loss: 0.1766
Epoch 102 Batch  170/269 - Train Accuracy: 0.8398, Validation Accuracy: 0.8485, Loss: 0.1725
Epoch 102 Batch  180/269 - Train Accuracy: 0.8575, Validation Accuracy: 0.8442, Loss: 0.1756
Epoch 102 Batch  190/269 - Train Accuracy: 0.8535, Validation Accuracy: 0.8465, Loss: 0.1696
Epoch 102 Batch  200/269 - Train Accuracy: 0.8426, Validation Accuracy: 0.8482, Loss: 0.1789
Epoch 102 Batch  210/269 - Train Accuracy: 0.8580, Validation Accuracy: 0.8496, Loss: 0.1732
Epoch 102 Batch  220/269 - Train Accuracy: 0.8472, Validation Accuracy: 0.8448, Loss: 0.1688
Epoch 102 Batch  230/269 - Train Accuracy: 0.8437, Validation Accuracy: 0.8432, Loss: 0.1678
Epoch 102 Batch  240/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8451, Loss: 0.1544
Epoch 102 Batch  250/269 - Train Accuracy: 0.8565, Validation Accuracy: 0.8549, Loss: 0.1777
Epoch 102 Batch  260/269 - Train Accuracy: 0.8320, Validation Accuracy: 0.8539, Loss: 0.1855
Epoch 103 Batch   10/269 - Train Accuracy: 0.8462, Validation Accuracy: 0.8429, Loss: 0.1902
Epoch 103 Batch   20/269 - Train Accuracy: 0.8487, Validation Accuracy: 0.8596, Loss: 0.1885
Epoch 103 Batch   30/269 - Train Accuracy: 0.8415, Validation Accuracy: 0.8496, Loss: 0.1694
Epoch 103 Batch   40/269 - Train Accuracy: 0.8367, Validation Accuracy: 0.8510, Loss: 0.1904
Epoch 103 Batch   50/269 - Train Accuracy: 0.8312, Validation Accuracy: 0.8509, Loss: 0.1885
Epoch 103 Batch   60/269 - Train Accuracy: 0.8440, Validation Accuracy: 0.8564, Loss: 0.1640
Epoch 103 Batch   70/269 - Train Accuracy: 0.8535, Validation Accuracy: 0.8515, Loss: 0.1769
Epoch 103 Batch   80/269 - Train Accuracy: 0.8560, Validation Accuracy: 0.8586, Loss: 0.1744
Epoch 103 Batch   90/269 - Train Accuracy: 0.8551, Validation Accuracy: 0.8458, Loss: 0.1943
Epoch 103 Batch  100/269 - Train Accuracy: 0.8484, Validation Accuracy: 0.8400, Loss: 0.1763
Epoch 103 Batch  110/269 - Train Accuracy: 0.8365, Validation Accuracy: 0.8513, Loss: 0.1824
Epoch 103 Batch  120/269 - Train Accuracy: 0.8414, Validation Accuracy: 0.8486, Loss: 0.1881
Epoch 103 Batch  130/269 - Train Accuracy: 0.8371, Validation Accuracy: 0.8528, Loss: 0.1898
Epoch 103 Batch  140/269 - Train Accuracy: 0.8454, Validation Accuracy: 0.8473, Loss: 0.1942
Epoch 103 Batch  150/269 - Train Accuracy: 0.8495, Validation Accuracy: 0.8537, Loss: 0.1771
Epoch 103 Batch  160/269 - Train Accuracy: 0.8442, Validation Accuracy: 0.8556, Loss: 0.1743
Epoch 103 Batch  170/269 - Train Accuracy: 0.8442, Validation Accuracy: 0.8554, Loss: 0.1800
Epoch 103 Batch  180/269 - Train Accuracy: 0.8583, Validation Accuracy: 0.8438, Loss: 0.1676
Epoch 103 Batch  190/269 - Train Accuracy: 0.8554, Validation Accuracy: 0.8478, Loss: 0.1699
Epoch 103 Batch  200/269 - Train Accuracy: 0.8462, Validation Accuracy: 0.8439, Loss: 0.1807
Epoch 103 Batch  210/269 - Train Accuracy: 0.8610, Validation Accuracy: 0.8453, Loss: 0.1741
Epoch 103 Batch  220/269 - Train Accuracy: 0.8392, Validation Accuracy: 0.8438, Loss: 0.1673
Epoch 103 Batch  230/269 - Train Accuracy: 0.8479, Validation Accuracy: 0.8483, Loss: 0.1738
Epoch 103 Batch  240/269 - Train Accuracy: 0.8696, Validation Accuracy: 0.8497, Loss: 0.1529
Epoch 103 Batch  250/269 - Train Accuracy: 0.8537, Validation Accuracy: 0.8574, Loss: 0.1777
Epoch 103 Batch  260/269 - Train Accuracy: 0.8243, Validation Accuracy: 0.8577, Loss: 0.1808
Epoch 104 Batch   10/269 - Train Accuracy: 0.8460, Validation Accuracy: 0.8470, Loss: 0.1777
Epoch 104 Batch   20/269 - Train Accuracy: 0.8385, Validation Accuracy: 0.8532, Loss: 0.1845
Epoch 104 Batch   30/269 - Train Accuracy: 0.8437, Validation Accuracy: 0.8571, Loss: 0.1712
Epoch 104 Batch   40/269 - Train Accuracy: 0.8343, Validation Accuracy: 0.8507, Loss: 0.1898
Epoch 104 Batch   50/269 - Train Accuracy: 0.8272, Validation Accuracy: 0.8587, Loss: 0.2025
Epoch 104 Batch   60/269 - Train Accuracy: 0.8374, Validation Accuracy: 0.8439, Loss: 0.1828
Epoch 104 Batch   70/269 - Train Accuracy: 0.8512, Validation Accuracy: 0.8453, Loss: 0.1919
Epoch 104 Batch   80/269 - Train Accuracy: 0.8458, Validation Accuracy: 0.8553, Loss: 0.1816
Epoch 104 Batch   90/269 - Train Accuracy: 0.8420, Validation Accuracy: 0.8447, Loss: 0.1840
Epoch 104 Batch  100/269 - Train Accuracy: 0.8510, Validation Accuracy: 0.8516, Loss: 0.1714
Epoch 104 Batch  110/269 - Train Accuracy: 0.8443, Validation Accuracy: 0.8530, Loss: 0.1812
Epoch 104 Batch  120/269 - Train Accuracy: 0.8434, Validation Accuracy: 0.8568, Loss: 0.1834
Epoch 104 Batch  130/269 - Train Accuracy: 0.8356, Validation Accuracy: 0.8519, Loss: 0.1901
Epoch 104 Batch  140/269 - Train Accuracy: 0.8518, Validation Accuracy: 0.8541, Loss: 0.1900
Epoch 104 Batch  150/269 - Train Accuracy: 0.8486, Validation Accuracy: 0.8533, Loss: 0.1741
Epoch 104 Batch  160/269 - Train Accuracy: 0.8456, Validation Accuracy: 0.8536, Loss: 0.1787
Epoch 104 Batch  170/269 - Train Accuracy: 0.8449, Validation Accuracy: 0.8563, Loss: 0.1705
Epoch 104 Batch  180/269 - Train Accuracy: 0.8668, Validation Accuracy: 0.8453, Loss: 0.1717
Epoch 104 Batch  190/269 - Train Accuracy: 0.8579, Validation Accuracy: 0.8529, Loss: 0.1680
Epoch 104 Batch  200/269 - Train Accuracy: 0.8364, Validation Accuracy: 0.8491, Loss: 0.1792
Epoch 104 Batch  210/269 - Train Accuracy: 0.8586, Validation Accuracy: 0.8505, Loss: 0.1666
Epoch 104 Batch  220/269 - Train Accuracy: 0.8479, Validation Accuracy: 0.8510, Loss: 0.1695
Epoch 104 Batch  230/269 - Train Accuracy: 0.8425, Validation Accuracy: 0.8452, Loss: 0.1671
Epoch 104 Batch  240/269 - Train Accuracy: 0.8700, Validation Accuracy: 0.8548, Loss: 0.1528
Epoch 104 Batch  250/269 - Train Accuracy: 0.8616, Validation Accuracy: 0.8517, Loss: 0.1748
Epoch 104 Batch  260/269 - Train Accuracy: 0.8258, Validation Accuracy: 0.8518, Loss: 0.1838
Epoch 105 Batch   10/269 - Train Accuracy: 0.8522, Validation Accuracy: 0.8513, Loss: 0.1670
Epoch 105 Batch   20/269 - Train Accuracy: 0.8440, Validation Accuracy: 0.8532, Loss: 0.1707
Epoch 105 Batch   30/269 - Train Accuracy: 0.8481, Validation Accuracy: 0.8600, Loss: 0.1718
Epoch 105 Batch   40/269 - Train Accuracy: 0.8377, Validation Accuracy: 0.8585, Loss: 0.1858
Epoch 105 Batch   50/269 - Train Accuracy: 0.8284, Validation Accuracy: 0.8587, Loss: 0.1873
Epoch 105 Batch   60/269 - Train Accuracy: 0.8487, Validation Accuracy: 0.8579, Loss: 0.1570
Epoch 105 Batch   70/269 - Train Accuracy: 0.8517, Validation Accuracy: 0.8496, Loss: 0.1780
Epoch 105 Batch   80/269 - Train Accuracy: 0.8517, Validation Accuracy: 0.8438, Loss: 0.1712
Epoch 105 Batch   90/269 - Train Accuracy: 0.8524, Validation Accuracy: 0.8512, Loss: 0.1784
Epoch 105 Batch  100/269 - Train Accuracy: 0.8569, Validation Accuracy: 0.8533, Loss: 0.1614
Epoch 105 Batch  110/269 - Train Accuracy: 0.8371, Validation Accuracy: 0.8516, Loss: 0.1740
Epoch 105 Batch  120/269 - Train Accuracy: 0.8452, Validation Accuracy: 0.8509, Loss: 0.1866
Epoch 105 Batch  130/269 - Train Accuracy: 0.8367, Validation Accuracy: 0.8517, Loss: 0.1893
Epoch 105 Batch  140/269 - Train Accuracy: 0.8496, Validation Accuracy: 0.8562, Loss: 0.1891
Epoch 105 Batch  150/269 - Train Accuracy: 0.8472, Validation Accuracy: 0.8478, Loss: 0.1734
Epoch 105 Batch  160/269 - Train Accuracy: 0.8391, Validation Accuracy: 0.8475, Loss: 0.1735
Epoch 105 Batch  170/269 - Train Accuracy: 0.8436, Validation Accuracy: 0.8538, Loss: 0.1793
Epoch 105 Batch  180/269 - Train Accuracy: 0.8724, Validation Accuracy: 0.8499, Loss: 0.1720
Epoch 105 Batch  190/269 - Train Accuracy: 0.8607, Validation Accuracy: 0.8548, Loss: 0.1730
Epoch 105 Batch  200/269 - Train Accuracy: 0.8414, Validation Accuracy: 0.8487, Loss: 0.1711
Epoch 105 Batch  210/269 - Train Accuracy: 0.8591, Validation Accuracy: 0.8524, Loss: 0.1699
Epoch 105 Batch  220/269 - Train Accuracy: 0.8408, Validation Accuracy: 0.8469, Loss: 0.1685
Epoch 105 Batch  230/269 - Train Accuracy: 0.8397, Validation Accuracy: 0.8516, Loss: 0.1729
Epoch 105 Batch  240/269 - Train Accuracy: 0.8688, Validation Accuracy: 0.8457, Loss: 0.1479
Epoch 105 Batch  250/269 - Train Accuracy: 0.8555, Validation Accuracy: 0.8569, Loss: 0.1805
Epoch 105 Batch  260/269 - Train Accuracy: 0.8266, Validation Accuracy: 0.8513, Loss: 0.1804
Epoch 106 Batch   10/269 - Train Accuracy: 0.8427, Validation Accuracy: 0.8457, Loss: 0.1637
Epoch 106 Batch   20/269 - Train Accuracy: 0.8462, Validation Accuracy: 0.8477, Loss: 0.1682
Epoch 106 Batch   30/269 - Train Accuracy: 0.8445, Validation Accuracy: 0.8552, Loss: 0.1696
Epoch 106 Batch   40/269 - Train Accuracy: 0.8358, Validation Accuracy: 0.8491, Loss: 0.1884
Epoch 106 Batch   50/269 - Train Accuracy: 0.8289, Validation Accuracy: 0.8533, Loss: 0.1817
Epoch 106 Batch   60/269 - Train Accuracy: 0.8441, Validation Accuracy: 0.8529, Loss: 0.1600
Epoch 106 Batch   70/269 - Train Accuracy: 0.8485, Validation Accuracy: 0.8515, Loss: 0.1655
Epoch 106 Batch   80/269 - Train Accuracy: 0.8559, Validation Accuracy: 0.8537, Loss: 0.1669
Epoch 106 Batch   90/269 - Train Accuracy: 0.8584, Validation Accuracy: 0.8535, Loss: 0.1791
Epoch 106 Batch  100/269 - Train Accuracy: 0.8576, Validation Accuracy: 0.8546, Loss: 0.1675
Epoch 106 Batch  110/269 - Train Accuracy: 0.8387, Validation Accuracy: 0.8532, Loss: 0.1849
Epoch 106 Batch  120/269 - Train Accuracy: 0.8431, Validation Accuracy: 0.8555, Loss: 0.1842
Epoch 106 Batch  130/269 - Train Accuracy: 0.8352, Validation Accuracy: 0.8495, Loss: 0.1801
Epoch 106 Batch  140/269 - Train Accuracy: 0.8529, Validation Accuracy: 0.8525, Loss: 0.1806
Epoch 106 Batch  150/269 - Train Accuracy: 0.8471, Validation Accuracy: 0.8532, Loss: 0.1723
Epoch 106 Batch  160/269 - Train Accuracy: 0.8424, Validation Accuracy: 0.8640, Loss: 0.1672
Epoch 106 Batch  170/269 - Train Accuracy: 0.8457, Validation Accuracy: 0.8525, Loss: 0.1686
Epoch 106 Batch  180/269 - Train Accuracy: 0.8653, Validation Accuracy: 0.8532, Loss: 0.1580
Epoch 106 Batch  190/269 - Train Accuracy: 0.8569, Validation Accuracy: 0.8553, Loss: 0.1637
Epoch 106 Batch  200/269 - Train Accuracy: 0.8396, Validation Accuracy: 0.8536, Loss: 0.1710
Epoch 106 Batch  210/269 - Train Accuracy: 0.8558, Validation Accuracy: 0.8422, Loss: 0.1722
Epoch 106 Batch  220/269 - Train Accuracy: 0.8466, Validation Accuracy: 0.8477, Loss: 0.1636
Epoch 106 Batch  230/269 - Train Accuracy: 0.8428, Validation Accuracy: 0.8507, Loss: 0.1616
Epoch 106 Batch  240/269 - Train Accuracy: 0.8678, Validation Accuracy: 0.8564, Loss: 0.1543
Epoch 106 Batch  250/269 - Train Accuracy: 0.8636, Validation Accuracy: 0.8555, Loss: 0.1703
Epoch 106 Batch  260/269 - Train Accuracy: 0.8332, Validation Accuracy: 0.8562, Loss: 0.1759
Epoch 107 Batch   10/269 - Train Accuracy: 0.8415, Validation Accuracy: 0.8415, Loss: 0.1629
Epoch 107 Batch   20/269 - Train Accuracy: 0.8456, Validation Accuracy: 0.8577, Loss: 0.1653
Epoch 107 Batch   30/269 - Train Accuracy: 0.8494, Validation Accuracy: 0.8562, Loss: 0.1645
Epoch 107 Batch   40/269 - Train Accuracy: 0.8347, Validation Accuracy: 0.8557, Loss: 0.1846
Epoch 107 Batch   50/269 - Train Accuracy: 0.8298, Validation Accuracy: 0.8590, Loss: 0.1819
Epoch 107 Batch   60/269 - Train Accuracy: 0.8457, Validation Accuracy: 0.8613, Loss: 0.1636
Epoch 107 Batch   70/269 - Train Accuracy: 0.8516, Validation Accuracy: 0.8536, Loss: 0.1625
Epoch 107 Batch   80/269 - Train Accuracy: 0.8529, Validation Accuracy: 0.8560, Loss: 0.1721
Epoch 107 Batch   90/269 - Train Accuracy: 0.8548, Validation Accuracy: 0.8473, Loss: 0.1776
Epoch 107 Batch  100/269 - Train Accuracy: 0.8598, Validation Accuracy: 0.8559, Loss: 0.1651
Epoch 107 Batch  110/269 - Train Accuracy: 0.8507, Validation Accuracy: 0.8613, Loss: 0.1813
Epoch 107 Batch  120/269 - Train Accuracy: 0.8450, Validation Accuracy: 0.8510, Loss: 0.1782
Epoch 107 Batch  130/269 - Train Accuracy: 0.8336, Validation Accuracy: 0.8452, Loss: 0.1709
Epoch 107 Batch  140/269 - Train Accuracy: 0.8501, Validation Accuracy: 0.8525, Loss: 0.1877
Epoch 107 Batch  150/269 - Train Accuracy: 0.8411, Validation Accuracy: 0.8533, Loss: 0.1735
Epoch 107 Batch  160/269 - Train Accuracy: 0.8442, Validation Accuracy: 0.8568, Loss: 0.1669
Epoch 107 Batch  170/269 - Train Accuracy: 0.8490, Validation Accuracy: 0.8629, Loss: 0.1634
Epoch 107 Batch  180/269 - Train Accuracy: 0.8698, Validation Accuracy: 0.8466, Loss: 0.1681
Epoch 107 Batch  190/269 - Train Accuracy: 0.8588, Validation Accuracy: 0.8477, Loss: 0.1650
Epoch 107 Batch  200/269 - Train Accuracy: 0.8447, Validation Accuracy: 0.8595, Loss: 0.1665
Epoch 107 Batch  210/269 - Train Accuracy: 0.8532, Validation Accuracy: 0.8481, Loss: 0.1703
Epoch 107 Batch  220/269 - Train Accuracy: 0.8440, Validation Accuracy: 0.8447, Loss: 0.1600
Epoch 107 Batch  230/269 - Train Accuracy: 0.8411, Validation Accuracy: 0.8509, Loss: 0.1796
Epoch 107 Batch  240/269 - Train Accuracy: 0.8689, Validation Accuracy: 0.8568, Loss: 0.1535
Epoch 107 Batch  250/269 - Train Accuracy: 0.8597, Validation Accuracy: 0.8545, Loss: 0.1780
Epoch 107 Batch  260/269 - Train Accuracy: 0.8358, Validation Accuracy: 0.8592, Loss: 0.1747
Epoch 108 Batch   10/269 - Train Accuracy: 0.8526, Validation Accuracy: 0.8441, Loss: 0.1635
Epoch 108 Batch   20/269 - Train Accuracy: 0.8480, Validation Accuracy: 0.8588, Loss: 0.1627
Epoch 108 Batch   30/269 - Train Accuracy: 0.8514, Validation Accuracy: 0.8548, Loss: 0.1704
Epoch 108 Batch   40/269 - Train Accuracy: 0.8387, Validation Accuracy: 0.8533, Loss: 0.1877
Epoch 108 Batch   50/269 - Train Accuracy: 0.8257, Validation Accuracy: 0.8590, Loss: 0.1831
Epoch 108 Batch   60/269 - Train Accuracy: 0.8552, Validation Accuracy: 0.8615, Loss: 0.1560
Epoch 108 Batch   70/269 - Train Accuracy: 0.8500, Validation Accuracy: 0.8450, Loss: 0.1736
Epoch 108 Batch   80/269 - Train Accuracy: 0.8528, Validation Accuracy: 0.8541, Loss: 0.1744
Epoch 108 Batch   90/269 - Train Accuracy: 0.8491, Validation Accuracy: 0.8532, Loss: 0.1711
Epoch 108 Batch  100/269 - Train Accuracy: 0.8592, Validation Accuracy: 0.8591, Loss: 0.1577
Epoch 108 Batch  110/269 - Train Accuracy: 0.8545, Validation Accuracy: 0.8596, Loss: 0.1750
Epoch 108 Batch  120/269 - Train Accuracy: 0.8408, Validation Accuracy: 0.8492, Loss: 0.1748
Epoch 108 Batch  130/269 - Train Accuracy: 0.8356, Validation Accuracy: 0.8632, Loss: 0.1749
Epoch 108 Batch  140/269 - Train Accuracy: 0.8560, Validation Accuracy: 0.8526, Loss: 0.1753
Epoch 108 Batch  150/269 - Train Accuracy: 0.8398, Validation Accuracy: 0.8556, Loss: 0.1724
Epoch 108 Batch  160/269 - Train Accuracy: 0.8424, Validation Accuracy: 0.8589, Loss: 0.1691
Epoch 108 Batch  170/269 - Train Accuracy: 0.8468, Validation Accuracy: 0.8600, Loss: 0.1671
Epoch 108 Batch  180/269 - Train Accuracy: 0.8684, Validation Accuracy: 0.8478, Loss: 0.1594
Epoch 108 Batch  190/269 - Train Accuracy: 0.8589, Validation Accuracy: 0.8478, Loss: 0.1679
Epoch 108 Batch  200/269 - Train Accuracy: 0.8371, Validation Accuracy: 0.8478, Loss: 0.1725
Epoch 108 Batch  210/269 - Train Accuracy: 0.8504, Validation Accuracy: 0.8461, Loss: 0.1732
Epoch 108 Batch  220/269 - Train Accuracy: 0.8472, Validation Accuracy: 0.8462, Loss: 0.1611
Epoch 108 Batch  230/269 - Train Accuracy: 0.8382, Validation Accuracy: 0.8544, Loss: 0.1654
Epoch 108 Batch  240/269 - Train Accuracy: 0.8629, Validation Accuracy: 0.8501, Loss: 0.1530
Epoch 108 Batch  250/269 - Train Accuracy: 0.8618, Validation Accuracy: 0.8539, Loss: 0.1739
Epoch 108 Batch  260/269 - Train Accuracy: 0.8301, Validation Accuracy: 0.8555, Loss: 0.1788
Epoch 109 Batch   10/269 - Train Accuracy: 0.8433, Validation Accuracy: 0.8478, Loss: 0.1545
Epoch 109 Batch   20/269 - Train Accuracy: 0.8415, Validation Accuracy: 0.8605, Loss: 0.1667
Epoch 109 Batch   30/269 - Train Accuracy: 0.8479, Validation Accuracy: 0.8597, Loss: 0.1748
Epoch 109 Batch   40/269 - Train Accuracy: 0.8341, Validation Accuracy: 0.8497, Loss: 0.1848
Epoch 109 Batch   50/269 - Train Accuracy: 0.8332, Validation Accuracy: 0.8601, Loss: 0.1924
Epoch 109 Batch   60/269 - Train Accuracy: 0.8544, Validation Accuracy: 0.8642, Loss: 0.1635
Epoch 109 Batch   70/269 - Train Accuracy: 0.8572, Validation Accuracy: 0.8597, Loss: 0.1638
Epoch 109 Batch   80/269 - Train Accuracy: 0.8514, Validation Accuracy: 0.8498, Loss: 0.1648
Epoch 109 Batch   90/269 - Train Accuracy: 0.8522, Validation Accuracy: 0.8534, Loss: 0.1765
Epoch 109 Batch  100/269 - Train Accuracy: 0.8602, Validation Accuracy: 0.8557, Loss: 0.1513
Epoch 109 Batch  110/269 - Train Accuracy: 0.8412, Validation Accuracy: 0.8570, Loss: 0.1751
Epoch 109 Batch  120/269 - Train Accuracy: 0.8432, Validation Accuracy: 0.8576, Loss: 0.1733
Epoch 109 Batch  130/269 - Train Accuracy: 0.8370, Validation Accuracy: 0.8508, Loss: 0.1666
Epoch 109 Batch  140/269 - Train Accuracy: 0.8556, Validation Accuracy: 0.8548, Loss: 0.1813
Epoch 109 Batch  150/269 - Train Accuracy: 0.8501, Validation Accuracy: 0.8606, Loss: 0.1664
Epoch 109 Batch  160/269 - Train Accuracy: 0.8459, Validation Accuracy: 0.8590, Loss: 0.1667
Epoch 109 Batch  170/269 - Train Accuracy: 0.8421, Validation Accuracy: 0.8479, Loss: 0.1682
Epoch 109 Batch  180/269 - Train Accuracy: 0.8734, Validation Accuracy: 0.8572, Loss: 0.1597
Epoch 109 Batch  190/269 - Train Accuracy: 0.8610, Validation Accuracy: 0.8516, Loss: 0.1555
Epoch 109 Batch  200/269 - Train Accuracy: 0.8387, Validation Accuracy: 0.8556, Loss: 0.1656
Epoch 109 Batch  210/269 - Train Accuracy: 0.8639, Validation Accuracy: 0.8544, Loss: 0.1676
Epoch 109 Batch  220/269 - Train Accuracy: 0.8456, Validation Accuracy: 0.8509, Loss: 0.1632
Epoch 109 Batch  230/269 - Train Accuracy: 0.8424, Validation Accuracy: 0.8540, Loss: 0.1596
Epoch 109 Batch  240/269 - Train Accuracy: 0.8719, Validation Accuracy: 0.8558, Loss: 0.1524
Epoch 109 Batch  250/269 - Train Accuracy: 0.8632, Validation Accuracy: 0.8595, Loss: 0.1594
Epoch 109 Batch  260/269 - Train Accuracy: 0.8274, Validation Accuracy: 0.8624, Loss: 0.1819
Epoch 110 Batch   10/269 - Train Accuracy: 0.8530, Validation Accuracy: 0.8476, Loss: 0.1609
Epoch 110 Batch   20/269 - Train Accuracy: 0.8410, Validation Accuracy: 0.8529, Loss: 0.1679
Epoch 110 Batch   30/269 - Train Accuracy: 0.8502, Validation Accuracy: 0.8608, Loss: 0.1600
Epoch 110 Batch   40/269 - Train Accuracy: 0.8396, Validation Accuracy: 0.8563, Loss: 0.1796
Epoch 110 Batch   50/269 - Train Accuracy: 0.8366, Validation Accuracy: 0.8660, Loss: 0.1837
Epoch 110 Batch   60/269 - Train Accuracy: 0.8541, Validation Accuracy: 0.8615, Loss: 0.1480
Epoch 110 Batch   70/269 - Train Accuracy: 0.8550, Validation Accuracy: 0.8617, Loss: 0.1717
Epoch 110 Batch   80/269 - Train Accuracy: 0.8505, Validation Accuracy: 0.8527, Loss: 0.1590
Epoch 110 Batch   90/269 - Train Accuracy: 0.8493, Validation Accuracy: 0.8501, Loss: 0.1749
Epoch 110 Batch  100/269 - Train Accuracy: 0.8600, Validation Accuracy: 0.8510, Loss: 0.1684
Epoch 110 Batch  110/269 - Train Accuracy: 0.8451, Validation Accuracy: 0.8612, Loss: 0.1753
Epoch 110 Batch  120/269 - Train Accuracy: 0.8429, Validation Accuracy: 0.8557, Loss: 0.1750
Epoch 110 Batch  130/269 - Train Accuracy: 0.8364, Validation Accuracy: 0.8515, Loss: 0.1751
Epoch 110 Batch  140/269 - Train Accuracy: 0.8547, Validation Accuracy: 0.8522, Loss: 0.1773
Epoch 110 Batch  150/269 - Train Accuracy: 0.8485, Validation Accuracy: 0.8551, Loss: 0.1648
Epoch 110 Batch  160/269 - Train Accuracy: 0.8470, Validation Accuracy: 0.8500, Loss: 0.1613
Epoch 110 Batch  170/269 - Train Accuracy: 0.8543, Validation Accuracy: 0.8602, Loss: 0.1615
Epoch 110 Batch  180/269 - Train Accuracy: 0.8720, Validation Accuracy: 0.8459, Loss: 0.1598
Epoch 110 Batch  190/269 - Train Accuracy: 0.8612, Validation Accuracy: 0.8583, Loss: 0.1624
Epoch 110 Batch  200/269 - Train Accuracy: 0.8433, Validation Accuracy: 0.8539, Loss: 0.1579
Epoch 110 Batch  210/269 - Train Accuracy: 0.8611, Validation Accuracy: 0.8528, Loss: 0.1627
Epoch 110 Batch  220/269 - Train Accuracy: 0.8494, Validation Accuracy: 0.8463, Loss: 0.1598
Epoch 110 Batch  230/269 - Train Accuracy: 0.8423, Validation Accuracy: 0.8564, Loss: 0.1712
Epoch 110 Batch  240/269 - Train Accuracy: 0.8667, Validation Accuracy: 0.8523, Loss: 0.1453
Epoch 110 Batch  250/269 - Train Accuracy: 0.8640, Validation Accuracy: 0.8574, Loss: 0.1542
Epoch 110 Batch  260/269 - Train Accuracy: 0.8318, Validation Accuracy: 0.8564, Loss: 0.1774
Epoch 111 Batch   10/269 - Train Accuracy: 0.8449, Validation Accuracy: 0.8532, Loss: 0.1603
Epoch 111 Batch   20/269 - Train Accuracy: 0.8548, Validation Accuracy: 0.8590, Loss: 0.1555
Epoch 111 Batch   30/269 - Train Accuracy: 0.8561, Validation Accuracy: 0.8610, Loss: 0.1664
Epoch 111 Batch   40/269 - Train Accuracy: 0.8355, Validation Accuracy: 0.8455, Loss: 0.1846
Epoch 111 Batch   50/269 - Train Accuracy: 0.8304, Validation Accuracy: 0.8616, Loss: 0.1937
Epoch 111 Batch   60/269 - Train Accuracy: 0.8483, Validation Accuracy: 0.8532, Loss: 0.1561
Epoch 111 Batch   70/269 - Train Accuracy: 0.8562, Validation Accuracy: 0.8477, Loss: 0.1573
Epoch 111 Batch   80/269 - Train Accuracy: 0.8544, Validation Accuracy: 0.8606, Loss: 0.1683
Epoch 111 Batch   90/269 - Train Accuracy: 0.8486, Validation Accuracy: 0.8548, Loss: 0.1668
Epoch 111 Batch  100/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8555, Loss: 0.1642
Epoch 111 Batch  110/269 - Train Accuracy: 0.8437, Validation Accuracy: 0.8575, Loss: 0.1682
Epoch 111 Batch  120/269 - Train Accuracy: 0.8434, Validation Accuracy: 0.8588, Loss: 0.1753
Epoch 111 Batch  130/269 - Train Accuracy: 0.8346, Validation Accuracy: 0.8507, Loss: 0.1731
Epoch 111 Batch  140/269 - Train Accuracy: 0.8539, Validation Accuracy: 0.8629, Loss: 0.1824
Epoch 111 Batch  150/269 - Train Accuracy: 0.8438, Validation Accuracy: 0.8573, Loss: 0.1604
Epoch 111 Batch  160/269 - Train Accuracy: 0.8533, Validation Accuracy: 0.8550, Loss: 0.1631
Epoch 111 Batch  170/269 - Train Accuracy: 0.8492, Validation Accuracy: 0.8548, Loss: 0.1585
Epoch 111 Batch  180/269 - Train Accuracy: 0.8730, Validation Accuracy: 0.8532, Loss: 0.1546
Epoch 111 Batch  190/269 - Train Accuracy: 0.8646, Validation Accuracy: 0.8596, Loss: 0.1562
Epoch 111 Batch  200/269 - Train Accuracy: 0.8423, Validation Accuracy: 0.8560, Loss: 0.1588
Epoch 111 Batch  210/269 - Train Accuracy: 0.8596, Validation Accuracy: 0.8510, Loss: 0.1621
Epoch 111 Batch  220/269 - Train Accuracy: 0.8489, Validation Accuracy: 0.8555, Loss: 0.1578
Epoch 111 Batch  230/269 - Train Accuracy: 0.8448, Validation Accuracy: 0.8521, Loss: 0.1596
Epoch 111 Batch  240/269 - Train Accuracy: 0.8741, Validation Accuracy: 0.8624, Loss: 0.1460
Epoch 111 Batch  250/269 - Train Accuracy: 0.8633, Validation Accuracy: 0.8587, Loss: 0.1677
Epoch 111 Batch  260/269 - Train Accuracy: 0.8304, Validation Accuracy: 0.8583, Loss: 0.1774
Epoch 112 Batch   10/269 - Train Accuracy: 0.8557, Validation Accuracy: 0.8582, Loss: 0.1613
Epoch 112 Batch   20/269 - Train Accuracy: 0.8454, Validation Accuracy: 0.8550, Loss: 0.1676
Epoch 112 Batch   30/269 - Train Accuracy: 0.8514, Validation Accuracy: 0.8612, Loss: 0.1705
Epoch 112 Batch   40/269 - Train Accuracy: 0.8376, Validation Accuracy: 0.8521, Loss: 0.1826
Epoch 112 Batch   50/269 - Train Accuracy: 0.8250, Validation Accuracy: 0.8588, Loss: 0.1881
Epoch 112 Batch   60/269 - Train Accuracy: 0.8496, Validation Accuracy: 0.8540, Loss: 0.1530
Epoch 112 Batch   70/269 - Train Accuracy: 0.8589, Validation Accuracy: 0.8517, Loss: 0.1670
Epoch 112 Batch   80/269 - Train Accuracy: 0.8467, Validation Accuracy: 0.8569, Loss: 0.1611
Epoch 112 Batch   90/269 - Train Accuracy: 0.8528, Validation Accuracy: 0.8607, Loss: 0.1717
Epoch 112 Batch  100/269 - Train Accuracy: 0.8662, Validation Accuracy: 0.8582, Loss: 0.1602
Epoch 112 Batch  110/269 - Train Accuracy: 0.8433, Validation Accuracy: 0.8617, Loss: 0.1623
Epoch 112 Batch  120/269 - Train Accuracy: 0.8440, Validation Accuracy: 0.8572, Loss: 0.1655
Epoch 112 Batch  130/269 - Train Accuracy: 0.8338, Validation Accuracy: 0.8573, Loss: 0.1766
Epoch 112 Batch  140/269 - Train Accuracy: 0.8522, Validation Accuracy: 0.8540, Loss: 0.1751
Epoch 112 Batch  150/269 - Train Accuracy: 0.8456, Validation Accuracy: 0.8509, Loss: 0.1625
Epoch 112 Batch  160/269 - Train Accuracy: 0.8488, Validation Accuracy: 0.8584, Loss: 0.1631
Epoch 112 Batch  170/269 - Train Accuracy: 0.8517, Validation Accuracy: 0.8580, Loss: 0.1606
Epoch 112 Batch  180/269 - Train Accuracy: 0.8694, Validation Accuracy: 0.8523, Loss: 0.1510
Epoch 112 Batch  190/269 - Train Accuracy: 0.8629, Validation Accuracy: 0.8528, Loss: 0.1568
Epoch 112 Batch  200/269 - Train Accuracy: 0.8433, Validation Accuracy: 0.8627, Loss: 0.1682
Epoch 112 Batch  210/269 - Train Accuracy: 0.8659, Validation Accuracy: 0.8519, Loss: 0.1559
Epoch 112 Batch  220/269 - Train Accuracy: 0.8446, Validation Accuracy: 0.8540, Loss: 0.1613
Epoch 112 Batch  230/269 - Train Accuracy: 0.8425, Validation Accuracy: 0.8508, Loss: 0.1690
Epoch 112 Batch  240/269 - Train Accuracy: 0.8731, Validation Accuracy: 0.8599, Loss: 0.1466
Epoch 112 Batch  250/269 - Train Accuracy: 0.8582, Validation Accuracy: 0.8579, Loss: 0.1629
Epoch 112 Batch  260/269 - Train Accuracy: 0.8341, Validation Accuracy: 0.8651, Loss: 0.1746
Epoch 113 Batch   10/269 - Train Accuracy: 0.8527, Validation Accuracy: 0.8580, Loss: 0.1633
Epoch 113 Batch   20/269 - Train Accuracy: 0.8443, Validation Accuracy: 0.8534, Loss: 0.1606
Epoch 113 Batch   30/269 - Train Accuracy: 0.8533, Validation Accuracy: 0.8580, Loss: 0.1600
Epoch 113 Batch   40/269 - Train Accuracy: 0.8363, Validation Accuracy: 0.8566, Loss: 0.1733
Epoch 113 Batch   50/269 - Train Accuracy: 0.8306, Validation Accuracy: 0.8554, Loss: 0.1786
Epoch 113 Batch   60/269 - Train Accuracy: 0.8487, Validation Accuracy: 0.8566, Loss: 0.1452
Epoch 113 Batch   70/269 - Train Accuracy: 0.8561, Validation Accuracy: 0.8557, Loss: 0.1601
Epoch 113 Batch   80/269 - Train Accuracy: 0.8546, Validation Accuracy: 0.8597, Loss: 0.1631
Epoch 113 Batch   90/269 - Train Accuracy: 0.8516, Validation Accuracy: 0.8532, Loss: 0.1688
Epoch 113 Batch  100/269 - Train Accuracy: 0.8590, Validation Accuracy: 0.8517, Loss: 0.1638
Epoch 113 Batch  110/269 - Train Accuracy: 0.8354, Validation Accuracy: 0.8520, Loss: 0.1677
Epoch 113 Batch  120/269 - Train Accuracy: 0.8428, Validation Accuracy: 0.8570, Loss: 0.1637
Epoch 113 Batch  130/269 - Train Accuracy: 0.8347, Validation Accuracy: 0.8620, Loss: 0.1758
Epoch 113 Batch  140/269 - Train Accuracy: 0.8597, Validation Accuracy: 0.8627, Loss: 0.1710
Epoch 113 Batch  150/269 - Train Accuracy: 0.8484, Validation Accuracy: 0.8567, Loss: 0.1566
Epoch 113 Batch  160/269 - Train Accuracy: 0.8467, Validation Accuracy: 0.8644, Loss: 0.1564
Epoch 113 Batch  170/269 - Train Accuracy: 0.8451, Validation Accuracy: 0.8536, Loss: 0.1569
Epoch 113 Batch  180/269 - Train Accuracy: 0.8716, Validation Accuracy: 0.8521, Loss: 0.1530
Epoch 113 Batch  190/269 - Train Accuracy: 0.8650, Validation Accuracy: 0.8532, Loss: 0.1639
Epoch 113 Batch  200/269 - Train Accuracy: 0.8482, Validation Accuracy: 0.8553, Loss: 0.1683
Epoch 113 Batch  210/269 - Train Accuracy: 0.8660, Validation Accuracy: 0.8562, Loss: 0.1579
Epoch 113 Batch  220/269 - Train Accuracy: 0.8489, Validation Accuracy: 0.8489, Loss: 0.1493
Epoch 113 Batch  230/269 - Train Accuracy: 0.8450, Validation Accuracy: 0.8536, Loss: 0.1521
Epoch 113 Batch  240/269 - Train Accuracy: 0.8691, Validation Accuracy: 0.8548, Loss: 0.1489
Epoch 113 Batch  250/269 - Train Accuracy: 0.8645, Validation Accuracy: 0.8562, Loss: 0.1626
Epoch 113 Batch  260/269 - Train Accuracy: 0.8256, Validation Accuracy: 0.8568, Loss: 0.1783
Epoch 114 Batch   10/269 - Train Accuracy: 0.8535, Validation Accuracy: 0.8619, Loss: 0.1491
Epoch 114 Batch   20/269 - Train Accuracy: 0.8525, Validation Accuracy: 0.8572, Loss: 0.1631
Epoch 114 Batch   30/269 - Train Accuracy: 0.8531, Validation Accuracy: 0.8579, Loss: 0.1586
Epoch 114 Batch   40/269 - Train Accuracy: 0.8384, Validation Accuracy: 0.8544, Loss: 0.1708
Epoch 114 Batch   50/269 - Train Accuracy: 0.8326, Validation Accuracy: 0.8643, Loss: 0.1808
Epoch 114 Batch   60/269 - Train Accuracy: 0.8533, Validation Accuracy: 0.8654, Loss: 0.1522
Epoch 114 Batch   70/269 - Train Accuracy: 0.8531, Validation Accuracy: 0.8522, Loss: 0.1618
Epoch 114 Batch   80/269 - Train Accuracy: 0.8584, Validation Accuracy: 0.8594, Loss: 0.1635
Epoch 114 Batch   90/269 - Train Accuracy: 0.8497, Validation Accuracy: 0.8485, Loss: 0.1654
Epoch 114 Batch  100/269 - Train Accuracy: 0.8627, Validation Accuracy: 0.8548, Loss: 0.1586
Epoch 114 Batch  110/269 - Train Accuracy: 0.8398, Validation Accuracy: 0.8576, Loss: 0.1629
Epoch 114 Batch  120/269 - Train Accuracy: 0.8472, Validation Accuracy: 0.8557, Loss: 0.1654
Epoch 114 Batch  130/269 - Train Accuracy: 0.8374, Validation Accuracy: 0.8598, Loss: 0.1744
Epoch 114 Batch  140/269 - Train Accuracy: 0.8626, Validation Accuracy: 0.8570, Loss: 0.1736
Epoch 114 Batch  150/269 - Train Accuracy: 0.8518, Validation Accuracy: 0.8560, Loss: 0.1640
Epoch 114 Batch  160/269 - Train Accuracy: 0.8525, Validation Accuracy: 0.8583, Loss: 0.1659
Epoch 114 Batch  170/269 - Train Accuracy: 0.8423, Validation Accuracy: 0.8566, Loss: 0.1554
Epoch 114 Batch  180/269 - Train Accuracy: 0.8767, Validation Accuracy: 0.8565, Loss: 0.1489
Epoch 114 Batch  190/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8580, Loss: 0.1484
Epoch 114 Batch  200/269 - Train Accuracy: 0.8482, Validation Accuracy: 0.8576, Loss: 0.1602
Epoch 114 Batch  210/269 - Train Accuracy: 0.8621, Validation Accuracy: 0.8580, Loss: 0.1601
Epoch 114 Batch  220/269 - Train Accuracy: 0.8454, Validation Accuracy: 0.8498, Loss: 0.1525
Epoch 114 Batch  230/269 - Train Accuracy: 0.8463, Validation Accuracy: 0.8544, Loss: 0.1564
Epoch 114 Batch  240/269 - Train Accuracy: 0.8701, Validation Accuracy: 0.8593, Loss: 0.1347
Epoch 114 Batch  250/269 - Train Accuracy: 0.8599, Validation Accuracy: 0.8524, Loss: 0.1635
Epoch 114 Batch  260/269 - Train Accuracy: 0.8321, Validation Accuracy: 0.8572, Loss: 0.1704
Epoch 115 Batch   10/269 - Train Accuracy: 0.8549, Validation Accuracy: 0.8570, Loss: 0.1616
Epoch 115 Batch   20/269 - Train Accuracy: 0.8511, Validation Accuracy: 0.8563, Loss: 0.1628
Epoch 115 Batch   30/269 - Train Accuracy: 0.8516, Validation Accuracy: 0.8609, Loss: 0.1611
Epoch 115 Batch   40/269 - Train Accuracy: 0.8343, Validation Accuracy: 0.8553, Loss: 0.1692
Epoch 115 Batch   50/269 - Train Accuracy: 0.8276, Validation Accuracy: 0.8628, Loss: 0.1806
Epoch 115 Batch   60/269 - Train Accuracy: 0.8561, Validation Accuracy: 0.8652, Loss: 0.1472
Epoch 115 Batch   70/269 - Train Accuracy: 0.8592, Validation Accuracy: 0.8620, Loss: 0.1664
Epoch 115 Batch   80/269 - Train Accuracy: 0.8530, Validation Accuracy: 0.8548, Loss: 0.1620
Epoch 115 Batch   90/269 - Train Accuracy: 0.8480, Validation Accuracy: 0.8519, Loss: 0.1671
Epoch 115 Batch  100/269 - Train Accuracy: 0.8580, Validation Accuracy: 0.8517, Loss: 0.1507
Epoch 115 Batch  110/269 - Train Accuracy: 0.8492, Validation Accuracy: 0.8588, Loss: 0.1675
Epoch 115 Batch  120/269 - Train Accuracy: 0.8469, Validation Accuracy: 0.8572, Loss: 0.1665
Epoch 115 Batch  130/269 - Train Accuracy: 0.8289, Validation Accuracy: 0.8545, Loss: 0.1685
Epoch 115 Batch  140/269 - Train Accuracy: 0.8529, Validation Accuracy: 0.8542, Loss: 0.1695
Epoch 115 Batch  150/269 - Train Accuracy: 0.8469, Validation Accuracy: 0.8602, Loss: 0.1564
Epoch 115 Batch  160/269 - Train Accuracy: 0.8477, Validation Accuracy: 0.8581, Loss: 0.1650
Epoch 115 Batch  170/269 - Train Accuracy: 0.8480, Validation Accuracy: 0.8549, Loss: 0.1602
Epoch 115 Batch  180/269 - Train Accuracy: 0.8726, Validation Accuracy: 0.8554, Loss: 0.1552
Epoch 115 Batch  190/269 - Train Accuracy: 0.8672, Validation Accuracy: 0.8545, Loss: 0.1568
Epoch 115 Batch  200/269 - Train Accuracy: 0.8431, Validation Accuracy: 0.8572, Loss: 0.1557
Epoch 115 Batch  210/269 - Train Accuracy: 0.8607, Validation Accuracy: 0.8565, Loss: 0.1528
Epoch 115 Batch  220/269 - Train Accuracy: 0.8438, Validation Accuracy: 0.8542, Loss: 0.1555
Epoch 115 Batch  230/269 - Train Accuracy: 0.8474, Validation Accuracy: 0.8589, Loss: 0.1745
Epoch 115 Batch  240/269 - Train Accuracy: 0.8741, Validation Accuracy: 0.8542, Loss: 0.1424
Epoch 115 Batch  250/269 - Train Accuracy: 0.8654, Validation Accuracy: 0.8585, Loss: 0.1568
Epoch 115 Batch  260/269 - Train Accuracy: 0.8311, Validation Accuracy: 0.8623, Loss: 0.1645
Epoch 116 Batch   10/269 - Train Accuracy: 0.8493, Validation Accuracy: 0.8517, Loss: 0.1539
Epoch 116 Batch   20/269 - Train Accuracy: 0.8575, Validation Accuracy: 0.8585, Loss: 0.1555
Epoch 116 Batch   30/269 - Train Accuracy: 0.8556, Validation Accuracy: 0.8532, Loss: 0.1529
Epoch 116 Batch   40/269 - Train Accuracy: 0.8390, Validation Accuracy: 0.8603, Loss: 0.1705
Epoch 116 Batch   50/269 - Train Accuracy: 0.8346, Validation Accuracy: 0.8580, Loss: 0.1739
Epoch 116 Batch   60/269 - Train Accuracy: 0.8565, Validation Accuracy: 0.8604, Loss: 0.1464
Epoch 116 Batch   70/269 - Train Accuracy: 0.8526, Validation Accuracy: 0.8554, Loss: 0.1538
Epoch 116 Batch   80/269 - Train Accuracy: 0.8524, Validation Accuracy: 0.8609, Loss: 0.1598
Epoch 116 Batch   90/269 - Train Accuracy: 0.8549, Validation Accuracy: 0.8517, Loss: 0.1690
Epoch 116 Batch  100/269 - Train Accuracy: 0.8644, Validation Accuracy: 0.8585, Loss: 0.1569
Epoch 116 Batch  110/269 - Train Accuracy: 0.8398, Validation Accuracy: 0.8597, Loss: 0.1627
Epoch 116 Batch  120/269 - Train Accuracy: 0.8481, Validation Accuracy: 0.8627, Loss: 0.1714
Epoch 116 Batch  130/269 - Train Accuracy: 0.8357, Validation Accuracy: 0.8574, Loss: 0.1652
Epoch 116 Batch  140/269 - Train Accuracy: 0.8585, Validation Accuracy: 0.8623, Loss: 0.1704
Epoch 116 Batch  150/269 - Train Accuracy: 0.8471, Validation Accuracy: 0.8545, Loss: 0.1543
Epoch 116 Batch  160/269 - Train Accuracy: 0.8531, Validation Accuracy: 0.8525, Loss: 0.1611
Epoch 116 Batch  170/269 - Train Accuracy: 0.8491, Validation Accuracy: 0.8585, Loss: 0.1565
Epoch 116 Batch  180/269 - Train Accuracy: 0.8717, Validation Accuracy: 0.8525, Loss: 0.1494
Epoch 116 Batch  190/269 - Train Accuracy: 0.8639, Validation Accuracy: 0.8496, Loss: 0.1613
Epoch 116 Batch  200/269 - Train Accuracy: 0.8423, Validation Accuracy: 0.8558, Loss: 0.1588
Epoch 116 Batch  210/269 - Train Accuracy: 0.8638, Validation Accuracy: 0.8569, Loss: 0.1499
Epoch 116 Batch  220/269 - Train Accuracy: 0.8524, Validation Accuracy: 0.8558, Loss: 0.1469
Epoch 116 Batch  230/269 - Train Accuracy: 0.8465, Validation Accuracy: 0.8528, Loss: 0.1478
Epoch 116 Batch  240/269 - Train Accuracy: 0.8731, Validation Accuracy: 0.8591, Loss: 0.1397
Epoch 116 Batch  250/269 - Train Accuracy: 0.8650, Validation Accuracy: 0.8575, Loss: 0.1531
Epoch 116 Batch  260/269 - Train Accuracy: 0.8313, Validation Accuracy: 0.8599, Loss: 0.1679
Epoch 117 Batch   10/269 - Train Accuracy: 0.8502, Validation Accuracy: 0.8567, Loss: 0.1617
Epoch 117 Batch   20/269 - Train Accuracy: 0.8495, Validation Accuracy: 0.8588, Loss: 0.1526
Epoch 117 Batch   30/269 - Train Accuracy: 0.8543, Validation Accuracy: 0.8592, Loss: 0.1489
Epoch 117 Batch   40/269 - Train Accuracy: 0.8403, Validation Accuracy: 0.8612, Loss: 0.1785
Epoch 117 Batch   50/269 - Train Accuracy: 0.8307, Validation Accuracy: 0.8569, Loss: 0.1661
Epoch 117 Batch   60/269 - Train Accuracy: 0.8564, Validation Accuracy: 0.8564, Loss: 0.1493
Epoch 117 Batch   70/269 - Train Accuracy: 0.8574, Validation Accuracy: 0.8606, Loss: 0.1563
Epoch 117 Batch   80/269 - Train Accuracy: 0.8515, Validation Accuracy: 0.8555, Loss: 0.1600
Epoch 117 Batch   90/269 - Train Accuracy: 0.8609, Validation Accuracy: 0.8592, Loss: 0.1597
Epoch 117 Batch  100/269 - Train Accuracy: 0.8675, Validation Accuracy: 0.8584, Loss: 0.1501
Epoch 117 Batch  110/269 - Train Accuracy: 0.8420, Validation Accuracy: 0.8605, Loss: 0.1650
Epoch 117 Batch  120/269 - Train Accuracy: 0.8489, Validation Accuracy: 0.8600, Loss: 0.1675
Epoch 117 Batch  130/269 - Train Accuracy: 0.8333, Validation Accuracy: 0.8573, Loss: 0.1595
Epoch 117 Batch  140/269 - Train Accuracy: 0.8529, Validation Accuracy: 0.8604, Loss: 0.1749
Epoch 117 Batch  150/269 - Train Accuracy: 0.8535, Validation Accuracy: 0.8574, Loss: 0.1631
Epoch 117 Batch  160/269 - Train Accuracy: 0.8517, Validation Accuracy: 0.8568, Loss: 0.1565
Epoch 117 Batch  170/269 - Train Accuracy: 0.8477, Validation Accuracy: 0.8566, Loss: 0.1609
Epoch 117 Batch  180/269 - Train Accuracy: 0.8669, Validation Accuracy: 0.8530, Loss: 0.1474
Epoch 117 Batch  190/269 - Train Accuracy: 0.8658, Validation Accuracy: 0.8509, Loss: 0.1498
Epoch 117 Batch  200/269 - Train Accuracy: 0.8449, Validation Accuracy: 0.8563, Loss: 0.1564
Epoch 117 Batch  210/269 - Train Accuracy: 0.8651, Validation Accuracy: 0.8573, Loss: 0.1590
Epoch 117 Batch  220/269 - Train Accuracy: 0.8517, Validation Accuracy: 0.8535, Loss: 0.1506
Epoch 117 Batch  230/269 - Train Accuracy: 0.8420, Validation Accuracy: 0.8598, Loss: 0.1591
Epoch 117 Batch  240/269 - Train Accuracy: 0.8731, Validation Accuracy: 0.8570, Loss: 0.1357
Epoch 117 Batch  250/269 - Train Accuracy: 0.8649, Validation Accuracy: 0.8570, Loss: 0.1596
Epoch 117 Batch  260/269 - Train Accuracy: 0.8290, Validation Accuracy: 0.8608, Loss: 0.1640
Epoch 118 Batch   10/269 - Train Accuracy: 0.8564, Validation Accuracy: 0.8613, Loss: 0.1472
Epoch 118 Batch   20/269 - Train Accuracy: 0.8459, Validation Accuracy: 0.8482, Loss: 0.1609
Epoch 118 Batch   30/269 - Train Accuracy: 0.8568, Validation Accuracy: 0.8599, Loss: 0.1543
Epoch 118 Batch   40/269 - Train Accuracy: 0.8410, Validation Accuracy: 0.8658, Loss: 0.1719
Epoch 118 Batch   50/269 - Train Accuracy: 0.8319, Validation Accuracy: 0.8601, Loss: 0.1737
Epoch 118 Batch   60/269 - Train Accuracy: 0.8510, Validation Accuracy: 0.8609, Loss: 0.1466
Epoch 118 Batch   70/269 - Train Accuracy: 0.8544, Validation Accuracy: 0.8596, Loss: 0.1544
Epoch 118 Batch   80/269 - Train Accuracy: 0.8508, Validation Accuracy: 0.8577, Loss: 0.1520
Epoch 118 Batch   90/269 - Train Accuracy: 0.8531, Validation Accuracy: 0.8600, Loss: 0.1660
Epoch 118 Batch  100/269 - Train Accuracy: 0.8648, Validation Accuracy: 0.8544, Loss: 0.1504
Epoch 118 Batch  110/269 - Train Accuracy: 0.8370, Validation Accuracy: 0.8587, Loss: 0.1593
Epoch 118 Batch  120/269 - Train Accuracy: 0.8495, Validation Accuracy: 0.8579, Loss: 0.1608
Epoch 118 Batch  130/269 - Train Accuracy: 0.8421, Validation Accuracy: 0.8652, Loss: 0.1680
Epoch 118 Batch  140/269 - Train Accuracy: 0.8573, Validation Accuracy: 0.8601, Loss: 0.1802
Epoch 118 Batch  150/269 - Train Accuracy: 0.8433, Validation Accuracy: 0.8588, Loss: 0.1564
Epoch 118 Batch  160/269 - Train Accuracy: 0.8486, Validation Accuracy: 0.8544, Loss: 0.1611
Epoch 118 Batch  170/269 - Train Accuracy: 0.8495, Validation Accuracy: 0.8592, Loss: 0.1538
Epoch 118 Batch  180/269 - Train Accuracy: 0.8721, Validation Accuracy: 0.8514, Loss: 0.1517
Epoch 118 Batch  190/269 - Train Accuracy: 0.8664, Validation Accuracy: 0.8650, Loss: 0.1474
Epoch 118 Batch  200/269 - Train Accuracy: 0.8469, Validation Accuracy: 0.8586, Loss: 0.1614
Epoch 118 Batch  210/269 - Train Accuracy: 0.8629, Validation Accuracy: 0.8558, Loss: 0.1628
Epoch 118 Batch  220/269 - Train Accuracy: 0.8495, Validation Accuracy: 0.8549, Loss: 0.1470
Epoch 118 Batch  230/269 - Train Accuracy: 0.8491, Validation Accuracy: 0.8647, Loss: 0.1574
Epoch 118 Batch  240/269 - Train Accuracy: 0.8707, Validation Accuracy: 0.8578, Loss: 0.1390
Epoch 118 Batch  250/269 - Train Accuracy: 0.8634, Validation Accuracy: 0.8567, Loss: 0.1529
Epoch 118 Batch  260/269 - Train Accuracy: 0.8366, Validation Accuracy: 0.8659, Loss: 0.1615
Epoch 119 Batch   10/269 - Train Accuracy: 0.8517, Validation Accuracy: 0.8544, Loss: 0.1508
Epoch 119 Batch   20/269 - Train Accuracy: 0.8439, Validation Accuracy: 0.8567, Loss: 0.1543
Epoch 119 Batch   30/269 - Train Accuracy: 0.8610, Validation Accuracy: 0.8624, Loss: 0.1478
Epoch 119 Batch   40/269 - Train Accuracy: 0.8407, Validation Accuracy: 0.8619, Loss: 0.1741
Epoch 119 Batch   50/269 - Train Accuracy: 0.8354, Validation Accuracy: 0.8612, Loss: 0.1814
Epoch 119 Batch   60/269 - Train Accuracy: 0.8612, Validation Accuracy: 0.8643, Loss: 0.1465
Epoch 119 Batch   70/269 - Train Accuracy: 0.8557, Validation Accuracy: 0.8598, Loss: 0.1606
Epoch 119 Batch   80/269 - Train Accuracy: 0.8534, Validation Accuracy: 0.8631, Loss: 0.1501
Epoch 119 Batch   90/269 - Train Accuracy: 0.8562, Validation Accuracy: 0.8607, Loss: 0.1603
Epoch 119 Batch  100/269 - Train Accuracy: 0.8628, Validation Accuracy: 0.8620, Loss: 0.1484
Epoch 119 Batch  110/269 - Train Accuracy: 0.8385, Validation Accuracy: 0.8606, Loss: 0.1592
Epoch 119 Batch  120/269 - Train Accuracy: 0.8492, Validation Accuracy: 0.8627, Loss: 0.1632
Epoch 119 Batch  130/269 - Train Accuracy: 0.8392, Validation Accuracy: 0.8610, Loss: 0.1614
Epoch 119 Batch  140/269 - Train Accuracy: 0.8581, Validation Accuracy: 0.8571, Loss: 0.1632
Epoch 119 Batch  150/269 - Train Accuracy: 0.8510, Validation Accuracy: 0.8592, Loss: 0.1468
Epoch 119 Batch  160/269 - Train Accuracy: 0.8497, Validation Accuracy: 0.8627, Loss: 0.1566
Epoch 119 Batch  170/269 - Train Accuracy: 0.8439, Validation Accuracy: 0.8628, Loss: 0.1480
Epoch 119 Batch  180/269 - Train Accuracy: 0.8672, Validation Accuracy: 0.8556, Loss: 0.1491
Epoch 119 Batch  190/269 - Train Accuracy: 0.8677, Validation Accuracy: 0.8602, Loss: 0.1554
Epoch 119 Batch  200/269 - Train Accuracy: 0.8482, Validation Accuracy: 0.8604, Loss: 0.1643
Epoch 119 Batch  210/269 - Train Accuracy: 0.8631, Validation Accuracy: 0.8564, Loss: 0.1527
Epoch 119 Batch  220/269 - Train Accuracy: 0.8597, Validation Accuracy: 0.8589, Loss: 0.1543
Epoch 119 Batch  230/269 - Train Accuracy: 0.8491, Validation Accuracy: 0.8584, Loss: 0.1570
Epoch 119 Batch  240/269 - Train Accuracy: 0.8691, Validation Accuracy: 0.8556, Loss: 0.1296
Epoch 119 Batch  250/269 - Train Accuracy: 0.8663, Validation Accuracy: 0.8635, Loss: 0.1489
Epoch 119 Batch  260/269 - Train Accuracy: 0.8361, Validation Accuracy: 0.8602, Loss: 0.1629
Epoch 120 Batch   10/269 - Train Accuracy: 0.8568, Validation Accuracy: 0.8599, Loss: 0.1493
Epoch 120 Batch   20/269 - Train Accuracy: 0.8527, Validation Accuracy: 0.8605, Loss: 0.1592
Epoch 120 Batch   30/269 - Train Accuracy: 0.8558, Validation Accuracy: 0.8643, Loss: 0.1560
Epoch 120 Batch   40/269 - Train Accuracy: 0.8438, Validation Accuracy: 0.8609, Loss: 0.1717
Epoch 120 Batch   50/269 - Train Accuracy: 0.8343, Validation Accuracy: 0.8597, Loss: 0.1704
Epoch 120 Batch   60/269 - Train Accuracy: 0.8515, Validation Accuracy: 0.8632, Loss: 0.1369
Epoch 120 Batch   70/269 - Train Accuracy: 0.8590, Validation Accuracy: 0.8577, Loss: 0.1581
Epoch 120 Batch   80/269 - Train Accuracy: 0.8536, Validation Accuracy: 0.8631, Loss: 0.1464
Epoch 120 Batch   90/269 - Train Accuracy: 0.8530, Validation Accuracy: 0.8591, Loss: 0.1620
Epoch 120 Batch  100/269 - Train Accuracy: 0.8643, Validation Accuracy: 0.8567, Loss: 0.1557
Epoch 120 Batch  110/269 - Train Accuracy: 0.8411, Validation Accuracy: 0.8645, Loss: 0.1600
Epoch 120 Batch  120/269 - Train Accuracy: 0.8538, Validation Accuracy: 0.8576, Loss: 0.1637
Epoch 120 Batch  130/269 - Train Accuracy: 0.8348, Validation Accuracy: 0.8581, Loss: 0.1662
Epoch 120 Batch  140/269 - Train Accuracy: 0.8558, Validation Accuracy: 0.8601, Loss: 0.1666
Epoch 120 Batch  150/269 - Train Accuracy: 0.8514, Validation Accuracy: 0.8578, Loss: 0.1435
Epoch 120 Batch  160/269 - Train Accuracy: 0.8529, Validation Accuracy: 0.8604, Loss: 0.1596
Epoch 120 Batch  170/269 - Train Accuracy: 0.8464, Validation Accuracy: 0.8580, Loss: 0.1492
Epoch 120 Batch  180/269 - Train Accuracy: 0.8764, Validation Accuracy: 0.8557, Loss: 0.1447
Epoch 120 Batch  190/269 - Train Accuracy: 0.8674, Validation Accuracy: 0.8631, Loss: 0.1545
Epoch 120 Batch  200/269 - Train Accuracy: 0.8479, Validation Accuracy: 0.8601, Loss: 0.1541
Epoch 120 Batch  210/269 - Train Accuracy: 0.8679, Validation Accuracy: 0.8617, Loss: 0.1506
Epoch 120 Batch  220/269 - Train Accuracy: 0.8501, Validation Accuracy: 0.8580, Loss: 0.1497
Epoch 120 Batch  230/269 - Train Accuracy: 0.8471, Validation Accuracy: 0.8554, Loss: 0.1513
Epoch 120 Batch  240/269 - Train Accuracy: 0.8729, Validation Accuracy: 0.8646, Loss: 0.1414
Epoch 120 Batch  250/269 - Train Accuracy: 0.8635, Validation Accuracy: 0.8628, Loss: 0.1576
Epoch 120 Batch  260/269 - Train Accuracy: 0.8291, Validation Accuracy: 0.8498, Loss: 0.1679
Epoch 121 Batch   10/269 - Train Accuracy: 0.8528, Validation Accuracy: 0.8524, Loss: 0.1544
Epoch 121 Batch   20/269 - Train Accuracy: 0.8472, Validation Accuracy: 0.8547, Loss: 0.1531
Epoch 121 Batch   30/269 - Train Accuracy: 0.8555, Validation Accuracy: 0.8581, Loss: 0.1453
Epoch 121 Batch   40/269 - Train Accuracy: 0.8410, Validation Accuracy: 0.8572, Loss: 0.1779
Epoch 121 Batch   50/269 - Train Accuracy: 0.8331, Validation Accuracy: 0.8608, Loss: 0.1689
Epoch 121 Batch   60/269 - Train Accuracy: 0.8517, Validation Accuracy: 0.8557, Loss: 0.1430
Epoch 121 Batch   70/269 - Train Accuracy: 0.8637, Validation Accuracy: 0.8568, Loss: 0.1521
Epoch 121 Batch   80/269 - Train Accuracy: 0.8592, Validation Accuracy: 0.8594, Loss: 0.1673
Epoch 121 Batch   90/269 - Train Accuracy: 0.8521, Validation Accuracy: 0.8517, Loss: 0.1673
Epoch 121 Batch  100/269 - Train Accuracy: 0.8630, Validation Accuracy: 0.8572, Loss: 0.1524
Epoch 121 Batch  110/269 - Train Accuracy: 0.8493, Validation Accuracy: 0.8650, Loss: 0.1602
Epoch 121 Batch  120/269 - Train Accuracy: 0.8472, Validation Accuracy: 0.8570, Loss: 0.1638
Epoch 121 Batch  130/269 - Train Accuracy: 0.8296, Validation Accuracy: 0.8566, Loss: 0.1652
Epoch 121 Batch  140/269 - Train Accuracy: 0.8610, Validation Accuracy: 0.8604, Loss: 0.1587
Epoch 121 Batch  150/269 - Train Accuracy: 0.8472, Validation Accuracy: 0.8598, Loss: 0.1509
Epoch 121 Batch  160/269 - Train Accuracy: 0.8483, Validation Accuracy: 0.8565, Loss: 0.1572
Epoch 121 Batch  170/269 - Train Accuracy: 0.8510, Validation Accuracy: 0.8603, Loss: 0.1510
Epoch 121 Batch  180/269 - Train Accuracy: 0.8753, Validation Accuracy: 0.8558, Loss: 0.1446
Epoch 121 Batch  190/269 - Train Accuracy: 0.8653, Validation Accuracy: 0.8588, Loss: 0.1570
Epoch 121 Batch  200/269 - Train Accuracy: 0.8467, Validation Accuracy: 0.8578, Loss: 0.1534
Epoch 121 Batch  210/269 - Train Accuracy: 0.8610, Validation Accuracy: 0.8564, Loss: 0.1581
Epoch 121 Batch  220/269 - Train Accuracy: 0.8522, Validation Accuracy: 0.8582, Loss: 0.1467
Epoch 121 Batch  230/269 - Train Accuracy: 0.8484, Validation Accuracy: 0.8584, Loss: 0.1499
Epoch 121 Batch  240/269 - Train Accuracy: 0.8719, Validation Accuracy: 0.8633, Loss: 0.1480
Epoch 121 Batch  250/269 - Train Accuracy: 0.8640, Validation Accuracy: 0.8610, Loss: 0.1614
Epoch 121 Batch  260/269 - Train Accuracy: 0.8267, Validation Accuracy: 0.8635, Loss: 0.1645
Epoch 122 Batch   10/269 - Train Accuracy: 0.8498, Validation Accuracy: 0.8506, Loss: 0.1544
Epoch 122 Batch   20/269 - Train Accuracy: 0.8538, Validation Accuracy: 0.8619, Loss: 0.1551
Epoch 122 Batch   30/269 - Train Accuracy: 0.8571, Validation Accuracy: 0.8668, Loss: 0.1608
Epoch 122 Batch   40/269 - Train Accuracy: 0.8411, Validation Accuracy: 0.8659, Loss: 0.1751
Epoch 122 Batch   50/269 - Train Accuracy: 0.8318, Validation Accuracy: 0.8599, Loss: 0.1680
Epoch 122 Batch   60/269 - Train Accuracy: 0.8541, Validation Accuracy: 0.8592, Loss: 0.1420
Epoch 122 Batch   70/269 - Train Accuracy: 0.8585, Validation Accuracy: 0.8605, Loss: 0.1470
Epoch 122 Batch   80/269 - Train Accuracy: 0.8562, Validation Accuracy: 0.8622, Loss: 0.1560
Epoch 122 Batch   90/269 - Train Accuracy: 0.8532, Validation Accuracy: 0.8601, Loss: 0.1776
Epoch 122 Batch  100/269 - Train Accuracy: 0.8675, Validation Accuracy: 0.8608, Loss: 0.1486
Epoch 122 Batch  110/269 - Train Accuracy: 0.8478, Validation Accuracy: 0.8662, Loss: 0.1596
Epoch 122 Batch  120/269 - Train Accuracy: 0.8516, Validation Accuracy: 0.8635, Loss: 0.1551
Epoch 122 Batch  130/269 - Train Accuracy: 0.8352, Validation Accuracy: 0.8601, Loss: 0.1616
Epoch 122 Batch  140/269 - Train Accuracy: 0.8558, Validation Accuracy: 0.8549, Loss: 0.1617
Epoch 122 Batch  150/269 - Train Accuracy: 0.8531, Validation Accuracy: 0.8659, Loss: 0.1528
Epoch 122 Batch  160/269 - Train Accuracy: 0.8524, Validation Accuracy: 0.8639, Loss: 0.1547
Epoch 122 Batch  170/269 - Train Accuracy: 0.8472, Validation Accuracy: 0.8623, Loss: 0.1479
Epoch 122 Batch  180/269 - Train Accuracy: 0.8783, Validation Accuracy: 0.8555, Loss: 0.1475
Epoch 122 Batch  190/269 - Train Accuracy: 0.8653, Validation Accuracy: 0.8595, Loss: 0.1527
Epoch 122 Batch  200/269 - Train Accuracy: 0.8528, Validation Accuracy: 0.8607, Loss: 0.1463
Epoch 122 Batch  210/269 - Train Accuracy: 0.8607, Validation Accuracy: 0.8561, Loss: 0.1528
Epoch 122 Batch  220/269 - Train Accuracy: 0.8454, Validation Accuracy: 0.8541, Loss: 0.1456
Epoch 122 Batch  230/269 - Train Accuracy: 0.8517, Validation Accuracy: 0.8613, Loss: 0.1500
Epoch 122 Batch  240/269 - Train Accuracy: 0.8737, Validation Accuracy: 0.8644, Loss: 0.1339
Epoch 122 Batch  250/269 - Train Accuracy: 0.8638, Validation Accuracy: 0.8603, Loss: 0.1517
Epoch 122 Batch  260/269 - Train Accuracy: 0.8321, Validation Accuracy: 0.8671, Loss: 0.1701
Epoch 123 Batch   10/269 - Train Accuracy: 0.8491, Validation Accuracy: 0.8590, Loss: 0.1496
Epoch 123 Batch   20/269 - Train Accuracy: 0.8435, Validation Accuracy: 0.8589, Loss: 0.1543
Epoch 123 Batch   30/269 - Train Accuracy: 0.8550, Validation Accuracy: 0.8603, Loss: 0.1467
Epoch 123 Batch   40/269 - Train Accuracy: 0.8434, Validation Accuracy: 0.8647, Loss: 0.1816
Epoch 123 Batch   50/269 - Train Accuracy: 0.8333, Validation Accuracy: 0.8605, Loss: 0.1693
Epoch 123 Batch   60/269 - Train Accuracy: 0.8643, Validation Accuracy: 0.8658, Loss: 0.1392
Epoch 123 Batch   70/269 - Train Accuracy: 0.8612, Validation Accuracy: 0.8615, Loss: 0.1470
Epoch 123 Batch   80/269 - Train Accuracy: 0.8550, Validation Accuracy: 0.8569, Loss: 0.1487
Epoch 123 Batch   90/269 - Train Accuracy: 0.8507, Validation Accuracy: 0.8557, Loss: 0.1581
Epoch 123 Batch  100/269 - Train Accuracy: 0.8657, Validation Accuracy: 0.8629, Loss: 0.1536
Epoch 123 Batch  110/269 - Train Accuracy: 0.8408, Validation Accuracy: 0.8564, Loss: 0.1647
Epoch 123 Batch  120/269 - Train Accuracy: 0.8570, Validation Accuracy: 0.8602, Loss: 0.1616
Epoch 123 Batch  130/269 - Train Accuracy: 0.8405, Validation Accuracy: 0.8636, Loss: 0.1529
Epoch 123 Batch  140/269 - Train Accuracy: 0.8550, Validation Accuracy: 0.8561, Loss: 0.1617
Epoch 123 Batch  150/269 - Train Accuracy: 0.8513, Validation Accuracy: 0.8598, Loss: 0.1504
Epoch 123 Batch  160/269 - Train Accuracy: 0.8502, Validation Accuracy: 0.8594, Loss: 0.1531
Epoch 123 Batch  170/269 - Train Accuracy: 0.8524, Validation Accuracy: 0.8630, Loss: 0.1452
Epoch 123 Batch  180/269 - Train Accuracy: 0.8757, Validation Accuracy: 0.8553, Loss: 0.1426
Epoch 123 Batch  190/269 - Train Accuracy: 0.8646, Validation Accuracy: 0.8609, Loss: 0.1420
Epoch 123 Batch  200/269 - Train Accuracy: 0.8510, Validation Accuracy: 0.8651, Loss: 0.1500
Epoch 123 Batch  210/269 - Train Accuracy: 0.8615, Validation Accuracy: 0.8544, Loss: 0.1467
Epoch 123 Batch  220/269 - Train Accuracy: 0.8459, Validation Accuracy: 0.8514, Loss: 0.1468
Epoch 123 Batch  230/269 - Train Accuracy: 0.8486, Validation Accuracy: 0.8591, Loss: 0.1531
Epoch 123 Batch  240/269 - Train Accuracy: 0.8705, Validation Accuracy: 0.8588, Loss: 0.1339
Epoch 123 Batch  250/269 - Train Accuracy: 0.8628, Validation Accuracy: 0.8604, Loss: 0.1625
Epoch 123 Batch  260/269 - Train Accuracy: 0.8328, Validation Accuracy: 0.8549, Loss: 0.1670
Epoch 124 Batch   10/269 - Train Accuracy: 0.8599, Validation Accuracy: 0.8603, Loss: 0.1401
Epoch 124 Batch   20/269 - Train Accuracy: 0.8527, Validation Accuracy: 0.8558, Loss: 0.1462
Epoch 124 Batch   30/269 - Train Accuracy: 0.8563, Validation Accuracy: 0.8603, Loss: 0.1442
Epoch 124 Batch   40/269 - Train Accuracy: 0.8430, Validation Accuracy: 0.8602, Loss: 0.1658
Epoch 124 Batch   50/269 - Train Accuracy: 0.8343, Validation Accuracy: 0.8638, Loss: 0.1672
Epoch 124 Batch   60/269 - Train Accuracy: 0.8591, Validation Accuracy: 0.8613, Loss: 0.1386
Epoch 124 Batch   70/269 - Train Accuracy: 0.8625, Validation Accuracy: 0.8623, Loss: 0.1567
Epoch 124 Batch   80/269 - Train Accuracy: 0.8525, Validation Accuracy: 0.8600, Loss: 0.1475
Epoch 124 Batch   90/269 - Train Accuracy: 0.8528, Validation Accuracy: 0.8593, Loss: 0.1652
Epoch 124 Batch  100/269 - Train Accuracy: 0.8650, Validation Accuracy: 0.8602, Loss: 0.1563
Epoch 124 Batch  110/269 - Train Accuracy: 0.8437, Validation Accuracy: 0.8574, Loss: 0.1551
Epoch 124 Batch  120/269 - Train Accuracy: 0.8556, Validation Accuracy: 0.8583, Loss: 0.1566
Epoch 124 Batch  130/269 - Train Accuracy: 0.8342, Validation Accuracy: 0.8614, Loss: 0.1617
Epoch 124 Batch  140/269 - Train Accuracy: 0.8603, Validation Accuracy: 0.8612, Loss: 0.1626
Epoch 124 Batch  150/269 - Train Accuracy: 0.8469, Validation Accuracy: 0.8593, Loss: 0.1459
Epoch 124 Batch  160/269 - Train Accuracy: 0.8525, Validation Accuracy: 0.8681, Loss: 0.1507
Epoch 124 Batch  170/269 - Train Accuracy: 0.8457, Validation Accuracy: 0.8587, Loss: 0.1468
Epoch 124 Batch  180/269 - Train Accuracy: 0.8770, Validation Accuracy: 0.8586, Loss: 0.1397
Epoch 124 Batch  190/269 - Train Accuracy: 0.8688, Validation Accuracy: 0.8605, Loss: 0.1504
Epoch 124 Batch  200/269 - Train Accuracy: 0.8490, Validation Accuracy: 0.8548, Loss: 0.1606
Epoch 124 Batch  210/269 - Train Accuracy: 0.8692, Validation Accuracy: 0.8623, Loss: 0.1480
Epoch 124 Batch  220/269 - Train Accuracy: 0.8528, Validation Accuracy: 0.8621, Loss: 0.1492
Epoch 124 Batch  230/269 - Train Accuracy: 0.8524, Validation Accuracy: 0.8596, Loss: 0.1422
Epoch 124 Batch  240/269 - Train Accuracy: 0.8656, Validation Accuracy: 0.8571, Loss: 0.1323
Epoch 124 Batch  250/269 - Train Accuracy: 0.8640, Validation Accuracy: 0.8584, Loss: 0.1486
Epoch 124 Batch  260/269 - Train Accuracy: 0.8301, Validation Accuracy: 0.8582, Loss: 0.1541
Epoch 125 Batch   10/269 - Train Accuracy: 0.8530, Validation Accuracy: 0.8537, Loss: 0.1438
Epoch 125 Batch   20/269 - Train Accuracy: 0.8537, Validation Accuracy: 0.8578, Loss: 0.1461
Epoch 125 Batch   30/269 - Train Accuracy: 0.8577, Validation Accuracy: 0.8671, Loss: 0.1422
Epoch 125 Batch   40/269 - Train Accuracy: 0.8412, Validation Accuracy: 0.8607, Loss: 0.1643
Epoch 125 Batch   50/269 - Train Accuracy: 0.8318, Validation Accuracy: 0.8603, Loss: 0.1620
Epoch 125 Batch   60/269 - Train Accuracy: 0.8565, Validation Accuracy: 0.8628, Loss: 0.1345
Epoch 125 Batch   70/269 - Train Accuracy: 0.8631, Validation Accuracy: 0.8676, Loss: 0.1465
Epoch 125 Batch   80/269 - Train Accuracy: 0.8627, Validation Accuracy: 0.8606, Loss: 0.1437
Epoch 125 Batch   90/269 - Train Accuracy: 0.8544, Validation Accuracy: 0.8545, Loss: 0.1573
Epoch 125 Batch  100/269 - Train Accuracy: 0.8713, Validation Accuracy: 0.8606, Loss: 0.1462
Epoch 125 Batch  110/269 - Train Accuracy: 0.8420, Validation Accuracy: 0.8589, Loss: 0.1545
Epoch 125 Batch  120/269 - Train Accuracy: 0.8573, Validation Accuracy: 0.8583, Loss: 0.1569
Epoch 125 Batch  130/269 - Train Accuracy: 0.8434, Validation Accuracy: 0.8597, Loss: 0.1566
Epoch 125 Batch  140/269 - Train Accuracy: 0.8618, Validation Accuracy: 0.8642, Loss: 0.1679
Epoch 125 Batch  150/269 - Train Accuracy: 0.8522, Validation Accuracy: 0.8653, Loss: 0.1539
Epoch 125 Batch  160/269 - Train Accuracy: 0.8537, Validation Accuracy: 0.8597, Loss: 0.1561
Epoch 125 Batch  170/269 - Train Accuracy: 0.8464, Validation Accuracy: 0.8573, Loss: 0.1534
Epoch 125 Batch  180/269 - Train Accuracy: 0.8720, Validation Accuracy: 0.8588, Loss: 0.1349
Epoch 125 Batch  190/269 - Train Accuracy: 0.8679, Validation Accuracy: 0.8638, Loss: 0.1533
Epoch 125 Batch  200/269 - Train Accuracy: 0.8497, Validation Accuracy: 0.8623, Loss: 0.1566
Epoch 125 Batch  210/269 - Train Accuracy: 0.8659, Validation Accuracy: 0.8580, Loss: 0.1567
Epoch 125 Batch  220/269 - Train Accuracy: 0.8532, Validation Accuracy: 0.8595, Loss: 0.1432
Epoch 125 Batch  230/269 - Train Accuracy: 0.8509, Validation Accuracy: 0.8622, Loss: 0.1517
Epoch 125 Batch  240/269 - Train Accuracy: 0.8697, Validation Accuracy: 0.8596, Loss: 0.1384
Epoch 125 Batch  250/269 - Train Accuracy: 0.8625, Validation Accuracy: 0.8628, Loss: 0.1547
Epoch 125 Batch  260/269 - Train Accuracy: 0.8340, Validation Accuracy: 0.8624, Loss: 0.1627
Epoch 126 Batch   10/269 - Train Accuracy: 0.8598, Validation Accuracy: 0.8604, Loss: 0.1384
Epoch 126 Batch   20/269 - Train Accuracy: 0.8527, Validation Accuracy: 0.8659, Loss: 0.1495
Epoch 126 Batch   30/269 - Train Accuracy: 0.8554, Validation Accuracy: 0.8607, Loss: 0.1466
Epoch 126 Batch   40/269 - Train Accuracy: 0.8446, Validation Accuracy: 0.8599, Loss: 0.1694
Epoch 126 Batch   50/269 - Train Accuracy: 0.8352, Validation Accuracy: 0.8611, Loss: 0.1698
Epoch 126 Batch   60/269 - Train Accuracy: 0.8555, Validation Accuracy: 0.8642, Loss: 0.1386
Epoch 126 Batch   70/269 - Train Accuracy: 0.8597, Validation Accuracy: 0.8566, Loss: 0.1530
Epoch 126 Batch   80/269 - Train Accuracy: 0.8520, Validation Accuracy: 0.8572, Loss: 0.1458
Epoch 126 Batch   90/269 - Train Accuracy: 0.8529, Validation Accuracy: 0.8589, Loss: 0.1655
Epoch 126 Batch  100/269 - Train Accuracy: 0.8609, Validation Accuracy: 0.8576, Loss: 0.1437
Epoch 126 Batch  110/269 - Train Accuracy: 0.8484, Validation Accuracy: 0.8653, Loss: 0.1513
Epoch 126 Batch  120/269 - Train Accuracy: 0.8536, Validation Accuracy: 0.8586, Loss: 0.1510
Epoch 126 Batch  130/269 - Train Accuracy: 0.8422, Validation Accuracy: 0.8573, Loss: 0.1655
Epoch 126 Batch  140/269 - Train Accuracy: 0.8550, Validation Accuracy: 0.8548, Loss: 0.1561
Epoch 126 Batch  150/269 - Train Accuracy: 0.8569, Validation Accuracy: 0.8581, Loss: 0.1520
Epoch 126 Batch  160/269 - Train Accuracy: 0.8566, Validation Accuracy: 0.8635, Loss: 0.1497
Epoch 126 Batch  170/269 - Train Accuracy: 0.8472, Validation Accuracy: 0.8603, Loss: 0.1440
Epoch 126 Batch  180/269 - Train Accuracy: 0.8730, Validation Accuracy: 0.8545, Loss: 0.1370
Epoch 126 Batch  190/269 - Train Accuracy: 0.8637, Validation Accuracy: 0.8554, Loss: 0.1400
Epoch 126 Batch  200/269 - Train Accuracy: 0.8517, Validation Accuracy: 0.8583, Loss: 0.1524
Epoch 126 Batch  210/269 - Train Accuracy: 0.8652, Validation Accuracy: 0.8650, Loss: 0.1532
Epoch 126 Batch  220/269 - Train Accuracy: 0.8544, Validation Accuracy: 0.8556, Loss: 0.1466
Epoch 126 Batch  230/269 - Train Accuracy: 0.8498, Validation Accuracy: 0.8581, Loss: 0.1520
Epoch 126 Batch  240/269 - Train Accuracy: 0.8658, Validation Accuracy: 0.8549, Loss: 0.1285
Epoch 126 Batch  250/269 - Train Accuracy: 0.8648, Validation Accuracy: 0.8655, Loss: 0.1442
Epoch 126 Batch  260/269 - Train Accuracy: 0.8300, Validation Accuracy: 0.8643, Loss: 0.1546
Epoch 127 Batch   10/269 - Train Accuracy: 0.8515, Validation Accuracy: 0.8602, Loss: 0.1423
Epoch 127 Batch   20/269 - Train Accuracy: 0.8540, Validation Accuracy: 0.8627, Loss: 0.1483
Epoch 127 Batch   30/269 - Train Accuracy: 0.8528, Validation Accuracy: 0.8619, Loss: 0.1482
Epoch 127 Batch   40/269 - Train Accuracy: 0.8470, Validation Accuracy: 0.8605, Loss: 0.1583
Epoch 127 Batch   50/269 - Train Accuracy: 0.8348, Validation Accuracy: 0.8666, Loss: 0.1605
Epoch 127 Batch   60/269 - Train Accuracy: 0.8562, Validation Accuracy: 0.8649, Loss: 0.1352
Epoch 127 Batch   70/269 - Train Accuracy: 0.8643, Validation Accuracy: 0.8628, Loss: 0.1436
Epoch 127 Batch   80/269 - Train Accuracy: 0.8542, Validation Accuracy: 0.8630, Loss: 0.1466
Epoch 127 Batch   90/269 - Train Accuracy: 0.8509, Validation Accuracy: 0.8618, Loss: 0.1551
Epoch 127 Batch  100/269 - Train Accuracy: 0.8662, Validation Accuracy: 0.8540, Loss: 0.1492
Epoch 127 Batch  110/269 - Train Accuracy: 0.8490, Validation Accuracy: 0.8678, Loss: 0.1601
Epoch 127 Batch  120/269 - Train Accuracy: 0.8590, Validation Accuracy: 0.8573, Loss: 0.1599
Epoch 127 Batch  130/269 - Train Accuracy: 0.8386, Validation Accuracy: 0.8603, Loss: 0.1568
Epoch 127 Batch  140/269 - Train Accuracy: 0.8623, Validation Accuracy: 0.8588, Loss: 0.1578
Epoch 127 Batch  150/269 - Train Accuracy: 0.8606, Validation Accuracy: 0.8600, Loss: 0.1474
Epoch 127 Batch  160/269 - Train Accuracy: 0.8563, Validation Accuracy: 0.8577, Loss: 0.1505
Epoch 127 Batch  170/269 - Train Accuracy: 0.8493, Validation Accuracy: 0.8558, Loss: 0.1570
Epoch 127 Batch  180/269 - Train Accuracy: 0.8802, Validation Accuracy: 0.8576, Loss: 0.1491
Epoch 127 Batch  190/269 - Train Accuracy: 0.8677, Validation Accuracy: 0.8603, Loss: 0.1635
Epoch 127 Batch  200/269 - Train Accuracy: 0.8539, Validation Accuracy: 0.8572, Loss: 0.1459
Epoch 127 Batch  210/269 - Train Accuracy: 0.8643, Validation Accuracy: 0.8573, Loss: 0.1383
Epoch 127 Batch  220/269 - Train Accuracy: 0.8504, Validation Accuracy: 0.8541, Loss: 0.1448
Epoch 127 Batch  230/269 - Train Accuracy: 0.8525, Validation Accuracy: 0.8598, Loss: 0.1417
Epoch 127 Batch  240/269 - Train Accuracy: 0.8685, Validation Accuracy: 0.8596, Loss: 0.1344
Epoch 127 Batch  250/269 - Train Accuracy: 0.8654, Validation Accuracy: 0.8605, Loss: 0.1475
Epoch 127 Batch  260/269 - Train Accuracy: 0.8393, Validation Accuracy: 0.8644, Loss: 0.1573
Epoch 128 Batch   10/269 - Train Accuracy: 0.8537, Validation Accuracy: 0.8531, Loss: 0.1424
Epoch 128 Batch   20/269 - Train Accuracy: 0.8545, Validation Accuracy: 0.8642, Loss: 0.1579
Epoch 128 Batch   30/269 - Train Accuracy: 0.8577, Validation Accuracy: 0.8612, Loss: 0.1510
Epoch 128 Batch   40/269 - Train Accuracy: 0.8416, Validation Accuracy: 0.8574, Loss: 0.1623
Epoch 128 Batch   50/269 - Train Accuracy: 0.8318, Validation Accuracy: 0.8614, Loss: 0.1589
Epoch 128 Batch   60/269 - Train Accuracy: 0.8558, Validation Accuracy: 0.8635, Loss: 0.1376
Epoch 128 Batch   70/269 - Train Accuracy: 0.8604, Validation Accuracy: 0.8644, Loss: 0.1484
Epoch 128 Batch   80/269 - Train Accuracy: 0.8573, Validation Accuracy: 0.8653, Loss: 0.1475
Epoch 128 Batch   90/269 - Train Accuracy: 0.8512, Validation Accuracy: 0.8597, Loss: 0.1575
Epoch 128 Batch  100/269 - Train Accuracy: 0.8672, Validation Accuracy: 0.8594, Loss: 0.1468
Epoch 128 Batch  110/269 - Train Accuracy: 0.8460, Validation Accuracy: 0.8678, Loss: 0.1543
Epoch 128 Batch  120/269 - Train Accuracy: 0.8604, Validation Accuracy: 0.8563, Loss: 0.1528
Epoch 128 Batch  130/269 - Train Accuracy: 0.8438, Validation Accuracy: 0.8601, Loss: 0.1540
Epoch 128 Batch  140/269 - Train Accuracy: 0.8599, Validation Accuracy: 0.8606, Loss: 0.1620
Epoch 128 Batch  150/269 - Train Accuracy: 0.8511, Validation Accuracy: 0.8597, Loss: 0.1524
Epoch 128 Batch  160/269 - Train Accuracy: 0.8533, Validation Accuracy: 0.8634, Loss: 0.1530
Epoch 128 Batch  170/269 - Train Accuracy: 0.8522, Validation Accuracy: 0.8635, Loss: 0.1592
Epoch 128 Batch  180/269 - Train Accuracy: 0.8757, Validation Accuracy: 0.8599, Loss: 0.1438
Epoch 128 Batch  190/269 - Train Accuracy: 0.8667, Validation Accuracy: 0.8625, Loss: 0.1498
Epoch 128 Batch  200/269 - Train Accuracy: 0.8480, Validation Accuracy: 0.8583, Loss: 0.1493
Epoch 128 Batch  210/269 - Train Accuracy: 0.8627, Validation Accuracy: 0.8574, Loss: 0.1468
Epoch 128 Batch  220/269 - Train Accuracy: 0.8488, Validation Accuracy: 0.8615, Loss: 0.1429
Epoch 128 Batch  230/269 - Train Accuracy: 0.8504, Validation Accuracy: 0.8642, Loss: 0.1427
Epoch 128 Batch  240/269 - Train Accuracy: 0.8729, Validation Accuracy: 0.8623, Loss: 0.1273
Epoch 128 Batch  250/269 - Train Accuracy: 0.8670, Validation Accuracy: 0.8629, Loss: 0.1438
Epoch 128 Batch  260/269 - Train Accuracy: 0.8401, Validation Accuracy: 0.8681, Loss: 0.1522
Epoch 129 Batch   10/269 - Train Accuracy: 0.8610, Validation Accuracy: 0.8613, Loss: 0.1412
Epoch 129 Batch   20/269 - Train Accuracy: 0.8523, Validation Accuracy: 0.8590, Loss: 0.1520
Epoch 129 Batch   30/269 - Train Accuracy: 0.8554, Validation Accuracy: 0.8651, Loss: 0.1436
Epoch 129 Batch   40/269 - Train Accuracy: 0.8479, Validation Accuracy: 0.8620, Loss: 0.1700
Epoch 129 Batch   50/269 - Train Accuracy: 0.8300, Validation Accuracy: 0.8677, Loss: 0.1634
Epoch 129 Batch   60/269 - Train Accuracy: 0.8577, Validation Accuracy: 0.8629, Loss: 0.1373
Epoch 129 Batch   70/269 - Train Accuracy: 0.8617, Validation Accuracy: 0.8582, Loss: 0.1466
Epoch 129 Batch   80/269 - Train Accuracy: 0.8568, Validation Accuracy: 0.8580, Loss: 0.1482
Epoch 129 Batch   90/269 - Train Accuracy: 0.8530, Validation Accuracy: 0.8556, Loss: 0.1598
Epoch 129 Batch  100/269 - Train Accuracy: 0.8691, Validation Accuracy: 0.8564, Loss: 0.1499
Epoch 129 Batch  110/269 - Train Accuracy: 0.8472, Validation Accuracy: 0.8674, Loss: 0.1519
Epoch 129 Batch  120/269 - Train Accuracy: 0.8559, Validation Accuracy: 0.8611, Loss: 0.1609
Epoch 129 Batch  130/269 - Train Accuracy: 0.8350, Validation Accuracy: 0.8600, Loss: 0.1588
Epoch 129 Batch  140/269 - Train Accuracy: 0.8617, Validation Accuracy: 0.8587, Loss: 0.1732
Epoch 129 Batch  150/269 - Train Accuracy: 0.8504, Validation Accuracy: 0.8572, Loss: 0.1463
Epoch 129 Batch  160/269 - Train Accuracy: 0.8527, Validation Accuracy: 0.8646, Loss: 0.1552
Epoch 129 Batch  170/269 - Train Accuracy: 0.8487, Validation Accuracy: 0.8627, Loss: 0.1498
Epoch 129 Batch  180/269 - Train Accuracy: 0.8790, Validation Accuracy: 0.8576, Loss: 0.1407
Epoch 129 Batch  190/269 - Train Accuracy: 0.8705, Validation Accuracy: 0.8661, Loss: 0.1485
Epoch 129 Batch  200/269 - Train Accuracy: 0.8578, Validation Accuracy: 0.8607, Loss: 0.1429
Epoch 129 Batch  210/269 - Train Accuracy: 0.8714, Validation Accuracy: 0.8656, Loss: 0.1483
Epoch 129 Batch  220/269 - Train Accuracy: 0.8551, Validation Accuracy: 0.8564, Loss: 0.1459
Epoch 129 Batch  230/269 - Train Accuracy: 0.8491, Validation Accuracy: 0.8591, Loss: 0.1458
Epoch 129 Batch  240/269 - Train Accuracy: 0.8697, Validation Accuracy: 0.8635, Loss: 0.1303
Epoch 129 Batch  250/269 - Train Accuracy: 0.8659, Validation Accuracy: 0.8603, Loss: 0.1471
Epoch 129 Batch  260/269 - Train Accuracy: 0.8393, Validation Accuracy: 0.8578, Loss: 0.1552
Epoch 130 Batch   10/269 - Train Accuracy: 0.8521, Validation Accuracy: 0.8591, Loss: 0.1459
Epoch 130 Batch   20/269 - Train Accuracy: 0.8553, Validation Accuracy: 0.8551, Loss: 0.1475
Epoch 130 Batch   30/269 - Train Accuracy: 0.8555, Validation Accuracy: 0.8646, Loss: 0.1455
Epoch 130 Batch   40/269 - Train Accuracy: 0.8458, Validation Accuracy: 0.8618, Loss: 0.1603
Epoch 130 Batch   50/269 - Train Accuracy: 0.8335, Validation Accuracy: 0.8676, Loss: 0.1677
Epoch 130 Batch   60/269 - Train Accuracy: 0.8496, Validation Accuracy: 0.8607, Loss: 0.1388
Epoch 130 Batch   70/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8608, Loss: 0.1396
Epoch 130 Batch   80/269 - Train Accuracy: 0.8570, Validation Accuracy: 0.8583, Loss: 0.1416
Epoch 130 Batch   90/269 - Train Accuracy: 0.8537, Validation Accuracy: 0.8587, Loss: 0.1538
Epoch 130 Batch  100/269 - Train Accuracy: 0.8638, Validation Accuracy: 0.8620, Loss: 0.1373
Epoch 130 Batch  110/269 - Train Accuracy: 0.8482, Validation Accuracy: 0.8683, Loss: 0.1561
Epoch 130 Batch  120/269 - Train Accuracy: 0.8590, Validation Accuracy: 0.8614, Loss: 0.1558
Epoch 130 Batch  130/269 - Train Accuracy: 0.8399, Validation Accuracy: 0.8544, Loss: 0.1567
Epoch 130 Batch  140/269 - Train Accuracy: 0.8579, Validation Accuracy: 0.8608, Loss: 0.1566
Epoch 130 Batch  150/269 - Train Accuracy: 0.8583, Validation Accuracy: 0.8670, Loss: 0.1437
Epoch 130 Batch  160/269 - Train Accuracy: 0.8552, Validation Accuracy: 0.8598, Loss: 0.1428
Epoch 130 Batch  170/269 - Train Accuracy: 0.8495, Validation Accuracy: 0.8570, Loss: 0.1472
Epoch 130 Batch  180/269 - Train Accuracy: 0.8765, Validation Accuracy: 0.8641, Loss: 0.1503
Epoch 130 Batch  190/269 - Train Accuracy: 0.8695, Validation Accuracy: 0.8599, Loss: 0.1439
Epoch 130 Batch  200/269 - Train Accuracy: 0.8543, Validation Accuracy: 0.8592, Loss: 0.1425
Epoch 130 Batch  210/269 - Train Accuracy: 0.8722, Validation Accuracy: 0.8677, Loss: 0.1443
Epoch 130 Batch  220/269 - Train Accuracy: 0.8600, Validation Accuracy: 0.8663, Loss: 0.1377
Epoch 130 Batch  230/269 - Train Accuracy: 0.8529, Validation Accuracy: 0.8603, Loss: 0.1458
Epoch 130 Batch  240/269 - Train Accuracy: 0.8731, Validation Accuracy: 0.8638, Loss: 0.1231
Epoch 130 Batch  250/269 - Train Accuracy: 0.8657, Validation Accuracy: 0.8654, Loss: 0.1444
Epoch 130 Batch  260/269 - Train Accuracy: 0.8350, Validation Accuracy: 0.8618, Loss: 0.1564
Epoch 131 Batch   10/269 - Train Accuracy: 0.8532, Validation Accuracy: 0.8590, Loss: 0.1495
Epoch 131 Batch   20/269 - Train Accuracy: 0.8516, Validation Accuracy: 0.8587, Loss: 0.1466
Epoch 131 Batch   30/269 - Train Accuracy: 0.8599, Validation Accuracy: 0.8612, Loss: 0.1491
Epoch 131 Batch   40/269 - Train Accuracy: 0.8478, Validation Accuracy: 0.8600, Loss: 0.1619
Epoch 131 Batch   50/269 - Train Accuracy: 0.8319, Validation Accuracy: 0.8631, Loss: 0.1587
Epoch 131 Batch   60/269 - Train Accuracy: 0.8572, Validation Accuracy: 0.8612, Loss: 0.1324
Epoch 131 Batch   70/269 - Train Accuracy: 0.8603, Validation Accuracy: 0.8613, Loss: 0.1481
Epoch 131 Batch   80/269 - Train Accuracy: 0.8592, Validation Accuracy: 0.8624, Loss: 0.1438
Epoch 131 Batch   90/269 - Train Accuracy: 0.8587, Validation Accuracy: 0.8596, Loss: 0.1566
Epoch 131 Batch  100/269 - Train Accuracy: 0.8725, Validation Accuracy: 0.8598, Loss: 0.1403
Epoch 131 Batch  110/269 - Train Accuracy: 0.8385, Validation Accuracy: 0.8576, Loss: 0.1575
Epoch 131 Batch  120/269 - Train Accuracy: 0.8609, Validation Accuracy: 0.8679, Loss: 0.1599
Epoch 131 Batch  130/269 - Train Accuracy: 0.8418, Validation Accuracy: 0.8649, Loss: 0.1622
Epoch 131 Batch  140/269 - Train Accuracy: 0.8531, Validation Accuracy: 0.8569, Loss: 0.1567
Epoch 131 Batch  150/269 - Train Accuracy: 0.8518, Validation Accuracy: 0.8607, Loss: 0.1511
Epoch 131 Batch  160/269 - Train Accuracy: 0.8544, Validation Accuracy: 0.8597, Loss: 0.1460
Epoch 131 Batch  170/269 - Train Accuracy: 0.8489, Validation Accuracy: 0.8622, Loss: 0.1584
Epoch 131 Batch  180/269 - Train Accuracy: 0.8752, Validation Accuracy: 0.8517, Loss: 0.1335
Epoch 131 Batch  190/269 - Train Accuracy: 0.8700, Validation Accuracy: 0.8596, Loss: 0.1487
Epoch 131 Batch  200/269 - Train Accuracy: 0.8487, Validation Accuracy: 0.8625, Loss: 0.1559
Epoch 131 Batch  210/269 - Train Accuracy: 0.8653, Validation Accuracy: 0.8644, Loss: 0.1537
Epoch 131 Batch  220/269 - Train Accuracy: 0.8605, Validation Accuracy: 0.8614, Loss: 0.1460
Epoch 131 Batch  230/269 - Train Accuracy: 0.8550, Validation Accuracy: 0.8581, Loss: 0.1448
Epoch 131 Batch  240/269 - Train Accuracy: 0.8725, Validation Accuracy: 0.8646, Loss: 0.1345
Epoch 131 Batch  250/269 - Train Accuracy: 0.8652, Validation Accuracy: 0.8622, Loss: 0.1423
Epoch 131 Batch  260/269 - Train Accuracy: 0.8368, Validation Accuracy: 0.8654, Loss: 0.1580
Epoch 132 Batch   10/269 - Train Accuracy: 0.8593, Validation Accuracy: 0.8635, Loss: 0.1484
Epoch 132 Batch   20/269 - Train Accuracy: 0.8521, Validation Accuracy: 0.8627, Loss: 0.1472
Epoch 132 Batch   30/269 - Train Accuracy: 0.8564, Validation Accuracy: 0.8564, Loss: 0.1485
Epoch 132 Batch   40/269 - Train Accuracy: 0.8457, Validation Accuracy: 0.8661, Loss: 0.1637
Epoch 132 Batch   50/269 - Train Accuracy: 0.8310, Validation Accuracy: 0.8589, Loss: 0.1599
Epoch 132 Batch   60/269 - Train Accuracy: 0.8576, Validation Accuracy: 0.8613, Loss: 0.1267
Epoch 132 Batch   70/269 - Train Accuracy: 0.8610, Validation Accuracy: 0.8592, Loss: 0.1487
Epoch 132 Batch   80/269 - Train Accuracy: 0.8540, Validation Accuracy: 0.8580, Loss: 0.1487
Epoch 132 Batch   90/269 - Train Accuracy: 0.8581, Validation Accuracy: 0.8643, Loss: 0.1576
Epoch 132 Batch  100/269 - Train Accuracy: 0.8650, Validation Accuracy: 0.8621, Loss: 0.1450
Epoch 132 Batch  110/269 - Train Accuracy: 0.8394, Validation Accuracy: 0.8604, Loss: 0.1535
Epoch 132 Batch  120/269 - Train Accuracy: 0.8683, Validation Accuracy: 0.8587, Loss: 0.1673
Epoch 132 Batch  130/269 - Train Accuracy: 0.8332, Validation Accuracy: 0.8615, Loss: 0.1515
Epoch 132 Batch  140/269 - Train Accuracy: 0.8609, Validation Accuracy: 0.8625, Loss: 0.1567
Epoch 132 Batch  150/269 - Train Accuracy: 0.8548, Validation Accuracy: 0.8654, Loss: 0.1418
Epoch 132 Batch  160/269 - Train Accuracy: 0.8549, Validation Accuracy: 0.8612, Loss: 0.1450
Epoch 132 Batch  170/269 - Train Accuracy: 0.8513, Validation Accuracy: 0.8602, Loss: 0.1387
Epoch 132 Batch  180/269 - Train Accuracy: 0.8711, Validation Accuracy: 0.8592, Loss: 0.1648
Epoch 132 Batch  190/269 - Train Accuracy: 0.8575, Validation Accuracy: 0.8532, Loss: 0.1588
Epoch 132 Batch  200/269 - Train Accuracy: 0.8441, Validation Accuracy: 0.8560, Loss: 0.1657
Epoch 132 Batch  210/269 - Train Accuracy: 0.8592, Validation Accuracy: 0.8569, Loss: 0.1479
Epoch 132 Batch  220/269 - Train Accuracy: 0.8564, Validation Accuracy: 0.8570, Loss: 0.1508
Epoch 132 Batch  230/269 - Train Accuracy: 0.8487, Validation Accuracy: 0.8548, Loss: 0.1492
Epoch 132 Batch  240/269 - Train Accuracy: 0.8698, Validation Accuracy: 0.8684, Loss: 0.1363
Epoch 132 Batch  250/269 - Train Accuracy: 0.8677, Validation Accuracy: 0.8612, Loss: 0.1448
Epoch 132 Batch  260/269 - Train Accuracy: 0.8330, Validation Accuracy: 0.8613, Loss: 0.1521
Epoch 133 Batch   10/269 - Train Accuracy: 0.8598, Validation Accuracy: 0.8596, Loss: 0.1374
Epoch 133 Batch   20/269 - Train Accuracy: 0.8483, Validation Accuracy: 0.8562, Loss: 0.1469
Epoch 133 Batch   30/269 - Train Accuracy: 0.8549, Validation Accuracy: 0.8602, Loss: 0.1412
Epoch 133 Batch   40/269 - Train Accuracy: 0.8443, Validation Accuracy: 0.8583, Loss: 0.1586
Epoch 133 Batch   50/269 - Train Accuracy: 0.8339, Validation Accuracy: 0.8614, Loss: 0.1594
Epoch 133 Batch   60/269 - Train Accuracy: 0.8559, Validation Accuracy: 0.8655, Loss: 0.1285
Epoch 133 Batch   70/269 - Train Accuracy: 0.8637, Validation Accuracy: 0.8576, Loss: 0.1409
Epoch 133 Batch   80/269 - Train Accuracy: 0.8541, Validation Accuracy: 0.8589, Loss: 0.1452
Epoch 133 Batch   90/269 - Train Accuracy: 0.8481, Validation Accuracy: 0.8586, Loss: 0.1460
Epoch 133 Batch  100/269 - Train Accuracy: 0.8710, Validation Accuracy: 0.8575, Loss: 0.1450
Epoch 133 Batch  110/269 - Train Accuracy: 0.8475, Validation Accuracy: 0.8647, Loss: 0.1413
Epoch 133 Batch  120/269 - Train Accuracy: 0.8555, Validation Accuracy: 0.8615, Loss: 0.1561
Epoch 133 Batch  130/269 - Train Accuracy: 0.8424, Validation Accuracy: 0.8640, Loss: 0.1496
Epoch 133 Batch  140/269 - Train Accuracy: 0.8560, Validation Accuracy: 0.8564, Loss: 0.1590
Epoch 133 Batch  150/269 - Train Accuracy: 0.8566, Validation Accuracy: 0.8626, Loss: 0.1404
Epoch 133 Batch  160/269 - Train Accuracy: 0.8568, Validation Accuracy: 0.8592, Loss: 0.1412
Epoch 133 Batch  170/269 - Train Accuracy: 0.8467, Validation Accuracy: 0.8579, Loss: 0.1480
Epoch 133 Batch  180/269 - Train Accuracy: 0.8749, Validation Accuracy: 0.8599, Loss: 0.1384
Epoch 133 Batch  190/269 - Train Accuracy: 0.8658, Validation Accuracy: 0.8586, Loss: 0.1323
Epoch 133 Batch  200/269 - Train Accuracy: 0.8519, Validation Accuracy: 0.8556, Loss: 0.1475
Epoch 133 Batch  210/269 - Train Accuracy: 0.8762, Validation Accuracy: 0.8641, Loss: 0.1522
Epoch 133 Batch  220/269 - Train Accuracy: 0.8537, Validation Accuracy: 0.8568, Loss: 0.1387
Epoch 133 Batch  230/269 - Train Accuracy: 0.8469, Validation Accuracy: 0.8546, Loss: 0.1411
Epoch 133 Batch  240/269 - Train Accuracy: 0.8760, Validation Accuracy: 0.8578, Loss: 0.1377
Epoch 133 Batch  250/269 - Train Accuracy: 0.8667, Validation Accuracy: 0.8639, Loss: 0.1517
Epoch 133 Batch  260/269 - Train Accuracy: 0.8408, Validation Accuracy: 0.8644, Loss: 0.1546
Epoch 134 Batch   10/269 - Train Accuracy: 0.8578, Validation Accuracy: 0.8600, Loss: 0.1417
Epoch 134 Batch   20/269 - Train Accuracy: 0.8532, Validation Accuracy: 0.8629, Loss: 0.1481
Epoch 134 Batch   30/269 - Train Accuracy: 0.8574, Validation Accuracy: 0.8632, Loss: 0.1500
Epoch 134 Batch   40/269 - Train Accuracy: 0.8432, Validation Accuracy: 0.8619, Loss: 0.1601
Epoch 134 Batch   50/269 - Train Accuracy: 0.8317, Validation Accuracy: 0.8676, Loss: 0.1572
Epoch 134 Batch   60/269 - Train Accuracy: 0.8580, Validation Accuracy: 0.8634, Loss: 0.1282
Epoch 134 Batch   70/269 - Train Accuracy: 0.8647, Validation Accuracy: 0.8690, Loss: 0.1380
Epoch 134 Batch   80/269 - Train Accuracy: 0.8515, Validation Accuracy: 0.8558, Loss: 0.1467
Epoch 134 Batch   90/269 - Train Accuracy: 0.8534, Validation Accuracy: 0.8585, Loss: 0.1503
Epoch 134 Batch  100/269 - Train Accuracy: 0.8741, Validation Accuracy: 0.8552, Loss: 0.1361
Epoch 134 Batch  110/269 - Train Accuracy: 0.8451, Validation Accuracy: 0.8606, Loss: 0.1518
Epoch 134 Batch  120/269 - Train Accuracy: 0.8609, Validation Accuracy: 0.8608, Loss: 0.1576
Epoch 134 Batch  130/269 - Train Accuracy: 0.8392, Validation Accuracy: 0.8586, Loss: 0.1524
Epoch 134 Batch  140/269 - Train Accuracy: 0.8580, Validation Accuracy: 0.8600, Loss: 0.1530
Epoch 134 Batch  150/269 - Train Accuracy: 0.8557, Validation Accuracy: 0.8651, Loss: 0.1415
Epoch 134 Batch  160/269 - Train Accuracy: 0.8594, Validation Accuracy: 0.8652, Loss: 0.1382
Epoch 134 Batch  170/269 - Train Accuracy: 0.8535, Validation Accuracy: 0.8610, Loss: 0.1457
Epoch 134 Batch  180/269 - Train Accuracy: 0.8780, Validation Accuracy: 0.8565, Loss: 0.1368
Epoch 134 Batch  190/269 - Train Accuracy: 0.8705, Validation Accuracy: 0.8575, Loss: 0.1401
Epoch 134 Batch  200/269 - Train Accuracy: 0.8518, Validation Accuracy: 0.8564, Loss: 0.1385
Epoch 134 Batch  210/269 - Train Accuracy: 0.8729, Validation Accuracy: 0.8651, Loss: 0.1463
Epoch 134 Batch  220/269 - Train Accuracy: 0.8540, Validation Accuracy: 0.8579, Loss: 0.1378
Epoch 134 Batch  230/269 - Train Accuracy: 0.8449, Validation Accuracy: 0.8588, Loss: 0.1440
Epoch 134 Batch  240/269 - Train Accuracy: 0.8753, Validation Accuracy: 0.8609, Loss: 0.1316
Epoch 134 Batch  250/269 - Train Accuracy: 0.8641, Validation Accuracy: 0.8658, Loss: 0.1411
Epoch 134 Batch  260/269 - Train Accuracy: 0.8331, Validation Accuracy: 0.8642, Loss: 0.1536
Epoch 135 Batch   10/269 - Train Accuracy: 0.8578, Validation Accuracy: 0.8591, Loss: 0.1381
Epoch 135 Batch   20/269 - Train Accuracy: 0.8539, Validation Accuracy: 0.8598, Loss: 0.1423
Epoch 135 Batch   30/269 - Train Accuracy: 0.8574, Validation Accuracy: 0.8679, Loss: 0.1491
Epoch 135 Batch   40/269 - Train Accuracy: 0.8489, Validation Accuracy: 0.8640, Loss: 0.1559
Epoch 135 Batch   50/269 - Train Accuracy: 0.8309, Validation Accuracy: 0.8657, Loss: 0.1562
Epoch 135 Batch   60/269 - Train Accuracy: 0.8593, Validation Accuracy: 0.8650, Loss: 0.1376
Epoch 135 Batch   70/269 - Train Accuracy: 0.8670, Validation Accuracy: 0.8628, Loss: 0.1509
Epoch 135 Batch   80/269 - Train Accuracy: 0.8584, Validation Accuracy: 0.8583, Loss: 0.1412
Epoch 135 Batch   90/269 - Train Accuracy: 0.8576, Validation Accuracy: 0.8573, Loss: 0.1437
Epoch 135 Batch  100/269 - Train Accuracy: 0.8745, Validation Accuracy: 0.8589, Loss: 0.1390
Epoch 135 Batch  110/269 - Train Accuracy: 0.8475, Validation Accuracy: 0.8685, Loss: 0.1505
Epoch 135 Batch  120/269 - Train Accuracy: 0.8638, Validation Accuracy: 0.8683, Loss: 0.1529
Epoch 135 Batch  130/269 - Train Accuracy: 0.8367, Validation Accuracy: 0.8606, Loss: 0.1486
Epoch 135 Batch  140/269 - Train Accuracy: 0.8560, Validation Accuracy: 0.8578, Loss: 0.1494
Epoch 135 Batch  150/269 - Train Accuracy: 0.8538, Validation Accuracy: 0.8559, Loss: 0.1446
Epoch 135 Batch  160/269 - Train Accuracy: 0.8550, Validation Accuracy: 0.8643, Loss: 0.1467
Epoch 135 Batch  170/269 - Train Accuracy: 0.8525, Validation Accuracy: 0.8648, Loss: 0.1431
Epoch 135 Batch  180/269 - Train Accuracy: 0.8799, Validation Accuracy: 0.8575, Loss: 0.1296
Epoch 135 Batch  190/269 - Train Accuracy: 0.8716, Validation Accuracy: 0.8651, Loss: 0.1453
Epoch 135 Batch  200/269 - Train Accuracy: 0.8576, Validation Accuracy: 0.8586, Loss: 0.1387
Epoch 135 Batch  210/269 - Train Accuracy: 0.8717, Validation Accuracy: 0.8633, Loss: 0.1499
Epoch 135 Batch  220/269 - Train Accuracy: 0.8593, Validation Accuracy: 0.8610, Loss: 0.1396
Epoch 135 Batch  230/269 - Train Accuracy: 0.8580, Validation Accuracy: 0.8667, Loss: 0.1412
Epoch 135 Batch  240/269 - Train Accuracy: 0.8669, Validation Accuracy: 0.8604, Loss: 0.1216
Epoch 135 Batch  250/269 - Train Accuracy: 0.8672, Validation Accuracy: 0.8610, Loss: 0.1398
Epoch 135 Batch  260/269 - Train Accuracy: 0.8414, Validation Accuracy: 0.8643, Loss: 0.1534
Epoch 136 Batch   10/269 - Train Accuracy: 0.8535, Validation Accuracy: 0.8564, Loss: 0.1302
Epoch 136 Batch   20/269 - Train Accuracy: 0.8572, Validation Accuracy: 0.8627, Loss: 0.1481
Epoch 136 Batch   30/269 - Train Accuracy: 0.8578, Validation Accuracy: 0.8630, Loss: 0.1410
Epoch 136 Batch   40/269 - Train Accuracy: 0.8464, Validation Accuracy: 0.8597, Loss: 0.1555
Epoch 136 Batch   50/269 - Train Accuracy: 0.8320, Validation Accuracy: 0.8612, Loss: 0.1640
Epoch 136 Batch   60/269 - Train Accuracy: 0.8596, Validation Accuracy: 0.8632, Loss: 0.1314
Epoch 136 Batch   70/269 - Train Accuracy: 0.8626, Validation Accuracy: 0.8570, Loss: 0.1398
Epoch 136 Batch   80/269 - Train Accuracy: 0.8614, Validation Accuracy: 0.8611, Loss: 0.1427
Epoch 136 Batch   90/269 - Train Accuracy: 0.8560, Validation Accuracy: 0.8623, Loss: 0.1651
Epoch 136 Batch  100/269 - Train Accuracy: 0.8695, Validation Accuracy: 0.8584, Loss: 0.1293
Epoch 136 Batch  110/269 - Train Accuracy: 0.8394, Validation Accuracy: 0.8596, Loss: 0.1478
Epoch 136 Batch  120/269 - Train Accuracy: 0.8651, Validation Accuracy: 0.8647, Loss: 0.1492
Epoch 136 Batch  130/269 - Train Accuracy: 0.8461, Validation Accuracy: 0.8619, Loss: 0.1463
Epoch 136 Batch  140/269 - Train Accuracy: 0.8545, Validation Accuracy: 0.8619, Loss: 0.1569
Epoch 136 Batch  150/269 - Train Accuracy: 0.8592, Validation Accuracy: 0.8592, Loss: 0.1424
Epoch 136 Batch  160/269 - Train Accuracy: 0.8526, Validation Accuracy: 0.8651, Loss: 0.1414
Epoch 136 Batch  170/269 - Train Accuracy: 0.8504, Validation Accuracy: 0.8610, Loss: 0.1449
Epoch 136 Batch  180/269 - Train Accuracy: 0.8750, Validation Accuracy: 0.8579, Loss: 0.1375
Epoch 136 Batch  190/269 - Train Accuracy: 0.8674, Validation Accuracy: 0.8578, Loss: 0.1364
Epoch 136 Batch  200/269 - Train Accuracy: 0.8518, Validation Accuracy: 0.8651, Loss: 0.1485
Epoch 136 Batch  210/269 - Train Accuracy: 0.8650, Validation Accuracy: 0.8605, Loss: 0.1401
Epoch 136 Batch  220/269 - Train Accuracy: 0.8579, Validation Accuracy: 0.8654, Loss: 0.1428
Epoch 136 Batch  230/269 - Train Accuracy: 0.8535, Validation Accuracy: 0.8632, Loss: 0.1442
Epoch 136 Batch  240/269 - Train Accuracy: 0.8713, Validation Accuracy: 0.8594, Loss: 0.1262
Epoch 136 Batch  250/269 - Train Accuracy: 0.8654, Validation Accuracy: 0.8666, Loss: 0.1489
Epoch 136 Batch  260/269 - Train Accuracy: 0.8464, Validation Accuracy: 0.8647, Loss: 0.1500
Epoch 137 Batch   10/269 - Train Accuracy: 0.8607, Validation Accuracy: 0.8596, Loss: 0.1367
Epoch 137 Batch   20/269 - Train Accuracy: 0.8603, Validation Accuracy: 0.8587, Loss: 0.1440
Epoch 137 Batch   30/269 - Train Accuracy: 0.8559, Validation Accuracy: 0.8630, Loss: 0.1347
Epoch 137 Batch   40/269 - Train Accuracy: 0.8484, Validation Accuracy: 0.8604, Loss: 0.1522
Epoch 137 Batch   50/269 - Train Accuracy: 0.8319, Validation Accuracy: 0.8652, Loss: 0.1502
Epoch 137 Batch   60/269 - Train Accuracy: 0.8623, Validation Accuracy: 0.8667, Loss: 0.1356
Epoch 137 Batch   70/269 - Train Accuracy: 0.8685, Validation Accuracy: 0.8580, Loss: 0.1441
Epoch 137 Batch   80/269 - Train Accuracy: 0.8547, Validation Accuracy: 0.8596, Loss: 0.1477
Epoch 137 Batch   90/269 - Train Accuracy: 0.8530, Validation Accuracy: 0.8582, Loss: 0.1524
Epoch 137 Batch  100/269 - Train Accuracy: 0.8695, Validation Accuracy: 0.8583, Loss: 0.1409
Epoch 137 Batch  110/269 - Train Accuracy: 0.8428, Validation Accuracy: 0.8609, Loss: 0.1469
Epoch 137 Batch  120/269 - Train Accuracy: 0.8604, Validation Accuracy: 0.8562, Loss: 0.1562
Epoch 137 Batch  130/269 - Train Accuracy: 0.8439, Validation Accuracy: 0.8635, Loss: 0.1582
Epoch 137 Batch  140/269 - Train Accuracy: 0.8513, Validation Accuracy: 0.8598, Loss: 0.1568
Epoch 137 Batch  150/269 - Train Accuracy: 0.8589, Validation Accuracy: 0.8607, Loss: 0.1420
Epoch 137 Batch  160/269 - Train Accuracy: 0.8552, Validation Accuracy: 0.8582, Loss: 0.1499
Epoch 137 Batch  170/269 - Train Accuracy: 0.8521, Validation Accuracy: 0.8616, Loss: 0.1421
Epoch 137 Batch  180/269 - Train Accuracy: 0.8770, Validation Accuracy: 0.8579, Loss: 0.1430
Epoch 137 Batch  190/269 - Train Accuracy: 0.8687, Validation Accuracy: 0.8584, Loss: 0.1427
Epoch 137 Batch  200/269 - Train Accuracy: 0.8548, Validation Accuracy: 0.8567, Loss: 0.1577
Epoch 137 Batch  210/269 - Train Accuracy: 0.8637, Validation Accuracy: 0.8572, Loss: 0.1475
Epoch 137 Batch  220/269 - Train Accuracy: 0.8585, Validation Accuracy: 0.8646, Loss: 0.1378
Epoch 137 Batch  230/269 - Train Accuracy: 0.8556, Validation Accuracy: 0.8607, Loss: 0.1432
Epoch 137 Batch  240/269 - Train Accuracy: 0.8688, Validation Accuracy: 0.8616, Loss: 0.1274
Epoch 137 Batch  250/269 - Train Accuracy: 0.8693, Validation Accuracy: 0.8651, Loss: 0.1395
Epoch 137 Batch  260/269 - Train Accuracy: 0.8412, Validation Accuracy: 0.8632, Loss: 0.1519
Epoch 138 Batch   10/269 - Train Accuracy: 0.8670, Validation Accuracy: 0.8615, Loss: 0.1374
Epoch 138 Batch   20/269 - Train Accuracy: 0.8494, Validation Accuracy: 0.8564, Loss: 0.1386
Epoch 138 Batch   30/269 - Train Accuracy: 0.8589, Validation Accuracy: 0.8645, Loss: 0.1315
Epoch 138 Batch   40/269 - Train Accuracy: 0.8473, Validation Accuracy: 0.8609, Loss: 0.1575
Epoch 138 Batch   50/269 - Train Accuracy: 0.8340, Validation Accuracy: 0.8714, Loss: 0.1552
Epoch 138 Batch   60/269 - Train Accuracy: 0.8556, Validation Accuracy: 0.8618, Loss: 0.1270
Epoch 138 Batch   70/269 - Train Accuracy: 0.8659, Validation Accuracy: 0.8667, Loss: 0.1419
Epoch 138 Batch   80/269 - Train Accuracy: 0.8569, Validation Accuracy: 0.8604, Loss: 0.1392
Epoch 138 Batch   90/269 - Train Accuracy: 0.8543, Validation Accuracy: 0.8604, Loss: 0.1593
Epoch 138 Batch  100/269 - Train Accuracy: 0.8752, Validation Accuracy: 0.8570, Loss: 0.1411
Epoch 138 Batch  110/269 - Train Accuracy: 0.8486, Validation Accuracy: 0.8647, Loss: 0.1500
Epoch 138 Batch  120/269 - Train Accuracy: 0.8612, Validation Accuracy: 0.8625, Loss: 0.1467
Epoch 138 Batch  130/269 - Train Accuracy: 0.8392, Validation Accuracy: 0.8634, Loss: 0.1458
Epoch 138 Batch  140/269 - Train Accuracy: 0.8540, Validation Accuracy: 0.8580, Loss: 0.1474
Epoch 138 Batch  150/269 - Train Accuracy: 0.8595, Validation Accuracy: 0.8627, Loss: 0.1371
Epoch 138 Batch  160/269 - Train Accuracy: 0.8568, Validation Accuracy: 0.8651, Loss: 0.1443
Epoch 138 Batch  170/269 - Train Accuracy: 0.8477, Validation Accuracy: 0.8642, Loss: 0.1402
Epoch 138 Batch  180/269 - Train Accuracy: 0.8754, Validation Accuracy: 0.8619, Loss: 0.1382
Epoch 138 Batch  190/269 - Train Accuracy: 0.8700, Validation Accuracy: 0.8580, Loss: 0.1341
Epoch 138 Batch  200/269 - Train Accuracy: 0.8572, Validation Accuracy: 0.8608, Loss: 0.1403
Epoch 138 Batch  210/269 - Train Accuracy: 0.8688, Validation Accuracy: 0.8613, Loss: 0.1442
Epoch 138 Batch  220/269 - Train Accuracy: 0.8600, Validation Accuracy: 0.8624, Loss: 0.1341
Epoch 138 Batch  230/269 - Train Accuracy: 0.8549, Validation Accuracy: 0.8651, Loss: 0.1350
Epoch 138 Batch  240/269 - Train Accuracy: 0.8746, Validation Accuracy: 0.8662, Loss: 0.1259
Epoch 138 Batch  250/269 - Train Accuracy: 0.8700, Validation Accuracy: 0.8683, Loss: 0.1386
Epoch 138 Batch  260/269 - Train Accuracy: 0.8392, Validation Accuracy: 0.8646, Loss: 0.1507
Epoch 139 Batch   10/269 - Train Accuracy: 0.8610, Validation Accuracy: 0.8562, Loss: 0.1442
Epoch 139 Batch   20/269 - Train Accuracy: 0.8571, Validation Accuracy: 0.8629, Loss: 0.1370
Epoch 139 Batch   30/269 - Train Accuracy: 0.8527, Validation Accuracy: 0.8646, Loss: 0.1410
Epoch 139 Batch   40/269 - Train Accuracy: 0.8495, Validation Accuracy: 0.8687, Loss: 0.1622
Epoch 139 Batch   50/269 - Train Accuracy: 0.8318, Validation Accuracy: 0.8658, Loss: 0.1536
Epoch 139 Batch   60/269 - Train Accuracy: 0.8641, Validation Accuracy: 0.8657, Loss: 0.1333
Epoch 139 Batch   70/269 - Train Accuracy: 0.8647, Validation Accuracy: 0.8663, Loss: 0.1529
Epoch 139 Batch   80/269 - Train Accuracy: 0.8607, Validation Accuracy: 0.8590, Loss: 0.1396
Epoch 139 Batch   90/269 - Train Accuracy: 0.8568, Validation Accuracy: 0.8627, Loss: 0.1399
Epoch 139 Batch  100/269 - Train Accuracy: 0.8742, Validation Accuracy: 0.8568, Loss: 0.1386
Epoch 139 Batch  110/269 - Train Accuracy: 0.8506, Validation Accuracy: 0.8624, Loss: 0.1479
Epoch 139 Batch  120/269 - Train Accuracy: 0.8667, Validation Accuracy: 0.8676, Loss: 0.1538
Epoch 139 Batch  130/269 - Train Accuracy: 0.8477, Validation Accuracy: 0.8645, Loss: 0.1546
Epoch 139 Batch  140/269 - Train Accuracy: 0.8517, Validation Accuracy: 0.8606, Loss: 0.1546
Epoch 139 Batch  150/269 - Train Accuracy: 0.8536, Validation Accuracy: 0.8651, Loss: 0.1400
Epoch 139 Batch  160/269 - Train Accuracy: 0.8596, Validation Accuracy: 0.8650, Loss: 0.1452
Epoch 139 Batch  170/269 - Train Accuracy: 0.8424, Validation Accuracy: 0.8662, Loss: 0.1444
Epoch 139 Batch  180/269 - Train Accuracy: 0.8824, Validation Accuracy: 0.8625, Loss: 0.1297
Epoch 139 Batch  190/269 - Train Accuracy: 0.8700, Validation Accuracy: 0.8633, Loss: 0.1383
Epoch 139 Batch  200/269 - Train Accuracy: 0.8590, Validation Accuracy: 0.8638, Loss: 0.1415
Epoch 139 Batch  210/269 - Train Accuracy: 0.8705, Validation Accuracy: 0.8646, Loss: 0.1523
Epoch 139 Batch  220/269 - Train Accuracy: 0.8547, Validation Accuracy: 0.8647, Loss: 0.1408
Epoch 139 Batch  230/269 - Train Accuracy: 0.8529, Validation Accuracy: 0.8618, Loss: 0.1425
Epoch 139 Batch  240/269 - Train Accuracy: 0.8694, Validation Accuracy: 0.8628, Loss: 0.1298
Epoch 139 Batch  250/269 - Train Accuracy: 0.8689, Validation Accuracy: 0.8646, Loss: 0.1406
Epoch 139 Batch  260/269 - Train Accuracy: 0.8406, Validation Accuracy: 0.8687, Loss: 0.1522
Epoch 140 Batch   10/269 - Train Accuracy: 0.8557, Validation Accuracy: 0.8602, Loss: 0.1375
Epoch 140 Batch   20/269 - Train Accuracy: 0.8526, Validation Accuracy: 0.8627, Loss: 0.1351
Epoch 140 Batch   30/269 - Train Accuracy: 0.8575, Validation Accuracy: 0.8666, Loss: 0.1373
Epoch 140 Batch   40/269 - Train Accuracy: 0.8504, Validation Accuracy: 0.8650, Loss: 0.1485
Epoch 140 Batch   50/269 - Train Accuracy: 0.8387, Validation Accuracy: 0.8654, Loss: 0.1553
Epoch 140 Batch   60/269 - Train Accuracy: 0.8540, Validation Accuracy: 0.8633, Loss: 0.1314
Epoch 140 Batch   70/269 - Train Accuracy: 0.8690, Validation Accuracy: 0.8613, Loss: 0.1505
Epoch 140 Batch   80/269 - Train Accuracy: 0.8584, Validation Accuracy: 0.8618, Loss: 0.1421
Epoch 140 Batch   90/269 - Train Accuracy: 0.8564, Validation Accuracy: 0.8628, Loss: 0.1555
Epoch 140 Batch  100/269 - Train Accuracy: 0.8717, Validation Accuracy: 0.8609, Loss: 0.1346
Epoch 140 Batch  110/269 - Train Accuracy: 0.8447, Validation Accuracy: 0.8644, Loss: 0.1457
Epoch 140 Batch  120/269 - Train Accuracy: 0.8661, Validation Accuracy: 0.8613, Loss: 0.1523
Epoch 140 Batch  130/269 - Train Accuracy: 0.8442, Validation Accuracy: 0.8616, Loss: 0.1475
Epoch 140 Batch  140/269 - Train Accuracy: 0.8605, Validation Accuracy: 0.8629, Loss: 0.1573
Epoch 140 Batch  150/269 - Train Accuracy: 0.8583, Validation Accuracy: 0.8582, Loss: 0.1424
Epoch 140 Batch  160/269 - Train Accuracy: 0.8607, Validation Accuracy: 0.8619, Loss: 0.1379
Epoch 140 Batch  170/269 - Train Accuracy: 0.8485, Validation Accuracy: 0.8599, Loss: 0.1352
Epoch 140 Batch  180/269 - Train Accuracy: 0.8727, Validation Accuracy: 0.8565, Loss: 0.1296
Epoch 140 Batch  190/269 - Train Accuracy: 0.8680, Validation Accuracy: 0.8653, Loss: 0.1366
Epoch 140 Batch  200/269 - Train Accuracy: 0.8543, Validation Accuracy: 0.8629, Loss: 0.1374
Epoch 140 Batch  210/269 - Train Accuracy: 0.8647, Validation Accuracy: 0.8636, Loss: 0.1358
Epoch 140 Batch  220/269 - Train Accuracy: 0.8544, Validation Accuracy: 0.8600, Loss: 0.1335
Epoch 140 Batch  230/269 - Train Accuracy: 0.8563, Validation Accuracy: 0.8640, Loss: 0.1477
Epoch 140 Batch  240/269 - Train Accuracy: 0.8719, Validation Accuracy: 0.8597, Loss: 0.1308
Epoch 140 Batch  250/269 - Train Accuracy: 0.8701, Validation Accuracy: 0.8658, Loss: 0.1345
Epoch 140 Batch  260/269 - Train Accuracy: 0.8425, Validation Accuracy: 0.8607, Loss: 0.1514
Epoch 141 Batch   10/269 - Train Accuracy: 0.8534, Validation Accuracy: 0.8538, Loss: 0.1372
Epoch 141 Batch   20/269 - Train Accuracy: 0.8521, Validation Accuracy: 0.8583, Loss: 0.1425
Epoch 141 Batch   30/269 - Train Accuracy: 0.8548, Validation Accuracy: 0.8611, Loss: 0.1358
Epoch 141 Batch   40/269 - Train Accuracy: 0.8514, Validation Accuracy: 0.8619, Loss: 0.1592
Epoch 141 Batch   50/269 - Train Accuracy: 0.8378, Validation Accuracy: 0.8651, Loss: 0.1531
Epoch 141 Batch   60/269 - Train Accuracy: 0.8608, Validation Accuracy: 0.8683, Loss: 0.1253
Epoch 141 Batch   70/269 - Train Accuracy: 0.8620, Validation Accuracy: 0.8572, Loss: 0.1426
Epoch 141 Batch   80/269 - Train Accuracy: 0.8592, Validation Accuracy: 0.8654, Loss: 0.1376
Epoch 141 Batch   90/269 - Train Accuracy: 0.8486, Validation Accuracy: 0.8602, Loss: 0.1521
Epoch 141 Batch  100/269 - Train Accuracy: 0.8724, Validation Accuracy: 0.8544, Loss: 0.1369
Epoch 141 Batch  110/269 - Train Accuracy: 0.8482, Validation Accuracy: 0.8603, Loss: 0.1425
Epoch 141 Batch  120/269 - Train Accuracy: 0.8588, Validation Accuracy: 0.8585, Loss: 0.1510
Epoch 141 Batch  130/269 - Train Accuracy: 0.8441, Validation Accuracy: 0.8617, Loss: 0.1414
Epoch 141 Batch  140/269 - Train Accuracy: 0.8570, Validation Accuracy: 0.8589, Loss: 0.1567
Epoch 141 Batch  150/269 - Train Accuracy: 0.8548, Validation Accuracy: 0.8568, Loss: 0.1427
Epoch 141 Batch  160/269 - Train Accuracy: 0.8535, Validation Accuracy: 0.8604, Loss: 0.1407
Epoch 141 Batch  170/269 - Train Accuracy: 0.8522, Validation Accuracy: 0.8639, Loss: 0.1367
Epoch 141 Batch  180/269 - Train Accuracy: 0.8792, Validation Accuracy: 0.8605, Loss: 0.1278
Epoch 141 Batch  190/269 - Train Accuracy: 0.8708, Validation Accuracy: 0.8661, Loss: 0.1375
Epoch 141 Batch  200/269 - Train Accuracy: 0.8540, Validation Accuracy: 0.8602, Loss: 0.1422
Epoch 141 Batch  210/269 - Train Accuracy: 0.8738, Validation Accuracy: 0.8650, Loss: 0.1388
Epoch 141 Batch  220/269 - Train Accuracy: 0.8606, Validation Accuracy: 0.8621, Loss: 0.1386
Epoch 141 Batch  230/269 - Train Accuracy: 0.8556, Validation Accuracy: 0.8609, Loss: 0.1484
Epoch 141 Batch  240/269 - Train Accuracy: 0.8721, Validation Accuracy: 0.8571, Loss: 0.1276
Epoch 141 Batch  250/269 - Train Accuracy: 0.8673, Validation Accuracy: 0.8588, Loss: 0.1352
Epoch 141 Batch  260/269 - Train Accuracy: 0.8405, Validation Accuracy: 0.8683, Loss: 0.1514
Epoch 142 Batch   10/269 - Train Accuracy: 0.8653, Validation Accuracy: 0.8714, Loss: 0.1374
Epoch 142 Batch   20/269 - Train Accuracy: 0.8537, Validation Accuracy: 0.8618, Loss: 0.1425
Epoch 142 Batch   30/269 - Train Accuracy: 0.8582, Validation Accuracy: 0.8609, Loss: 0.1356
Epoch 142 Batch   40/269 - Train Accuracy: 0.8521, Validation Accuracy: 0.8681, Loss: 0.1528
Epoch 142 Batch   50/269 - Train Accuracy: 0.8345, Validation Accuracy: 0.8641, Loss: 0.1583
Epoch 142 Batch   60/269 - Train Accuracy: 0.8627, Validation Accuracy: 0.8682, Loss: 0.1206
Epoch 142 Batch   70/269 - Train Accuracy: 0.8669, Validation Accuracy: 0.8615, Loss: 0.1455
Epoch 142 Batch   80/269 - Train Accuracy: 0.8539, Validation Accuracy: 0.8633, Loss: 0.1371
Epoch 142 Batch   90/269 - Train Accuracy: 0.8469, Validation Accuracy: 0.8565, Loss: 0.1562
Epoch 142 Batch  100/269 - Train Accuracy: 0.8690, Validation Accuracy: 0.8591, Loss: 0.1349
Epoch 142 Batch  110/269 - Train Accuracy: 0.8526, Validation Accuracy: 0.8619, Loss: 0.1391
Epoch 142 Batch  120/269 - Train Accuracy: 0.8651, Validation Accuracy: 0.8633, Loss: 0.1539
Epoch 142 Batch  130/269 - Train Accuracy: 0.8425, Validation Accuracy: 0.8636, Loss: 0.1527
Epoch 142 Batch  140/269 - Train Accuracy: 0.8540, Validation Accuracy: 0.8613, Loss: 0.1518
Epoch 142 Batch  150/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8626, Loss: 0.1408
Epoch 142 Batch  160/269 - Train Accuracy: 0.8591, Validation Accuracy: 0.8707, Loss: 0.1353
Epoch 142 Batch  170/269 - Train Accuracy: 0.8493, Validation Accuracy: 0.8607, Loss: 0.1353
Epoch 142 Batch  180/269 - Train Accuracy: 0.8806, Validation Accuracy: 0.8623, Loss: 0.1318
Epoch 142 Batch  190/269 - Train Accuracy: 0.8667, Validation Accuracy: 0.8656, Loss: 0.1340
Epoch 142 Batch  200/269 - Train Accuracy: 0.8539, Validation Accuracy: 0.8589, Loss: 0.1364
Epoch 142 Batch  210/269 - Train Accuracy: 0.8662, Validation Accuracy: 0.8571, Loss: 0.1394
Epoch 142 Batch  220/269 - Train Accuracy: 0.8556, Validation Accuracy: 0.8600, Loss: 0.1373
Epoch 142 Batch  230/269 - Train Accuracy: 0.8549, Validation Accuracy: 0.8597, Loss: 0.1354
Epoch 142 Batch  240/269 - Train Accuracy: 0.8728, Validation Accuracy: 0.8639, Loss: 0.1347
Epoch 142 Batch  250/269 - Train Accuracy: 0.8699, Validation Accuracy: 0.8674, Loss: 0.1389
Epoch 142 Batch  260/269 - Train Accuracy: 0.8480, Validation Accuracy: 0.8656, Loss: 0.1470
Epoch 143 Batch   10/269 - Train Accuracy: 0.8656, Validation Accuracy: 0.8654, Loss: 0.1325
Epoch 143 Batch   20/269 - Train Accuracy: 0.8576, Validation Accuracy: 0.8634, Loss: 0.1380
Epoch 143 Batch   30/269 - Train Accuracy: 0.8623, Validation Accuracy: 0.8666, Loss: 0.1377
Epoch 143 Batch   40/269 - Train Accuracy: 0.8501, Validation Accuracy: 0.8649, Loss: 0.1517
Epoch 143 Batch   50/269 - Train Accuracy: 0.8332, Validation Accuracy: 0.8672, Loss: 0.1454
Epoch 143 Batch   60/269 - Train Accuracy: 0.8631, Validation Accuracy: 0.8651, Loss: 0.1249
Epoch 143 Batch   70/269 - Train Accuracy: 0.8651, Validation Accuracy: 0.8666, Loss: 0.1436
Epoch 143 Batch   80/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8643, Loss: 0.1398
Epoch 143 Batch   90/269 - Train Accuracy: 0.8537, Validation Accuracy: 0.8566, Loss: 0.1588
Epoch 143 Batch  100/269 - Train Accuracy: 0.8690, Validation Accuracy: 0.8613, Loss: 0.1297
Epoch 143 Batch  110/269 - Train Accuracy: 0.8516, Validation Accuracy: 0.8642, Loss: 0.1393
Epoch 143 Batch  120/269 - Train Accuracy: 0.8651, Validation Accuracy: 0.8631, Loss: 0.1595
Epoch 143 Batch  130/269 - Train Accuracy: 0.8331, Validation Accuracy: 0.8614, Loss: 0.1438
Epoch 143 Batch  140/269 - Train Accuracy: 0.8541, Validation Accuracy: 0.8615, Loss: 0.1470
Epoch 143 Batch  150/269 - Train Accuracy: 0.8587, Validation Accuracy: 0.8643, Loss: 0.1410
Epoch 143 Batch  160/269 - Train Accuracy: 0.8580, Validation Accuracy: 0.8658, Loss: 0.1352
Epoch 143 Batch  170/269 - Train Accuracy: 0.8518, Validation Accuracy: 0.8612, Loss: 0.1265
Epoch 143 Batch  180/269 - Train Accuracy: 0.8811, Validation Accuracy: 0.8635, Loss: 0.1339
Epoch 143 Batch  190/269 - Train Accuracy: 0.8687, Validation Accuracy: 0.8617, Loss: 0.1392
Epoch 143 Batch  200/269 - Train Accuracy: 0.8550, Validation Accuracy: 0.8657, Loss: 0.1430
Epoch 143 Batch  210/269 - Train Accuracy: 0.8695, Validation Accuracy: 0.8608, Loss: 0.1454
Epoch 143 Batch  220/269 - Train Accuracy: 0.8545, Validation Accuracy: 0.8595, Loss: 0.1351
Epoch 143 Batch  230/269 - Train Accuracy: 0.8561, Validation Accuracy: 0.8619, Loss: 0.1407
Epoch 143 Batch  240/269 - Train Accuracy: 0.8777, Validation Accuracy: 0.8608, Loss: 0.1256
Epoch 143 Batch  250/269 - Train Accuracy: 0.8729, Validation Accuracy: 0.8678, Loss: 0.1398
Epoch 143 Batch  260/269 - Train Accuracy: 0.8412, Validation Accuracy: 0.8643, Loss: 0.1531
Epoch 144 Batch   10/269 - Train Accuracy: 0.8651, Validation Accuracy: 0.8592, Loss: 0.1360
Epoch 144 Batch   20/269 - Train Accuracy: 0.8485, Validation Accuracy: 0.8567, Loss: 0.1372
Epoch 144 Batch   30/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8661, Loss: 0.1348
Epoch 144 Batch   40/269 - Train Accuracy: 0.8513, Validation Accuracy: 0.8669, Loss: 0.1596
Epoch 144 Batch   50/269 - Train Accuracy: 0.8400, Validation Accuracy: 0.8675, Loss: 0.1509
Epoch 144 Batch   60/269 - Train Accuracy: 0.8620, Validation Accuracy: 0.8675, Loss: 0.1252
Epoch 144 Batch   70/269 - Train Accuracy: 0.8623, Validation Accuracy: 0.8646, Loss: 0.1425
Epoch 144 Batch   80/269 - Train Accuracy: 0.8645, Validation Accuracy: 0.8648, Loss: 0.1370
Epoch 144 Batch   90/269 - Train Accuracy: 0.8567, Validation Accuracy: 0.8646, Loss: 0.1436
Epoch 144 Batch  100/269 - Train Accuracy: 0.8752, Validation Accuracy: 0.8612, Loss: 0.1327
Epoch 144 Batch  110/269 - Train Accuracy: 0.8493, Validation Accuracy: 0.8604, Loss: 0.1462
Epoch 144 Batch  120/269 - Train Accuracy: 0.8652, Validation Accuracy: 0.8689, Loss: 0.1496
Epoch 144 Batch  130/269 - Train Accuracy: 0.8393, Validation Accuracy: 0.8604, Loss: 0.1496
Epoch 144 Batch  140/269 - Train Accuracy: 0.8564, Validation Accuracy: 0.8606, Loss: 0.1478
Epoch 144 Batch  150/269 - Train Accuracy: 0.8637, Validation Accuracy: 0.8670, Loss: 0.1532
Epoch 144 Batch  160/269 - Train Accuracy: 0.8622, Validation Accuracy: 0.8639, Loss: 0.1328
Epoch 144 Batch  170/269 - Train Accuracy: 0.8521, Validation Accuracy: 0.8618, Loss: 0.1373
Epoch 144 Batch  180/269 - Train Accuracy: 0.8811, Validation Accuracy: 0.8618, Loss: 0.1303
Epoch 144 Batch  190/269 - Train Accuracy: 0.8677, Validation Accuracy: 0.8653, Loss: 0.1468
Epoch 144 Batch  200/269 - Train Accuracy: 0.8583, Validation Accuracy: 0.8622, Loss: 0.1425
Epoch 144 Batch  210/269 - Train Accuracy: 0.8654, Validation Accuracy: 0.8582, Loss: 0.1365
Epoch 144 Batch  220/269 - Train Accuracy: 0.8599, Validation Accuracy: 0.8608, Loss: 0.1337
Epoch 144 Batch  230/269 - Train Accuracy: 0.8590, Validation Accuracy: 0.8648, Loss: 0.1338
Epoch 144 Batch  240/269 - Train Accuracy: 0.8736, Validation Accuracy: 0.8612, Loss: 0.1275
Epoch 144 Batch  250/269 - Train Accuracy: 0.8679, Validation Accuracy: 0.8697, Loss: 0.1419
Epoch 144 Batch  260/269 - Train Accuracy: 0.8406, Validation Accuracy: 0.8647, Loss: 0.1389
Epoch 145 Batch   10/269 - Train Accuracy: 0.8631, Validation Accuracy: 0.8604, Loss: 0.1347
Epoch 145 Batch   20/269 - Train Accuracy: 0.8520, Validation Accuracy: 0.8601, Loss: 0.1335
Epoch 145 Batch   30/269 - Train Accuracy: 0.8597, Validation Accuracy: 0.8681, Loss: 0.1308
Epoch 145 Batch   40/269 - Train Accuracy: 0.8494, Validation Accuracy: 0.8655, Loss: 0.1559
Epoch 145 Batch   50/269 - Train Accuracy: 0.8370, Validation Accuracy: 0.8706, Loss: 0.1509
Epoch 145 Batch   60/269 - Train Accuracy: 0.8603, Validation Accuracy: 0.8641, Loss: 0.1236
Epoch 145 Batch   70/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8583, Loss: 0.1451
Epoch 145 Batch   80/269 - Train Accuracy: 0.8579, Validation Accuracy: 0.8540, Loss: 0.1392
Epoch 145 Batch   90/269 - Train Accuracy: 0.8599, Validation Accuracy: 0.8576, Loss: 0.1507
Epoch 145 Batch  100/269 - Train Accuracy: 0.8708, Validation Accuracy: 0.8613, Loss: 0.1454
Epoch 145 Batch  110/269 - Train Accuracy: 0.8493, Validation Accuracy: 0.8597, Loss: 0.1533
Epoch 145 Batch  120/269 - Train Accuracy: 0.8663, Validation Accuracy: 0.8631, Loss: 0.1519
Epoch 145 Batch  130/269 - Train Accuracy: 0.8520, Validation Accuracy: 0.8657, Loss: 0.1480
Epoch 145 Batch  140/269 - Train Accuracy: 0.8558, Validation Accuracy: 0.8619, Loss: 0.1417
Epoch 145 Batch  150/269 - Train Accuracy: 0.8566, Validation Accuracy: 0.8602, Loss: 0.1442
Epoch 145 Batch  160/269 - Train Accuracy: 0.8543, Validation Accuracy: 0.8621, Loss: 0.1414
Epoch 145 Batch  170/269 - Train Accuracy: 0.8517, Validation Accuracy: 0.8617, Loss: 0.1354
Epoch 145 Batch  180/269 - Train Accuracy: 0.8828, Validation Accuracy: 0.8657, Loss: 0.1270
Epoch 145 Batch  190/269 - Train Accuracy: 0.8688, Validation Accuracy: 0.8648, Loss: 0.1336
Epoch 145 Batch  200/269 - Train Accuracy: 0.8542, Validation Accuracy: 0.8602, Loss: 0.1399
Epoch 145 Batch  210/269 - Train Accuracy: 0.8647, Validation Accuracy: 0.8626, Loss: 0.1312
Epoch 145 Batch  220/269 - Train Accuracy: 0.8532, Validation Accuracy: 0.8601, Loss: 0.1352
Epoch 145 Batch  230/269 - Train Accuracy: 0.8579, Validation Accuracy: 0.8630, Loss: 0.1337
Epoch 145 Batch  240/269 - Train Accuracy: 0.8740, Validation Accuracy: 0.8659, Loss: 0.1160
Epoch 145 Batch  250/269 - Train Accuracy: 0.8677, Validation Accuracy: 0.8648, Loss: 0.1339
Epoch 145 Batch  260/269 - Train Accuracy: 0.8365, Validation Accuracy: 0.8594, Loss: 0.1455
Epoch 146 Batch   10/269 - Train Accuracy: 0.8662, Validation Accuracy: 0.8621, Loss: 0.1284
Epoch 146 Batch   20/269 - Train Accuracy: 0.8531, Validation Accuracy: 0.8554, Loss: 0.1370
Epoch 146 Batch   30/269 - Train Accuracy: 0.8586, Validation Accuracy: 0.8635, Loss: 0.1316
Epoch 146 Batch   40/269 - Train Accuracy: 0.8471, Validation Accuracy: 0.8607, Loss: 0.1492
Epoch 146 Batch   50/269 - Train Accuracy: 0.8429, Validation Accuracy: 0.8707, Loss: 0.1539
Epoch 146 Batch   60/269 - Train Accuracy: 0.8626, Validation Accuracy: 0.8682, Loss: 0.1238
Epoch 146 Batch   70/269 - Train Accuracy: 0.8690, Validation Accuracy: 0.8660, Loss: 0.1313
Epoch 146 Batch   80/269 - Train Accuracy: 0.8574, Validation Accuracy: 0.8597, Loss: 0.1381
Epoch 146 Batch   90/269 - Train Accuracy: 0.8601, Validation Accuracy: 0.8627, Loss: 0.1474
Epoch 146 Batch  100/269 - Train Accuracy: 0.8750, Validation Accuracy: 0.8635, Loss: 0.1377
Epoch 146 Batch  110/269 - Train Accuracy: 0.8520, Validation Accuracy: 0.8649, Loss: 0.1417
Epoch 146 Batch  120/269 - Train Accuracy: 0.8692, Validation Accuracy: 0.8643, Loss: 0.1478
Epoch 146 Batch  130/269 - Train Accuracy: 0.8396, Validation Accuracy: 0.8633, Loss: 0.1493
Epoch 146 Batch  140/269 - Train Accuracy: 0.8601, Validation Accuracy: 0.8630, Loss: 0.1506
Epoch 146 Batch  150/269 - Train Accuracy: 0.8581, Validation Accuracy: 0.8605, Loss: 0.1353
Epoch 146 Batch  160/269 - Train Accuracy: 0.8610, Validation Accuracy: 0.8662, Loss: 0.1432
Epoch 146 Batch  170/269 - Train Accuracy: 0.8561, Validation Accuracy: 0.8564, Loss: 0.1396
Epoch 146 Batch  180/269 - Train Accuracy: 0.8849, Validation Accuracy: 0.8611, Loss: 0.1362
Epoch 146 Batch  190/269 - Train Accuracy: 0.8676, Validation Accuracy: 0.8622, Loss: 0.1437
Epoch 146 Batch  200/269 - Train Accuracy: 0.8550, Validation Accuracy: 0.8645, Loss: 0.1411
Epoch 146 Batch  210/269 - Train Accuracy: 0.8631, Validation Accuracy: 0.8574, Loss: 0.1362
Epoch 146 Batch  220/269 - Train Accuracy: 0.8541, Validation Accuracy: 0.8603, Loss: 0.1406
Epoch 146 Batch  230/269 - Train Accuracy: 0.8619, Validation Accuracy: 0.8635, Loss: 0.1342
Epoch 146 Batch  240/269 - Train Accuracy: 0.8725, Validation Accuracy: 0.8622, Loss: 0.1313
Epoch 146 Batch  250/269 - Train Accuracy: 0.8691, Validation Accuracy: 0.8622, Loss: 0.1405
Epoch 146 Batch  260/269 - Train Accuracy: 0.8422, Validation Accuracy: 0.8679, Loss: 0.1500
Epoch 147 Batch   10/269 - Train Accuracy: 0.8587, Validation Accuracy: 0.8612, Loss: 0.1276
Epoch 147 Batch   20/269 - Train Accuracy: 0.8562, Validation Accuracy: 0.8612, Loss: 0.1369
Epoch 147 Batch   30/269 - Train Accuracy: 0.8595, Validation Accuracy: 0.8632, Loss: 0.1386
Epoch 147 Batch   40/269 - Train Accuracy: 0.8483, Validation Accuracy: 0.8604, Loss: 0.1532
Epoch 147 Batch   50/269 - Train Accuracy: 0.8396, Validation Accuracy: 0.8673, Loss: 0.1498
Epoch 147 Batch   60/269 - Train Accuracy: 0.8606, Validation Accuracy: 0.8604, Loss: 0.1265
Epoch 147 Batch   70/269 - Train Accuracy: 0.8687, Validation Accuracy: 0.8620, Loss: 0.1322
Epoch 147 Batch   80/269 - Train Accuracy: 0.8612, Validation Accuracy: 0.8631, Loss: 0.1409
Epoch 147 Batch   90/269 - Train Accuracy: 0.8584, Validation Accuracy: 0.8619, Loss: 0.1475
Epoch 147 Batch  100/269 - Train Accuracy: 0.8721, Validation Accuracy: 0.8614, Loss: 0.1306
Epoch 147 Batch  110/269 - Train Accuracy: 0.8489, Validation Accuracy: 0.8616, Loss: 0.1517
Epoch 147 Batch  120/269 - Train Accuracy: 0.8666, Validation Accuracy: 0.8598, Loss: 0.1503
Epoch 147 Batch  130/269 - Train Accuracy: 0.8436, Validation Accuracy: 0.8643, Loss: 0.1399
Epoch 147 Batch  140/269 - Train Accuracy: 0.8556, Validation Accuracy: 0.8573, Loss: 0.1426
Epoch 147 Batch  150/269 - Train Accuracy: 0.8610, Validation Accuracy: 0.8632, Loss: 0.1432
Epoch 147 Batch  160/269 - Train Accuracy: 0.8586, Validation Accuracy: 0.8690, Loss: 0.1393
Epoch 147 Batch  170/269 - Train Accuracy: 0.8516, Validation Accuracy: 0.8593, Loss: 0.1317
Epoch 147 Batch  180/269 - Train Accuracy: 0.8868, Validation Accuracy: 0.8599, Loss: 0.1336
Epoch 147 Batch  190/269 - Train Accuracy: 0.8716, Validation Accuracy: 0.8620, Loss: 0.1277
Epoch 147 Batch  200/269 - Train Accuracy: 0.8451, Validation Accuracy: 0.8514, Loss: 0.1432
Epoch 147 Batch  210/269 - Train Accuracy: 0.8698, Validation Accuracy: 0.8630, Loss: 0.1408
Epoch 147 Batch  220/269 - Train Accuracy: 0.8622, Validation Accuracy: 0.8677, Loss: 0.1346
Epoch 147 Batch  230/269 - Train Accuracy: 0.8522, Validation Accuracy: 0.8675, Loss: 0.1334
Epoch 147 Batch  240/269 - Train Accuracy: 0.8740, Validation Accuracy: 0.8616, Loss: 0.1290
Epoch 147 Batch  250/269 - Train Accuracy: 0.8699, Validation Accuracy: 0.8699, Loss: 0.1379
Epoch 147 Batch  260/269 - Train Accuracy: 0.8420, Validation Accuracy: 0.8647, Loss: 0.1471
Epoch 148 Batch   10/269 - Train Accuracy: 0.8602, Validation Accuracy: 0.8601, Loss: 0.1347
Epoch 148 Batch   20/269 - Train Accuracy: 0.8535, Validation Accuracy: 0.8647, Loss: 0.1307
Epoch 148 Batch   30/269 - Train Accuracy: 0.8606, Validation Accuracy: 0.8672, Loss: 0.1389
Epoch 148 Batch   40/269 - Train Accuracy: 0.8509, Validation Accuracy: 0.8635, Loss: 0.1497
Epoch 148 Batch   50/269 - Train Accuracy: 0.8409, Validation Accuracy: 0.8666, Loss: 0.1434
Epoch 148 Batch   60/269 - Train Accuracy: 0.8617, Validation Accuracy: 0.8611, Loss: 0.1301
Epoch 148 Batch   70/269 - Train Accuracy: 0.8676, Validation Accuracy: 0.8618, Loss: 0.1391
Epoch 148 Batch   80/269 - Train Accuracy: 0.8560, Validation Accuracy: 0.8630, Loss: 0.1366
Epoch 148 Batch   90/269 - Train Accuracy: 0.8596, Validation Accuracy: 0.8587, Loss: 0.1512
Epoch 148 Batch  100/269 - Train Accuracy: 0.8726, Validation Accuracy: 0.8619, Loss: 0.1401
Epoch 148 Batch  110/269 - Train Accuracy: 0.8511, Validation Accuracy: 0.8622, Loss: 0.1440
Epoch 148 Batch  120/269 - Train Accuracy: 0.8697, Validation Accuracy: 0.8600, Loss: 0.1489
Epoch 148 Batch  130/269 - Train Accuracy: 0.8438, Validation Accuracy: 0.8644, Loss: 0.1485
Epoch 148 Batch  140/269 - Train Accuracy: 0.8494, Validation Accuracy: 0.8635, Loss: 0.1422
Epoch 148 Batch  150/269 - Train Accuracy: 0.8612, Validation Accuracy: 0.8650, Loss: 0.1371
Epoch 148 Batch  160/269 - Train Accuracy: 0.8599, Validation Accuracy: 0.8646, Loss: 0.1302
Epoch 148 Batch  170/269 - Train Accuracy: 0.8540, Validation Accuracy: 0.8690, Loss: 0.1348
Epoch 148 Batch  180/269 - Train Accuracy: 0.8807, Validation Accuracy: 0.8593, Loss: 0.1260
Epoch 148 Batch  190/269 - Train Accuracy: 0.8709, Validation Accuracy: 0.8631, Loss: 0.1379
Epoch 148 Batch  200/269 - Train Accuracy: 0.8570, Validation Accuracy: 0.8636, Loss: 0.1386
Epoch 148 Batch  210/269 - Train Accuracy: 0.8785, Validation Accuracy: 0.8680, Loss: 0.1365
Epoch 148 Batch  220/269 - Train Accuracy: 0.8564, Validation Accuracy: 0.8602, Loss: 0.1358
Epoch 148 Batch  230/269 - Train Accuracy: 0.8572, Validation Accuracy: 0.8620, Loss: 0.1325
Epoch 148 Batch  240/269 - Train Accuracy: 0.8758, Validation Accuracy: 0.8594, Loss: 0.1180
Epoch 148 Batch  250/269 - Train Accuracy: 0.8714, Validation Accuracy: 0.8673, Loss: 0.1404
Epoch 148 Batch  260/269 - Train Accuracy: 0.8441, Validation Accuracy: 0.8692, Loss: 0.1474
Epoch 149 Batch   10/269 - Train Accuracy: 0.8632, Validation Accuracy: 0.8642, Loss: 0.1253
Epoch 149 Batch   20/269 - Train Accuracy: 0.8526, Validation Accuracy: 0.8619, Loss: 0.1315
Epoch 149 Batch   30/269 - Train Accuracy: 0.8575, Validation Accuracy: 0.8651, Loss: 0.1318
Epoch 149 Batch   40/269 - Train Accuracy: 0.8514, Validation Accuracy: 0.8633, Loss: 0.1512
Epoch 149 Batch   50/269 - Train Accuracy: 0.8393, Validation Accuracy: 0.8599, Loss: 0.1619
Epoch 149 Batch   60/269 - Train Accuracy: 0.8660, Validation Accuracy: 0.8643, Loss: 0.1226
Epoch 149 Batch   70/269 - Train Accuracy: 0.8707, Validation Accuracy: 0.8653, Loss: 0.1383
Epoch 149 Batch   80/269 - Train Accuracy: 0.8591, Validation Accuracy: 0.8643, Loss: 0.1313
Epoch 149 Batch   90/269 - Train Accuracy: 0.8556, Validation Accuracy: 0.8633, Loss: 0.1552
Epoch 149 Batch  100/269 - Train Accuracy: 0.8738, Validation Accuracy: 0.8635, Loss: 0.1288
Epoch 149 Batch  110/269 - Train Accuracy: 0.8505, Validation Accuracy: 0.8624, Loss: 0.1399
Epoch 149 Batch  120/269 - Train Accuracy: 0.8677, Validation Accuracy: 0.8643, Loss: 0.1490
Epoch 149 Batch  130/269 - Train Accuracy: 0.8444, Validation Accuracy: 0.8637, Loss: 0.1391
Epoch 149 Batch  140/269 - Train Accuracy: 0.8522, Validation Accuracy: 0.8613, Loss: 0.1514
Epoch 149 Batch  150/269 - Train Accuracy: 0.8636, Validation Accuracy: 0.8610, Loss: 0.1313
Epoch 149 Batch  160/269 - Train Accuracy: 0.8610, Validation Accuracy: 0.8648, Loss: 0.1436
Epoch 149 Batch  170/269 - Train Accuracy: 0.8531, Validation Accuracy: 0.8613, Loss: 0.1337
Epoch 149 Batch  180/269 - Train Accuracy: 0.8862, Validation Accuracy: 0.8652, Loss: 0.1267
Epoch 149 Batch  190/269 - Train Accuracy: 0.8755, Validation Accuracy: 0.8663, Loss: 0.1335
Epoch 149 Batch  200/269 - Train Accuracy: 0.8578, Validation Accuracy: 0.8593, Loss: 0.1614
Epoch 149 Batch  210/269 - Train Accuracy: 0.8767, Validation Accuracy: 0.8698, Loss: 0.1364
Epoch 149 Batch  220/269 - Train Accuracy: 0.8651, Validation Accuracy: 0.8650, Loss: 0.1342
Epoch 149 Batch  230/269 - Train Accuracy: 0.8563, Validation Accuracy: 0.8651, Loss: 0.1313
Epoch 149 Batch  240/269 - Train Accuracy: 0.8786, Validation Accuracy: 0.8605, Loss: 0.1250
Epoch 149 Batch  250/269 - Train Accuracy: 0.8726, Validation Accuracy: 0.8679, Loss: 0.1285
Epoch 149 Batch  260/269 - Train Accuracy: 0.8403, Validation Accuracy: 0.8582, Loss: 0.1533
Epoch 150 Batch   10/269 - Train Accuracy: 0.8662, Validation Accuracy: 0.8624, Loss: 0.1322
Epoch 150 Batch   20/269 - Train Accuracy: 0.8370, Validation Accuracy: 0.8485, Loss: 0.2892
Epoch 150 Batch   30/269 - Train Accuracy: 0.8453, Validation Accuracy: 0.8441, Loss: 0.1743
Epoch 150 Batch   40/269 - Train Accuracy: 0.8274, Validation Accuracy: 0.8572, Loss: 0.1802
Epoch 150 Batch   50/269 - Train Accuracy: 0.8363, Validation Accuracy: 0.8688, Loss: 0.1611
Epoch 150 Batch   60/269 - Train Accuracy: 0.8580, Validation Accuracy: 0.8614, Loss: 0.1349
Epoch 150 Batch   70/269 - Train Accuracy: 0.8660, Validation Accuracy: 0.8643, Loss: 0.1315
Epoch 150 Batch   80/269 - Train Accuracy: 0.8566, Validation Accuracy: 0.8663, Loss: 0.1372
Epoch 150 Batch   90/269 - Train Accuracy: 0.8568, Validation Accuracy: 0.8578, Loss: 0.1578
Epoch 150 Batch  100/269 - Train Accuracy: 0.8767, Validation Accuracy: 0.8650, Loss: 0.1412
Epoch 150 Batch  110/269 - Train Accuracy: 0.8542, Validation Accuracy: 0.8601, Loss: 0.1584
Epoch 150 Batch  120/269 - Train Accuracy: 0.8628, Validation Accuracy: 0.8659, Loss: 0.1429
Epoch 150 Batch  130/269 - Train Accuracy: 0.8437, Validation Accuracy: 0.8658, Loss: 0.1506
Epoch 150 Batch  140/269 - Train Accuracy: 0.8602, Validation Accuracy: 0.8655, Loss: 0.1476
Epoch 150 Batch  150/269 - Train Accuracy: 0.8540, Validation Accuracy: 0.8646, Loss: 0.1371
Epoch 150 Batch  160/269 - Train Accuracy: 0.8543, Validation Accuracy: 0.8589, Loss: 0.1334
Epoch 150 Batch  170/269 - Train Accuracy: 0.8537, Validation Accuracy: 0.8659, Loss: 0.1313
Epoch 150 Batch  180/269 - Train Accuracy: 0.8821, Validation Accuracy: 0.8616, Loss: 0.1292
Epoch 150 Batch  190/269 - Train Accuracy: 0.8705, Validation Accuracy: 0.8646, Loss: 0.1411
Epoch 150 Batch  200/269 - Train Accuracy: 0.8564, Validation Accuracy: 0.8608, Loss: 0.1364
Epoch 150 Batch  210/269 - Train Accuracy: 0.8677, Validation Accuracy: 0.8705, Loss: 0.1346
Epoch 150 Batch  220/269 - Train Accuracy: 0.8573, Validation Accuracy: 0.8674, Loss: 0.1289
Epoch 150 Batch  230/269 - Train Accuracy: 0.8520, Validation Accuracy: 0.8641, Loss: 0.1326
Epoch 150 Batch  240/269 - Train Accuracy: 0.8760, Validation Accuracy: 0.8642, Loss: 0.1231
Epoch 150 Batch  250/269 - Train Accuracy: 0.8717, Validation Accuracy: 0.8659, Loss: 0.1303
Epoch 150 Batch  260/269 - Train Accuracy: 0.8410, Validation Accuracy: 0.8718, Loss: 0.1404
Epoch 151 Batch   10/269 - Train Accuracy: 0.8650, Validation Accuracy: 0.8627, Loss: 0.1318
Epoch 151 Batch   20/269 - Train Accuracy: 0.8568, Validation Accuracy: 0.8683, Loss: 0.1294
Epoch 151 Batch   30/269 - Train Accuracy: 0.8652, Validation Accuracy: 0.8666, Loss: 0.1326
Epoch 151 Batch   40/269 - Train Accuracy: 0.8516, Validation Accuracy: 0.8636, Loss: 0.1497
Epoch 151 Batch   50/269 - Train Accuracy: 0.8406, Validation Accuracy: 0.8670, Loss: 0.1505
Epoch 151 Batch   60/269 - Train Accuracy: 0.8655, Validation Accuracy: 0.8712, Loss: 0.1220
Epoch 151 Batch   70/269 - Train Accuracy: 0.8664, Validation Accuracy: 0.8660, Loss: 0.1361
Epoch 151 Batch   80/269 - Train Accuracy: 0.8645, Validation Accuracy: 0.8655, Loss: 0.1300
Epoch 151 Batch   90/269 - Train Accuracy: 0.8623, Validation Accuracy: 0.8667, Loss: 0.1409
Epoch 151 Batch  100/269 - Train Accuracy: 0.8794, Validation Accuracy: 0.8627, Loss: 0.1261
Epoch 151 Batch  110/269 - Train Accuracy: 0.8544, Validation Accuracy: 0.8626, Loss: 0.1416
Epoch 151 Batch  120/269 - Train Accuracy: 0.8721, Validation Accuracy: 0.8656, Loss: 0.1470
Epoch 151 Batch  130/269 - Train Accuracy: 0.8464, Validation Accuracy: 0.8675, Loss: 0.1447
Epoch 151 Batch  140/269 - Train Accuracy: 0.8577, Validation Accuracy: 0.8626, Loss: 0.1443
Epoch 151 Batch  150/269 - Train Accuracy: 0.8620, Validation Accuracy: 0.8620, Loss: 0.1375
Epoch 151 Batch  160/269 - Train Accuracy: 0.8630, Validation Accuracy: 0.8607, Loss: 0.1373
Epoch 151 Batch  170/269 - Train Accuracy: 0.8550, Validation Accuracy: 0.8632, Loss: 0.1295
Epoch 151 Batch  180/269 - Train Accuracy: 0.8811, Validation Accuracy: 0.8638, Loss: 0.1296
Epoch 151 Batch  190/269 - Train Accuracy: 0.8709, Validation Accuracy: 0.8601, Loss: 0.1358
Epoch 151 Batch  200/269 - Train Accuracy: 0.8563, Validation Accuracy: 0.8571, Loss: 0.1257
Epoch 151 Batch  210/269 - Train Accuracy: 0.8685, Validation Accuracy: 0.8608, Loss: 0.1468
Epoch 151 Batch  220/269 - Train Accuracy: 0.8615, Validation Accuracy: 0.8663, Loss: 0.1330
Epoch 151 Batch  230/269 - Train Accuracy: 0.8601, Validation Accuracy: 0.8676, Loss: 0.1301
Epoch 151 Batch  240/269 - Train Accuracy: 0.8775, Validation Accuracy: 0.8673, Loss: 0.1178
Epoch 151 Batch  250/269 - Train Accuracy: 0.8745, Validation Accuracy: 0.8671, Loss: 0.1234
Epoch 151 Batch  260/269 - Train Accuracy: 0.8498, Validation Accuracy: 0.8662, Loss: 0.1528
Epoch 152 Batch   10/269 - Train Accuracy: 0.8643, Validation Accuracy: 0.8584, Loss: 0.1288
Epoch 152 Batch   20/269 - Train Accuracy: 0.8566, Validation Accuracy: 0.8656, Loss: 0.1360
Epoch 152 Batch   30/269 - Train Accuracy: 0.8634, Validation Accuracy: 0.8674, Loss: 0.1295
Epoch 152 Batch   40/269 - Train Accuracy: 0.8504, Validation Accuracy: 0.8642, Loss: 0.1466
Epoch 152 Batch   50/269 - Train Accuracy: 0.8420, Validation Accuracy: 0.8710, Loss: 0.1431
Epoch 152 Batch   60/269 - Train Accuracy: 0.8612, Validation Accuracy: 0.8691, Loss: 0.1255
Epoch 152 Batch   70/269 - Train Accuracy: 0.8664, Validation Accuracy: 0.8682, Loss: 0.1371
Epoch 152 Batch   80/269 - Train Accuracy: 0.8608, Validation Accuracy: 0.8622, Loss: 0.1382
Epoch 152 Batch   90/269 - Train Accuracy: 0.8671, Validation Accuracy: 0.8655, Loss: 0.1413
Epoch 152 Batch  100/269 - Train Accuracy: 0.8771, Validation Accuracy: 0.8599, Loss: 0.1274
Epoch 152 Batch  110/269 - Train Accuracy: 0.8525, Validation Accuracy: 0.8643, Loss: 0.1438
Epoch 152 Batch  120/269 - Train Accuracy: 0.8724, Validation Accuracy: 0.8642, Loss: 0.1412
Epoch 152 Batch  130/269 - Train Accuracy: 0.8480, Validation Accuracy: 0.8667, Loss: 0.1444
Epoch 152 Batch  140/269 - Train Accuracy: 0.8590, Validation Accuracy: 0.8592, Loss: 0.1468
Epoch 152 Batch  150/269 - Train Accuracy: 0.8556, Validation Accuracy: 0.8655, Loss: 0.1345
Epoch 152 Batch  160/269 - Train Accuracy: 0.8601, Validation Accuracy: 0.8667, Loss: 0.1272
Epoch 152 Batch  170/269 - Train Accuracy: 0.8480, Validation Accuracy: 0.8648, Loss: 0.1300
Epoch 152 Batch  180/269 - Train Accuracy: 0.8824, Validation Accuracy: 0.8639, Loss: 0.1248
Epoch 152 Batch  190/269 - Train Accuracy: 0.8730, Validation Accuracy: 0.8655, Loss: 0.1276
Epoch 152 Batch  200/269 - Train Accuracy: 0.8547, Validation Accuracy: 0.8662, Loss: 0.1333
Epoch 152 Batch  210/269 - Train Accuracy: 0.8774, Validation Accuracy: 0.8706, Loss: 0.1310
Epoch 152 Batch  220/269 - Train Accuracy: 0.8608, Validation Accuracy: 0.8644, Loss: 0.1367
Epoch 152 Batch  230/269 - Train Accuracy: 0.8551, Validation Accuracy: 0.8632, Loss: 0.1364
Epoch 152 Batch  240/269 - Train Accuracy: 0.8758, Validation Accuracy: 0.8619, Loss: 0.1176
Epoch 152 Batch  250/269 - Train Accuracy: 0.8695, Validation Accuracy: 0.8627, Loss: 0.1409
Epoch 152 Batch  260/269 - Train Accuracy: 0.8500, Validation Accuracy: 0.8691, Loss: 0.1468
Epoch 153 Batch   10/269 - Train Accuracy: 0.8643, Validation Accuracy: 0.8634, Loss: 0.1354
Epoch 153 Batch   20/269 - Train Accuracy: 0.8613, Validation Accuracy: 0.8657, Loss: 0.1416
Epoch 153 Batch   30/269 - Train Accuracy: 0.8605, Validation Accuracy: 0.8674, Loss: 0.1289
Epoch 153 Batch   40/269 - Train Accuracy: 0.8499, Validation Accuracy: 0.8648, Loss: 0.1502
Epoch 153 Batch   50/269 - Train Accuracy: 0.8390, Validation Accuracy: 0.8674, Loss: 0.1489
Epoch 153 Batch   60/269 - Train Accuracy: 0.8626, Validation Accuracy: 0.8645, Loss: 0.1242
Epoch 153 Batch   70/269 - Train Accuracy: 0.8726, Validation Accuracy: 0.8695, Loss: 0.1317
Epoch 153 Batch   80/269 - Train Accuracy: 0.8617, Validation Accuracy: 0.8620, Loss: 0.1330
Epoch 153 Batch   90/269 - Train Accuracy: 0.8574, Validation Accuracy: 0.8624, Loss: 0.1450
Epoch 153 Batch  100/269 - Train Accuracy: 0.8732, Validation Accuracy: 0.8572, Loss: 0.1333
Epoch 153 Batch  110/269 - Train Accuracy: 0.8514, Validation Accuracy: 0.8612, Loss: 0.1435
Epoch 153 Batch  120/269 - Train Accuracy: 0.8674, Validation Accuracy: 0.8642, Loss: 0.1475
Epoch 153 Batch  130/269 - Train Accuracy: 0.8523, Validation Accuracy: 0.8604, Loss: 0.1442
Epoch 153 Batch  140/269 - Train Accuracy: 0.8540, Validation Accuracy: 0.8581, Loss: 0.1414
Epoch 153 Batch  150/269 - Train Accuracy: 0.8589, Validation Accuracy: 0.8627, Loss: 0.1342
Epoch 153 Batch  160/269 - Train Accuracy: 0.8595, Validation Accuracy: 0.8586, Loss: 0.1351
Epoch 153 Batch  170/269 - Train Accuracy: 0.8618, Validation Accuracy: 0.8659, Loss: 0.1362
Epoch 153 Batch  180/269 - Train Accuracy: 0.8782, Validation Accuracy: 0.8626, Loss: 0.1277
Epoch 153 Batch  190/269 - Train Accuracy: 0.8690, Validation Accuracy: 0.8644, Loss: 0.1317
Epoch 153 Batch  200/269 - Train Accuracy: 0.8593, Validation Accuracy: 0.8649, Loss: 0.1386
Epoch 153 Batch  210/269 - Train Accuracy: 0.8760, Validation Accuracy: 0.8650, Loss: 0.1358
Epoch 153 Batch  220/269 - Train Accuracy: 0.8595, Validation Accuracy: 0.8604, Loss: 0.1346
Epoch 153 Batch  230/269 - Train Accuracy: 0.8554, Validation Accuracy: 0.8633, Loss: 0.1366
Epoch 153 Batch  240/269 - Train Accuracy: 0.8774, Validation Accuracy: 0.8619, Loss: 0.1221
Epoch 153 Batch  250/269 - Train Accuracy: 0.8708, Validation Accuracy: 0.8685, Loss: 0.1296
Epoch 153 Batch  260/269 - Train Accuracy: 0.8519, Validation Accuracy: 0.8708, Loss: 0.1347
Epoch 154 Batch   10/269 - Train Accuracy: 0.8642, Validation Accuracy: 0.8659, Loss: 0.1391
Epoch 154 Batch   20/269 - Train Accuracy: 0.8568, Validation Accuracy: 0.8641, Loss: 0.1354
Epoch 154 Batch   30/269 - Train Accuracy: 0.8644, Validation Accuracy: 0.8588, Loss: 0.1334
Epoch 154 Batch   40/269 - Train Accuracy: 0.8515, Validation Accuracy: 0.8665, Loss: 0.1560
Epoch 154 Batch   50/269 - Train Accuracy: 0.8388, Validation Accuracy: 0.8689, Loss: 0.1515
Epoch 154 Batch   60/269 - Train Accuracy: 0.8598, Validation Accuracy: 0.8643, Loss: 0.1259
Epoch 154 Batch   70/269 - Train Accuracy: 0.8735, Validation Accuracy: 0.8667, Loss: 0.1386
Epoch 154 Batch   80/269 - Train Accuracy: 0.8570, Validation Accuracy: 0.8629, Loss: 0.1307
Epoch 154 Batch   90/269 - Train Accuracy: 0.8594, Validation Accuracy: 0.8651, Loss: 0.1337
Epoch 154 Batch  100/269 - Train Accuracy: 0.8756, Validation Accuracy: 0.8619, Loss: 0.1287
Epoch 154 Batch  110/269 - Train Accuracy: 0.8508, Validation Accuracy: 0.8673, Loss: 0.1509
Epoch 154 Batch  120/269 - Train Accuracy: 0.8614, Validation Accuracy: 0.8620, Loss: 0.1477
Epoch 154 Batch  130/269 - Train Accuracy: 0.8415, Validation Accuracy: 0.8617, Loss: 0.1456
Epoch 154 Batch  140/269 - Train Accuracy: 0.8549, Validation Accuracy: 0.8612, Loss: 0.1405
Epoch 154 Batch  150/269 - Train Accuracy: 0.8629, Validation Accuracy: 0.8663, Loss: 0.1354
Epoch 154 Batch  160/269 - Train Accuracy: 0.8696, Validation Accuracy: 0.8645, Loss: 0.1388
Epoch 154 Batch  170/269 - Train Accuracy: 0.8555, Validation Accuracy: 0.8693, Loss: 0.1279
Epoch 154 Batch  180/269 - Train Accuracy: 0.8844, Validation Accuracy: 0.8636, Loss: 0.1237
Epoch 154 Batch  190/269 - Train Accuracy: 0.8747, Validation Accuracy: 0.8684, Loss: 0.1320
Epoch 154 Batch  200/269 - Train Accuracy: 0.8559, Validation Accuracy: 0.8596, Loss: 0.1358
Epoch 154 Batch  210/269 - Train Accuracy: 0.8707, Validation Accuracy: 0.8644, Loss: 0.1348
Epoch 154 Batch  220/269 - Train Accuracy: 0.8623, Validation Accuracy: 0.8592, Loss: 0.1283
Epoch 154 Batch  230/269 - Train Accuracy: 0.8511, Validation Accuracy: 0.8610, Loss: 0.1422
Epoch 154 Batch  240/269 - Train Accuracy: 0.8780, Validation Accuracy: 0.8613, Loss: 0.1202
Epoch 154 Batch  250/269 - Train Accuracy: 0.8694, Validation Accuracy: 0.8660, Loss: 0.1324
Epoch 154 Batch  260/269 - Train Accuracy: 0.8494, Validation Accuracy: 0.8668, Loss: 0.1453
Epoch 155 Batch   10/269 - Train Accuracy: 0.8693, Validation Accuracy: 0.8644, Loss: 0.1288
Epoch 155 Batch   20/269 - Train Accuracy: 0.8574, Validation Accuracy: 0.8619, Loss: 0.1333
Epoch 155 Batch   30/269 - Train Accuracy: 0.8655, Validation Accuracy: 0.8630, Loss: 0.1272
Epoch 155 Batch   40/269 - Train Accuracy: 0.8454, Validation Accuracy: 0.8610, Loss: 0.1541
Epoch 155 Batch   50/269 - Train Accuracy: 0.8389, Validation Accuracy: 0.8685, Loss: 0.1410
Epoch 155 Batch   60/269 - Train Accuracy: 0.8664, Validation Accuracy: 0.8658, Loss: 0.1258
Epoch 155 Batch   70/269 - Train Accuracy: 0.8726, Validation Accuracy: 0.8647, Loss: 0.1425
Epoch 155 Batch   80/269 - Train Accuracy: 0.8655, Validation Accuracy: 0.8635, Loss: 0.1362
Epoch 155 Batch   90/269 - Train Accuracy: 0.8646, Validation Accuracy: 0.8573, Loss: 0.1432
Epoch 155 Batch  100/269 - Train Accuracy: 0.8742, Validation Accuracy: 0.8617, Loss: 0.1331
Epoch 155 Batch  110/269 - Train Accuracy: 0.8612, Validation Accuracy: 0.8697, Loss: 0.1312
Epoch 155 Batch  120/269 - Train Accuracy: 0.8745, Validation Accuracy: 0.8615, Loss: 0.1455
Epoch 155 Batch  130/269 - Train Accuracy: 0.8445, Validation Accuracy: 0.8621, Loss: 0.1305
Epoch 155 Batch  140/269 - Train Accuracy: 0.8563, Validation Accuracy: 0.8602, Loss: 0.1324
Epoch 155 Batch  150/269 - Train Accuracy: 0.8608, Validation Accuracy: 0.8662, Loss: 0.1369
Epoch 155 Batch  160/269 - Train Accuracy: 0.8678, Validation Accuracy: 0.8648, Loss: 0.1394
Epoch 155 Batch  170/269 - Train Accuracy: 0.8573, Validation Accuracy: 0.8716, Loss: 0.1268
Epoch 155 Batch  180/269 - Train Accuracy: 0.8836, Validation Accuracy: 0.8637, Loss: 0.1265
Epoch 155 Batch  190/269 - Train Accuracy: 0.8703, Validation Accuracy: 0.8691, Loss: 0.1328
Epoch 155 Batch  200/269 - Train Accuracy: 0.8626, Validation Accuracy: 0.8651, Loss: 0.1311
Epoch 155 Batch  210/269 - Train Accuracy: 0.8714, Validation Accuracy: 0.8580, Loss: 0.1340
Epoch 155 Batch  220/269 - Train Accuracy: 0.8633, Validation Accuracy: 0.8612, Loss: 0.1258
Epoch 155 Batch  230/269 - Train Accuracy: 0.8563, Validation Accuracy: 0.8640, Loss: 0.1301
Epoch 155 Batch  240/269 - Train Accuracy: 0.8736, Validation Accuracy: 0.8670, Loss: 0.1199
Epoch 155 Batch  250/269 - Train Accuracy: 0.8691, Validation Accuracy: 0.8667, Loss: 0.1252
Epoch 155 Batch  260/269 - Train Accuracy: 0.8465, Validation Accuracy: 0.8709, Loss: 0.1463
Epoch 156 Batch   10/269 - Train Accuracy: 0.8686, Validation Accuracy: 0.8665, Loss: 0.1313
Epoch 156 Batch   20/269 - Train Accuracy: 0.8518, Validation Accuracy: 0.8598, Loss: 0.1374
Epoch 156 Batch   30/269 - Train Accuracy: 0.8568, Validation Accuracy: 0.8667, Loss: 0.1313
Epoch 156 Batch   40/269 - Train Accuracy: 0.8479, Validation Accuracy: 0.8681, Loss: 0.1542
Epoch 156 Batch   50/269 - Train Accuracy: 0.8410, Validation Accuracy: 0.8711, Loss: 0.1462
Epoch 156 Batch   60/269 - Train Accuracy: 0.8640, Validation Accuracy: 0.8652, Loss: 0.1284
Epoch 156 Batch   70/269 - Train Accuracy: 0.8719, Validation Accuracy: 0.8669, Loss: 0.1355
Epoch 156 Batch   80/269 - Train Accuracy: 0.8622, Validation Accuracy: 0.8605, Loss: 0.1265
Epoch 156 Batch   90/269 - Train Accuracy: 0.8664, Validation Accuracy: 0.8651, Loss: 0.1484
Epoch 156 Batch  100/269 - Train Accuracy: 0.8737, Validation Accuracy: 0.8614, Loss: 0.1379
Epoch 156 Batch  110/269 - Train Accuracy: 0.8512, Validation Accuracy: 0.8583, Loss: 0.1365
Epoch 156 Batch  120/269 - Train Accuracy: 0.8657, Validation Accuracy: 0.8652, Loss: 0.1486
Epoch 156 Batch  130/269 - Train Accuracy: 0.8430, Validation Accuracy: 0.8657, Loss: 0.1366
Epoch 156 Batch  140/269 - Train Accuracy: 0.8578, Validation Accuracy: 0.8683, Loss: 0.1412
Epoch 156 Batch  150/269 - Train Accuracy: 0.8642, Validation Accuracy: 0.8680, Loss: 0.1311
Epoch 156 Batch  160/269 - Train Accuracy: 0.8623, Validation Accuracy: 0.8637, Loss: 0.1301
Epoch 156 Batch  170/269 - Train Accuracy: 0.8536, Validation Accuracy: 0.8665, Loss: 0.1300
Epoch 156 Batch  180/269 - Train Accuracy: 0.8858, Validation Accuracy: 0.8660, Loss: 0.1281
Epoch 156 Batch  190/269 - Train Accuracy: 0.8703, Validation Accuracy: 0.8664, Loss: 0.1278
Epoch 156 Batch  200/269 - Train Accuracy: 0.8614, Validation Accuracy: 0.8600, Loss: 0.1346
Epoch 156 Batch  210/269 - Train Accuracy: 0.8757, Validation Accuracy: 0.8659, Loss: 0.1390
Epoch 156 Batch  220/269 - Train Accuracy: 0.8633, Validation Accuracy: 0.8629, Loss: 0.1300
Epoch 156 Batch  230/269 - Train Accuracy: 0.8570, Validation Accuracy: 0.8675, Loss: 0.1298
Epoch 156 Batch  240/269 - Train Accuracy: 0.8723, Validation Accuracy: 0.8643, Loss: 0.1165
Epoch 156 Batch  250/269 - Train Accuracy: 0.8706, Validation Accuracy: 0.8623, Loss: 0.1300
Epoch 156 Batch  260/269 - Train Accuracy: 0.8496, Validation Accuracy: 0.8684, Loss: 0.1420
Epoch 157 Batch   10/269 - Train Accuracy: 0.8610, Validation Accuracy: 0.8570, Loss: 0.1259
Epoch 157 Batch   20/269 - Train Accuracy: 0.8536, Validation Accuracy: 0.8569, Loss: 0.1265
Epoch 157 Batch   30/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8688, Loss: 0.1372
Epoch 157 Batch   40/269 - Train Accuracy: 0.8513, Validation Accuracy: 0.8663, Loss: 0.1401
Epoch 157 Batch   50/269 - Train Accuracy: 0.8400, Validation Accuracy: 0.8705, Loss: 0.1469
Epoch 157 Batch   60/269 - Train Accuracy: 0.8664, Validation Accuracy: 0.8670, Loss: 0.1259
Epoch 157 Batch   70/269 - Train Accuracy: 0.8749, Validation Accuracy: 0.8651, Loss: 0.1274
Epoch 157 Batch   80/269 - Train Accuracy: 0.8618, Validation Accuracy: 0.8661, Loss: 0.1411
Epoch 157 Batch   90/269 - Train Accuracy: 0.8639, Validation Accuracy: 0.8634, Loss: 0.1374
Epoch 157 Batch  100/269 - Train Accuracy: 0.8756, Validation Accuracy: 0.8605, Loss: 0.1317
Epoch 157 Batch  110/269 - Train Accuracy: 0.8581, Validation Accuracy: 0.8676, Loss: 0.1408
Epoch 157 Batch  120/269 - Train Accuracy: 0.8732, Validation Accuracy: 0.8657, Loss: 0.1468
Epoch 157 Batch  130/269 - Train Accuracy: 0.8484, Validation Accuracy: 0.8656, Loss: 0.1405
Epoch 157 Batch  140/269 - Train Accuracy: 0.8602, Validation Accuracy: 0.8668, Loss: 0.1470
Epoch 157 Batch  150/269 - Train Accuracy: 0.8641, Validation Accuracy: 0.8654, Loss: 0.1293
Epoch 157 Batch  160/269 - Train Accuracy: 0.8637, Validation Accuracy: 0.8653, Loss: 0.1367
Epoch 157 Batch  170/269 - Train Accuracy: 0.8544, Validation Accuracy: 0.8695, Loss: 0.1282
Epoch 157 Batch  180/269 - Train Accuracy: 0.8881, Validation Accuracy: 0.8633, Loss: 0.1275
Epoch 157 Batch  190/269 - Train Accuracy: 0.8720, Validation Accuracy: 0.8659, Loss: 0.1290
Epoch 157 Batch  200/269 - Train Accuracy: 0.8577, Validation Accuracy: 0.8595, Loss: 0.1403
Epoch 157 Batch  210/269 - Train Accuracy: 0.8689, Validation Accuracy: 0.8675, Loss: 0.1326
Epoch 157 Batch  220/269 - Train Accuracy: 0.8637, Validation Accuracy: 0.8642, Loss: 0.1268
Epoch 157 Batch  230/269 - Train Accuracy: 0.8595, Validation Accuracy: 0.8644, Loss: 0.1278
Epoch 157 Batch  240/269 - Train Accuracy: 0.8768, Validation Accuracy: 0.8670, Loss: 0.1181
Epoch 157 Batch  250/269 - Train Accuracy: 0.8732, Validation Accuracy: 0.8720, Loss: 0.1259
Epoch 157 Batch  260/269 - Train Accuracy: 0.8532, Validation Accuracy: 0.8654, Loss: 0.1455
Epoch 158 Batch   10/269 - Train Accuracy: 0.8635, Validation Accuracy: 0.8608, Loss: 0.1303
Epoch 158 Batch   20/269 - Train Accuracy: 0.8576, Validation Accuracy: 0.8620, Loss: 0.1282
Epoch 158 Batch   30/269 - Train Accuracy: 0.8649, Validation Accuracy: 0.8660, Loss: 0.1317
Epoch 158 Batch   40/269 - Train Accuracy: 0.8531, Validation Accuracy: 0.8718, Loss: 0.1508
Epoch 158 Batch   50/269 - Train Accuracy: 0.8359, Validation Accuracy: 0.8694, Loss: 0.1414
Epoch 158 Batch   60/269 - Train Accuracy: 0.8705, Validation Accuracy: 0.8694, Loss: 0.1164
Epoch 158 Batch   70/269 - Train Accuracy: 0.8738, Validation Accuracy: 0.8656, Loss: 0.1292
Epoch 158 Batch   80/269 - Train Accuracy: 0.8631, Validation Accuracy: 0.8651, Loss: 0.1337
Epoch 158 Batch   90/269 - Train Accuracy: 0.8651, Validation Accuracy: 0.8632, Loss: 0.1427
Epoch 158 Batch  100/269 - Train Accuracy: 0.8740, Validation Accuracy: 0.8636, Loss: 0.1266
Epoch 158 Batch  110/269 - Train Accuracy: 0.8516, Validation Accuracy: 0.8604, Loss: 0.1409
Epoch 158 Batch  120/269 - Train Accuracy: 0.8673, Validation Accuracy: 0.8666, Loss: 0.1410
Epoch 158 Batch  130/269 - Train Accuracy: 0.8536, Validation Accuracy: 0.8659, Loss: 0.1344
Epoch 158 Batch  140/269 - Train Accuracy: 0.8555, Validation Accuracy: 0.8628, Loss: 0.1345
Epoch 158 Batch  150/269 - Train Accuracy: 0.8610, Validation Accuracy: 0.8623, Loss: 0.1288
Epoch 158 Batch  160/269 - Train Accuracy: 0.8659, Validation Accuracy: 0.8659, Loss: 0.1311
Epoch 158 Batch  170/269 - Train Accuracy: 0.8546, Validation Accuracy: 0.8646, Loss: 0.1330
Epoch 158 Batch  180/269 - Train Accuracy: 0.8816, Validation Accuracy: 0.8643, Loss: 0.1256
Epoch 158 Batch  190/269 - Train Accuracy: 0.8719, Validation Accuracy: 0.8656, Loss: 0.1295
Epoch 158 Batch  200/269 - Train Accuracy: 0.8561, Validation Accuracy: 0.8632, Loss: 0.1331
Epoch 158 Batch  210/269 - Train Accuracy: 0.8713, Validation Accuracy: 0.8686, Loss: 0.1324
Epoch 158 Batch  220/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8659, Loss: 0.1341
Epoch 158 Batch  230/269 - Train Accuracy: 0.8626, Validation Accuracy: 0.8701, Loss: 0.1307
Epoch 158 Batch  240/269 - Train Accuracy: 0.8746, Validation Accuracy: 0.8670, Loss: 0.1218
Epoch 158 Batch  250/269 - Train Accuracy: 0.8732, Validation Accuracy: 0.8680, Loss: 0.1318
Epoch 158 Batch  260/269 - Train Accuracy: 0.8532, Validation Accuracy: 0.8687, Loss: 0.1416
Epoch 159 Batch   10/269 - Train Accuracy: 0.8707, Validation Accuracy: 0.8619, Loss: 0.1312
Epoch 159 Batch   20/269 - Train Accuracy: 0.8545, Validation Accuracy: 0.8642, Loss: 0.1403
Epoch 159 Batch   30/269 - Train Accuracy: 0.8626, Validation Accuracy: 0.8622, Loss: 0.1261
Epoch 159 Batch   40/269 - Train Accuracy: 0.8516, Validation Accuracy: 0.8658, Loss: 0.1481
Epoch 159 Batch   50/269 - Train Accuracy: 0.8404, Validation Accuracy: 0.8692, Loss: 0.1444
Epoch 159 Batch   60/269 - Train Accuracy: 0.8640, Validation Accuracy: 0.8651, Loss: 0.1185
Epoch 159 Batch   70/269 - Train Accuracy: 0.8729, Validation Accuracy: 0.8663, Loss: 0.1322
Epoch 159 Batch   80/269 - Train Accuracy: 0.8596, Validation Accuracy: 0.8616, Loss: 0.1403
Epoch 159 Batch   90/269 - Train Accuracy: 0.8701, Validation Accuracy: 0.8582, Loss: 0.1365
Epoch 159 Batch  100/269 - Train Accuracy: 0.8735, Validation Accuracy: 0.8628, Loss: 0.1211
Epoch 159 Batch  110/269 - Train Accuracy: 0.8544, Validation Accuracy: 0.8647, Loss: 0.1391
Epoch 159 Batch  120/269 - Train Accuracy: 0.8666, Validation Accuracy: 0.8666, Loss: 0.1423
Epoch 159 Batch  130/269 - Train Accuracy: 0.8463, Validation Accuracy: 0.8656, Loss: 0.1318
Epoch 159 Batch  140/269 - Train Accuracy: 0.8591, Validation Accuracy: 0.8630, Loss: 0.1385
Epoch 159 Batch  150/269 - Train Accuracy: 0.8588, Validation Accuracy: 0.8662, Loss: 0.1325
Epoch 159 Batch  160/269 - Train Accuracy: 0.8590, Validation Accuracy: 0.8665, Loss: 0.1350
Epoch 159 Batch  170/269 - Train Accuracy: 0.8491, Validation Accuracy: 0.8602, Loss: 0.1213
Epoch 159 Batch  180/269 - Train Accuracy: 0.8850, Validation Accuracy: 0.8638, Loss: 0.1230
Epoch 159 Batch  190/269 - Train Accuracy: 0.8752, Validation Accuracy: 0.8647, Loss: 0.1307
Epoch 159 Batch  200/269 - Train Accuracy: 0.8588, Validation Accuracy: 0.8698, Loss: 0.1303
Epoch 159 Batch  210/269 - Train Accuracy: 0.8720, Validation Accuracy: 0.8669, Loss: 0.1308
Epoch 159 Batch  220/269 - Train Accuracy: 0.8652, Validation Accuracy: 0.8678, Loss: 0.1270
Epoch 159 Batch  230/269 - Train Accuracy: 0.8555, Validation Accuracy: 0.8658, Loss: 0.1278
Epoch 159 Batch  240/269 - Train Accuracy: 0.8787, Validation Accuracy: 0.8702, Loss: 0.1176
Epoch 159 Batch  250/269 - Train Accuracy: 0.8723, Validation Accuracy: 0.8700, Loss: 0.1324
Epoch 159 Batch  260/269 - Train Accuracy: 0.8460, Validation Accuracy: 0.8692, Loss: 0.1436
Epoch 160 Batch   10/269 - Train Accuracy: 0.8692, Validation Accuracy: 0.8618, Loss: 0.1261
Epoch 160 Batch   20/269 - Train Accuracy: 0.8548, Validation Accuracy: 0.8641, Loss: 0.1301
Epoch 160 Batch   30/269 - Train Accuracy: 0.8595, Validation Accuracy: 0.8619, Loss: 0.1320
Epoch 160 Batch   40/269 - Train Accuracy: 0.8527, Validation Accuracy: 0.8688, Loss: 0.1519
Epoch 160 Batch   50/269 - Train Accuracy: 0.8449, Validation Accuracy: 0.8667, Loss: 0.1439
Epoch 160 Batch   60/269 - Train Accuracy: 0.8543, Validation Accuracy: 0.8599, Loss: 0.1225
Epoch 160 Batch   70/269 - Train Accuracy: 0.8717, Validation Accuracy: 0.8680, Loss: 0.1297
Epoch 160 Batch   80/269 - Train Accuracy: 0.8703, Validation Accuracy: 0.8663, Loss: 0.1334
Epoch 160 Batch   90/269 - Train Accuracy: 0.8650, Validation Accuracy: 0.8617, Loss: 0.1346
Epoch 160 Batch  100/269 - Train Accuracy: 0.8778, Validation Accuracy: 0.8592, Loss: 0.1351
Epoch 160 Batch  110/269 - Train Accuracy: 0.8541, Validation Accuracy: 0.8603, Loss: 0.1317
Epoch 160 Batch  120/269 - Train Accuracy: 0.8697, Validation Accuracy: 0.8623, Loss: 0.1390
Epoch 160 Batch  130/269 - Train Accuracy: 0.8545, Validation Accuracy: 0.8734, Loss: 0.1360
Epoch 160 Batch  140/269 - Train Accuracy: 0.8610, Validation Accuracy: 0.8621, Loss: 0.1465
Epoch 160 Batch  150/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8619, Loss: 0.1364
Epoch 160 Batch  160/269 - Train Accuracy: 0.8664, Validation Accuracy: 0.8655, Loss: 0.1354
Epoch 160 Batch  170/269 - Train Accuracy: 0.8467, Validation Accuracy: 0.8605, Loss: 0.1274
Epoch 160 Batch  180/269 - Train Accuracy: 0.8736, Validation Accuracy: 0.8576, Loss: 0.1267
Epoch 160 Batch  190/269 - Train Accuracy: 0.8739, Validation Accuracy: 0.8661, Loss: 0.1287
Epoch 160 Batch  200/269 - Train Accuracy: 0.8591, Validation Accuracy: 0.8609, Loss: 0.1278
Epoch 160 Batch  210/269 - Train Accuracy: 0.8671, Validation Accuracy: 0.8655, Loss: 0.1277
Epoch 160 Batch  220/269 - Train Accuracy: 0.8605, Validation Accuracy: 0.8619, Loss: 0.1200
Epoch 160 Batch  230/269 - Train Accuracy: 0.8597, Validation Accuracy: 0.8660, Loss: 0.1324
Epoch 160 Batch  240/269 - Train Accuracy: 0.8734, Validation Accuracy: 0.8644, Loss: 0.1171
Epoch 160 Batch  250/269 - Train Accuracy: 0.8704, Validation Accuracy: 0.8697, Loss: 0.1354
Epoch 160 Batch  260/269 - Train Accuracy: 0.8480, Validation Accuracy: 0.8682, Loss: 0.1399
Epoch 161 Batch   10/269 - Train Accuracy: 0.8677, Validation Accuracy: 0.8596, Loss: 0.1237
Epoch 161 Batch   20/269 - Train Accuracy: 0.8556, Validation Accuracy: 0.8644, Loss: 0.1292
Epoch 161 Batch   30/269 - Train Accuracy: 0.8689, Validation Accuracy: 0.8641, Loss: 0.1266
Epoch 161 Batch   40/269 - Train Accuracy: 0.8546, Validation Accuracy: 0.8667, Loss: 0.1506
Epoch 161 Batch   50/269 - Train Accuracy: 0.8391, Validation Accuracy: 0.8665, Loss: 0.1415
Epoch 161 Batch   60/269 - Train Accuracy: 0.8661, Validation Accuracy: 0.8706, Loss: 0.1182
Epoch 161 Batch   70/269 - Train Accuracy: 0.8730, Validation Accuracy: 0.8695, Loss: 0.1307
Epoch 161 Batch   80/269 - Train Accuracy: 0.8614, Validation Accuracy: 0.8627, Loss: 0.1317
Epoch 161 Batch   90/269 - Train Accuracy: 0.8656, Validation Accuracy: 0.8593, Loss: 0.1488
Epoch 161 Batch  100/269 - Train Accuracy: 0.8771, Validation Accuracy: 0.8641, Loss: 0.1367
Epoch 161 Batch  110/269 - Train Accuracy: 0.8523, Validation Accuracy: 0.8641, Loss: 0.1344
Epoch 161 Batch  120/269 - Train Accuracy: 0.8659, Validation Accuracy: 0.8658, Loss: 0.1343
Epoch 161 Batch  130/269 - Train Accuracy: 0.8501, Validation Accuracy: 0.8661, Loss: 0.1447
Epoch 161 Batch  140/269 - Train Accuracy: 0.8601, Validation Accuracy: 0.8628, Loss: 0.1404
Epoch 161 Batch  150/269 - Train Accuracy: 0.8616, Validation Accuracy: 0.8682, Loss: 0.1350
Epoch 161 Batch  160/269 - Train Accuracy: 0.8627, Validation Accuracy: 0.8651, Loss: 0.1310
Epoch 161 Batch  170/269 - Train Accuracy: 0.8524, Validation Accuracy: 0.8633, Loss: 0.1224
Epoch 161 Batch  180/269 - Train Accuracy: 0.8888, Validation Accuracy: 0.8645, Loss: 0.1331
Epoch 161 Batch  190/269 - Train Accuracy: 0.8727, Validation Accuracy: 0.8691, Loss: 0.1296
Epoch 161 Batch  200/269 - Train Accuracy: 0.8601, Validation Accuracy: 0.8686, Loss: 0.1334
Epoch 161 Batch  210/269 - Train Accuracy: 0.8743, Validation Accuracy: 0.8647, Loss: 0.1350
Epoch 161 Batch  220/269 - Train Accuracy: 0.8585, Validation Accuracy: 0.8651, Loss: 0.1251
Epoch 161 Batch  230/269 - Train Accuracy: 0.8580, Validation Accuracy: 0.8675, Loss: 0.1346
Epoch 161 Batch  240/269 - Train Accuracy: 0.8791, Validation Accuracy: 0.8635, Loss: 0.1186
Epoch 161 Batch  250/269 - Train Accuracy: 0.8731, Validation Accuracy: 0.8731, Loss: 0.1260
Epoch 161 Batch  260/269 - Train Accuracy: 0.8454, Validation Accuracy: 0.8639, Loss: 0.1369
Epoch 162 Batch   10/269 - Train Accuracy: 0.8725, Validation Accuracy: 0.8592, Loss: 0.1205
Epoch 162 Batch   20/269 - Train Accuracy: 0.8525, Validation Accuracy: 0.8640, Loss: 0.1313
Epoch 162 Batch   30/269 - Train Accuracy: 0.8645, Validation Accuracy: 0.8683, Loss: 0.1221
Epoch 162 Batch   40/269 - Train Accuracy: 0.8507, Validation Accuracy: 0.8719, Loss: 0.1368
Epoch 162 Batch   50/269 - Train Accuracy: 0.8410, Validation Accuracy: 0.8683, Loss: 0.1452
Epoch 162 Batch   60/269 - Train Accuracy: 0.8704, Validation Accuracy: 0.8662, Loss: 0.1237
Epoch 162 Batch   70/269 - Train Accuracy: 0.8656, Validation Accuracy: 0.8687, Loss: 0.1389
Epoch 162 Batch   80/269 - Train Accuracy: 0.8600, Validation Accuracy: 0.8650, Loss: 0.1243
Epoch 162 Batch   90/269 - Train Accuracy: 0.8671, Validation Accuracy: 0.8666, Loss: 0.1369
Epoch 162 Batch  100/269 - Train Accuracy: 0.8783, Validation Accuracy: 0.8639, Loss: 0.1304
Epoch 162 Batch  110/269 - Train Accuracy: 0.8586, Validation Accuracy: 0.8682, Loss: 0.1376
Epoch 162 Batch  120/269 - Train Accuracy: 0.8652, Validation Accuracy: 0.8599, Loss: 0.1379
Epoch 162 Batch  130/269 - Train Accuracy: 0.8503, Validation Accuracy: 0.8668, Loss: 0.1349
Epoch 162 Batch  140/269 - Train Accuracy: 0.8609, Validation Accuracy: 0.8621, Loss: 0.1433
Epoch 162 Batch  150/269 - Train Accuracy: 0.8661, Validation Accuracy: 0.8673, Loss: 0.1321
Epoch 162 Batch  160/269 - Train Accuracy: 0.8687, Validation Accuracy: 0.8730, Loss: 0.1314
Epoch 162 Batch  170/269 - Train Accuracy: 0.8553, Validation Accuracy: 0.8604, Loss: 0.1344
Epoch 162 Batch  180/269 - Train Accuracy: 0.8809, Validation Accuracy: 0.8643, Loss: 0.1210
Epoch 162 Batch  190/269 - Train Accuracy: 0.8736, Validation Accuracy: 0.8665, Loss: 0.1278
Epoch 162 Batch  200/269 - Train Accuracy: 0.8549, Validation Accuracy: 0.8680, Loss: 0.1309
Epoch 162 Batch  210/269 - Train Accuracy: 0.8743, Validation Accuracy: 0.8675, Loss: 0.1324
Epoch 162 Batch  220/269 - Train Accuracy: 0.8671, Validation Accuracy: 0.8681, Loss: 0.1236
Epoch 162 Batch  230/269 - Train Accuracy: 0.8562, Validation Accuracy: 0.8663, Loss: 0.1245
Epoch 162 Batch  240/269 - Train Accuracy: 0.8755, Validation Accuracy: 0.8651, Loss: 0.1158
Epoch 162 Batch  250/269 - Train Accuracy: 0.8757, Validation Accuracy: 0.8671, Loss: 0.1296
Epoch 162 Batch  260/269 - Train Accuracy: 0.8507, Validation Accuracy: 0.8693, Loss: 0.1359
Epoch 163 Batch   10/269 - Train Accuracy: 0.8601, Validation Accuracy: 0.8636, Loss: 0.1187
Epoch 163 Batch   20/269 - Train Accuracy: 0.8539, Validation Accuracy: 0.8627, Loss: 0.1274
Epoch 163 Batch   30/269 - Train Accuracy: 0.8625, Validation Accuracy: 0.8657, Loss: 0.1225
Epoch 163 Batch   40/269 - Train Accuracy: 0.8485, Validation Accuracy: 0.8715, Loss: 0.1480
Epoch 163 Batch   50/269 - Train Accuracy: 0.8347, Validation Accuracy: 0.8687, Loss: 0.1455
Epoch 163 Batch   60/269 - Train Accuracy: 0.8669, Validation Accuracy: 0.8768, Loss: 0.1278
Epoch 163 Batch   70/269 - Train Accuracy: 0.8778, Validation Accuracy: 0.8685, Loss: 0.1271
Epoch 163 Batch   80/269 - Train Accuracy: 0.8626, Validation Accuracy: 0.8691, Loss: 0.1210
Epoch 163 Batch   90/269 - Train Accuracy: 0.8534, Validation Accuracy: 0.8605, Loss: 0.1399
Epoch 163 Batch  100/269 - Train Accuracy: 0.8749, Validation Accuracy: 0.8677, Loss: 0.1246
Epoch 163 Batch  110/269 - Train Accuracy: 0.8539, Validation Accuracy: 0.8659, Loss: 0.1294
Epoch 163 Batch  120/269 - Train Accuracy: 0.8667, Validation Accuracy: 0.8611, Loss: 0.1388
Epoch 163 Batch  130/269 - Train Accuracy: 0.8452, Validation Accuracy: 0.8675, Loss: 0.1343
Epoch 163 Batch  140/269 - Train Accuracy: 0.8552, Validation Accuracy: 0.8596, Loss: 0.1469
Epoch 163 Batch  150/269 - Train Accuracy: 0.8614, Validation Accuracy: 0.8708, Loss: 0.1334
Epoch 163 Batch  160/269 - Train Accuracy: 0.8678, Validation Accuracy: 0.8669, Loss: 0.1332
Epoch 163 Batch  170/269 - Train Accuracy: 0.8610, Validation Accuracy: 0.8647, Loss: 0.1272
Epoch 163 Batch  180/269 - Train Accuracy: 0.8837, Validation Accuracy: 0.8665, Loss: 0.1355
Epoch 163 Batch  190/269 - Train Accuracy: 0.8730, Validation Accuracy: 0.8677, Loss: 0.1214
Epoch 163 Batch  200/269 - Train Accuracy: 0.8599, Validation Accuracy: 0.8614, Loss: 0.1351
Epoch 163 Batch  210/269 - Train Accuracy: 0.8762, Validation Accuracy: 0.8648, Loss: 0.1312
Epoch 163 Batch  220/269 - Train Accuracy: 0.8636, Validation Accuracy: 0.8655, Loss: 0.1292
Epoch 163 Batch  230/269 - Train Accuracy: 0.8607, Validation Accuracy: 0.8691, Loss: 0.1284
Epoch 163 Batch  240/269 - Train Accuracy: 0.8749, Validation Accuracy: 0.8618, Loss: 0.1144
Epoch 163 Batch  250/269 - Train Accuracy: 0.8689, Validation Accuracy: 0.8736, Loss: 0.1366
Epoch 163 Batch  260/269 - Train Accuracy: 0.8564, Validation Accuracy: 0.8732, Loss: 0.1372
Epoch 164 Batch   10/269 - Train Accuracy: 0.8656, Validation Accuracy: 0.8581, Loss: 0.1178
Epoch 164 Batch   20/269 - Train Accuracy: 0.8507, Validation Accuracy: 0.8636, Loss: 0.1356
Epoch 164 Batch   30/269 - Train Accuracy: 0.8581, Validation Accuracy: 0.8596, Loss: 0.1258
Epoch 164 Batch   40/269 - Train Accuracy: 0.8522, Validation Accuracy: 0.8684, Loss: 0.1370
Epoch 164 Batch   50/269 - Train Accuracy: 0.8398, Validation Accuracy: 0.8715, Loss: 0.1434
Epoch 164 Batch   60/269 - Train Accuracy: 0.8650, Validation Accuracy: 0.8643, Loss: 0.1202
Epoch 164 Batch   70/269 - Train Accuracy: 0.8741, Validation Accuracy: 0.8659, Loss: 0.1284
Epoch 164 Batch   80/269 - Train Accuracy: 0.8584, Validation Accuracy: 0.8670, Loss: 0.1311
Epoch 164 Batch   90/269 - Train Accuracy: 0.8589, Validation Accuracy: 0.8605, Loss: 0.1494
Epoch 164 Batch  100/269 - Train Accuracy: 0.8794, Validation Accuracy: 0.8640, Loss: 0.1219
Epoch 164 Batch  110/269 - Train Accuracy: 0.8553, Validation Accuracy: 0.8658, Loss: 0.1255
Epoch 164 Batch  120/269 - Train Accuracy: 0.8662, Validation Accuracy: 0.8657, Loss: 0.1428
Epoch 164 Batch  130/269 - Train Accuracy: 0.8494, Validation Accuracy: 0.8637, Loss: 0.1430
Epoch 164 Batch  140/269 - Train Accuracy: 0.8622, Validation Accuracy: 0.8686, Loss: 0.1415
Epoch 164 Batch  150/269 - Train Accuracy: 0.8667, Validation Accuracy: 0.8662, Loss: 0.1413
Epoch 164 Batch  160/269 - Train Accuracy: 0.8663, Validation Accuracy: 0.8623, Loss: 0.1333
Epoch 164 Batch  170/269 - Train Accuracy: 0.8636, Validation Accuracy: 0.8632, Loss: 0.1304
Epoch 164 Batch  180/269 - Train Accuracy: 0.8871, Validation Accuracy: 0.8673, Loss: 0.1268
Epoch 164 Batch  190/269 - Train Accuracy: 0.8698, Validation Accuracy: 0.8576, Loss: 0.1247
Epoch 164 Batch  200/269 - Train Accuracy: 0.8594, Validation Accuracy: 0.8635, Loss: 0.1282
Epoch 164 Batch  210/269 - Train Accuracy: 0.8726, Validation Accuracy: 0.8620, Loss: 0.1252
Epoch 164 Batch  220/269 - Train Accuracy: 0.8660, Validation Accuracy: 0.8680, Loss: 0.1261
Epoch 164 Batch  230/269 - Train Accuracy: 0.8582, Validation Accuracy: 0.8675, Loss: 0.1233
Epoch 164 Batch  240/269 - Train Accuracy: 0.8768, Validation Accuracy: 0.8644, Loss: 0.1138
Epoch 164 Batch  250/269 - Train Accuracy: 0.8659, Validation Accuracy: 0.8661, Loss: 0.1294
Epoch 164 Batch  260/269 - Train Accuracy: 0.8562, Validation Accuracy: 0.8699, Loss: 0.1384
Epoch 165 Batch   10/269 - Train Accuracy: 0.8660, Validation Accuracy: 0.8654, Loss: 0.1223
Epoch 165 Batch   20/269 - Train Accuracy: 0.8568, Validation Accuracy: 0.8597, Loss: 0.1255
Epoch 165 Batch   30/269 - Train Accuracy: 0.8623, Validation Accuracy: 0.8663, Loss: 0.1219
Epoch 165 Batch   40/269 - Train Accuracy: 0.8518, Validation Accuracy: 0.8686, Loss: 0.1464
Epoch 165 Batch   50/269 - Train Accuracy: 0.8387, Validation Accuracy: 0.8687, Loss: 0.1478
Epoch 165 Batch   60/269 - Train Accuracy: 0.8630, Validation Accuracy: 0.8691, Loss: 0.1224
Epoch 165 Batch   70/269 - Train Accuracy: 0.8715, Validation Accuracy: 0.8606, Loss: 0.1281
Epoch 165 Batch   80/269 - Train Accuracy: 0.8613, Validation Accuracy: 0.8644, Loss: 0.1256
Epoch 165 Batch   90/269 - Train Accuracy: 0.8623, Validation Accuracy: 0.8627, Loss: 0.1417
Epoch 165 Batch  100/269 - Train Accuracy: 0.8758, Validation Accuracy: 0.8659, Loss: 0.1306
Epoch 165 Batch  110/269 - Train Accuracy: 0.8577, Validation Accuracy: 0.8657, Loss: 0.1386
Epoch 165 Batch  120/269 - Train Accuracy: 0.8663, Validation Accuracy: 0.8670, Loss: 0.1368
Epoch 165 Batch  130/269 - Train Accuracy: 0.8564, Validation Accuracy: 0.8690, Loss: 0.1311
Epoch 165 Batch  140/269 - Train Accuracy: 0.8575, Validation Accuracy: 0.8611, Loss: 0.1437
Epoch 165 Batch  150/269 - Train Accuracy: 0.8631, Validation Accuracy: 0.8649, Loss: 0.1306
Epoch 165 Batch  160/269 - Train Accuracy: 0.8649, Validation Accuracy: 0.8659, Loss: 0.1317
Epoch 165 Batch  170/269 - Train Accuracy: 0.8514, Validation Accuracy: 0.8621, Loss: 0.1300
Epoch 165 Batch  180/269 - Train Accuracy: 0.8843, Validation Accuracy: 0.8702, Loss: 0.1195
Epoch 165 Batch  190/269 - Train Accuracy: 0.8758, Validation Accuracy: 0.8674, Loss: 0.1240
Epoch 165 Batch  200/269 - Train Accuracy: 0.8551, Validation Accuracy: 0.8672, Loss: 0.1359
Epoch 165 Batch  210/269 - Train Accuracy: 0.8643, Validation Accuracy: 0.8645, Loss: 0.1256
Epoch 165 Batch  220/269 - Train Accuracy: 0.8644, Validation Accuracy: 0.8643, Loss: 0.1210
Epoch 165 Batch  230/269 - Train Accuracy: 0.8556, Validation Accuracy: 0.8651, Loss: 0.1262
Epoch 165 Batch  240/269 - Train Accuracy: 0.8752, Validation Accuracy: 0.8614, Loss: 0.1182
Epoch 165 Batch  250/269 - Train Accuracy: 0.8694, Validation Accuracy: 0.8655, Loss: 0.1282
Epoch 165 Batch  260/269 - Train Accuracy: 0.8474, Validation Accuracy: 0.8689, Loss: 0.1390
Epoch 166 Batch   10/269 - Train Accuracy: 0.8699, Validation Accuracy: 0.8645, Loss: 0.1251
Epoch 166 Batch   20/269 - Train Accuracy: 0.8594, Validation Accuracy: 0.8662, Loss: 0.1266
Epoch 166 Batch   30/269 - Train Accuracy: 0.8641, Validation Accuracy: 0.8667, Loss: 0.1229
Epoch 166 Batch   40/269 - Train Accuracy: 0.8502, Validation Accuracy: 0.8656, Loss: 0.1435
Epoch 166 Batch   50/269 - Train Accuracy: 0.8461, Validation Accuracy: 0.8692, Loss: 0.1398
Epoch 166 Batch   60/269 - Train Accuracy: 0.8614, Validation Accuracy: 0.8657, Loss: 0.1117
Epoch 166 Batch   70/269 - Train Accuracy: 0.8728, Validation Accuracy: 0.8738, Loss: 0.1318
Epoch 166 Batch   80/269 - Train Accuracy: 0.8663, Validation Accuracy: 0.8722, Loss: 0.1289
Epoch 166 Batch   90/269 - Train Accuracy: 0.8665, Validation Accuracy: 0.8625, Loss: 0.1392
Epoch 166 Batch  100/269 - Train Accuracy: 0.8751, Validation Accuracy: 0.8674, Loss: 0.1266
Epoch 166 Batch  110/269 - Train Accuracy: 0.8553, Validation Accuracy: 0.8596, Loss: 0.1330
Epoch 166 Batch  120/269 - Train Accuracy: 0.8729, Validation Accuracy: 0.8674, Loss: 0.1484
Epoch 166 Batch  130/269 - Train Accuracy: 0.8522, Validation Accuracy: 0.8712, Loss: 0.1336
Epoch 166 Batch  140/269 - Train Accuracy: 0.8569, Validation Accuracy: 0.8650, Loss: 0.1382
Epoch 166 Batch  150/269 - Train Accuracy: 0.8661, Validation Accuracy: 0.8642, Loss: 0.1402
Epoch 166 Batch  160/269 - Train Accuracy: 0.8691, Validation Accuracy: 0.8573, Loss: 0.1439
Epoch 166 Batch  170/269 - Train Accuracy: 0.8542, Validation Accuracy: 0.8627, Loss: 0.1315
Epoch 166 Batch  180/269 - Train Accuracy: 0.8929, Validation Accuracy: 0.8618, Loss: 0.1185
Epoch 166 Batch  190/269 - Train Accuracy: 0.8768, Validation Accuracy: 0.8675, Loss: 0.1275
Epoch 166 Batch  200/269 - Train Accuracy: 0.8595, Validation Accuracy: 0.8668, Loss: 0.1298
Epoch 166 Batch  210/269 - Train Accuracy: 0.8742, Validation Accuracy: 0.8681, Loss: 0.1315
Epoch 166 Batch  220/269 - Train Accuracy: 0.8666, Validation Accuracy: 0.8618, Loss: 0.1339
Epoch 166 Batch  230/269 - Train Accuracy: 0.8555, Validation Accuracy: 0.8637, Loss: 0.1279
Epoch 166 Batch  240/269 - Train Accuracy: 0.8783, Validation Accuracy: 0.8661, Loss: 0.1168
Epoch 166 Batch  250/269 - Train Accuracy: 0.8745, Validation Accuracy: 0.8691, Loss: 0.1276
Epoch 166 Batch  260/269 - Train Accuracy: 0.8501, Validation Accuracy: 0.8701, Loss: 0.1398
Epoch 167 Batch   10/269 - Train Accuracy: 0.8707, Validation Accuracy: 0.8638, Loss: 0.1233
Epoch 167 Batch   20/269 - Train Accuracy: 0.8589, Validation Accuracy: 0.8651, Loss: 0.1369
Epoch 167 Batch   30/269 - Train Accuracy: 0.8667, Validation Accuracy: 0.8664, Loss: 0.1258
Epoch 167 Batch   40/269 - Train Accuracy: 0.8535, Validation Accuracy: 0.8653, Loss: 0.1463
Epoch 167 Batch   50/269 - Train Accuracy: 0.8400, Validation Accuracy: 0.8699, Loss: 0.1419
Epoch 167 Batch   60/269 - Train Accuracy: 0.8701, Validation Accuracy: 0.8691, Loss: 0.1191
Epoch 167 Batch   70/269 - Train Accuracy: 0.8715, Validation Accuracy: 0.8713, Loss: 0.1375
Epoch 167 Batch   80/269 - Train Accuracy: 0.8594, Validation Accuracy: 0.8619, Loss: 0.1268
Epoch 167 Batch   90/269 - Train Accuracy: 0.8551, Validation Accuracy: 0.8667, Loss: 0.1360
Epoch 167 Batch  100/269 - Train Accuracy: 0.8776, Validation Accuracy: 0.8716, Loss: 0.1299
Epoch 167 Batch  110/269 - Train Accuracy: 0.8573, Validation Accuracy: 0.8662, Loss: 0.1315
Epoch 167 Batch  120/269 - Train Accuracy: 0.8754, Validation Accuracy: 0.8662, Loss: 0.1419
Epoch 167 Batch  130/269 - Train Accuracy: 0.8530, Validation Accuracy: 0.8671, Loss: 0.1420
Epoch 167 Batch  140/269 - Train Accuracy: 0.8555, Validation Accuracy: 0.8653, Loss: 0.1508
Epoch 167 Batch  150/269 - Train Accuracy: 0.8674, Validation Accuracy: 0.8678, Loss: 0.1275
Epoch 167 Batch  160/269 - Train Accuracy: 0.8632, Validation Accuracy: 0.8668, Loss: 0.1269
Epoch 167 Batch  170/269 - Train Accuracy: 0.8599, Validation Accuracy: 0.8698, Loss: 0.1241
Epoch 167 Batch  180/269 - Train Accuracy: 0.8855, Validation Accuracy: 0.8668, Loss: 0.1236
Epoch 167 Batch  190/269 - Train Accuracy: 0.8726, Validation Accuracy: 0.8651, Loss: 0.1267
Epoch 167 Batch  200/269 - Train Accuracy: 0.8667, Validation Accuracy: 0.8675, Loss: 0.1256
Epoch 167 Batch  210/269 - Train Accuracy: 0.8740, Validation Accuracy: 0.8695, Loss: 0.1307
Epoch 167 Batch  220/269 - Train Accuracy: 0.8626, Validation Accuracy: 0.8647, Loss: 0.1292
Epoch 167 Batch  230/269 - Train Accuracy: 0.8580, Validation Accuracy: 0.8653, Loss: 0.1292
Epoch 167 Batch  240/269 - Train Accuracy: 0.8744, Validation Accuracy: 0.8614, Loss: 0.1183
Epoch 167 Batch  250/269 - Train Accuracy: 0.8701, Validation Accuracy: 0.8699, Loss: 0.1268
Epoch 167 Batch  260/269 - Train Accuracy: 0.8499, Validation Accuracy: 0.8683, Loss: 0.1345
Epoch 168 Batch   10/269 - Train Accuracy: 0.8598, Validation Accuracy: 0.8643, Loss: 0.1277
Epoch 168 Batch   20/269 - Train Accuracy: 0.8565, Validation Accuracy: 0.8603, Loss: 0.1232
Epoch 168 Batch   30/269 - Train Accuracy: 0.8677, Validation Accuracy: 0.8706, Loss: 0.1265
Epoch 168 Batch   40/269 - Train Accuracy: 0.8489, Validation Accuracy: 0.8627, Loss: 0.1428
Epoch 168 Batch   50/269 - Train Accuracy: 0.8405, Validation Accuracy: 0.8699, Loss: 0.1408
Epoch 168 Batch   60/269 - Train Accuracy: 0.8664, Validation Accuracy: 0.8676, Loss: 0.1248
Epoch 168 Batch   70/269 - Train Accuracy: 0.8754, Validation Accuracy: 0.8683, Loss: 0.1371
Epoch 168 Batch   80/269 - Train Accuracy: 0.8572, Validation Accuracy: 0.8661, Loss: 0.1284
Epoch 168 Batch   90/269 - Train Accuracy: 0.8628, Validation Accuracy: 0.8645, Loss: 0.1362
Epoch 168 Batch  100/269 - Train Accuracy: 0.8778, Validation Accuracy: 0.8685, Loss: 0.1250
Epoch 168 Batch  110/269 - Train Accuracy: 0.8517, Validation Accuracy: 0.8583, Loss: 0.1358
Epoch 168 Batch  120/269 - Train Accuracy: 0.8711, Validation Accuracy: 0.8659, Loss: 0.1460
Epoch 168 Batch  130/269 - Train Accuracy: 0.8544, Validation Accuracy: 0.8695, Loss: 0.1351
Epoch 168 Batch  140/269 - Train Accuracy: 0.8630, Validation Accuracy: 0.8731, Loss: 0.1469
Epoch 168 Batch  150/269 - Train Accuracy: 0.8675, Validation Accuracy: 0.8655, Loss: 0.1247
Epoch 168 Batch  160/269 - Train Accuracy: 0.8670, Validation Accuracy: 0.8714, Loss: 0.1289
Epoch 168 Batch  170/269 - Train Accuracy: 0.8529, Validation Accuracy: 0.8677, Loss: 0.1242
Epoch 168 Batch  180/269 - Train Accuracy: 0.8886, Validation Accuracy: 0.8686, Loss: 0.1268
Epoch 168 Batch  190/269 - Train Accuracy: 0.8725, Validation Accuracy: 0.8717, Loss: 0.1361
Epoch 168 Batch  200/269 - Train Accuracy: 0.8586, Validation Accuracy: 0.8652, Loss: 0.1254
Epoch 168 Batch  210/269 - Train Accuracy: 0.8711, Validation Accuracy: 0.8647, Loss: 0.1236
Epoch 168 Batch  220/269 - Train Accuracy: 0.8654, Validation Accuracy: 0.8678, Loss: 0.1234
Epoch 168 Batch  230/269 - Train Accuracy: 0.8610, Validation Accuracy: 0.8714, Loss: 0.1280
Epoch 168 Batch  240/269 - Train Accuracy: 0.8796, Validation Accuracy: 0.8687, Loss: 0.1206
Epoch 168 Batch  250/269 - Train Accuracy: 0.8723, Validation Accuracy: 0.8699, Loss: 0.1263
Epoch 168 Batch  260/269 - Train Accuracy: 0.8504, Validation Accuracy: 0.8682, Loss: 0.1430
Epoch 169 Batch   10/269 - Train Accuracy: 0.8691, Validation Accuracy: 0.8717, Loss: 0.1199
Epoch 169 Batch   20/269 - Train Accuracy: 0.8546, Validation Accuracy: 0.8619, Loss: 0.1275
Epoch 169 Batch   30/269 - Train Accuracy: 0.8627, Validation Accuracy: 0.8657, Loss: 0.1235
Epoch 169 Batch   40/269 - Train Accuracy: 0.8574, Validation Accuracy: 0.8718, Loss: 0.1349
Epoch 169 Batch   50/269 - Train Accuracy: 0.8427, Validation Accuracy: 0.8712, Loss: 0.1443
Epoch 169 Batch   60/269 - Train Accuracy: 0.8643, Validation Accuracy: 0.8681, Loss: 0.1159
Epoch 169 Batch   70/269 - Train Accuracy: 0.8699, Validation Accuracy: 0.8677, Loss: 0.1350
Epoch 169 Batch   80/269 - Train Accuracy: 0.8627, Validation Accuracy: 0.8654, Loss: 0.1206
Epoch 169 Batch   90/269 - Train Accuracy: 0.8660, Validation Accuracy: 0.8652, Loss: 0.1345
Epoch 169 Batch  100/269 - Train Accuracy: 0.8770, Validation Accuracy: 0.8664, Loss: 0.1184
Epoch 169 Batch  110/269 - Train Accuracy: 0.8551, Validation Accuracy: 0.8630, Loss: 0.1368
Epoch 169 Batch  120/269 - Train Accuracy: 0.8673, Validation Accuracy: 0.8702, Loss: 0.1425
Epoch 169 Batch  130/269 - Train Accuracy: 0.8507, Validation Accuracy: 0.8696, Loss: 0.1367
Epoch 169 Batch  140/269 - Train Accuracy: 0.8600, Validation Accuracy: 0.8604, Loss: 0.1378
Epoch 169 Batch  150/269 - Train Accuracy: 0.8690, Validation Accuracy: 0.8673, Loss: 0.1299
Epoch 169 Batch  160/269 - Train Accuracy: 0.8700, Validation Accuracy: 0.8691, Loss: 0.1296
Epoch 169 Batch  170/269 - Train Accuracy: 0.8599, Validation Accuracy: 0.8713, Loss: 0.1200
Epoch 169 Batch  180/269 - Train Accuracy: 0.8826, Validation Accuracy: 0.8581, Loss: 0.1133
Epoch 169 Batch  190/269 - Train Accuracy: 0.8695, Validation Accuracy: 0.8676, Loss: 0.1203
Epoch 169 Batch  200/269 - Train Accuracy: 0.8612, Validation Accuracy: 0.8622, Loss: 0.1454
Epoch 169 Batch  210/269 - Train Accuracy: 0.8723, Validation Accuracy: 0.8625, Loss: 0.1316
Epoch 169 Batch  220/269 - Train Accuracy: 0.8621, Validation Accuracy: 0.8629, Loss: 0.1248
Epoch 169 Batch  230/269 - Train Accuracy: 0.8590, Validation Accuracy: 0.8664, Loss: 0.1319
Epoch 169 Batch  240/269 - Train Accuracy: 0.8781, Validation Accuracy: 0.8659, Loss: 0.1219
Epoch 169 Batch  250/269 - Train Accuracy: 0.8727, Validation Accuracy: 0.8721, Loss: 0.1305
Epoch 169 Batch  260/269 - Train Accuracy: 0.8542, Validation Accuracy: 0.8701, Loss: 0.1348
Epoch 170 Batch   10/269 - Train Accuracy: 0.8680, Validation Accuracy: 0.8623, Loss: 0.1225
Epoch 170 Batch   20/269 - Train Accuracy: 0.8614, Validation Accuracy: 0.8619, Loss: 0.1185
Epoch 170 Batch   30/269 - Train Accuracy: 0.8653, Validation Accuracy: 0.8663, Loss: 0.1270
Epoch 170 Batch   40/269 - Train Accuracy: 0.8509, Validation Accuracy: 0.8650, Loss: 0.1397
Epoch 170 Batch   50/269 - Train Accuracy: 0.8414, Validation Accuracy: 0.8723, Loss: 0.1422
Epoch 170 Batch   60/269 - Train Accuracy: 0.8698, Validation Accuracy: 0.8669, Loss: 0.1168
Epoch 170 Batch   70/269 - Train Accuracy: 0.8741, Validation Accuracy: 0.8711, Loss: 0.1287
Epoch 170 Batch   80/269 - Train Accuracy: 0.8600, Validation Accuracy: 0.8616, Loss: 0.1280
Epoch 170 Batch   90/269 - Train Accuracy: 0.8593, Validation Accuracy: 0.8644, Loss: 0.1310
Epoch 170 Batch  100/269 - Train Accuracy: 0.8744, Validation Accuracy: 0.8683, Loss: 0.1310
Epoch 170 Batch  110/269 - Train Accuracy: 0.8517, Validation Accuracy: 0.8628, Loss: 0.1334
Epoch 170 Batch  120/269 - Train Accuracy: 0.8679, Validation Accuracy: 0.8730, Loss: 0.1399
Epoch 170 Batch  130/269 - Train Accuracy: 0.8530, Validation Accuracy: 0.8702, Loss: 0.1355
Epoch 170 Batch  140/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8652, Loss: 0.1418
Epoch 170 Batch  150/269 - Train Accuracy: 0.8634, Validation Accuracy: 0.8648, Loss: 0.1230
Epoch 170 Batch  160/269 - Train Accuracy: 0.8724, Validation Accuracy: 0.8661, Loss: 0.1268
Epoch 170 Batch  170/269 - Train Accuracy: 0.8582, Validation Accuracy: 0.8624, Loss: 0.1202
Epoch 170 Batch  180/269 - Train Accuracy: 0.8894, Validation Accuracy: 0.8706, Loss: 0.1202
Epoch 170 Batch  190/269 - Train Accuracy: 0.8714, Validation Accuracy: 0.8695, Loss: 0.1294
Epoch 170 Batch  200/269 - Train Accuracy: 0.8568, Validation Accuracy: 0.8610, Loss: 0.1337
Epoch 170 Batch  210/269 - Train Accuracy: 0.8682, Validation Accuracy: 0.8657, Loss: 0.1452
Epoch 170 Batch  220/269 - Train Accuracy: 0.8667, Validation Accuracy: 0.8627, Loss: 0.1326
Epoch 170 Batch  230/269 - Train Accuracy: 0.8548, Validation Accuracy: 0.8675, Loss: 0.1286
Epoch 170 Batch  240/269 - Train Accuracy: 0.8761, Validation Accuracy: 0.8714, Loss: 0.1160
Epoch 170 Batch  250/269 - Train Accuracy: 0.8708, Validation Accuracy: 0.8625, Loss: 0.1191
Epoch 170 Batch  260/269 - Train Accuracy: 0.8548, Validation Accuracy: 0.8624, Loss: 0.1432
Epoch 171 Batch   10/269 - Train Accuracy: 0.8713, Validation Accuracy: 0.8658, Loss: 0.1334
Epoch 171 Batch   20/269 - Train Accuracy: 0.8579, Validation Accuracy: 0.8695, Loss: 0.1212
Epoch 171 Batch   30/269 - Train Accuracy: 0.8616, Validation Accuracy: 0.8659, Loss: 0.1248
Epoch 171 Batch   40/269 - Train Accuracy: 0.8540, Validation Accuracy: 0.8687, Loss: 0.1362
Epoch 171 Batch   50/269 - Train Accuracy: 0.8414, Validation Accuracy: 0.8695, Loss: 0.1414
Epoch 171 Batch   60/269 - Train Accuracy: 0.8691, Validation Accuracy: 0.8765, Loss: 0.1098
Epoch 171 Batch   70/269 - Train Accuracy: 0.8758, Validation Accuracy: 0.8688, Loss: 0.1318
Epoch 171 Batch   80/269 - Train Accuracy: 0.8594, Validation Accuracy: 0.8634, Loss: 0.1256
Epoch 171 Batch   90/269 - Train Accuracy: 0.8636, Validation Accuracy: 0.8611, Loss: 0.1381
Epoch 171 Batch  100/269 - Train Accuracy: 0.8778, Validation Accuracy: 0.8694, Loss: 0.1211
Epoch 171 Batch  110/269 - Train Accuracy: 0.8558, Validation Accuracy: 0.8675, Loss: 0.1312
Epoch 171 Batch  120/269 - Train Accuracy: 0.8696, Validation Accuracy: 0.8655, Loss: 0.1326
Epoch 171 Batch  130/269 - Train Accuracy: 0.8547, Validation Accuracy: 0.8719, Loss: 0.1315
Epoch 171 Batch  140/269 - Train Accuracy: 0.8562, Validation Accuracy: 0.8627, Loss: 0.1481
Epoch 171 Batch  150/269 - Train Accuracy: 0.8659, Validation Accuracy: 0.8648, Loss: 0.1249
Epoch 171 Batch  160/269 - Train Accuracy: 0.8725, Validation Accuracy: 0.8596, Loss: 0.1387
Epoch 171 Batch  170/269 - Train Accuracy: 0.8548, Validation Accuracy: 0.8587, Loss: 0.1211
Epoch 171 Batch  180/269 - Train Accuracy: 0.8867, Validation Accuracy: 0.8698, Loss: 0.1190
Epoch 171 Batch  190/269 - Train Accuracy: 0.8709, Validation Accuracy: 0.8666, Loss: 0.1223
Epoch 171 Batch  200/269 - Train Accuracy: 0.8511, Validation Accuracy: 0.8573, Loss: 0.1213
Epoch 171 Batch  210/269 - Train Accuracy: 0.8712, Validation Accuracy: 0.8543, Loss: 0.1353
Epoch 171 Batch  220/269 - Train Accuracy: 0.8610, Validation Accuracy: 0.8616, Loss: 0.1214
Epoch 171 Batch  230/269 - Train Accuracy: 0.8541, Validation Accuracy: 0.8679, Loss: 0.1241
Epoch 171 Batch  240/269 - Train Accuracy: 0.8716, Validation Accuracy: 0.8633, Loss: 0.1143
Epoch 171 Batch  250/269 - Train Accuracy: 0.8702, Validation Accuracy: 0.8675, Loss: 0.1227
Epoch 171 Batch  260/269 - Train Accuracy: 0.8541, Validation Accuracy: 0.8657, Loss: 0.1321
Epoch 172 Batch   10/269 - Train Accuracy: 0.8594, Validation Accuracy: 0.8625, Loss: 0.1350
Epoch 172 Batch   20/269 - Train Accuracy: 0.8514, Validation Accuracy: 0.8653, Loss: 0.1296
Epoch 172 Batch   30/269 - Train Accuracy: 0.8674, Validation Accuracy: 0.8706, Loss: 0.1352
Epoch 172 Batch   40/269 - Train Accuracy: 0.8491, Validation Accuracy: 0.8701, Loss: 0.1606
Epoch 172 Batch   50/269 - Train Accuracy: 0.8439, Validation Accuracy: 0.8681, Loss: 0.1388
Epoch 172 Batch   60/269 - Train Accuracy: 0.8657, Validation Accuracy: 0.8687, Loss: 0.1151
Epoch 172 Batch   70/269 - Train Accuracy: 0.8774, Validation Accuracy: 0.8677, Loss: 0.1432
Epoch 172 Batch   80/269 - Train Accuracy: 0.8718, Validation Accuracy: 0.8694, Loss: 0.1255
Epoch 172 Batch   90/269 - Train Accuracy: 0.8639, Validation Accuracy: 0.8610, Loss: 0.1394
Epoch 172 Batch  100/269 - Train Accuracy: 0.8751, Validation Accuracy: 0.8645, Loss: 0.1257
Epoch 172 Batch  110/269 - Train Accuracy: 0.8521, Validation Accuracy: 0.8655, Loss: 0.1369
Epoch 172 Batch  120/269 - Train Accuracy: 0.8710, Validation Accuracy: 0.8664, Loss: 0.1346
Epoch 172 Batch  130/269 - Train Accuracy: 0.8518, Validation Accuracy: 0.8657, Loss: 0.1346
Epoch 172 Batch  140/269 - Train Accuracy: 0.8546, Validation Accuracy: 0.8632, Loss: 0.1360
Epoch 172 Batch  150/269 - Train Accuracy: 0.8648, Validation Accuracy: 0.8616, Loss: 0.1293
Epoch 172 Batch  160/269 - Train Accuracy: 0.8729, Validation Accuracy: 0.8639, Loss: 0.1231
Epoch 172 Batch  170/269 - Train Accuracy: 0.8557, Validation Accuracy: 0.8667, Loss: 0.1236
Epoch 172 Batch  180/269 - Train Accuracy: 0.8853, Validation Accuracy: 0.8591, Loss: 0.1194
Epoch 172 Batch  190/269 - Train Accuracy: 0.8718, Validation Accuracy: 0.8667, Loss: 0.1259
Epoch 172 Batch  200/269 - Train Accuracy: 0.8542, Validation Accuracy: 0.8649, Loss: 0.1317
Epoch 172 Batch  210/269 - Train Accuracy: 0.8702, Validation Accuracy: 0.8654, Loss: 0.1223
Epoch 172 Batch  220/269 - Train Accuracy: 0.8635, Validation Accuracy: 0.8619, Loss: 0.1270
Epoch 172 Batch  230/269 - Train Accuracy: 0.8561, Validation Accuracy: 0.8675, Loss: 0.1236
Epoch 172 Batch  240/269 - Train Accuracy: 0.8697, Validation Accuracy: 0.8629, Loss: 0.1209
Epoch 172 Batch  250/269 - Train Accuracy: 0.8699, Validation Accuracy: 0.8644, Loss: 0.1536
Epoch 172 Batch  260/269 - Train Accuracy: 0.8482, Validation Accuracy: 0.8646, Loss: 0.1400
Epoch 173 Batch   10/269 - Train Accuracy: 0.8684, Validation Accuracy: 0.8636, Loss: 0.1259
Epoch 173 Batch   20/269 - Train Accuracy: 0.8573, Validation Accuracy: 0.8655, Loss: 0.1333
Epoch 173 Batch   30/269 - Train Accuracy: 0.8608, Validation Accuracy: 0.8688, Loss: 0.1274
Epoch 173 Batch   40/269 - Train Accuracy: 0.8511, Validation Accuracy: 0.8694, Loss: 0.1366
Epoch 173 Batch   50/269 - Train Accuracy: 0.8427, Validation Accuracy: 0.8714, Loss: 0.1339
Epoch 173 Batch   60/269 - Train Accuracy: 0.8670, Validation Accuracy: 0.8714, Loss: 0.1158
Epoch 173 Batch   70/269 - Train Accuracy: 0.8725, Validation Accuracy: 0.8667, Loss: 0.1228
Epoch 173 Batch   80/269 - Train Accuracy: 0.8597, Validation Accuracy: 0.8678, Loss: 0.1250
Epoch 173 Batch   90/269 - Train Accuracy: 0.8620, Validation Accuracy: 0.8670, Loss: 0.1343
Epoch 173 Batch  100/269 - Train Accuracy: 0.8798, Validation Accuracy: 0.8691, Loss: 0.1301
Epoch 173 Batch  110/269 - Train Accuracy: 0.8563, Validation Accuracy: 0.8653, Loss: 0.1264
Epoch 173 Batch  120/269 - Train Accuracy: 0.8747, Validation Accuracy: 0.8729, Loss: 0.1336
Epoch 173 Batch  130/269 - Train Accuracy: 0.8493, Validation Accuracy: 0.8713, Loss: 0.1359
Epoch 173 Batch  140/269 - Train Accuracy: 0.8611, Validation Accuracy: 0.8671, Loss: 0.1345
Epoch 173 Batch  150/269 - Train Accuracy: 0.8669, Validation Accuracy: 0.8648, Loss: 0.1263
Epoch 173 Batch  160/269 - Train Accuracy: 0.8701, Validation Accuracy: 0.8659, Loss: 0.1250
Epoch 173 Batch  170/269 - Train Accuracy: 0.8557, Validation Accuracy: 0.8686, Loss: 0.1283
Epoch 173 Batch  180/269 - Train Accuracy: 0.8835, Validation Accuracy: 0.8636, Loss: 0.1193
Epoch 173 Batch  190/269 - Train Accuracy: 0.8756, Validation Accuracy: 0.8683, Loss: 0.1194
Epoch 173 Batch  200/269 - Train Accuracy: 0.8601, Validation Accuracy: 0.8619, Loss: 0.1227
Epoch 173 Batch  210/269 - Train Accuracy: 0.8670, Validation Accuracy: 0.8661, Loss: 0.1349
Epoch 173 Batch  220/269 - Train Accuracy: 0.8639, Validation Accuracy: 0.8647, Loss: 0.1153
Epoch 173 Batch  230/269 - Train Accuracy: 0.8562, Validation Accuracy: 0.8674, Loss: 0.1218
Epoch 173 Batch  240/269 - Train Accuracy: 0.8733, Validation Accuracy: 0.8638, Loss: 0.1090
Epoch 173 Batch  250/269 - Train Accuracy: 0.8768, Validation Accuracy: 0.8710, Loss: 0.1270
Epoch 173 Batch  260/269 - Train Accuracy: 0.8504, Validation Accuracy: 0.8738, Loss: 0.1366
Epoch 174 Batch   10/269 - Train Accuracy: 0.8647, Validation Accuracy: 0.8580, Loss: 0.1194
Epoch 174 Batch   20/269 - Train Accuracy: 0.8564, Validation Accuracy: 0.8629, Loss: 0.1207
Epoch 174 Batch   30/269 - Train Accuracy: 0.8664, Validation Accuracy: 0.8680, Loss: 0.1203
Epoch 174 Batch   40/269 - Train Accuracy: 0.8521, Validation Accuracy: 0.8683, Loss: 0.1386
Epoch 174 Batch   50/269 - Train Accuracy: 0.8434, Validation Accuracy: 0.8720, Loss: 0.1322
Epoch 174 Batch   60/269 - Train Accuracy: 0.8706, Validation Accuracy: 0.8734, Loss: 0.1175
Epoch 174 Batch   70/269 - Train Accuracy: 0.8753, Validation Accuracy: 0.8724, Loss: 0.1310
Epoch 174 Batch   80/269 - Train Accuracy: 0.8650, Validation Accuracy: 0.8677, Loss: 0.1298
Epoch 174 Batch   90/269 - Train Accuracy: 0.8652, Validation Accuracy: 0.8617, Loss: 0.1308
Epoch 174 Batch  100/269 - Train Accuracy: 0.8770, Validation Accuracy: 0.8662, Loss: 0.1229
Epoch 174 Batch  110/269 - Train Accuracy: 0.8597, Validation Accuracy: 0.8668, Loss: 0.1329
Epoch 174 Batch  120/269 - Train Accuracy: 0.8721, Validation Accuracy: 0.8684, Loss: 0.1401
Epoch 174 Batch  130/269 - Train Accuracy: 0.8529, Validation Accuracy: 0.8710, Loss: 0.1296
Epoch 174 Batch  140/269 - Train Accuracy: 0.8599, Validation Accuracy: 0.8672, Loss: 0.1386
Epoch 174 Batch  150/269 - Train Accuracy: 0.8563, Validation Accuracy: 0.8672, Loss: 0.1264
Epoch 174 Batch  160/269 - Train Accuracy: 0.8699, Validation Accuracy: 0.8689, Loss: 0.1227
Epoch 174 Batch  170/269 - Train Accuracy: 0.8573, Validation Accuracy: 0.8766, Loss: 0.1225
Epoch 174 Batch  180/269 - Train Accuracy: 0.8834, Validation Accuracy: 0.8692, Loss: 0.1218
Epoch 174 Batch  190/269 - Train Accuracy: 0.8750, Validation Accuracy: 0.8687, Loss: 0.1172
Epoch 174 Batch  200/269 - Train Accuracy: 0.8602, Validation Accuracy: 0.8714, Loss: 0.1190
Epoch 174 Batch  210/269 - Train Accuracy: 0.8685, Validation Accuracy: 0.8590, Loss: 0.1302
Epoch 174 Batch  220/269 - Train Accuracy: 0.8642, Validation Accuracy: 0.8619, Loss: 0.1311
Epoch 174 Batch  230/269 - Train Accuracy: 0.8620, Validation Accuracy: 0.8655, Loss: 0.1221
Epoch 174 Batch  240/269 - Train Accuracy: 0.8702, Validation Accuracy: 0.8665, Loss: 0.1060
Epoch 174 Batch  250/269 - Train Accuracy: 0.8728, Validation Accuracy: 0.8667, Loss: 0.1202
Epoch 174 Batch  260/269 - Train Accuracy: 0.8531, Validation Accuracy: 0.8706, Loss: 0.1382
Epoch 175 Batch   10/269 - Train Accuracy: 0.8652, Validation Accuracy: 0.8672, Loss: 0.1199
Epoch 175 Batch   20/269 - Train Accuracy: 0.8521, Validation Accuracy: 0.8668, Loss: 0.1172
Epoch 175 Batch   30/269 - Train Accuracy: 0.8604, Validation Accuracy: 0.8669, Loss: 0.1234
Epoch 175 Batch   40/269 - Train Accuracy: 0.8579, Validation Accuracy: 0.8677, Loss: 0.1455
Epoch 175 Batch   50/269 - Train Accuracy: 0.8447, Validation Accuracy: 0.8699, Loss: 0.1378
Epoch 175 Batch   60/269 - Train Accuracy: 0.8700, Validation Accuracy: 0.8728, Loss: 0.1104
Epoch 175 Batch   70/269 - Train Accuracy: 0.8741, Validation Accuracy: 0.8740, Loss: 0.1240
Epoch 175 Batch   80/269 - Train Accuracy: 0.8656, Validation Accuracy: 0.8652, Loss: 0.1219
Epoch 175 Batch   90/269 - Train Accuracy: 0.8600, Validation Accuracy: 0.8641, Loss: 0.1359
Epoch 175 Batch  100/269 - Train Accuracy: 0.8769, Validation Accuracy: 0.8667, Loss: 0.1191
Epoch 175 Batch  110/269 - Train Accuracy: 0.8575, Validation Accuracy: 0.8659, Loss: 0.1321
Epoch 175 Batch  120/269 - Train Accuracy: 0.8668, Validation Accuracy: 0.8700, Loss: 0.1409
Epoch 175 Batch  130/269 - Train Accuracy: 0.8487, Validation Accuracy: 0.8696, Loss: 0.1323
Epoch 175 Batch  140/269 - Train Accuracy: 0.8614, Validation Accuracy: 0.8616, Loss: 0.1341
Epoch 175 Batch  150/269 - Train Accuracy: 0.8684, Validation Accuracy: 0.8679, Loss: 0.1290
Epoch 175 Batch  160/269 - Train Accuracy: 0.8656, Validation Accuracy: 0.8693, Loss: 0.1289
Epoch 175 Batch  170/269 - Train Accuracy: 0.8550, Validation Accuracy: 0.8667, Loss: 0.1345
Epoch 175 Batch  180/269 - Train Accuracy: 0.8858, Validation Accuracy: 0.8640, Loss: 0.1187
Epoch 175 Batch  190/269 - Train Accuracy: 0.8690, Validation Accuracy: 0.8666, Loss: 0.1255
Epoch 175 Batch  200/269 - Train Accuracy: 0.8577, Validation Accuracy: 0.8623, Loss: 0.1220
Epoch 175 Batch  210/269 - Train Accuracy: 0.8738, Validation Accuracy: 0.8668, Loss: 0.1208
Epoch 175 Batch  220/269 - Train Accuracy: 0.8641, Validation Accuracy: 0.8667, Loss: 0.1247
Epoch 175 Batch  230/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8683, Loss: 0.1326
Epoch 175 Batch  240/269 - Train Accuracy: 0.8780, Validation Accuracy: 0.8681, Loss: 0.1067
Epoch 175 Batch  250/269 - Train Accuracy: 0.8744, Validation Accuracy: 0.8714, Loss: 0.1212
Epoch 175 Batch  260/269 - Train Accuracy: 0.8533, Validation Accuracy: 0.8675, Loss: 0.1386
Epoch 176 Batch   10/269 - Train Accuracy: 0.8611, Validation Accuracy: 0.8675, Loss: 0.1206
Epoch 176 Batch   20/269 - Train Accuracy: 0.8560, Validation Accuracy: 0.8667, Loss: 0.1184
Epoch 176 Batch   30/269 - Train Accuracy: 0.8656, Validation Accuracy: 0.8668, Loss: 0.1180
Epoch 176 Batch   40/269 - Train Accuracy: 0.8514, Validation Accuracy: 0.8669, Loss: 0.1326
Epoch 176 Batch   50/269 - Train Accuracy: 0.8434, Validation Accuracy: 0.8689, Loss: 0.1368
Epoch 176 Batch   60/269 - Train Accuracy: 0.8682, Validation Accuracy: 0.8714, Loss: 0.1077
Epoch 176 Batch   70/269 - Train Accuracy: 0.8751, Validation Accuracy: 0.8723, Loss: 0.1245
Epoch 176 Batch   80/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8697, Loss: 0.1295
Epoch 176 Batch   90/269 - Train Accuracy: 0.8634, Validation Accuracy: 0.8615, Loss: 0.1314
Epoch 176 Batch  100/269 - Train Accuracy: 0.8773, Validation Accuracy: 0.8666, Loss: 0.1179
Epoch 176 Batch  110/269 - Train Accuracy: 0.8524, Validation Accuracy: 0.8674, Loss: 0.1309
Epoch 176 Batch  120/269 - Train Accuracy: 0.8674, Validation Accuracy: 0.8729, Loss: 0.1339
Epoch 176 Batch  130/269 - Train Accuracy: 0.8581, Validation Accuracy: 0.8738, Loss: 0.1301
Epoch 176 Batch  140/269 - Train Accuracy: 0.8612, Validation Accuracy: 0.8680, Loss: 0.1357
Epoch 176 Batch  150/269 - Train Accuracy: 0.8640, Validation Accuracy: 0.8692, Loss: 0.1304
Epoch 176 Batch  160/269 - Train Accuracy: 0.8729, Validation Accuracy: 0.8696, Loss: 0.1190
Epoch 176 Batch  170/269 - Train Accuracy: 0.8584, Validation Accuracy: 0.8693, Loss: 0.1244
Epoch 176 Batch  180/269 - Train Accuracy: 0.8834, Validation Accuracy: 0.8686, Loss: 0.1196
Epoch 176 Batch  190/269 - Train Accuracy: 0.8730, Validation Accuracy: 0.8665, Loss: 0.1176
Epoch 176 Batch  200/269 - Train Accuracy: 0.8523, Validation Accuracy: 0.8647, Loss: 0.1402
Epoch 176 Batch  210/269 - Train Accuracy: 0.8674, Validation Accuracy: 0.8686, Loss: 0.1315
Epoch 176 Batch  220/269 - Train Accuracy: 0.8666, Validation Accuracy: 0.8614, Loss: 0.1211
Epoch 176 Batch  230/269 - Train Accuracy: 0.8533, Validation Accuracy: 0.8651, Loss: 0.1236
Epoch 176 Batch  240/269 - Train Accuracy: 0.8758, Validation Accuracy: 0.8628, Loss: 0.1129
Epoch 176 Batch  250/269 - Train Accuracy: 0.8728, Validation Accuracy: 0.8709, Loss: 0.1334
Epoch 176 Batch  260/269 - Train Accuracy: 0.8572, Validation Accuracy: 0.8730, Loss: 0.1314
Epoch 177 Batch   10/269 - Train Accuracy: 0.8633, Validation Accuracy: 0.8693, Loss: 0.1196
Epoch 177 Batch   20/269 - Train Accuracy: 0.8529, Validation Accuracy: 0.8651, Loss: 0.1196
Epoch 177 Batch   30/269 - Train Accuracy: 0.8633, Validation Accuracy: 0.8728, Loss: 0.1243
Epoch 177 Batch   40/269 - Train Accuracy: 0.8500, Validation Accuracy: 0.8683, Loss: 0.1341
Epoch 177 Batch   50/269 - Train Accuracy: 0.8438, Validation Accuracy: 0.8719, Loss: 0.1388
Epoch 177 Batch   60/269 - Train Accuracy: 0.8682, Validation Accuracy: 0.8750, Loss: 0.1098
Epoch 177 Batch   70/269 - Train Accuracy: 0.8771, Validation Accuracy: 0.8702, Loss: 0.1226
Epoch 177 Batch   80/269 - Train Accuracy: 0.8638, Validation Accuracy: 0.8680, Loss: 0.1242
Epoch 177 Batch   90/269 - Train Accuracy: 0.8653, Validation Accuracy: 0.8686, Loss: 0.1349
Epoch 177 Batch  100/269 - Train Accuracy: 0.8770, Validation Accuracy: 0.8714, Loss: 0.1212
Epoch 177 Batch  110/269 - Train Accuracy: 0.8631, Validation Accuracy: 0.8685, Loss: 0.1318
Epoch 177 Batch  120/269 - Train Accuracy: 0.8640, Validation Accuracy: 0.8724, Loss: 0.1411
Epoch 177 Batch  130/269 - Train Accuracy: 0.8466, Validation Accuracy: 0.8684, Loss: 0.1323
Epoch 177 Batch  140/269 - Train Accuracy: 0.8592, Validation Accuracy: 0.8708, Loss: 0.1276
Epoch 177 Batch  150/269 - Train Accuracy: 0.8657, Validation Accuracy: 0.8644, Loss: 0.1276
Epoch 177 Batch  160/269 - Train Accuracy: 0.8690, Validation Accuracy: 0.8697, Loss: 0.1278
Epoch 177 Batch  170/269 - Train Accuracy: 0.8618, Validation Accuracy: 0.8661, Loss: 0.1180
Epoch 177 Batch  180/269 - Train Accuracy: 0.8810, Validation Accuracy: 0.8642, Loss: 0.1224
Epoch 177 Batch  190/269 - Train Accuracy: 0.8736, Validation Accuracy: 0.8708, Loss: 0.1245
Epoch 177 Batch  200/269 - Train Accuracy: 0.8557, Validation Accuracy: 0.8684, Loss: 0.1305
Epoch 177 Batch  210/269 - Train Accuracy: 0.8721, Validation Accuracy: 0.8615, Loss: 0.1280
Epoch 177 Batch  220/269 - Train Accuracy: 0.8655, Validation Accuracy: 0.8641, Loss: 0.1233
Epoch 177 Batch  230/269 - Train Accuracy: 0.8554, Validation Accuracy: 0.8604, Loss: 0.1230
Epoch 177 Batch  240/269 - Train Accuracy: 0.8781, Validation Accuracy: 0.8654, Loss: 0.1131
Epoch 177 Batch  250/269 - Train Accuracy: 0.8722, Validation Accuracy: 0.8699, Loss: 0.1274
Epoch 177 Batch  260/269 - Train Accuracy: 0.8563, Validation Accuracy: 0.8706, Loss: 0.1354
Epoch 178 Batch   10/269 - Train Accuracy: 0.8670, Validation Accuracy: 0.8616, Loss: 0.1125
Epoch 178 Batch   20/269 - Train Accuracy: 0.8522, Validation Accuracy: 0.8675, Loss: 0.1205
Epoch 178 Batch   30/269 - Train Accuracy: 0.8665, Validation Accuracy: 0.8711, Loss: 0.1189
Epoch 178 Batch   40/269 - Train Accuracy: 0.8500, Validation Accuracy: 0.8682, Loss: 0.1458
Epoch 178 Batch   50/269 - Train Accuracy: 0.8447, Validation Accuracy: 0.8720, Loss: 0.1346
Epoch 178 Batch   60/269 - Train Accuracy: 0.8699, Validation Accuracy: 0.8704, Loss: 0.1063
Epoch 178 Batch   70/269 - Train Accuracy: 0.8725, Validation Accuracy: 0.8677, Loss: 0.1245
Epoch 178 Batch   80/269 - Train Accuracy: 0.8634, Validation Accuracy: 0.8683, Loss: 0.1298
Epoch 178 Batch   90/269 - Train Accuracy: 0.8616, Validation Accuracy: 0.8695, Loss: 0.1368
Epoch 178 Batch  100/269 - Train Accuracy: 0.8795, Validation Accuracy: 0.8645, Loss: 0.1269
Epoch 178 Batch  110/269 - Train Accuracy: 0.8527, Validation Accuracy: 0.8684, Loss: 0.1336
Epoch 178 Batch  120/269 - Train Accuracy: 0.8730, Validation Accuracy: 0.8725, Loss: 0.1287
Epoch 178 Batch  130/269 - Train Accuracy: 0.8523, Validation Accuracy: 0.8737, Loss: 0.1339
Epoch 178 Batch  140/269 - Train Accuracy: 0.8594, Validation Accuracy: 0.8654, Loss: 0.1330
Epoch 178 Batch  150/269 - Train Accuracy: 0.8672, Validation Accuracy: 0.8652, Loss: 0.1209
Epoch 178 Batch  160/269 - Train Accuracy: 0.8714, Validation Accuracy: 0.8691, Loss: 0.1371
Epoch 178 Batch  170/269 - Train Accuracy: 0.8628, Validation Accuracy: 0.8783, Loss: 0.1249
Epoch 178 Batch  180/269 - Train Accuracy: 0.8871, Validation Accuracy: 0.8671, Loss: 0.1229
Epoch 178 Batch  190/269 - Train Accuracy: 0.8790, Validation Accuracy: 0.8722, Loss: 0.1273
Epoch 178 Batch  200/269 - Train Accuracy: 0.8579, Validation Accuracy: 0.8679, Loss: 0.1284
Epoch 178 Batch  210/269 - Train Accuracy: 0.8688, Validation Accuracy: 0.8624, Loss: 0.1265
Epoch 178 Batch  220/269 - Train Accuracy: 0.8690, Validation Accuracy: 0.8676, Loss: 0.1227
Epoch 178 Batch  230/269 - Train Accuracy: 0.8555, Validation Accuracy: 0.8655, Loss: 0.1258
Epoch 178 Batch  240/269 - Train Accuracy: 0.8719, Validation Accuracy: 0.8635, Loss: 0.1138
Epoch 178 Batch  250/269 - Train Accuracy: 0.8725, Validation Accuracy: 0.8687, Loss: 0.1274
Epoch 178 Batch  260/269 - Train Accuracy: 0.8545, Validation Accuracy: 0.8689, Loss: 0.1329
Epoch 179 Batch   10/269 - Train Accuracy: 0.8703, Validation Accuracy: 0.8676, Loss: 0.1229
Epoch 179 Batch   20/269 - Train Accuracy: 0.8617, Validation Accuracy: 0.8616, Loss: 0.1235
Epoch 179 Batch   30/269 - Train Accuracy: 0.8627, Validation Accuracy: 0.8690, Loss: 0.1256
Epoch 179 Batch   40/269 - Train Accuracy: 0.8512, Validation Accuracy: 0.8734, Loss: 0.1322
Epoch 179 Batch   50/269 - Train Accuracy: 0.8433, Validation Accuracy: 0.8738, Loss: 0.1346
Epoch 179 Batch   60/269 - Train Accuracy: 0.8704, Validation Accuracy: 0.8706, Loss: 0.1145
Epoch 179 Batch   70/269 - Train Accuracy: 0.8767, Validation Accuracy: 0.8714, Loss: 0.1269
Epoch 179 Batch   80/269 - Train Accuracy: 0.8664, Validation Accuracy: 0.8664, Loss: 0.1213
Epoch 179 Batch   90/269 - Train Accuracy: 0.8609, Validation Accuracy: 0.8587, Loss: 0.1389
Epoch 179 Batch  100/269 - Train Accuracy: 0.8759, Validation Accuracy: 0.8677, Loss: 0.1161
Epoch 179 Batch  110/269 - Train Accuracy: 0.8548, Validation Accuracy: 0.8655, Loss: 0.1334
Epoch 179 Batch  120/269 - Train Accuracy: 0.8681, Validation Accuracy: 0.8685, Loss: 0.1384
Epoch 179 Batch  130/269 - Train Accuracy: 0.8551, Validation Accuracy: 0.8714, Loss: 0.1307
Epoch 179 Batch  140/269 - Train Accuracy: 0.8613, Validation Accuracy: 0.8677, Loss: 0.1354
Epoch 179 Batch  150/269 - Train Accuracy: 0.8686, Validation Accuracy: 0.8644, Loss: 0.1278
Epoch 179 Batch  160/269 - Train Accuracy: 0.8637, Validation Accuracy: 0.8681, Loss: 0.1201
Epoch 179 Batch  170/269 - Train Accuracy: 0.8596, Validation Accuracy: 0.8699, Loss: 0.1237
Epoch 179 Batch  180/269 - Train Accuracy: 0.8868, Validation Accuracy: 0.8682, Loss: 0.1103
Epoch 179 Batch  190/269 - Train Accuracy: 0.8737, Validation Accuracy: 0.8745, Loss: 0.1203
Epoch 179 Batch  200/269 - Train Accuracy: 0.8518, Validation Accuracy: 0.8715, Loss: 0.1180
Epoch 179 Batch  210/269 - Train Accuracy: 0.8694, Validation Accuracy: 0.8625, Loss: 0.1273
Epoch 179 Batch  220/269 - Train Accuracy: 0.8699, Validation Accuracy: 0.8624, Loss: 0.1214
Epoch 179 Batch  230/269 - Train Accuracy: 0.8591, Validation Accuracy: 0.8709, Loss: 0.1194
Epoch 179 Batch  240/269 - Train Accuracy: 0.8771, Validation Accuracy: 0.8708, Loss: 0.1120
Epoch 179 Batch  250/269 - Train Accuracy: 0.8752, Validation Accuracy: 0.8721, Loss: 0.1206
Epoch 179 Batch  260/269 - Train Accuracy: 0.8527, Validation Accuracy: 0.8693, Loss: 0.1423
Epoch 180 Batch   10/269 - Train Accuracy: 0.8697, Validation Accuracy: 0.8627, Loss: 0.1164
Epoch 180 Batch   20/269 - Train Accuracy: 0.8511, Validation Accuracy: 0.8660, Loss: 0.1139
Epoch 180 Batch   30/269 - Train Accuracy: 0.8646, Validation Accuracy: 0.8685, Loss: 0.1180
Epoch 180 Batch   40/269 - Train Accuracy: 0.8453, Validation Accuracy: 0.8699, Loss: 0.1437
Epoch 180 Batch   50/269 - Train Accuracy: 0.8455, Validation Accuracy: 0.8737, Loss: 0.1358
Epoch 180 Batch   60/269 - Train Accuracy: 0.8634, Validation Accuracy: 0.8707, Loss: 0.1186
Epoch 180 Batch   70/269 - Train Accuracy: 0.8755, Validation Accuracy: 0.8651, Loss: 0.1322
Epoch 180 Batch   80/269 - Train Accuracy: 0.8613, Validation Accuracy: 0.8652, Loss: 0.1341
Epoch 180 Batch   90/269 - Train Accuracy: 0.8601, Validation Accuracy: 0.8622, Loss: 0.1354
Epoch 180 Batch  100/269 - Train Accuracy: 0.8766, Validation Accuracy: 0.8717, Loss: 0.1401
Epoch 180 Batch  110/269 - Train Accuracy: 0.8533, Validation Accuracy: 0.8684, Loss: 0.1317
Epoch 180 Batch  120/269 - Train Accuracy: 0.8670, Validation Accuracy: 0.8642, Loss: 0.1391
Epoch 180 Batch  130/269 - Train Accuracy: 0.8465, Validation Accuracy: 0.8713, Loss: 0.1302
Epoch 180 Batch  140/269 - Train Accuracy: 0.8595, Validation Accuracy: 0.8650, Loss: 0.1329
Epoch 180 Batch  150/269 - Train Accuracy: 0.8652, Validation Accuracy: 0.8608, Loss: 0.1325
Epoch 180 Batch  160/269 - Train Accuracy: 0.8719, Validation Accuracy: 0.8703, Loss: 0.1268
Epoch 180 Batch  170/269 - Train Accuracy: 0.8588, Validation Accuracy: 0.8681, Loss: 0.1249
Epoch 180 Batch  180/269 - Train Accuracy: 0.8870, Validation Accuracy: 0.8687, Loss: 0.1143
Epoch 180 Batch  190/269 - Train Accuracy: 0.8710, Validation Accuracy: 0.8706, Loss: 0.1230
Epoch 180 Batch  200/269 - Train Accuracy: 0.8521, Validation Accuracy: 0.8638, Loss: 0.1218
Epoch 180 Batch  210/269 - Train Accuracy: 0.8720, Validation Accuracy: 0.8666, Loss: 0.1282
Epoch 180 Batch  220/269 - Train Accuracy: 0.8631, Validation Accuracy: 0.8659, Loss: 0.1205
Epoch 180 Batch  230/269 - Train Accuracy: 0.8585, Validation Accuracy: 0.8707, Loss: 0.1129
Epoch 180 Batch  240/269 - Train Accuracy: 0.8758, Validation Accuracy: 0.8685, Loss: 0.1091
Epoch 180 Batch  250/269 - Train Accuracy: 0.8771, Validation Accuracy: 0.8735, Loss: 0.1273
Epoch 180 Batch  260/269 - Train Accuracy: 0.8553, Validation Accuracy: 0.8690, Loss: 0.1294
Epoch 181 Batch   10/269 - Train Accuracy: 0.8685, Validation Accuracy: 0.8636, Loss: 0.1132
Epoch 181 Batch   20/269 - Train Accuracy: 0.8580, Validation Accuracy: 0.8674, Loss: 0.1251
Epoch 181 Batch   30/269 - Train Accuracy: 0.8677, Validation Accuracy: 0.8738, Loss: 0.1174
Epoch 181 Batch   40/269 - Train Accuracy: 0.8544, Validation Accuracy: 0.8693, Loss: 0.1369
Epoch 181 Batch   50/269 - Train Accuracy: 0.8416, Validation Accuracy: 0.8722, Loss: 0.1421
Epoch 181 Batch   60/269 - Train Accuracy: 0.8722, Validation Accuracy: 0.8716, Loss: 0.1055
Epoch 181 Batch   70/269 - Train Accuracy: 0.8759, Validation Accuracy: 0.8675, Loss: 0.1249
Epoch 181 Batch   80/269 - Train Accuracy: 0.8650, Validation Accuracy: 0.8698, Loss: 0.1163
Epoch 181 Batch   90/269 - Train Accuracy: 0.8659, Validation Accuracy: 0.8668, Loss: 0.1285
Epoch 181 Batch  100/269 - Train Accuracy: 0.8783, Validation Accuracy: 0.8678, Loss: 0.1185
Epoch 181 Batch  110/269 - Train Accuracy: 0.8564, Validation Accuracy: 0.8699, Loss: 0.1272
Epoch 181 Batch  120/269 - Train Accuracy: 0.8695, Validation Accuracy: 0.8661, Loss: 0.1369
Epoch 181 Batch  130/269 - Train Accuracy: 0.8508, Validation Accuracy: 0.8681, Loss: 0.1299
Epoch 181 Batch  140/269 - Train Accuracy: 0.8583, Validation Accuracy: 0.8698, Loss: 0.1322
Epoch 181 Batch  150/269 - Train Accuracy: 0.8676, Validation Accuracy: 0.8675, Loss: 0.1366
Epoch 181 Batch  160/269 - Train Accuracy: 0.8688, Validation Accuracy: 0.8702, Loss: 0.1243
Epoch 181 Batch  170/269 - Train Accuracy: 0.8613, Validation Accuracy: 0.8704, Loss: 0.1226
Epoch 181 Batch  180/269 - Train Accuracy: 0.8838, Validation Accuracy: 0.8687, Loss: 0.1163
Epoch 181 Batch  190/269 - Train Accuracy: 0.8744, Validation Accuracy: 0.8651, Loss: 0.1236
Epoch 181 Batch  200/269 - Train Accuracy: 0.8615, Validation Accuracy: 0.8716, Loss: 0.1239
Epoch 181 Batch  210/269 - Train Accuracy: 0.8727, Validation Accuracy: 0.8661, Loss: 0.1150
Epoch 181 Batch  220/269 - Train Accuracy: 0.8620, Validation Accuracy: 0.8637, Loss: 0.1232
Epoch 181 Batch  230/269 - Train Accuracy: 0.8557, Validation Accuracy: 0.8679, Loss: 0.1193
Epoch 181 Batch  240/269 - Train Accuracy: 0.8764, Validation Accuracy: 0.8624, Loss: 0.1111
Epoch 181 Batch  250/269 - Train Accuracy: 0.8738, Validation Accuracy: 0.8648, Loss: 0.1334
Epoch 181 Batch  260/269 - Train Accuracy: 0.8467, Validation Accuracy: 0.8673, Loss: 0.1338
Epoch 182 Batch   10/269 - Train Accuracy: 0.8670, Validation Accuracy: 0.8655, Loss: 0.1227
Epoch 182 Batch   20/269 - Train Accuracy: 0.8492, Validation Accuracy: 0.8609, Loss: 0.1234
Epoch 182 Batch   30/269 - Train Accuracy: 0.8679, Validation Accuracy: 0.8665, Loss: 0.1242
Epoch 182 Batch   40/269 - Train Accuracy: 0.8566, Validation Accuracy: 0.8691, Loss: 0.1440
Epoch 182 Batch   50/269 - Train Accuracy: 0.8400, Validation Accuracy: 0.8685, Loss: 0.1386
Epoch 182 Batch   60/269 - Train Accuracy: 0.8751, Validation Accuracy: 0.8735, Loss: 0.1149
Epoch 182 Batch   70/269 - Train Accuracy: 0.8690, Validation Accuracy: 0.8691, Loss: 0.1250
Epoch 182 Batch   80/269 - Train Accuracy: 0.8680, Validation Accuracy: 0.8681, Loss: 0.1211
Epoch 182 Batch   90/269 - Train Accuracy: 0.8673, Validation Accuracy: 0.8678, Loss: 0.1348
Epoch 182 Batch  100/269 - Train Accuracy: 0.8846, Validation Accuracy: 0.8730, Loss: 0.1185
Epoch 182 Batch  110/269 - Train Accuracy: 0.8575, Validation Accuracy: 0.8670, Loss: 0.1363
Epoch 182 Batch  120/269 - Train Accuracy: 0.8693, Validation Accuracy: 0.8721, Loss: 0.1258
Epoch 182 Batch  130/269 - Train Accuracy: 0.8559, Validation Accuracy: 0.8693, Loss: 0.1342
Epoch 182 Batch  140/269 - Train Accuracy: 0.8557, Validation Accuracy: 0.8606, Loss: 0.1386
Epoch 182 Batch  150/269 - Train Accuracy: 0.8625, Validation Accuracy: 0.8691, Loss: 0.1303
Epoch 182 Batch  160/269 - Train Accuracy: 0.8717, Validation Accuracy: 0.8684, Loss: 0.1219
Epoch 182 Batch  170/269 - Train Accuracy: 0.8633, Validation Accuracy: 0.8738, Loss: 0.1230
Epoch 182 Batch  180/269 - Train Accuracy: 0.8855, Validation Accuracy: 0.8655, Loss: 0.1212
Epoch 182 Batch  190/269 - Train Accuracy: 0.8763, Validation Accuracy: 0.8727, Loss: 0.1175
Epoch 182 Batch  200/269 - Train Accuracy: 0.8603, Validation Accuracy: 0.8684, Loss: 0.1137
Epoch 182 Batch  210/269 - Train Accuracy: 0.8673, Validation Accuracy: 0.8618, Loss: 0.1257
Epoch 182 Batch  220/269 - Train Accuracy: 0.8634, Validation Accuracy: 0.8671, Loss: 0.1240
Epoch 182 Batch  230/269 - Train Accuracy: 0.8572, Validation Accuracy: 0.8662, Loss: 0.1176
Epoch 182 Batch  240/269 - Train Accuracy: 0.8742, Validation Accuracy: 0.8690, Loss: 0.1125
Epoch 182 Batch  250/269 - Train Accuracy: 0.8749, Validation Accuracy: 0.8700, Loss: 0.1248
Epoch 182 Batch  260/269 - Train Accuracy: 0.8565, Validation Accuracy: 0.8648, Loss: 0.1307
Epoch 183 Batch   10/269 - Train Accuracy: 0.8686, Validation Accuracy: 0.8627, Loss: 0.1148
Epoch 183 Batch   20/269 - Train Accuracy: 0.8497, Validation Accuracy: 0.8712, Loss: 0.1211
Epoch 183 Batch   30/269 - Train Accuracy: 0.8664, Validation Accuracy: 0.8721, Loss: 0.1269
Epoch 183 Batch   40/269 - Train Accuracy: 0.8562, Validation Accuracy: 0.8751, Loss: 0.1355
Epoch 183 Batch   50/269 - Train Accuracy: 0.8429, Validation Accuracy: 0.8734, Loss: 0.1397
Epoch 183 Batch   60/269 - Train Accuracy: 0.8738, Validation Accuracy: 0.8741, Loss: 0.1177
Epoch 183 Batch   70/269 - Train Accuracy: 0.8736, Validation Accuracy: 0.8691, Loss: 0.1299
Epoch 183 Batch   80/269 - Train Accuracy: 0.8674, Validation Accuracy: 0.8729, Loss: 0.1207
Epoch 183 Batch   90/269 - Train Accuracy: 0.8706, Validation Accuracy: 0.8644, Loss: 0.1344
Epoch 183 Batch  100/269 - Train Accuracy: 0.8828, Validation Accuracy: 0.8732, Loss: 0.1388
Epoch 183 Batch  110/269 - Train Accuracy: 0.8544, Validation Accuracy: 0.8663, Loss: 0.1353
Epoch 183 Batch  120/269 - Train Accuracy: 0.8736, Validation Accuracy: 0.8691, Loss: 0.1307
Epoch 183 Batch  130/269 - Train Accuracy: 0.8498, Validation Accuracy: 0.8735, Loss: 0.1342
Epoch 183 Batch  140/269 - Train Accuracy: 0.8629, Validation Accuracy: 0.8751, Loss: 0.1347
Epoch 183 Batch  150/269 - Train Accuracy: 0.8686, Validation Accuracy: 0.8685, Loss: 0.1241
Epoch 183 Batch  160/269 - Train Accuracy: 0.8676, Validation Accuracy: 0.8652, Loss: 0.1258
Epoch 183 Batch  170/269 - Train Accuracy: 0.8635, Validation Accuracy: 0.8697, Loss: 0.1175
Epoch 183 Batch  180/269 - Train Accuracy: 0.8838, Validation Accuracy: 0.8660, Loss: 0.1163
Epoch 183 Batch  190/269 - Train Accuracy: 0.8735, Validation Accuracy: 0.8730, Loss: 0.1112
Epoch 183 Batch  200/269 - Train Accuracy: 0.8588, Validation Accuracy: 0.8751, Loss: 0.1244
Epoch 183 Batch  210/269 - Train Accuracy: 0.8673, Validation Accuracy: 0.8605, Loss: 0.1219
Epoch 183 Batch  220/269 - Train Accuracy: 0.8622, Validation Accuracy: 0.8644, Loss: 0.1157
Epoch 183 Batch  230/269 - Train Accuracy: 0.8629, Validation Accuracy: 0.8708, Loss: 0.1222
Epoch 183 Batch  240/269 - Train Accuracy: 0.8745, Validation Accuracy: 0.8689, Loss: 0.1106
Epoch 183 Batch  250/269 - Train Accuracy: 0.8759, Validation Accuracy: 0.8746, Loss: 0.1211
Epoch 183 Batch  260/269 - Train Accuracy: 0.8629, Validation Accuracy: 0.8706, Loss: 0.1343
Epoch 184 Batch   10/269 - Train Accuracy: 0.8707, Validation Accuracy: 0.8640, Loss: 0.1144
Epoch 184 Batch   20/269 - Train Accuracy: 0.8591, Validation Accuracy: 0.8679, Loss: 0.1212
Epoch 184 Batch   30/269 - Train Accuracy: 0.8643, Validation Accuracy: 0.8728, Loss: 0.1218
Epoch 184 Batch   40/269 - Train Accuracy: 0.8521, Validation Accuracy: 0.8745, Loss: 0.1330
Epoch 184 Batch   50/269 - Train Accuracy: 0.8443, Validation Accuracy: 0.8725, Loss: 0.1361
Epoch 184 Batch   60/269 - Train Accuracy: 0.8699, Validation Accuracy: 0.8738, Loss: 0.1139
Epoch 184 Batch   70/269 - Train Accuracy: 0.8766, Validation Accuracy: 0.8737, Loss: 0.1254
Epoch 184 Batch   80/269 - Train Accuracy: 0.8661, Validation Accuracy: 0.8715, Loss: 0.1273
Epoch 184 Batch   90/269 - Train Accuracy: 0.8667, Validation Accuracy: 0.8663, Loss: 0.1311
Epoch 184 Batch  100/269 - Train Accuracy: 0.8777, Validation Accuracy: 0.8751, Loss: 0.1224
Epoch 184 Batch  110/269 - Train Accuracy: 0.8556, Validation Accuracy: 0.8712, Loss: 0.1272
Epoch 184 Batch  120/269 - Train Accuracy: 0.8648, Validation Accuracy: 0.8665, Loss: 0.1308
Epoch 184 Batch  130/269 - Train Accuracy: 0.8520, Validation Accuracy: 0.8688, Loss: 0.1349
Epoch 184 Batch  140/269 - Train Accuracy: 0.8549, Validation Accuracy: 0.8641, Loss: 0.1358
Epoch 184 Batch  150/269 - Train Accuracy: 0.8687, Validation Accuracy: 0.8713, Loss: 0.1232
Epoch 184 Batch  160/269 - Train Accuracy: 0.8654, Validation Accuracy: 0.8635, Loss: 0.1206
Epoch 184 Batch  170/269 - Train Accuracy: 0.8614, Validation Accuracy: 0.8685, Loss: 0.1156
Epoch 184 Batch  180/269 - Train Accuracy: 0.8890, Validation Accuracy: 0.8694, Loss: 0.1183
Epoch 184 Batch  190/269 - Train Accuracy: 0.8743, Validation Accuracy: 0.8746, Loss: 0.1174
Epoch 184 Batch  200/269 - Train Accuracy: 0.8660, Validation Accuracy: 0.8706, Loss: 0.1140
Epoch 184 Batch  210/269 - Train Accuracy: 0.8662, Validation Accuracy: 0.8646, Loss: 0.1244
Epoch 184 Batch  220/269 - Train Accuracy: 0.8683, Validation Accuracy: 0.8639, Loss: 0.1278
Epoch 184 Batch  230/269 - Train Accuracy: 0.8563, Validation Accuracy: 0.8663, Loss: 0.1191
Epoch 184 Batch  240/269 - Train Accuracy: 0.8753, Validation Accuracy: 0.8649, Loss: 0.1105
Epoch 184 Batch  250/269 - Train Accuracy: 0.8768, Validation Accuracy: 0.8713, Loss: 0.1250
Epoch 184 Batch  260/269 - Train Accuracy: 0.8577, Validation Accuracy: 0.8685, Loss: 0.1279
Epoch 185 Batch   10/269 - Train Accuracy: 0.8730, Validation Accuracy: 0.8681, Loss: 0.1246
Epoch 185 Batch   20/269 - Train Accuracy: 0.8604, Validation Accuracy: 0.8651, Loss: 0.1192
Epoch 185 Batch   30/269 - Train Accuracy: 0.8675, Validation Accuracy: 0.8699, Loss: 0.1187
Epoch 185 Batch   40/269 - Train Accuracy: 0.8573, Validation Accuracy: 0.8691, Loss: 0.1332
Epoch 185 Batch   50/269 - Train Accuracy: 0.8449, Validation Accuracy: 0.8683, Loss: 0.1404
Epoch 185 Batch   60/269 - Train Accuracy: 0.8733, Validation Accuracy: 0.8729, Loss: 0.1347
Epoch 185 Batch   70/269 - Train Accuracy: 0.8821, Validation Accuracy: 0.8719, Loss: 0.1238
Epoch 185 Batch   80/269 - Train Accuracy: 0.8662, Validation Accuracy: 0.8714, Loss: 0.1280
Epoch 185 Batch   90/269 - Train Accuracy: 0.8699, Validation Accuracy: 0.8643, Loss: 0.1380
Epoch 185 Batch  100/269 - Train Accuracy: 0.8780, Validation Accuracy: 0.8700, Loss: 0.1342
Epoch 185 Batch  110/269 - Train Accuracy: 0.8543, Validation Accuracy: 0.8720, Loss: 0.1312
Epoch 185 Batch  120/269 - Train Accuracy: 0.8655, Validation Accuracy: 0.8705, Loss: 0.1369
Epoch 185 Batch  130/269 - Train Accuracy: 0.8475, Validation Accuracy: 0.8683, Loss: 0.1326
Epoch 185 Batch  140/269 - Train Accuracy: 0.8564, Validation Accuracy: 0.8616, Loss: 0.1408
Epoch 185 Batch  150/269 - Train Accuracy: 0.8608, Validation Accuracy: 0.8625, Loss: 0.1280
Epoch 185 Batch  160/269 - Train Accuracy: 0.8685, Validation Accuracy: 0.8672, Loss: 0.1236
Epoch 185 Batch  170/269 - Train Accuracy: 0.8614, Validation Accuracy: 0.8728, Loss: 0.1189
Epoch 185 Batch  180/269 - Train Accuracy: 0.8897, Validation Accuracy: 0.8691, Loss: 0.1175
Epoch 185 Batch  190/269 - Train Accuracy: 0.8730, Validation Accuracy: 0.8728, Loss: 0.1238
Epoch 185 Batch  200/269 - Train Accuracy: 0.8651, Validation Accuracy: 0.8668, Loss: 0.1069
Epoch 185 Batch  210/269 - Train Accuracy: 0.8647, Validation Accuracy: 0.8701, Loss: 0.1439
Epoch 185 Batch  220/269 - Train Accuracy: 0.8622, Validation Accuracy: 0.8661, Loss: 0.1261
Epoch 185 Batch  230/269 - Train Accuracy: 0.8582, Validation Accuracy: 0.8683, Loss: 0.1238
Epoch 185 Batch  240/269 - Train Accuracy: 0.8731, Validation Accuracy: 0.8664, Loss: 0.1190
Epoch 185 Batch  250/269 - Train Accuracy: 0.8752, Validation Accuracy: 0.8745, Loss: 0.1193
Epoch 185 Batch  260/269 - Train Accuracy: 0.8545, Validation Accuracy: 0.8748, Loss: 0.1300
Epoch 186 Batch   10/269 - Train Accuracy: 0.8729, Validation Accuracy: 0.8617, Loss: 0.1119
Epoch 186 Batch   20/269 - Train Accuracy: 0.8581, Validation Accuracy: 0.8642, Loss: 0.1216
Epoch 186 Batch   30/269 - Train Accuracy: 0.8633, Validation Accuracy: 0.8714, Loss: 0.1192
Epoch 186 Batch   40/269 - Train Accuracy: 0.8521, Validation Accuracy: 0.8746, Loss: 0.1376
Epoch 186 Batch   50/269 - Train Accuracy: 0.8445, Validation Accuracy: 0.8708, Loss: 0.1280
Epoch 186 Batch   60/269 - Train Accuracy: 0.8706, Validation Accuracy: 0.8713, Loss: 0.1137
Epoch 186 Batch   70/269 - Train Accuracy: 0.8735, Validation Accuracy: 0.8685, Loss: 0.1181
Epoch 186 Batch   80/269 - Train Accuracy: 0.8658, Validation Accuracy: 0.8671, Loss: 0.1243
Epoch 186 Batch   90/269 - Train Accuracy: 0.8639, Validation Accuracy: 0.8654, Loss: 0.1259
Epoch 186 Batch  100/269 - Train Accuracy: 0.8816, Validation Accuracy: 0.8681, Loss: 0.1206
Epoch 186 Batch  110/269 - Train Accuracy: 0.8575, Validation Accuracy: 0.8649, Loss: 0.1257
Epoch 186 Batch  120/269 - Train Accuracy: 0.8737, Validation Accuracy: 0.8667, Loss: 0.1392
Epoch 186 Batch  130/269 - Train Accuracy: 0.8531, Validation Accuracy: 0.8725, Loss: 0.1259
Epoch 186 Batch  140/269 - Train Accuracy: 0.8570, Validation Accuracy: 0.8675, Loss: 0.1319
Epoch 186 Batch  150/269 - Train Accuracy: 0.8645, Validation Accuracy: 0.8701, Loss: 0.1211
Epoch 186 Batch  160/269 - Train Accuracy: 0.8681, Validation Accuracy: 0.8650, Loss: 0.1265
Epoch 186 Batch  170/269 - Train Accuracy: 0.8617, Validation Accuracy: 0.8732, Loss: 0.1217
Epoch 186 Batch  180/269 - Train Accuracy: 0.8926, Validation Accuracy: 0.8691, Loss: 0.1208
Epoch 186 Batch  190/269 - Train Accuracy: 0.8761, Validation Accuracy: 0.8714, Loss: 0.1193
Epoch 186 Batch  200/269 - Train Accuracy: 0.8623, Validation Accuracy: 0.8663, Loss: 0.1272
Epoch 186 Batch  210/269 - Train Accuracy: 0.8715, Validation Accuracy: 0.8667, Loss: 0.1267
Epoch 186 Batch  220/269 - Train Accuracy: 0.8613, Validation Accuracy: 0.8651, Loss: 0.1241
Epoch 186 Batch  230/269 - Train Accuracy: 0.8587, Validation Accuracy: 0.8690, Loss: 0.1231
Epoch 186 Batch  240/269 - Train Accuracy: 0.8698, Validation Accuracy: 0.8634, Loss: 0.1139
Epoch 186 Batch  250/269 - Train Accuracy: 0.8746, Validation Accuracy: 0.8665, Loss: 0.1219
Epoch 186 Batch  260/269 - Train Accuracy: 0.8529, Validation Accuracy: 0.8691, Loss: 0.1344
Epoch 187 Batch   10/269 - Train Accuracy: 0.8761, Validation Accuracy: 0.8649, Loss: 0.1186
Epoch 187 Batch   20/269 - Train Accuracy: 0.8626, Validation Accuracy: 0.8711, Loss: 0.1202
Epoch 187 Batch   30/269 - Train Accuracy: 0.8645, Validation Accuracy: 0.8710, Loss: 0.1176
Epoch 187 Batch   40/269 - Train Accuracy: 0.8508, Validation Accuracy: 0.8752, Loss: 0.1374
Epoch 187 Batch   50/269 - Train Accuracy: 0.8433, Validation Accuracy: 0.8769, Loss: 0.1341
Epoch 187 Batch   60/269 - Train Accuracy: 0.8681, Validation Accuracy: 0.8699, Loss: 0.1167
Epoch 187 Batch   70/269 - Train Accuracy: 0.8778, Validation Accuracy: 0.8759, Loss: 0.1233
Epoch 187 Batch   80/269 - Train Accuracy: 0.8702, Validation Accuracy: 0.8736, Loss: 0.1138
Epoch 187 Batch   90/269 - Train Accuracy: 0.8636, Validation Accuracy: 0.8631, Loss: 0.1222
Epoch 187 Batch  100/269 - Train Accuracy: 0.8770, Validation Accuracy: 0.8657, Loss: 0.1160
Epoch 187 Batch  110/269 - Train Accuracy: 0.8562, Validation Accuracy: 0.8716, Loss: 0.1249
Epoch 187 Batch  120/269 - Train Accuracy: 0.8658, Validation Accuracy: 0.8723, Loss: 0.1271
Epoch 187 Batch  130/269 - Train Accuracy: 0.8543, Validation Accuracy: 0.8738, Loss: 0.1278
Epoch 187 Batch  140/269 - Train Accuracy: 0.8578, Validation Accuracy: 0.8699, Loss: 0.1298
Epoch 187 Batch  150/269 - Train Accuracy: 0.8641, Validation Accuracy: 0.8693, Loss: 0.1228
Epoch 187 Batch  160/269 - Train Accuracy: 0.8730, Validation Accuracy: 0.8685, Loss: 0.1177
Epoch 187 Batch  170/269 - Train Accuracy: 0.8689, Validation Accuracy: 0.8697, Loss: 0.1156
Epoch 187 Batch  180/269 - Train Accuracy: 0.8841, Validation Accuracy: 0.8668, Loss: 0.1121
Epoch 187 Batch  190/269 - Train Accuracy: 0.8734, Validation Accuracy: 0.8729, Loss: 0.1155
Epoch 187 Batch  200/269 - Train Accuracy: 0.8610, Validation Accuracy: 0.8705, Loss: 0.1172
Epoch 187 Batch  210/269 - Train Accuracy: 0.8688, Validation Accuracy: 0.8710, Loss: 0.1242
Epoch 187 Batch  220/269 - Train Accuracy: 0.8657, Validation Accuracy: 0.8664, Loss: 0.1192
Epoch 187 Batch  230/269 - Train Accuracy: 0.8592, Validation Accuracy: 0.8701, Loss: 0.1207
Epoch 187 Batch  240/269 - Train Accuracy: 0.8747, Validation Accuracy: 0.8675, Loss: 0.1116
Epoch 187 Batch  250/269 - Train Accuracy: 0.8789, Validation Accuracy: 0.8705, Loss: 0.1134
Epoch 187 Batch  260/269 - Train Accuracy: 0.8569, Validation Accuracy: 0.8683, Loss: 0.1262
Epoch 188 Batch   10/269 - Train Accuracy: 0.8676, Validation Accuracy: 0.8611, Loss: 0.1112
Epoch 188 Batch   20/269 - Train Accuracy: 0.8622, Validation Accuracy: 0.8694, Loss: 0.1166
Epoch 188 Batch   30/269 - Train Accuracy: 0.8648, Validation Accuracy: 0.8716, Loss: 0.1214
Epoch 188 Batch   40/269 - Train Accuracy: 0.8523, Validation Accuracy: 0.8726, Loss: 0.1364
Epoch 188 Batch   50/269 - Train Accuracy: 0.8485, Validation Accuracy: 0.8721, Loss: 0.1337
Epoch 188 Batch   60/269 - Train Accuracy: 0.8758, Validation Accuracy: 0.8717, Loss: 0.1142
Epoch 188 Batch   70/269 - Train Accuracy: 0.8767, Validation Accuracy: 0.8740, Loss: 0.1200
Epoch 188 Batch   80/269 - Train Accuracy: 0.8647, Validation Accuracy: 0.8707, Loss: 0.1196
Epoch 188 Batch   90/269 - Train Accuracy: 0.8722, Validation Accuracy: 0.8680, Loss: 0.1287
Epoch 188 Batch  100/269 - Train Accuracy: 0.8784, Validation Accuracy: 0.8722, Loss: 0.1235
Epoch 188 Batch  110/269 - Train Accuracy: 0.8568, Validation Accuracy: 0.8746, Loss: 0.1316
Epoch 188 Batch  120/269 - Train Accuracy: 0.8653, Validation Accuracy: 0.8651, Loss: 0.1274
Epoch 188 Batch  130/269 - Train Accuracy: 0.8520, Validation Accuracy: 0.8753, Loss: 0.1313
Epoch 188 Batch  140/269 - Train Accuracy: 0.8592, Validation Accuracy: 0.8638, Loss: 0.1336
Epoch 188 Batch  150/269 - Train Accuracy: 0.8634, Validation Accuracy: 0.8737, Loss: 0.1235
Epoch 188 Batch  160/269 - Train Accuracy: 0.8721, Validation Accuracy: 0.8667, Loss: 0.1240
Epoch 188 Batch  170/269 - Train Accuracy: 0.8651, Validation Accuracy: 0.8757, Loss: 0.1245
Epoch 188 Batch  180/269 - Train Accuracy: 0.8865, Validation Accuracy: 0.8669, Loss: 0.1138
Epoch 188 Batch  190/269 - Train Accuracy: 0.8727, Validation Accuracy: 0.8733, Loss: 0.1190
Epoch 188 Batch  200/269 - Train Accuracy: 0.8563, Validation Accuracy: 0.8673, Loss: 0.1135
Epoch 188 Batch  210/269 - Train Accuracy: 0.8646, Validation Accuracy: 0.8722, Loss: 0.1132
Epoch 188 Batch  220/269 - Train Accuracy: 0.8734, Validation Accuracy: 0.8686, Loss: 0.1203
Epoch 188 Batch  230/269 - Train Accuracy: 0.8559, Validation Accuracy: 0.8700, Loss: 0.1208
Epoch 188 Batch  240/269 - Train Accuracy: 0.8772, Validation Accuracy: 0.8667, Loss: 0.1060
Epoch 188 Batch  250/269 - Train Accuracy: 0.8782, Validation Accuracy: 0.8718, Loss: 0.1249
Epoch 188 Batch  260/269 - Train Accuracy: 0.8484, Validation Accuracy: 0.8718, Loss: 0.1435
Epoch 189 Batch   10/269 - Train Accuracy: 0.8706, Validation Accuracy: 0.8668, Loss: 0.1312
Epoch 189 Batch   20/269 - Train Accuracy: 0.8593, Validation Accuracy: 0.8694, Loss: 0.1291
Epoch 189 Batch   30/269 - Train Accuracy: 0.8601, Validation Accuracy: 0.8717, Loss: 0.1150
Epoch 189 Batch   40/269 - Train Accuracy: 0.8504, Validation Accuracy: 0.8701, Loss: 0.1391
Epoch 189 Batch   50/269 - Train Accuracy: 0.8426, Validation Accuracy: 0.8739, Loss: 0.1303
Epoch 189 Batch   60/269 - Train Accuracy: 0.8684, Validation Accuracy: 0.8707, Loss: 0.1115
Epoch 189 Batch   70/269 - Train Accuracy: 0.8761, Validation Accuracy: 0.8713, Loss: 0.1217
Epoch 189 Batch   80/269 - Train Accuracy: 0.8639, Validation Accuracy: 0.8614, Loss: 0.1178
Epoch 189 Batch   90/269 - Train Accuracy: 0.8647, Validation Accuracy: 0.8637, Loss: 0.1393
Epoch 189 Batch  100/269 - Train Accuracy: 0.8766, Validation Accuracy: 0.8720, Loss: 0.1221
Epoch 189 Batch  110/269 - Train Accuracy: 0.8580, Validation Accuracy: 0.8690, Loss: 0.1195
Epoch 189 Batch  120/269 - Train Accuracy: 0.8725, Validation Accuracy: 0.8720, Loss: 0.1354
Epoch 189 Batch  130/269 - Train Accuracy: 0.8570, Validation Accuracy: 0.8742, Loss: 0.1290
Epoch 189 Batch  140/269 - Train Accuracy: 0.8627, Validation Accuracy: 0.8733, Loss: 0.1253
Epoch 189 Batch  150/269 - Train Accuracy: 0.8647, Validation Accuracy: 0.8721, Loss: 0.1225
Epoch 189 Batch  160/269 - Train Accuracy: 0.8753, Validation Accuracy: 0.8714, Loss: 0.1222
Epoch 189 Batch  170/269 - Train Accuracy: 0.8664, Validation Accuracy: 0.8758, Loss: 0.1137
Epoch 189 Batch  180/269 - Train Accuracy: 0.8899, Validation Accuracy: 0.8670, Loss: 0.1200
Epoch 189 Batch  190/269 - Train Accuracy: 0.8759, Validation Accuracy: 0.8694, Loss: 0.1210
Epoch 189 Batch  200/269 - Train Accuracy: 0.8602, Validation Accuracy: 0.8654, Loss: 0.1203
Epoch 189 Batch  210/269 - Train Accuracy: 0.8711, Validation Accuracy: 0.8704, Loss: 0.1150
Epoch 189 Batch  220/269 - Train Accuracy: 0.8739, Validation Accuracy: 0.8689, Loss: 0.1229
Epoch 189 Batch  230/269 - Train Accuracy: 0.8551, Validation Accuracy: 0.8745, Loss: 0.1200
Epoch 189 Batch  240/269 - Train Accuracy: 0.8741, Validation Accuracy: 0.8642, Loss: 0.1037
Epoch 189 Batch  250/269 - Train Accuracy: 0.8803, Validation Accuracy: 0.8729, Loss: 0.1171
Epoch 189 Batch  260/269 - Train Accuracy: 0.8563, Validation Accuracy: 0.8667, Loss: 0.1187
Epoch 190 Batch   10/269 - Train Accuracy: 0.8679, Validation Accuracy: 0.8692, Loss: 0.1090
Epoch 190 Batch   20/269 - Train Accuracy: 0.8612, Validation Accuracy: 0.8662, Loss: 0.1243
Epoch 190 Batch   30/269 - Train Accuracy: 0.8650, Validation Accuracy: 0.8706, Loss: 0.1155
Epoch 190 Batch   40/269 - Train Accuracy: 0.8549, Validation Accuracy: 0.8730, Loss: 0.1282
Epoch 190 Batch   50/269 - Train Accuracy: 0.8474, Validation Accuracy: 0.8723, Loss: 0.1348
Epoch 190 Batch   60/269 - Train Accuracy: 0.8722, Validation Accuracy: 0.8720, Loss: 0.1071
Epoch 190 Batch   70/269 - Train Accuracy: 0.8755, Validation Accuracy: 0.8707, Loss: 0.1259
Epoch 190 Batch   80/269 - Train Accuracy: 0.8694, Validation Accuracy: 0.8740, Loss: 0.1174
Epoch 190 Batch   90/269 - Train Accuracy: 0.8646, Validation Accuracy: 0.8660, Loss: 0.1259
Epoch 190 Batch  100/269 - Train Accuracy: 0.8785, Validation Accuracy: 0.8716, Loss: 0.1120
Epoch 190 Batch  110/269 - Train Accuracy: 0.8589, Validation Accuracy: 0.8765, Loss: 0.1241
Epoch 190 Batch  120/269 - Train Accuracy: 0.8686, Validation Accuracy: 0.8690, Loss: 0.1273
Epoch 190 Batch  130/269 - Train Accuracy: 0.8538, Validation Accuracy: 0.8704, Loss: 0.1252
Epoch 190 Batch  140/269 - Train Accuracy: 0.8556, Validation Accuracy: 0.8707, Loss: 0.1340
Epoch 190 Batch  150/269 - Train Accuracy: 0.8661, Validation Accuracy: 0.8719, Loss: 0.1220
Epoch 190 Batch  160/269 - Train Accuracy: 0.8702, Validation Accuracy: 0.8729, Loss: 0.1259
Epoch 190 Batch  170/269 - Train Accuracy: 0.8677, Validation Accuracy: 0.8750, Loss: 0.1165
Epoch 190 Batch  180/269 - Train Accuracy: 0.8891, Validation Accuracy: 0.8700, Loss: 0.1128
Epoch 190 Batch  190/269 - Train Accuracy: 0.8759, Validation Accuracy: 0.8699, Loss: 0.1235
Epoch 190 Batch  200/269 - Train Accuracy: 0.8590, Validation Accuracy: 0.8762, Loss: 0.1121
Epoch 190 Batch  210/269 - Train Accuracy: 0.8689, Validation Accuracy: 0.8770, Loss: 0.1180
Epoch 190 Batch  220/269 - Train Accuracy: 0.8626, Validation Accuracy: 0.8648, Loss: 0.1139
Epoch 190 Batch  230/269 - Train Accuracy: 0.8505, Validation Accuracy: 0.8676, Loss: 0.1215
Epoch 190 Batch  240/269 - Train Accuracy: 0.8799, Validation Accuracy: 0.8701, Loss: 0.1078
Epoch 190 Batch  250/269 - Train Accuracy: 0.8795, Validation Accuracy: 0.8681, Loss: 0.1162
Epoch 190 Batch  260/269 - Train Accuracy: 0.8574, Validation Accuracy: 0.8712, Loss: 0.1192
Epoch 191 Batch   10/269 - Train Accuracy: 0.8698, Validation Accuracy: 0.8657, Loss: 0.1120
Epoch 191 Batch   20/269 - Train Accuracy: 0.8580, Validation Accuracy: 0.8707, Loss: 0.1253
Epoch 191 Batch   30/269 - Train Accuracy: 0.8649, Validation Accuracy: 0.8736, Loss: 0.1178
Epoch 191 Batch   40/269 - Train Accuracy: 0.8475, Validation Accuracy: 0.8714, Loss: 0.1351
Epoch 191 Batch   50/269 - Train Accuracy: 0.8440, Validation Accuracy: 0.8751, Loss: 0.1398
Epoch 191 Batch   60/269 - Train Accuracy: 0.8776, Validation Accuracy: 0.8722, Loss: 0.1102
Epoch 191 Batch   70/269 - Train Accuracy: 0.8747, Validation Accuracy: 0.8754, Loss: 0.1293
Epoch 191 Batch   80/269 - Train Accuracy: 0.8642, Validation Accuracy: 0.8665, Loss: 0.1196
Epoch 191 Batch   90/269 - Train Accuracy: 0.8655, Validation Accuracy: 0.8643, Loss: 0.1308
Epoch 191 Batch  100/269 - Train Accuracy: 0.8806, Validation Accuracy: 0.8687, Loss: 0.1178
Epoch 191 Batch  110/269 - Train Accuracy: 0.8599, Validation Accuracy: 0.8659, Loss: 0.1258
Epoch 191 Batch  120/269 - Train Accuracy: 0.8724, Validation Accuracy: 0.8682, Loss: 0.1294
Epoch 191 Batch  130/269 - Train Accuracy: 0.8553, Validation Accuracy: 0.8747, Loss: 0.1296
Epoch 191 Batch  140/269 - Train Accuracy: 0.8622, Validation Accuracy: 0.8648, Loss: 0.1242
Epoch 191 Batch  150/269 - Train Accuracy: 0.8673, Validation Accuracy: 0.8721, Loss: 0.1169
Epoch 191 Batch  160/269 - Train Accuracy: 0.8728, Validation Accuracy: 0.8659, Loss: 0.1260
Epoch 191 Batch  170/269 - Train Accuracy: 0.8670, Validation Accuracy: 0.8742, Loss: 0.1196
Epoch 191 Batch  180/269 - Train Accuracy: 0.8855, Validation Accuracy: 0.8698, Loss: 0.1209
Epoch 191 Batch  190/269 - Train Accuracy: 0.8771, Validation Accuracy: 0.8732, Loss: 0.1179
Epoch 191 Batch  200/269 - Train Accuracy: 0.8570, Validation Accuracy: 0.8748, Loss: 0.1212
Epoch 191 Batch  210/269 - Train Accuracy: 0.8717, Validation Accuracy: 0.8701, Loss: 0.1163
Epoch 191 Batch  220/269 - Train Accuracy: 0.8650, Validation Accuracy: 0.8744, Loss: 0.1213
Epoch 191 Batch  230/269 - Train Accuracy: 0.8604, Validation Accuracy: 0.8706, Loss: 0.1216
Epoch 191 Batch  240/269 - Train Accuracy: 0.8738, Validation Accuracy: 0.8697, Loss: 0.1191
Epoch 191 Batch  250/269 - Train Accuracy: 0.8740, Validation Accuracy: 0.8726, Loss: 0.1144
Epoch 191 Batch  260/269 - Train Accuracy: 0.8571, Validation Accuracy: 0.8726, Loss: 0.1311
Epoch 192 Batch   10/269 - Train Accuracy: 0.8709, Validation Accuracy: 0.8675, Loss: 0.1230
Epoch 192 Batch   20/269 - Train Accuracy: 0.8573, Validation Accuracy: 0.8685, Loss: 0.1189
Epoch 192 Batch   30/269 - Train Accuracy: 0.8669, Validation Accuracy: 0.8718, Loss: 0.1193
Epoch 192 Batch   40/269 - Train Accuracy: 0.8562, Validation Accuracy: 0.8772, Loss: 0.1332
Epoch 192 Batch   50/269 - Train Accuracy: 0.8431, Validation Accuracy: 0.8683, Loss: 0.1362
Epoch 192 Batch   60/269 - Train Accuracy: 0.8715, Validation Accuracy: 0.8727, Loss: 0.1063
Epoch 192 Batch   70/269 - Train Accuracy: 0.8760, Validation Accuracy: 0.8736, Loss: 0.1191
Epoch 192 Batch   80/269 - Train Accuracy: 0.8717, Validation Accuracy: 0.8683, Loss: 0.1167
Epoch 192 Batch   90/269 - Train Accuracy: 0.8621, Validation Accuracy: 0.8675, Loss: 0.1234
Epoch 192 Batch  100/269 - Train Accuracy: 0.8807, Validation Accuracy: 0.8707, Loss: 0.1137
Epoch 192 Batch  110/269 - Train Accuracy: 0.8583, Validation Accuracy: 0.8691, Loss: 0.1240
Epoch 192 Batch  120/269 - Train Accuracy: 0.8654, Validation Accuracy: 0.8707, Loss: 0.1320
Epoch 192 Batch  130/269 - Train Accuracy: 0.8516, Validation Accuracy: 0.8726, Loss: 0.1289
Epoch 192 Batch  140/269 - Train Accuracy: 0.8598, Validation Accuracy: 0.8627, Loss: 0.1294
Epoch 192 Batch  150/269 - Train Accuracy: 0.8678, Validation Accuracy: 0.8637, Loss: 0.1201
Epoch 192 Batch  160/269 - Train Accuracy: 0.8717, Validation Accuracy: 0.8674, Loss: 0.1171
Epoch 192 Batch  170/269 - Train Accuracy: 0.8656, Validation Accuracy: 0.8729, Loss: 0.1129
Epoch 192 Batch  180/269 - Train Accuracy: 0.8857, Validation Accuracy: 0.8698, Loss: 0.1106
Epoch 192 Batch  190/269 - Train Accuracy: 0.8765, Validation Accuracy: 0.8714, Loss: 0.1150
Epoch 192 Batch  200/269 - Train Accuracy: 0.8587, Validation Accuracy: 0.8667, Loss: 0.1162
Epoch 192 Batch  210/269 - Train Accuracy: 0.8725, Validation Accuracy: 0.8721, Loss: 0.1210
Epoch 192 Batch  220/269 - Train Accuracy: 0.8648, Validation Accuracy: 0.8690, Loss: 0.1181
Epoch 192 Batch  230/269 - Train Accuracy: 0.8614, Validation Accuracy: 0.8719, Loss: 0.1144
Epoch 192 Batch  240/269 - Train Accuracy: 0.8767, Validation Accuracy: 0.8627, Loss: 0.1090
Epoch 192 Batch  250/269 - Train Accuracy: 0.8746, Validation Accuracy: 0.8675, Loss: 0.1152
Epoch 192 Batch  260/269 - Train Accuracy: 0.8561, Validation Accuracy: 0.8765, Loss: 0.1344
Epoch 193 Batch   10/269 - Train Accuracy: 0.8716, Validation Accuracy: 0.8672, Loss: 0.1139
Epoch 193 Batch   20/269 - Train Accuracy: 0.8616, Validation Accuracy: 0.8724, Loss: 0.1168
Epoch 193 Batch   30/269 - Train Accuracy: 0.8618, Validation Accuracy: 0.8729, Loss: 0.1182
Epoch 193 Batch   40/269 - Train Accuracy: 0.8519, Validation Accuracy: 0.8759, Loss: 0.1289
Epoch 193 Batch   50/269 - Train Accuracy: 0.8451, Validation Accuracy: 0.8754, Loss: 0.1278
Epoch 193 Batch   60/269 - Train Accuracy: 0.8699, Validation Accuracy: 0.8707, Loss: 0.1068
Epoch 193 Batch   70/269 - Train Accuracy: 0.8763, Validation Accuracy: 0.8721, Loss: 0.1220
Epoch 193 Batch   80/269 - Train Accuracy: 0.8676, Validation Accuracy: 0.8702, Loss: 0.1126
Epoch 193 Batch   90/269 - Train Accuracy: 0.8672, Validation Accuracy: 0.8657, Loss: 0.1277
Epoch 193 Batch  100/269 - Train Accuracy: 0.8805, Validation Accuracy: 0.8754, Loss: 0.1149
Epoch 193 Batch  110/269 - Train Accuracy: 0.8563, Validation Accuracy: 0.8710, Loss: 0.1219
Epoch 193 Batch  120/269 - Train Accuracy: 0.8666, Validation Accuracy: 0.8675, Loss: 0.1304
Epoch 193 Batch  130/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8711, Loss: 0.1246
Epoch 193 Batch  140/269 - Train Accuracy: 0.8623, Validation Accuracy: 0.8675, Loss: 0.1262
Epoch 193 Batch  150/269 - Train Accuracy: 0.8702, Validation Accuracy: 0.8710, Loss: 0.1253
Epoch 193 Batch  160/269 - Train Accuracy: 0.8710, Validation Accuracy: 0.8691, Loss: 0.1216
Epoch 193 Batch  170/269 - Train Accuracy: 0.8687, Validation Accuracy: 0.8686, Loss: 0.1126
Epoch 193 Batch  180/269 - Train Accuracy: 0.8860, Validation Accuracy: 0.8708, Loss: 0.1123
Epoch 193 Batch  190/269 - Train Accuracy: 0.8766, Validation Accuracy: 0.8627, Loss: 0.1197
Epoch 193 Batch  200/269 - Train Accuracy: 0.8552, Validation Accuracy: 0.8603, Loss: 0.1184
Epoch 193 Batch  210/269 - Train Accuracy: 0.8716, Validation Accuracy: 0.8717, Loss: 0.1195
Epoch 193 Batch  220/269 - Train Accuracy: 0.8647, Validation Accuracy: 0.8662, Loss: 0.1268
Epoch 193 Batch  230/269 - Train Accuracy: 0.8550, Validation Accuracy: 0.8724, Loss: 0.1200
Epoch 193 Batch  240/269 - Train Accuracy: 0.8781, Validation Accuracy: 0.8669, Loss: 0.1063
Epoch 193 Batch  250/269 - Train Accuracy: 0.8793, Validation Accuracy: 0.8683, Loss: 0.1104
Epoch 193 Batch  260/269 - Train Accuracy: 0.8540, Validation Accuracy: 0.8694, Loss: 0.1306
Epoch 194 Batch   10/269 - Train Accuracy: 0.8701, Validation Accuracy: 0.8668, Loss: 0.1130
Epoch 194 Batch   20/269 - Train Accuracy: 0.8652, Validation Accuracy: 0.8691, Loss: 0.1208
Epoch 194 Batch   30/269 - Train Accuracy: 0.8656, Validation Accuracy: 0.8765, Loss: 0.1271
Epoch 194 Batch   40/269 - Train Accuracy: 0.8472, Validation Accuracy: 0.8751, Loss: 0.1301
Epoch 194 Batch   50/269 - Train Accuracy: 0.8471, Validation Accuracy: 0.8779, Loss: 0.1310
Epoch 194 Batch   60/269 - Train Accuracy: 0.8749, Validation Accuracy: 0.8686, Loss: 0.1133
Epoch 194 Batch   70/269 - Train Accuracy: 0.8756, Validation Accuracy: 0.8730, Loss: 0.1262
Epoch 194 Batch   80/269 - Train Accuracy: 0.8723, Validation Accuracy: 0.8719, Loss: 0.1120
Epoch 194 Batch   90/269 - Train Accuracy: 0.8673, Validation Accuracy: 0.8676, Loss: 0.1282
Epoch 194 Batch  100/269 - Train Accuracy: 0.8766, Validation Accuracy: 0.8708, Loss: 0.1164
Epoch 194 Batch  110/269 - Train Accuracy: 0.8581, Validation Accuracy: 0.8685, Loss: 0.1218
Epoch 194 Batch  120/269 - Train Accuracy: 0.8704, Validation Accuracy: 0.8740, Loss: 0.1290
Epoch 194 Batch  130/269 - Train Accuracy: 0.8476, Validation Accuracy: 0.8701, Loss: 0.1286
Epoch 194 Batch  140/269 - Train Accuracy: 0.8591, Validation Accuracy: 0.8650, Loss: 0.1269
Epoch 194 Batch  150/269 - Train Accuracy: 0.8661, Validation Accuracy: 0.8633, Loss: 0.1245
Epoch 194 Batch  160/269 - Train Accuracy: 0.8730, Validation Accuracy: 0.8778, Loss: 0.1317
Epoch 194 Batch  170/269 - Train Accuracy: 0.8679, Validation Accuracy: 0.8750, Loss: 0.1124
Epoch 194 Batch  180/269 - Train Accuracy: 0.8863, Validation Accuracy: 0.8691, Loss: 0.1129
Epoch 194 Batch  190/269 - Train Accuracy: 0.8745, Validation Accuracy: 0.8770, Loss: 0.1173
Epoch 194 Batch  200/269 - Train Accuracy: 0.8574, Validation Accuracy: 0.8743, Loss: 0.1173
Epoch 194 Batch  210/269 - Train Accuracy: 0.8695, Validation Accuracy: 0.8714, Loss: 0.1123
Epoch 194 Batch  220/269 - Train Accuracy: 0.8675, Validation Accuracy: 0.8693, Loss: 0.1150
Epoch 194 Batch  230/269 - Train Accuracy: 0.8565, Validation Accuracy: 0.8732, Loss: 0.1168
Epoch 194 Batch  240/269 - Train Accuracy: 0.8770, Validation Accuracy: 0.8735, Loss: 0.1033
Epoch 194 Batch  250/269 - Train Accuracy: 0.8763, Validation Accuracy: 0.8779, Loss: 0.1141
Epoch 194 Batch  260/269 - Train Accuracy: 0.8536, Validation Accuracy: 0.8750, Loss: 0.1288
Epoch 195 Batch   10/269 - Train Accuracy: 0.8694, Validation Accuracy: 0.8658, Loss: 0.1115
Epoch 195 Batch   20/269 - Train Accuracy: 0.8600, Validation Accuracy: 0.8691, Loss: 0.1184
Epoch 195 Batch   30/269 - Train Accuracy: 0.8650, Validation Accuracy: 0.8674, Loss: 0.1114
Epoch 195 Batch   40/269 - Train Accuracy: 0.8572, Validation Accuracy: 0.8784, Loss: 0.1229
Epoch 195 Batch   50/269 - Train Accuracy: 0.8443, Validation Accuracy: 0.8719, Loss: 0.1237
Epoch 195 Batch   60/269 - Train Accuracy: 0.8775, Validation Accuracy: 0.8762, Loss: 0.1145
Epoch 195 Batch   70/269 - Train Accuracy: 0.8770, Validation Accuracy: 0.8776, Loss: 0.1129
Epoch 195 Batch   80/269 - Train Accuracy: 0.8717, Validation Accuracy: 0.8687, Loss: 0.1186
Epoch 195 Batch   90/269 - Train Accuracy: 0.8728, Validation Accuracy: 0.8675, Loss: 0.1280
Epoch 195 Batch  100/269 - Train Accuracy: 0.8780, Validation Accuracy: 0.8652, Loss: 0.1184
Epoch 195 Batch  110/269 - Train Accuracy: 0.8544, Validation Accuracy: 0.8689, Loss: 0.1249
Epoch 195 Batch  120/269 - Train Accuracy: 0.8728, Validation Accuracy: 0.8749, Loss: 0.1325
Epoch 195 Batch  130/269 - Train Accuracy: 0.8565, Validation Accuracy: 0.8780, Loss: 0.1291
Epoch 195 Batch  140/269 - Train Accuracy: 0.8555, Validation Accuracy: 0.8697, Loss: 0.1274
Epoch 195 Batch  150/269 - Train Accuracy: 0.8618, Validation Accuracy: 0.8604, Loss: 0.1205
Epoch 195 Batch  160/269 - Train Accuracy: 0.8783, Validation Accuracy: 0.8719, Loss: 0.1215
Epoch 195 Batch  170/269 - Train Accuracy: 0.8629, Validation Accuracy: 0.8698, Loss: 0.1142
Epoch 195 Batch  180/269 - Train Accuracy: 0.8876, Validation Accuracy: 0.8707, Loss: 0.1158
Epoch 195 Batch  190/269 - Train Accuracy: 0.8771, Validation Accuracy: 0.8741, Loss: 0.1172
Epoch 195 Batch  200/269 - Train Accuracy: 0.8582, Validation Accuracy: 0.8715, Loss: 0.1129
Epoch 195 Batch  210/269 - Train Accuracy: 0.8726, Validation Accuracy: 0.8642, Loss: 0.1206
Epoch 195 Batch  220/269 - Train Accuracy: 0.8701, Validation Accuracy: 0.8634, Loss: 0.1138
Epoch 195 Batch  230/269 - Train Accuracy: 0.8557, Validation Accuracy: 0.8683, Loss: 0.1187
Epoch 195 Batch  240/269 - Train Accuracy: 0.8690, Validation Accuracy: 0.8670, Loss: 0.1042
Epoch 195 Batch  250/269 - Train Accuracy: 0.8749, Validation Accuracy: 0.8758, Loss: 0.1149
Epoch 195 Batch  260/269 - Train Accuracy: 0.8551, Validation Accuracy: 0.8670, Loss: 0.1341
Epoch 196 Batch   10/269 - Train Accuracy: 0.8729, Validation Accuracy: 0.8616, Loss: 0.1301
Epoch 196 Batch   20/269 - Train Accuracy: 0.8537, Validation Accuracy: 0.8658, Loss: 0.1327
Epoch 196 Batch   30/269 - Train Accuracy: 0.8622, Validation Accuracy: 0.8741, Loss: 0.1196
Epoch 196 Batch   40/269 - Train Accuracy: 0.8542, Validation Accuracy: 0.8760, Loss: 0.1272
Epoch 196 Batch   50/269 - Train Accuracy: 0.8509, Validation Accuracy: 0.8752, Loss: 0.1302
Epoch 196 Batch   60/269 - Train Accuracy: 0.8746, Validation Accuracy: 0.8784, Loss: 0.1059
Epoch 196 Batch   70/269 - Train Accuracy: 0.8814, Validation Accuracy: 0.8740, Loss: 0.1111
Epoch 196 Batch   80/269 - Train Accuracy: 0.8703, Validation Accuracy: 0.8675, Loss: 0.1222
Epoch 196 Batch   90/269 - Train Accuracy: 0.8681, Validation Accuracy: 0.8668, Loss: 0.1257
Epoch 196 Batch  100/269 - Train Accuracy: 0.8783, Validation Accuracy: 0.8715, Loss: 0.1195
Epoch 196 Batch  110/269 - Train Accuracy: 0.8570, Validation Accuracy: 0.8689, Loss: 0.1173
Epoch 196 Batch  120/269 - Train Accuracy: 0.8663, Validation Accuracy: 0.8692, Loss: 0.1238
Epoch 196 Batch  130/269 - Train Accuracy: 0.8569, Validation Accuracy: 0.8736, Loss: 0.1241
Epoch 196 Batch  140/269 - Train Accuracy: 0.8618, Validation Accuracy: 0.8701, Loss: 0.1238
Epoch 196 Batch  150/269 - Train Accuracy: 0.8638, Validation Accuracy: 0.8670, Loss: 0.1215
Epoch 196 Batch  160/269 - Train Accuracy: 0.8759, Validation Accuracy: 0.8726, Loss: 0.1213
Epoch 196 Batch  170/269 - Train Accuracy: 0.8583, Validation Accuracy: 0.8676, Loss: 0.1150
Epoch 196 Batch  180/269 - Train Accuracy: 0.8918, Validation Accuracy: 0.8692, Loss: 0.1154
Epoch 196 Batch  190/269 - Train Accuracy: 0.8764, Validation Accuracy: 0.8754, Loss: 0.1132
Epoch 196 Batch  200/269 - Train Accuracy: 0.8652, Validation Accuracy: 0.8735, Loss: 0.1174
Epoch 196 Batch  210/269 - Train Accuracy: 0.8717, Validation Accuracy: 0.8665, Loss: 0.1149
Epoch 196 Batch  220/269 - Train Accuracy: 0.8669, Validation Accuracy: 0.8683, Loss: 0.1211
Epoch 196 Batch  230/269 - Train Accuracy: 0.8578, Validation Accuracy: 0.8633, Loss: 0.1201
Epoch 196 Batch  240/269 - Train Accuracy: 0.8771, Validation Accuracy: 0.8739, Loss: 0.1024
Epoch 196 Batch  250/269 - Train Accuracy: 0.8803, Validation Accuracy: 0.8756, Loss: 0.1217
Epoch 196 Batch  260/269 - Train Accuracy: 0.8623, Validation Accuracy: 0.8772, Loss: 0.1223
Epoch 197 Batch   10/269 - Train Accuracy: 0.8688, Validation Accuracy: 0.8672, Loss: 0.1298
Epoch 197 Batch   20/269 - Train Accuracy: 0.8600, Validation Accuracy: 0.8694, Loss: 0.1184
Epoch 197 Batch   30/269 - Train Accuracy: 0.8685, Validation Accuracy: 0.8727, Loss: 0.1129
Epoch 197 Batch   40/269 - Train Accuracy: 0.8512, Validation Accuracy: 0.8765, Loss: 0.1404
Epoch 197 Batch   50/269 - Train Accuracy: 0.8498, Validation Accuracy: 0.8722, Loss: 0.1346
Epoch 197 Batch   60/269 - Train Accuracy: 0.8764, Validation Accuracy: 0.8738, Loss: 0.1253
Epoch 197 Batch   70/269 - Train Accuracy: 0.8739, Validation Accuracy: 0.8689, Loss: 0.1159
Epoch 197 Batch   80/269 - Train Accuracy: 0.8695, Validation Accuracy: 0.8728, Loss: 0.1131
Epoch 197 Batch   90/269 - Train Accuracy: 0.8803, Validation Accuracy: 0.8742, Loss: 0.1236
Epoch 197 Batch  100/269 - Train Accuracy: 0.8806, Validation Accuracy: 0.8753, Loss: 0.1206
Epoch 197 Batch  110/269 - Train Accuracy: 0.8599, Validation Accuracy: 0.8666, Loss: 0.1191
Epoch 197 Batch  120/269 - Train Accuracy: 0.8745, Validation Accuracy: 0.8692, Loss: 0.1301
Epoch 197 Batch  130/269 - Train Accuracy: 0.8517, Validation Accuracy: 0.8711, Loss: 0.1205
Epoch 197 Batch  140/269 - Train Accuracy: 0.8664, Validation Accuracy: 0.8721, Loss: 0.1241
Epoch 197 Batch  150/269 - Train Accuracy: 0.8623, Validation Accuracy: 0.8728, Loss: 0.1140
Epoch 197 Batch  160/269 - Train Accuracy: 0.8713, Validation Accuracy: 0.8705, Loss: 0.1281
Epoch 197 Batch  170/269 - Train Accuracy: 0.8612, Validation Accuracy: 0.8746, Loss: 0.1181
Epoch 197 Batch  180/269 - Train Accuracy: 0.8828, Validation Accuracy: 0.8716, Loss: 0.1088
Epoch 197 Batch  190/269 - Train Accuracy: 0.8786, Validation Accuracy: 0.8704, Loss: 0.1174
Epoch 197 Batch  200/269 - Train Accuracy: 0.8548, Validation Accuracy: 0.8702, Loss: 0.1170
Epoch 197 Batch  210/269 - Train Accuracy: 0.8694, Validation Accuracy: 0.8703, Loss: 0.1172
Epoch 197 Batch  220/269 - Train Accuracy: 0.8731, Validation Accuracy: 0.8700, Loss: 0.1171
Epoch 197 Batch  230/269 - Train Accuracy: 0.8601, Validation Accuracy: 0.8745, Loss: 0.1233
Epoch 197 Batch  240/269 - Train Accuracy: 0.8719, Validation Accuracy: 0.8693, Loss: 0.1157
Epoch 197 Batch  250/269 - Train Accuracy: 0.8722, Validation Accuracy: 0.8717, Loss: 0.1184
Epoch 197 Batch  260/269 - Train Accuracy: 0.8549, Validation Accuracy: 0.8707, Loss: 0.1310
Epoch 198 Batch   10/269 - Train Accuracy: 0.8748, Validation Accuracy: 0.8682, Loss: 0.1076
Epoch 198 Batch   20/269 - Train Accuracy: 0.8583, Validation Accuracy: 0.8738, Loss: 0.1213
Epoch 198 Batch   30/269 - Train Accuracy: 0.8660, Validation Accuracy: 0.8791, Loss: 0.1162
Epoch 198 Batch   40/269 - Train Accuracy: 0.8516, Validation Accuracy: 0.8731, Loss: 0.1243
Epoch 198 Batch   50/269 - Train Accuracy: 0.8468, Validation Accuracy: 0.8744, Loss: 0.1267
Epoch 198 Batch   60/269 - Train Accuracy: 0.8727, Validation Accuracy: 0.8758, Loss: 0.1139
Epoch 198 Batch   70/269 - Train Accuracy: 0.8772, Validation Accuracy: 0.8750, Loss: 0.1243
Epoch 198 Batch   80/269 - Train Accuracy: 0.8706, Validation Accuracy: 0.8721, Loss: 0.1152
Epoch 198 Batch   90/269 - Train Accuracy: 0.8752, Validation Accuracy: 0.8701, Loss: 0.1335
Epoch 198 Batch  100/269 - Train Accuracy: 0.8828, Validation Accuracy: 0.8784, Loss: 0.1134
Epoch 198 Batch  110/269 - Train Accuracy: 0.8581, Validation Accuracy: 0.8721, Loss: 0.1205
Epoch 198 Batch  120/269 - Train Accuracy: 0.8760, Validation Accuracy: 0.8718, Loss: 0.1374
Epoch 198 Batch  130/269 - Train Accuracy: 0.8470, Validation Accuracy: 0.8709, Loss: 0.1363
Epoch 198 Batch  140/269 - Train Accuracy: 0.8590, Validation Accuracy: 0.8716, Loss: 0.1331
Epoch 198 Batch  150/269 - Train Accuracy: 0.8654, Validation Accuracy: 0.8693, Loss: 0.1186
Epoch 198 Batch  160/269 - Train Accuracy: 0.8702, Validation Accuracy: 0.8712, Loss: 0.1271
Epoch 198 Batch  170/269 - Train Accuracy: 0.8667, Validation Accuracy: 0.8724, Loss: 0.1147
Epoch 198 Batch  180/269 - Train Accuracy: 0.8924, Validation Accuracy: 0.8708, Loss: 0.1106
Epoch 198 Batch  190/269 - Train Accuracy: 0.8792, Validation Accuracy: 0.8742, Loss: 0.1234
Epoch 198 Batch  200/269 - Train Accuracy: 0.8557, Validation Accuracy: 0.8731, Loss: 0.1235
Epoch 198 Batch  210/269 - Train Accuracy: 0.8681, Validation Accuracy: 0.8658, Loss: 0.1210
Epoch 198 Batch  220/269 - Train Accuracy: 0.8643, Validation Accuracy: 0.8690, Loss: 0.1145
Epoch 198 Batch  230/269 - Train Accuracy: 0.8565, Validation Accuracy: 0.8699, Loss: 0.1132
Epoch 198 Batch  240/269 - Train Accuracy: 0.8747, Validation Accuracy: 0.8667, Loss: 0.1094
Epoch 198 Batch  250/269 - Train Accuracy: 0.8764, Validation Accuracy: 0.8749, Loss: 0.1101
Epoch 198 Batch  260/269 - Train Accuracy: 0.8521, Validation Accuracy: 0.8712, Loss: 0.1347
Epoch 199 Batch   10/269 - Train Accuracy: 0.8640, Validation Accuracy: 0.8655, Loss: 0.1099
Epoch 199 Batch   20/269 - Train Accuracy: 0.8515, Validation Accuracy: 0.8699, Loss: 0.1161
Epoch 199 Batch   30/269 - Train Accuracy: 0.8629, Validation Accuracy: 0.8731, Loss: 0.1181
Epoch 199 Batch   40/269 - Train Accuracy: 0.8554, Validation Accuracy: 0.8775, Loss: 0.1367
Epoch 199 Batch   50/269 - Train Accuracy: 0.8470, Validation Accuracy: 0.8695, Loss: 0.1285
Epoch 199 Batch   60/269 - Train Accuracy: 0.8729, Validation Accuracy: 0.8714, Loss: 0.1051
Epoch 199 Batch   70/269 - Train Accuracy: 0.8786, Validation Accuracy: 0.8730, Loss: 0.1151
Epoch 199 Batch   80/269 - Train Accuracy: 0.8662, Validation Accuracy: 0.8771, Loss: 0.1164
Epoch 199 Batch   90/269 - Train Accuracy: 0.8754, Validation Accuracy: 0.8697, Loss: 0.1250
Epoch 199 Batch  100/269 - Train Accuracy: 0.8788, Validation Accuracy: 0.8691, Loss: 0.1144
Epoch 199 Batch  110/269 - Train Accuracy: 0.8582, Validation Accuracy: 0.8717, Loss: 0.1265
Epoch 199 Batch  120/269 - Train Accuracy: 0.8681, Validation Accuracy: 0.8692, Loss: 0.1191
Epoch 199 Batch  130/269 - Train Accuracy: 0.8544, Validation Accuracy: 0.8728, Loss: 0.1295
Epoch 199 Batch  140/269 - Train Accuracy: 0.8616, Validation Accuracy: 0.8637, Loss: 0.1225
Epoch 199 Batch  150/269 - Train Accuracy: 0.8655, Validation Accuracy: 0.8730, Loss: 0.1274
Epoch 199 Batch  160/269 - Train Accuracy: 0.8736, Validation Accuracy: 0.8647, Loss: 0.1228
Epoch 199 Batch  170/269 - Train Accuracy: 0.8582, Validation Accuracy: 0.8716, Loss: 0.1179
Epoch 199 Batch  180/269 - Train Accuracy: 0.8903, Validation Accuracy: 0.8714, Loss: 0.1198
Epoch 199 Batch  190/269 - Train Accuracy: 0.8754, Validation Accuracy: 0.8697, Loss: 0.1091
Epoch 199 Batch  200/269 - Train Accuracy: 0.8588, Validation Accuracy: 0.8705, Loss: 0.1136
Epoch 199 Batch  210/269 - Train Accuracy: 0.8688, Validation Accuracy: 0.8633, Loss: 0.1191
Epoch 199 Batch  220/269 - Train Accuracy: 0.8688, Validation Accuracy: 0.8632, Loss: 0.1172
Epoch 199 Batch  230/269 - Train Accuracy: 0.8589, Validation Accuracy: 0.8808, Loss: 0.1104
Epoch 199 Batch  240/269 - Train Accuracy: 0.8719, Validation Accuracy: 0.8682, Loss: 0.1087
Epoch 199 Batch  250/269 - Train Accuracy: 0.8769, Validation Accuracy: 0.8771, Loss: 0.1141
Epoch 199 Batch  260/269 - Train Accuracy: 0.8525, Validation Accuracy: 0.8742, Loss: 0.1263
Epoch 200 Batch   10/269 - Train Accuracy: 0.8708, Validation Accuracy: 0.8754, Loss: 0.1201
Epoch 200 Batch   20/269 - Train Accuracy: 0.8599, Validation Accuracy: 0.8690, Loss: 0.1189
Epoch 200 Batch   30/269 - Train Accuracy: 0.8636, Validation Accuracy: 0.8740, Loss: 0.1161
Epoch 200 Batch   40/269 - Train Accuracy: 0.8498, Validation Accuracy: 0.8737, Loss: 0.1278
Epoch 200 Batch   50/269 - Train Accuracy: 0.8486, Validation Accuracy: 0.8738, Loss: 0.1307
Epoch 200 Batch   60/269 - Train Accuracy: 0.8700, Validation Accuracy: 0.8699, Loss: 0.1066
Epoch 200 Batch   70/269 - Train Accuracy: 0.8732, Validation Accuracy: 0.8736, Loss: 0.1264
Epoch 200 Batch   80/269 - Train Accuracy: 0.8689, Validation Accuracy: 0.8751, Loss: 0.1179
Epoch 200 Batch   90/269 - Train Accuracy: 0.8720, Validation Accuracy: 0.8714, Loss: 0.1146
Epoch 200 Batch  100/269 - Train Accuracy: 0.8822, Validation Accuracy: 0.8728, Loss: 0.1153
Epoch 200 Batch  110/269 - Train Accuracy: 0.8612, Validation Accuracy: 0.8711, Loss: 0.1301
Epoch 200 Batch  120/269 - Train Accuracy: 0.8688, Validation Accuracy: 0.8743, Loss: 0.1222
Epoch 200 Batch  130/269 - Train Accuracy: 0.8554, Validation Accuracy: 0.8673, Loss: 0.1210
Epoch 200 Batch  140/269 - Train Accuracy: 0.8578, Validation Accuracy: 0.8754, Loss: 0.1354
Epoch 200 Batch  150/269 - Train Accuracy: 0.8654, Validation Accuracy: 0.8691, Loss: 0.1202
Epoch 200 Batch  160/269 - Train Accuracy: 0.8755, Validation Accuracy: 0.8717, Loss: 0.1124
Epoch 200 Batch  170/269 - Train Accuracy: 0.8611, Validation Accuracy: 0.8726, Loss: 0.1344
Epoch 200 Batch  180/269 - Train Accuracy: 0.8861, Validation Accuracy: 0.8706, Loss: 0.1105
Epoch 200 Batch  190/269 - Train Accuracy: 0.8734, Validation Accuracy: 0.8733, Loss: 0.1176
Epoch 200 Batch  200/269 - Train Accuracy: 0.8576, Validation Accuracy: 0.8685, Loss: 0.1194
Epoch 200 Batch  210/269 - Train Accuracy: 0.8664, Validation Accuracy: 0.8594, Loss: 0.1231
Epoch 200 Batch  220/269 - Train Accuracy: 0.8707, Validation Accuracy: 0.8676, Loss: 0.1142
Epoch 200 Batch  230/269 - Train Accuracy: 0.8587, Validation Accuracy: 0.8758, Loss: 0.1104
Epoch 200 Batch  240/269 - Train Accuracy: 0.8769, Validation Accuracy: 0.8685, Loss: 0.1061
Epoch 200 Batch  250/269 - Train Accuracy: 0.8781, Validation Accuracy: 0.8756, Loss: 0.1122
Epoch 200 Batch  260/269 - Train Accuracy: 0.8540, Validation Accuracy: 0.8722, Loss: 0.1334
Epoch 201 Batch   10/269 - Train Accuracy: 0.8729, Validation Accuracy: 0.8661, Loss: 0.1183
Epoch 201 Batch   20/269 - Train Accuracy: 0.8633, Validation Accuracy: 0.8704, Loss: 0.1142
Epoch 201 Batch   30/269 - Train Accuracy: 0.8628, Validation Accuracy: 0.8692, Loss: 0.1218
Epoch 201 Batch   40/269 - Train Accuracy: 0.8510, Validation Accuracy: 0.8765, Loss: 0.1219
Epoch 201 Batch   50/269 - Train Accuracy: 0.8502, Validation Accuracy: 0.8705, Loss: 0.1286
Epoch 201 Batch   60/269 - Train Accuracy: 0.8769, Validation Accuracy: 0.8690, Loss: 0.1188
Epoch 201 Batch   70/269 - Train Accuracy: 0.8770, Validation Accuracy: 0.8728, Loss: 0.1139
Epoch 201 Batch   80/269 - Train Accuracy: 0.8687, Validation Accuracy: 0.8703, Loss: 0.1153
Epoch 201 Batch   90/269 - Train Accuracy: 0.8658, Validation Accuracy: 0.8634, Loss: 0.1274
Epoch 201 Batch  100/269 - Train Accuracy: 0.8821, Validation Accuracy: 0.8705, Loss: 0.1174
Epoch 201 Batch  110/269 - Train Accuracy: 0.8570, Validation Accuracy: 0.8702, Loss: 0.1198
Epoch 201 Batch  120/269 - Train Accuracy: 0.8654, Validation Accuracy: 0.8723, Loss: 0.1295
Epoch 201 Batch  130/269 - Train Accuracy: 0.8593, Validation Accuracy: 0.8714, Loss: 0.1238
Epoch 201 Batch  140/269 - Train Accuracy: 0.8529, Validation Accuracy: 0.8675, Loss: 0.1311
Epoch 201 Batch  150/269 - Train Accuracy: 0.8656, Validation Accuracy: 0.8689, Loss: 0.1202
Epoch 201 Batch  160/269 - Train Accuracy: 0.8770, Validation Accuracy: 0.8764, Loss: 0.1156
Epoch 201 Batch  170/269 - Train Accuracy: 0.8699, Validation Accuracy: 0.8773, Loss: 0.1144
Epoch 201 Batch  180/269 - Train Accuracy: 0.8901, Validation Accuracy: 0.8730, Loss: 0.1117
Epoch 201 Batch  190/269 - Train Accuracy: 0.8755, Validation Accuracy: 0.8704, Loss: 0.1161
Epoch 201 Batch  200/269 - Train Accuracy: 0.8496, Validation Accuracy: 0.8728, Loss: 0.1142
Epoch 201 Batch  210/269 - Train Accuracy: 0.8674, Validation Accuracy: 0.8716, Loss: 0.1238
Epoch 201 Batch  220/269 - Train Accuracy: 0.8718, Validation Accuracy: 0.8679, Loss: 0.1256
Epoch 201 Batch  230/269 - Train Accuracy: 0.8584, Validation Accuracy: 0.8706, Loss: 0.1164
Epoch 201 Batch  240/269 - Train Accuracy: 0.8730, Validation Accuracy: 0.8715, Loss: 0.1128
Epoch 201 Batch  250/269 - Train Accuracy: 0.8773, Validation Accuracy: 0.8695, Loss: 0.1169
Epoch 201 Batch  260/269 - Train Accuracy: 0.8553, Validation Accuracy: 0.8724, Loss: 0.1210
Epoch 202 Batch   10/269 - Train Accuracy: 0.8696, Validation Accuracy: 0.8683, Loss: 0.1117
Epoch 202 Batch   20/269 - Train Accuracy: 0.8636, Validation Accuracy: 0.8720, Loss: 0.1142
Epoch 202 Batch   30/269 - Train Accuracy: 0.8649, Validation Accuracy: 0.8762, Loss: 0.1182
Epoch 202 Batch   40/269 - Train Accuracy: 0.8516, Validation Accuracy: 0.8741, Loss: 0.1293
Epoch 202 Batch   50/269 - Train Accuracy: 0.8492, Validation Accuracy: 0.8682, Loss: 0.1276
Epoch 202 Batch   60/269 - Train Accuracy: 0.8753, Validation Accuracy: 0.8738, Loss: 0.1039
Epoch 202 Batch   70/269 - Train Accuracy: 0.8726, Validation Accuracy: 0.8714, Loss: 0.1229
Epoch 202 Batch   80/269 - Train Accuracy: 0.8728, Validation Accuracy: 0.8711, Loss: 0.1098
Epoch 202 Batch   90/269 - Train Accuracy: 0.8750, Validation Accuracy: 0.8706, Loss: 0.1203
Epoch 202 Batch  100/269 - Train Accuracy: 0.8783, Validation Accuracy: 0.8713, Loss: 0.1140
Epoch 202 Batch  110/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8714, Loss: 0.1227
Epoch 202 Batch  120/269 - Train Accuracy: 0.8699, Validation Accuracy: 0.8738, Loss: 0.1254
Epoch 202 Batch  130/269 - Train Accuracy: 0.8612, Validation Accuracy: 0.8730, Loss: 0.1213
Epoch 202 Batch  140/269 - Train Accuracy: 0.8589, Validation Accuracy: 0.8669, Loss: 0.1238
Epoch 202 Batch  150/269 - Train Accuracy: 0.8660, Validation Accuracy: 0.8725, Loss: 0.1203
Epoch 202 Batch  160/269 - Train Accuracy: 0.8753, Validation Accuracy: 0.8746, Loss: 0.1161
Epoch 202 Batch  170/269 - Train Accuracy: 0.8633, Validation Accuracy: 0.8706, Loss: 0.1095
Epoch 202 Batch  180/269 - Train Accuracy: 0.8876, Validation Accuracy: 0.8726, Loss: 0.1058
Epoch 202 Batch  190/269 - Train Accuracy: 0.8804, Validation Accuracy: 0.8764, Loss: 0.1120
Epoch 202 Batch  200/269 - Train Accuracy: 0.8569, Validation Accuracy: 0.8721, Loss: 0.1162
Epoch 202 Batch  210/269 - Train Accuracy: 0.8659, Validation Accuracy: 0.8712, Loss: 0.1120
Epoch 202 Batch  220/269 - Train Accuracy: 0.8706, Validation Accuracy: 0.8695, Loss: 0.1194
Epoch 202 Batch  230/269 - Train Accuracy: 0.8599, Validation Accuracy: 0.8696, Loss: 0.1196
Epoch 202 Batch  240/269 - Train Accuracy: 0.8766, Validation Accuracy: 0.8715, Loss: 0.1009
Epoch 202 Batch  250/269 - Train Accuracy: 0.8777, Validation Accuracy: 0.8773, Loss: 0.1102
Epoch 202 Batch  260/269 - Train Accuracy: 0.8537, Validation Accuracy: 0.8741, Loss: 0.1324
Epoch 203 Batch   10/269 - Train Accuracy: 0.8703, Validation Accuracy: 0.8695, Loss: 0.1102
Epoch 203 Batch   20/269 - Train Accuracy: 0.8626, Validation Accuracy: 0.8684, Loss: 0.1177
Epoch 203 Batch   30/269 - Train Accuracy: 0.8628, Validation Accuracy: 0.8716, Loss: 0.1181
Epoch 203 Batch   40/269 - Train Accuracy: 0.8549, Validation Accuracy: 0.8695, Loss: 0.1241
Epoch 203 Batch   50/269 - Train Accuracy: 0.8468, Validation Accuracy: 0.8733, Loss: 0.1234
Epoch 203 Batch   60/269 - Train Accuracy: 0.8778, Validation Accuracy: 0.8760, Loss: 0.1105
Epoch 203 Batch   70/269 - Train Accuracy: 0.8782, Validation Accuracy: 0.8707, Loss: 0.1240
Epoch 203 Batch   80/269 - Train Accuracy: 0.8669, Validation Accuracy: 0.8672, Loss: 0.1139
Epoch 203 Batch   90/269 - Train Accuracy: 0.8665, Validation Accuracy: 0.8744, Loss: 0.1225
Epoch 203 Batch  100/269 - Train Accuracy: 0.8808, Validation Accuracy: 0.8705, Loss: 0.1279
Epoch 203 Batch  110/269 - Train Accuracy: 0.8582, Validation Accuracy: 0.8683, Loss: 0.1176
Epoch 203 Batch  120/269 - Train Accuracy: 0.8687, Validation Accuracy: 0.8683, Loss: 0.1215
Epoch 203 Batch  130/269 - Train Accuracy: 0.8613, Validation Accuracy: 0.8727, Loss: 0.1229
Epoch 203 Batch  140/269 - Train Accuracy: 0.8604, Validation Accuracy: 0.8724, Loss: 0.1285
Epoch 203 Batch  150/269 - Train Accuracy: 0.8642, Validation Accuracy: 0.8714, Loss: 0.1145
Epoch 203 Batch  160/269 - Train Accuracy: 0.8709, Validation Accuracy: 0.8687, Loss: 0.1199
Epoch 203 Batch  170/269 - Train Accuracy: 0.8637, Validation Accuracy: 0.8730, Loss: 0.1110
Epoch 203 Batch  180/269 - Train Accuracy: 0.8924, Validation Accuracy: 0.8677, Loss: 0.1097
Epoch 203 Batch  190/269 - Train Accuracy: 0.8799, Validation Accuracy: 0.8730, Loss: 0.1106
Epoch 203 Batch  200/269 - Train Accuracy: 0.8631, Validation Accuracy: 0.8710, Loss: 0.1111
Epoch 203 Batch  210/269 - Train Accuracy: 0.8708, Validation Accuracy: 0.8724, Loss: 0.1173
Epoch 203 Batch  220/269 - Train Accuracy: 0.8684, Validation Accuracy: 0.8661, Loss: 0.1157
Epoch 203 Batch  230/269 - Train Accuracy: 0.8596, Validation Accuracy: 0.8759, Loss: 0.1165
Epoch 203 Batch  240/269 - Train Accuracy: 0.8696, Validation Accuracy: 0.8685, Loss: 0.0987
Epoch 203 Batch  250/269 - Train Accuracy: 0.8829, Validation Accuracy: 0.8770, Loss: 0.1101
Epoch 203 Batch  260/269 - Train Accuracy: 0.8551, Validation Accuracy: 0.8735, Loss: 0.1274
Epoch 204 Batch   10/269 - Train Accuracy: 0.8682, Validation Accuracy: 0.8667, Loss: 0.1183
Epoch 204 Batch   20/269 - Train Accuracy: 0.8625, Validation Accuracy: 0.8703, Loss: 0.1147
Epoch 204 Batch   30/269 - Train Accuracy: 0.8650, Validation Accuracy: 0.8764, Loss: 0.1204
Epoch 204 Batch   40/269 - Train Accuracy: 0.8568, Validation Accuracy: 0.8770, Loss: 0.1277
Epoch 204 Batch   50/269 - Train Accuracy: 0.8480, Validation Accuracy: 0.8735, Loss: 0.1337
Epoch 204 Batch   60/269 - Train Accuracy: 0.8771, Validation Accuracy: 0.8752, Loss: 0.1042
Epoch 204 Batch   70/269 - Train Accuracy: 0.8803, Validation Accuracy: 0.8779, Loss: 0.1117
Epoch 204 Batch   80/269 - Train Accuracy: 0.8724, Validation Accuracy: 0.8690, Loss: 0.1152
Epoch 204 Batch   90/269 - Train Accuracy: 0.8640, Validation Accuracy: 0.8652, Loss: 0.1181
Epoch 204 Batch  100/269 - Train Accuracy: 0.8804, Validation Accuracy: 0.8740, Loss: 0.1148
Epoch 204 Batch  110/269 - Train Accuracy: 0.8628, Validation Accuracy: 0.8666, Loss: 0.1304
Epoch 204 Batch  120/269 - Train Accuracy: 0.8729, Validation Accuracy: 0.8755, Loss: 0.1305
Epoch 204 Batch  130/269 - Train Accuracy: 0.8620, Validation Accuracy: 0.8756, Loss: 0.1197
Epoch 204 Batch  140/269 - Train Accuracy: 0.8622, Validation Accuracy: 0.8691, Loss: 0.1300
Epoch 204 Batch  150/269 - Train Accuracy: 0.8619, Validation Accuracy: 0.8667, Loss: 0.1126
Epoch 204 Batch  160/269 - Train Accuracy: 0.8734, Validation Accuracy: 0.8707, Loss: 0.1157
Epoch 204 Batch  170/269 - Train Accuracy: 0.8636, Validation Accuracy: 0.8676, Loss: 0.1121
Epoch 204 Batch  180/269 - Train Accuracy: 0.8846, Validation Accuracy: 0.8652, Loss: 0.1103
Epoch 204 Batch  190/269 - Train Accuracy: 0.8746, Validation Accuracy: 0.8738, Loss: 0.1171
Epoch 204 Batch  200/269 - Train Accuracy: 0.8664, Validation Accuracy: 0.8737, Loss: 0.1079
Epoch 204 Batch  210/269 - Train Accuracy: 0.8667, Validation Accuracy: 0.8723, Loss: 0.1142
Epoch 204 Batch  220/269 - Train Accuracy: 0.8734, Validation Accuracy: 0.8649, Loss: 0.1124
Epoch 204 Batch  230/269 - Train Accuracy: 0.8567, Validation Accuracy: 0.8750, Loss: 0.1075
Epoch 204 Batch  240/269 - Train Accuracy: 0.8781, Validation Accuracy: 0.8694, Loss: 0.1145
Epoch 204 Batch  250/269 - Train Accuracy: 0.8746, Validation Accuracy: 0.8722, Loss: 0.1113
Epoch 204 Batch  260/269 - Train Accuracy: 0.8597, Validation Accuracy: 0.8776, Loss: 0.1196
Epoch 205 Batch   10/269 - Train Accuracy: 0.8740, Validation Accuracy: 0.8695, Loss: 0.1107
Epoch 205 Batch   20/269 - Train Accuracy: 0.8607, Validation Accuracy: 0.8718, Loss: 0.1182
Epoch 205 Batch   30/269 - Train Accuracy: 0.8596, Validation Accuracy: 0.8747, Loss: 0.1057
Epoch 205 Batch   40/269 - Train Accuracy: 0.8535, Validation Accuracy: 0.8751, Loss: 0.1502
Epoch 205 Batch   50/269 - Train Accuracy: 0.8491, Validation Accuracy: 0.8702, Loss: 0.1312
Epoch 205 Batch   60/269 - Train Accuracy: 0.8752, Validation Accuracy: 0.8708, Loss: 0.1142
Epoch 205 Batch   70/269 - Train Accuracy: 0.8773, Validation Accuracy: 0.8736, Loss: 0.1104
Epoch 205 Batch   80/269 - Train Accuracy: 0.8722, Validation Accuracy: 0.8770, Loss: 0.1150
Epoch 205 Batch   90/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8711, Loss: 0.1214
Epoch 205 Batch  100/269 - Train Accuracy: 0.8772, Validation Accuracy: 0.8716, Loss: 0.1126
Epoch 205 Batch  110/269 - Train Accuracy: 0.8575, Validation Accuracy: 0.8711, Loss: 0.1199
Epoch 205 Batch  120/269 - Train Accuracy: 0.8691, Validation Accuracy: 0.8733, Loss: 0.1237
Epoch 205 Batch  130/269 - Train Accuracy: 0.8629, Validation Accuracy: 0.8758, Loss: 0.1156
Epoch 205 Batch  140/269 - Train Accuracy: 0.8613, Validation Accuracy: 0.8717, Loss: 0.1323
Epoch 205 Batch  150/269 - Train Accuracy: 0.8648, Validation Accuracy: 0.8770, Loss: 0.1281
Epoch 205 Batch  160/269 - Train Accuracy: 0.8707, Validation Accuracy: 0.8660, Loss: 0.1216
Epoch 205 Batch  170/269 - Train Accuracy: 0.8603, Validation Accuracy: 0.8770, Loss: 0.1102
Epoch 205 Batch  180/269 - Train Accuracy: 0.8893, Validation Accuracy: 0.8710, Loss: 0.1114
Epoch 205 Batch  190/269 - Train Accuracy: 0.8825, Validation Accuracy: 0.8711, Loss: 0.1202
Epoch 205 Batch  200/269 - Train Accuracy: 0.8656, Validation Accuracy: 0.8763, Loss: 0.1138
Epoch 205 Batch  210/269 - Train Accuracy: 0.8649, Validation Accuracy: 0.8730, Loss: 0.1163
Epoch 205 Batch  220/269 - Train Accuracy: 0.8691, Validation Accuracy: 0.8685, Loss: 0.1159
Epoch 205 Batch  230/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8750, Loss: 0.1113
Epoch 205 Batch  240/269 - Train Accuracy: 0.8748, Validation Accuracy: 0.8737, Loss: 0.1103
Epoch 205 Batch  250/269 - Train Accuracy: 0.8805, Validation Accuracy: 0.8739, Loss: 0.1099
Epoch 205 Batch  260/269 - Train Accuracy: 0.8528, Validation Accuracy: 0.8778, Loss: 0.1195
Epoch 206 Batch   10/269 - Train Accuracy: 0.8684, Validation Accuracy: 0.8673, Loss: 0.1148
Epoch 206 Batch   20/269 - Train Accuracy: 0.8608, Validation Accuracy: 0.8697, Loss: 0.1172
Epoch 206 Batch   30/269 - Train Accuracy: 0.8603, Validation Accuracy: 0.8742, Loss: 0.1187
Epoch 206 Batch   40/269 - Train Accuracy: 0.8540, Validation Accuracy: 0.8782, Loss: 0.1335
Epoch 206 Batch   50/269 - Train Accuracy: 0.8520, Validation Accuracy: 0.8706, Loss: 0.1300
Epoch 206 Batch   60/269 - Train Accuracy: 0.8791, Validation Accuracy: 0.8683, Loss: 0.1024
Epoch 206 Batch   70/269 - Train Accuracy: 0.8778, Validation Accuracy: 0.8731, Loss: 0.1129
Epoch 206 Batch   80/269 - Train Accuracy: 0.8767, Validation Accuracy: 0.8752, Loss: 0.1159
Epoch 206 Batch   90/269 - Train Accuracy: 0.8762, Validation Accuracy: 0.8723, Loss: 0.1182
Epoch 206 Batch  100/269 - Train Accuracy: 0.8800, Validation Accuracy: 0.8699, Loss: 0.1126
Epoch 206 Batch  110/269 - Train Accuracy: 0.8576, Validation Accuracy: 0.8700, Loss: 0.1116
Epoch 206 Batch  120/269 - Train Accuracy: 0.8718, Validation Accuracy: 0.8768, Loss: 0.1259
Epoch 206 Batch  130/269 - Train Accuracy: 0.8588, Validation Accuracy: 0.8715, Loss: 0.1230
Epoch 206 Batch  140/269 - Train Accuracy: 0.8555, Validation Accuracy: 0.8676, Loss: 0.1416
Epoch 206 Batch  150/269 - Train Accuracy: 0.8613, Validation Accuracy: 0.8681, Loss: 0.1276
Epoch 206 Batch  160/269 - Train Accuracy: 0.8711, Validation Accuracy: 0.8687, Loss: 0.1250
Epoch 206 Batch  170/269 - Train Accuracy: 0.8668, Validation Accuracy: 0.8730, Loss: 0.1174
Epoch 206 Batch  180/269 - Train Accuracy: 0.8885, Validation Accuracy: 0.8735, Loss: 0.1196
Epoch 206 Batch  190/269 - Train Accuracy: 0.8765, Validation Accuracy: 0.8699, Loss: 0.1139
Epoch 206 Batch  200/269 - Train Accuracy: 0.8599, Validation Accuracy: 0.8734, Loss: 0.1171
Epoch 206 Batch  210/269 - Train Accuracy: 0.8659, Validation Accuracy: 0.8683, Loss: 0.1144
Epoch 206 Batch  220/269 - Train Accuracy: 0.8700, Validation Accuracy: 0.8697, Loss: 0.1155
Epoch 206 Batch  230/269 - Train Accuracy: 0.8559, Validation Accuracy: 0.8718, Loss: 0.1149
Epoch 206 Batch  240/269 - Train Accuracy: 0.8776, Validation Accuracy: 0.8728, Loss: 0.1044
Epoch 206 Batch  250/269 - Train Accuracy: 0.8810, Validation Accuracy: 0.8740, Loss: 0.1121
Epoch 206 Batch  260/269 - Train Accuracy: 0.8587, Validation Accuracy: 0.8743, Loss: 0.1257
Epoch 207 Batch   10/269 - Train Accuracy: 0.8733, Validation Accuracy: 0.8694, Loss: 0.1114
Epoch 207 Batch   20/269 - Train Accuracy: 0.8669, Validation Accuracy: 0.8753, Loss: 0.1149
Epoch 207 Batch   30/269 - Train Accuracy: 0.8649, Validation Accuracy: 0.8802, Loss: 0.1105
Epoch 207 Batch   40/269 - Train Accuracy: 0.8559, Validation Accuracy: 0.8752, Loss: 0.1265
Epoch 207 Batch   50/269 - Train Accuracy: 0.8521, Validation Accuracy: 0.8749, Loss: 0.1285
Epoch 207 Batch   60/269 - Train Accuracy: 0.8771, Validation Accuracy: 0.8757, Loss: 0.1064
Epoch 207 Batch   70/269 - Train Accuracy: 0.8805, Validation Accuracy: 0.8763, Loss: 0.1109
Epoch 207 Batch   80/269 - Train Accuracy: 0.8662, Validation Accuracy: 0.8714, Loss: 0.1068
Epoch 207 Batch   90/269 - Train Accuracy: 0.8641, Validation Accuracy: 0.8705, Loss: 0.1236
Epoch 207 Batch  100/269 - Train Accuracy: 0.8829, Validation Accuracy: 0.8766, Loss: 0.1182
Epoch 207 Batch  110/269 - Train Accuracy: 0.8574, Validation Accuracy: 0.8729, Loss: 0.1398
Epoch 207 Batch  120/269 - Train Accuracy: 0.8657, Validation Accuracy: 0.8694, Loss: 0.1296
Epoch 207 Batch  130/269 - Train Accuracy: 0.8585, Validation Accuracy: 0.8773, Loss: 0.1313
Epoch 207 Batch  140/269 - Train Accuracy: 0.8629, Validation Accuracy: 0.8733, Loss: 0.1280
Epoch 207 Batch  150/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8700, Loss: 0.1231
Epoch 207 Batch  160/269 - Train Accuracy: 0.8714, Validation Accuracy: 0.8709, Loss: 0.1207
Epoch 207 Batch  170/269 - Train Accuracy: 0.8635, Validation Accuracy: 0.8721, Loss: 0.1187
Epoch 207 Batch  180/269 - Train Accuracy: 0.8883, Validation Accuracy: 0.8617, Loss: 0.1142
Epoch 207 Batch  190/269 - Train Accuracy: 0.8793, Validation Accuracy: 0.8746, Loss: 0.1195
Epoch 207 Batch  200/269 - Train Accuracy: 0.8645, Validation Accuracy: 0.8708, Loss: 0.1128
Epoch 207 Batch  210/269 - Train Accuracy: 0.8651, Validation Accuracy: 0.8706, Loss: 0.1148
Epoch 207 Batch  220/269 - Train Accuracy: 0.8696, Validation Accuracy: 0.8640, Loss: 0.1124
Epoch 207 Batch  230/269 - Train Accuracy: 0.8581, Validation Accuracy: 0.8763, Loss: 0.1157
Epoch 207 Batch  240/269 - Train Accuracy: 0.8776, Validation Accuracy: 0.8713, Loss: 0.1024
Epoch 207 Batch  250/269 - Train Accuracy: 0.8804, Validation Accuracy: 0.8779, Loss: 0.1137
Epoch 207 Batch  260/269 - Train Accuracy: 0.8564, Validation Accuracy: 0.8729, Loss: 0.1161
Epoch 208 Batch   10/269 - Train Accuracy: 0.8679, Validation Accuracy: 0.8675, Loss: 0.1102
Epoch 208 Batch   20/269 - Train Accuracy: 0.8617, Validation Accuracy: 0.8731, Loss: 0.1212
Epoch 208 Batch   30/269 - Train Accuracy: 0.8623, Validation Accuracy: 0.8750, Loss: 0.1194
Epoch 208 Batch   40/269 - Train Accuracy: 0.8522, Validation Accuracy: 0.8797, Loss: 0.1251
Epoch 208 Batch   50/269 - Train Accuracy: 0.8521, Validation Accuracy: 0.8733, Loss: 0.1270
Epoch 208 Batch   60/269 - Train Accuracy: 0.8734, Validation Accuracy: 0.8781, Loss: 0.1062
Epoch 208 Batch   70/269 - Train Accuracy: 0.8810, Validation Accuracy: 0.8782, Loss: 0.1188
Epoch 208 Batch   80/269 - Train Accuracy: 0.8689, Validation Accuracy: 0.8725, Loss: 0.1175
Epoch 208 Batch   90/269 - Train Accuracy: 0.8674, Validation Accuracy: 0.8709, Loss: 0.1213
Epoch 208 Batch  100/269 - Train Accuracy: 0.8802, Validation Accuracy: 0.8723, Loss: 0.1091
Epoch 208 Batch  110/269 - Train Accuracy: 0.8544, Validation Accuracy: 0.8738, Loss: 0.1249
Epoch 208 Batch  120/269 - Train Accuracy: 0.8708, Validation Accuracy: 0.8739, Loss: 0.1209
Epoch 208 Batch  130/269 - Train Accuracy: 0.8538, Validation Accuracy: 0.8706, Loss: 0.1263
Epoch 208 Batch  140/269 - Train Accuracy: 0.8615, Validation Accuracy: 0.8711, Loss: 0.1173
Epoch 208 Batch  150/269 - Train Accuracy: 0.8677, Validation Accuracy: 0.8748, Loss: 0.1224
Epoch 208 Batch  160/269 - Train Accuracy: 0.8684, Validation Accuracy: 0.8721, Loss: 0.1221
Epoch 208 Batch  170/269 - Train Accuracy: 0.8655, Validation Accuracy: 0.8692, Loss: 0.1177
Epoch 208 Batch  180/269 - Train Accuracy: 0.8901, Validation Accuracy: 0.8685, Loss: 0.1139
Epoch 208 Batch  190/269 - Train Accuracy: 0.8783, Validation Accuracy: 0.8756, Loss: 0.1097
Epoch 208 Batch  200/269 - Train Accuracy: 0.8569, Validation Accuracy: 0.8759, Loss: 0.1120
Epoch 208 Batch  210/269 - Train Accuracy: 0.8642, Validation Accuracy: 0.8671, Loss: 0.1158
Epoch 208 Batch  220/269 - Train Accuracy: 0.8681, Validation Accuracy: 0.8741, Loss: 0.1141
Epoch 208 Batch  230/269 - Train Accuracy: 0.8592, Validation Accuracy: 0.8732, Loss: 0.1128
Epoch 208 Batch  240/269 - Train Accuracy: 0.8791, Validation Accuracy: 0.8722, Loss: 0.1045
Epoch 208 Batch  250/269 - Train Accuracy: 0.8810, Validation Accuracy: 0.8732, Loss: 0.1183
Epoch 208 Batch  260/269 - Train Accuracy: 0.8536, Validation Accuracy: 0.8778, Loss: 0.1243
Epoch 209 Batch   10/269 - Train Accuracy: 0.8682, Validation Accuracy: 0.8699, Loss: 0.1101
Epoch 209 Batch   20/269 - Train Accuracy: 0.8604, Validation Accuracy: 0.8740, Loss: 0.1160
Epoch 209 Batch   30/269 - Train Accuracy: 0.8613, Validation Accuracy: 0.8704, Loss: 0.1119
Epoch 209 Batch   40/269 - Train Accuracy: 0.8507, Validation Accuracy: 0.8714, Loss: 0.1330
Epoch 209 Batch   50/269 - Train Accuracy: 0.8502, Validation Accuracy: 0.8710, Loss: 0.1254
Epoch 209 Batch   60/269 - Train Accuracy: 0.8706, Validation Accuracy: 0.8733, Loss: 0.1053
Epoch 209 Batch   70/269 - Train Accuracy: 0.8839, Validation Accuracy: 0.8778, Loss: 0.1232
Epoch 209 Batch   80/269 - Train Accuracy: 0.8728, Validation Accuracy: 0.8729, Loss: 0.1194
Epoch 209 Batch   90/269 - Train Accuracy: 0.8574, Validation Accuracy: 0.8721, Loss: 0.1226
Epoch 209 Batch  100/269 - Train Accuracy: 0.8797, Validation Accuracy: 0.8722, Loss: 0.1172
Epoch 209 Batch  110/269 - Train Accuracy: 0.8554, Validation Accuracy: 0.8699, Loss: 0.1230
Epoch 209 Batch  120/269 - Train Accuracy: 0.8713, Validation Accuracy: 0.8717, Loss: 0.1253
Epoch 209 Batch  130/269 - Train Accuracy: 0.8549, Validation Accuracy: 0.8745, Loss: 0.1281
Epoch 209 Batch  140/269 - Train Accuracy: 0.8541, Validation Accuracy: 0.8748, Loss: 0.1251
Epoch 209 Batch  150/269 - Train Accuracy: 0.8671, Validation Accuracy: 0.8694, Loss: 0.1141
Epoch 209 Batch  160/269 - Train Accuracy: 0.8717, Validation Accuracy: 0.8692, Loss: 0.1128
Epoch 209 Batch  170/269 - Train Accuracy: 0.8636, Validation Accuracy: 0.8721, Loss: 0.1124
Epoch 209 Batch  180/269 - Train Accuracy: 0.8855, Validation Accuracy: 0.8708, Loss: 0.1093
Epoch 209 Batch  190/269 - Train Accuracy: 0.8759, Validation Accuracy: 0.8680, Loss: 0.1117
Epoch 209 Batch  200/269 - Train Accuracy: 0.8660, Validation Accuracy: 0.8735, Loss: 0.1144
Epoch 209 Batch  210/269 - Train Accuracy: 0.8708, Validation Accuracy: 0.8722, Loss: 0.1159
Epoch 209 Batch  220/269 - Train Accuracy: 0.8705, Validation Accuracy: 0.8723, Loss: 0.1114
Epoch 209 Batch  230/269 - Train Accuracy: 0.8587, Validation Accuracy: 0.8713, Loss: 0.1138
Epoch 209 Batch  240/269 - Train Accuracy: 0.8803, Validation Accuracy: 0.8742, Loss: 0.1095
Epoch 209 Batch  250/269 - Train Accuracy: 0.8781, Validation Accuracy: 0.8743, Loss: 0.1147
Epoch 209 Batch  260/269 - Train Accuracy: 0.8554, Validation Accuracy: 0.8761, Loss: 0.1220
Epoch 210 Batch   10/269 - Train Accuracy: 0.8681, Validation Accuracy: 0.8745, Loss: 0.1121
Epoch 210 Batch   20/269 - Train Accuracy: 0.8613, Validation Accuracy: 0.8724, Loss: 0.1115
Epoch 210 Batch   30/269 - Train Accuracy: 0.8685, Validation Accuracy: 0.8760, Loss: 0.1115
Epoch 210 Batch   40/269 - Train Accuracy: 0.8554, Validation Accuracy: 0.8722, Loss: 0.1284
Epoch 210 Batch   50/269 - Train Accuracy: 0.8474, Validation Accuracy: 0.8720, Loss: 0.1276
Epoch 210 Batch   60/269 - Train Accuracy: 0.8809, Validation Accuracy: 0.8778, Loss: 0.1020
Epoch 210 Batch   70/269 - Train Accuracy: 0.8713, Validation Accuracy: 0.8727, Loss: 0.1191
Epoch 210 Batch   80/269 - Train Accuracy: 0.8735, Validation Accuracy: 0.8756, Loss: 0.1254
Epoch 210 Batch   90/269 - Train Accuracy: 0.8697, Validation Accuracy: 0.8726, Loss: 0.1209
Epoch 210 Batch  100/269 - Train Accuracy: 0.8833, Validation Accuracy: 0.8742, Loss: 0.1125
Epoch 210 Batch  110/269 - Train Accuracy: 0.8546, Validation Accuracy: 0.8666, Loss: 0.1132
Epoch 210 Batch  120/269 - Train Accuracy: 0.8709, Validation Accuracy: 0.8722, Loss: 0.1230
Epoch 210 Batch  130/269 - Train Accuracy: 0.8584, Validation Accuracy: 0.8725, Loss: 0.1264
Epoch 210 Batch  140/269 - Train Accuracy: 0.8593, Validation Accuracy: 0.8694, Loss: 0.1294
Epoch 210 Batch  150/269 - Train Accuracy: 0.8636, Validation Accuracy: 0.8727, Loss: 0.1158
Epoch 210 Batch  160/269 - Train Accuracy: 0.8739, Validation Accuracy: 0.8769, Loss: 0.1107
Epoch 210 Batch  170/269 - Train Accuracy: 0.8630, Validation Accuracy: 0.8691, Loss: 0.1110
Epoch 210 Batch  180/269 - Train Accuracy: 0.8889, Validation Accuracy: 0.8707, Loss: 0.1104
Epoch 210 Batch  190/269 - Train Accuracy: 0.8766, Validation Accuracy: 0.8663, Loss: 0.1122
Epoch 210 Batch  200/269 - Train Accuracy: 0.8648, Validation Accuracy: 0.8690, Loss: 0.1119
Epoch 210 Batch  210/269 - Train Accuracy: 0.8704, Validation Accuracy: 0.8680, Loss: 0.1111
Epoch 210 Batch  220/269 - Train Accuracy: 0.8767, Validation Accuracy: 0.8693, Loss: 0.1102
Epoch 210 Batch  230/269 - Train Accuracy: 0.8570, Validation Accuracy: 0.8706, Loss: 0.1075
Epoch 210 Batch  240/269 - Train Accuracy: 0.8728, Validation Accuracy: 0.8705, Loss: 0.1059
Epoch 210 Batch  250/269 - Train Accuracy: 0.8795, Validation Accuracy: 0.8746, Loss: 0.1173
Epoch 210 Batch  260/269 - Train Accuracy: 0.8610, Validation Accuracy: 0.8752, Loss: 0.1264
Epoch 211 Batch   10/269 - Train Accuracy: 0.8684, Validation Accuracy: 0.8747, Loss: 0.1106
Epoch 211 Batch   20/269 - Train Accuracy: 0.8603, Validation Accuracy: 0.8702, Loss: 0.1116
Epoch 211 Batch   30/269 - Train Accuracy: 0.8601, Validation Accuracy: 0.8754, Loss: 0.1136
Epoch 211 Batch   40/269 - Train Accuracy: 0.8461, Validation Accuracy: 0.8738, Loss: 0.1278
Epoch 211 Batch   50/269 - Train Accuracy: 0.8442, Validation Accuracy: 0.8771, Loss: 0.1275
Epoch 211 Batch   60/269 - Train Accuracy: 0.8766, Validation Accuracy: 0.8771, Loss: 0.0985
Epoch 211 Batch   70/269 - Train Accuracy: 0.8808, Validation Accuracy: 0.8797, Loss: 0.1162
Epoch 211 Batch   80/269 - Train Accuracy: 0.8717, Validation Accuracy: 0.8739, Loss: 0.1070
Epoch 211 Batch   90/269 - Train Accuracy: 0.8705, Validation Accuracy: 0.8669, Loss: 0.1172
Epoch 211 Batch  100/269 - Train Accuracy: 0.8757, Validation Accuracy: 0.8730, Loss: 0.1064
Epoch 211 Batch  110/269 - Train Accuracy: 0.8593, Validation Accuracy: 0.8697, Loss: 0.1257
Epoch 211 Batch  120/269 - Train Accuracy: 0.8760, Validation Accuracy: 0.8690, Loss: 0.1298
Epoch 211 Batch  130/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8807, Loss: 0.1247
Epoch 211 Batch  140/269 - Train Accuracy: 0.8638, Validation Accuracy: 0.8775, Loss: 0.1220
Epoch 211 Batch  150/269 - Train Accuracy: 0.8695, Validation Accuracy: 0.8749, Loss: 0.1207
Epoch 211 Batch  160/269 - Train Accuracy: 0.8757, Validation Accuracy: 0.8711, Loss: 0.1186
Epoch 211 Batch  170/269 - Train Accuracy: 0.8639, Validation Accuracy: 0.8701, Loss: 0.1069
Epoch 211 Batch  180/269 - Train Accuracy: 0.8869, Validation Accuracy: 0.8717, Loss: 0.1143
Epoch 211 Batch  190/269 - Train Accuracy: 0.8717, Validation Accuracy: 0.8673, Loss: 0.1123
Epoch 211 Batch  200/269 - Train Accuracy: 0.8655, Validation Accuracy: 0.8732, Loss: 0.1152
Epoch 211 Batch  210/269 - Train Accuracy: 0.8666, Validation Accuracy: 0.8720, Loss: 0.1148
Epoch 211 Batch  220/269 - Train Accuracy: 0.8694, Validation Accuracy: 0.8786, Loss: 0.1199
Epoch 211 Batch  230/269 - Train Accuracy: 0.8589, Validation Accuracy: 0.8767, Loss: 0.1167
Epoch 211 Batch  240/269 - Train Accuracy: 0.8733, Validation Accuracy: 0.8757, Loss: 0.1045
Epoch 211 Batch  250/269 - Train Accuracy: 0.8772, Validation Accuracy: 0.8765, Loss: 0.1105
Epoch 211 Batch  260/269 - Train Accuracy: 0.8516, Validation Accuracy: 0.8731, Loss: 0.1344
Epoch 212 Batch   10/269 - Train Accuracy: 0.8720, Validation Accuracy: 0.8715, Loss: 0.1337
Epoch 212 Batch   20/269 - Train Accuracy: 0.8607, Validation Accuracy: 0.8706, Loss: 0.1149
Epoch 212 Batch   30/269 - Train Accuracy: 0.8658, Validation Accuracy: 0.8745, Loss: 0.1145
Epoch 212 Batch   40/269 - Train Accuracy: 0.8540, Validation Accuracy: 0.8762, Loss: 0.1322
Epoch 212 Batch   50/269 - Train Accuracy: 0.8505, Validation Accuracy: 0.8713, Loss: 0.1300
Epoch 212 Batch   60/269 - Train Accuracy: 0.8735, Validation Accuracy: 0.8744, Loss: 0.1055
Epoch 212 Batch   70/269 - Train Accuracy: 0.8823, Validation Accuracy: 0.8721, Loss: 0.1110
Epoch 212 Batch   80/269 - Train Accuracy: 0.8761, Validation Accuracy: 0.8752, Loss: 0.1162
Epoch 212 Batch   90/269 - Train Accuracy: 0.8775, Validation Accuracy: 0.8721, Loss: 0.1199
Epoch 212 Batch  100/269 - Train Accuracy: 0.8791, Validation Accuracy: 0.8746, Loss: 0.1063
Epoch 212 Batch  110/269 - Train Accuracy: 0.8584, Validation Accuracy: 0.8747, Loss: 0.1186
Epoch 212 Batch  120/269 - Train Accuracy: 0.8753, Validation Accuracy: 0.8739, Loss: 0.1372
Epoch 212 Batch  130/269 - Train Accuracy: 0.8631, Validation Accuracy: 0.8727, Loss: 0.1253
Epoch 212 Batch  140/269 - Train Accuracy: 0.8631, Validation Accuracy: 0.8661, Loss: 0.1174
Epoch 212 Batch  150/269 - Train Accuracy: 0.8588, Validation Accuracy: 0.8701, Loss: 0.1172
Epoch 212 Batch  160/269 - Train Accuracy: 0.8738, Validation Accuracy: 0.8738, Loss: 0.1129
Epoch 212 Batch  170/269 - Train Accuracy: 0.8650, Validation Accuracy: 0.8725, Loss: 0.1172
Epoch 212 Batch  180/269 - Train Accuracy: 0.8811, Validation Accuracy: 0.8668, Loss: 0.1085
Epoch 212 Batch  190/269 - Train Accuracy: 0.8783, Validation Accuracy: 0.8723, Loss: 0.1109
Epoch 212 Batch  200/269 - Train Accuracy: 0.8627, Validation Accuracy: 0.8738, Loss: 0.1091
Epoch 212 Batch  210/269 - Train Accuracy: 0.8683, Validation Accuracy: 0.8725, Loss: 0.1245
Epoch 212 Batch  220/269 - Train Accuracy: 0.8767, Validation Accuracy: 0.8750, Loss: 0.1158
Epoch 212 Batch  230/269 - Train Accuracy: 0.8575, Validation Accuracy: 0.8753, Loss: 0.1187
Epoch 212 Batch  240/269 - Train Accuracy: 0.8747, Validation Accuracy: 0.8672, Loss: 0.0969
Epoch 212 Batch  250/269 - Train Accuracy: 0.8800, Validation Accuracy: 0.8757, Loss: 0.1111
Epoch 212 Batch  260/269 - Train Accuracy: 0.8576, Validation Accuracy: 0.8770, Loss: 0.1257
Epoch 213 Batch   10/269 - Train Accuracy: 0.8687, Validation Accuracy: 0.8687, Loss: 0.1065
Epoch 213 Batch   20/269 - Train Accuracy: 0.8572, Validation Accuracy: 0.8671, Loss: 0.1229
Epoch 213 Batch   30/269 - Train Accuracy: 0.8604, Validation Accuracy: 0.8746, Loss: 0.1170
Epoch 213 Batch   40/269 - Train Accuracy: 0.8464, Validation Accuracy: 0.8690, Loss: 0.1321
Epoch 213 Batch   50/269 - Train Accuracy: 0.8510, Validation Accuracy: 0.8681, Loss: 0.1272
Epoch 213 Batch   60/269 - Train Accuracy: 0.8689, Validation Accuracy: 0.8706, Loss: 0.1097
Epoch 213 Batch   70/269 - Train Accuracy: 0.8785, Validation Accuracy: 0.8726, Loss: 0.1180
Epoch 213 Batch   80/269 - Train Accuracy: 0.8755, Validation Accuracy: 0.8780, Loss: 0.1111
Epoch 213 Batch   90/269 - Train Accuracy: 0.8682, Validation Accuracy: 0.8706, Loss: 0.1246
Epoch 213 Batch  100/269 - Train Accuracy: 0.8797, Validation Accuracy: 0.8764, Loss: 0.1182
Epoch 213 Batch  110/269 - Train Accuracy: 0.8607, Validation Accuracy: 0.8769, Loss: 0.1193
Epoch 213 Batch  120/269 - Train Accuracy: 0.8709, Validation Accuracy: 0.8689, Loss: 0.1270
Epoch 213 Batch  130/269 - Train Accuracy: 0.8535, Validation Accuracy: 0.8712, Loss: 0.1218
Epoch 213 Batch  140/269 - Train Accuracy: 0.8582, Validation Accuracy: 0.8730, Loss: 0.1222
Epoch 213 Batch  150/269 - Train Accuracy: 0.8633, Validation Accuracy: 0.8730, Loss: 0.1167
Epoch 213 Batch  160/269 - Train Accuracy: 0.8743, Validation Accuracy: 0.8714, Loss: 0.1184
Epoch 213 Batch  170/269 - Train Accuracy: 0.8674, Validation Accuracy: 0.8738, Loss: 0.1140
Epoch 213 Batch  180/269 - Train Accuracy: 0.8902, Validation Accuracy: 0.8681, Loss: 0.1045
Epoch 213 Batch  190/269 - Train Accuracy: 0.8758, Validation Accuracy: 0.8710, Loss: 0.1098
Epoch 213 Batch  200/269 - Train Accuracy: 0.8736, Validation Accuracy: 0.8730, Loss: 0.1090
Epoch 213 Batch  210/269 - Train Accuracy: 0.8697, Validation Accuracy: 0.8712, Loss: 0.1152
Epoch 213 Batch  220/269 - Train Accuracy: 0.8705, Validation Accuracy: 0.8713, Loss: 0.1112
Epoch 213 Batch  230/269 - Train Accuracy: 0.8599, Validation Accuracy: 0.8706, Loss: 0.1150
Epoch 213 Batch  240/269 - Train Accuracy: 0.8775, Validation Accuracy: 0.8747, Loss: 0.1068
Epoch 213 Batch  250/269 - Train Accuracy: 0.8762, Validation Accuracy: 0.8785, Loss: 0.1075
Epoch 213 Batch  260/269 - Train Accuracy: 0.8610, Validation Accuracy: 0.8751, Loss: 0.1292
Epoch 214 Batch   10/269 - Train Accuracy: 0.8704, Validation Accuracy: 0.8780, Loss: 0.1142
Epoch 214 Batch   20/269 - Train Accuracy: 0.8638, Validation Accuracy: 0.8722, Loss: 0.1224
Epoch 214 Batch   30/269 - Train Accuracy: 0.8641, Validation Accuracy: 0.8714, Loss: 0.1197
Epoch 214 Batch   40/269 - Train Accuracy: 0.8523, Validation Accuracy: 0.8746, Loss: 0.1250
Epoch 214 Batch   50/269 - Train Accuracy: 0.8521, Validation Accuracy: 0.8731, Loss: 0.1244
Epoch 214 Batch   60/269 - Train Accuracy: 0.8792, Validation Accuracy: 0.8733, Loss: 0.1079
Epoch 214 Batch   70/269 - Train Accuracy: 0.8806, Validation Accuracy: 0.8818, Loss: 0.1107
Epoch 214 Batch   80/269 - Train Accuracy: 0.8741, Validation Accuracy: 0.8706, Loss: 0.1110
Epoch 214 Batch   90/269 - Train Accuracy: 0.8735, Validation Accuracy: 0.8715, Loss: 0.1138
Epoch 214 Batch  100/269 - Train Accuracy: 0.8815, Validation Accuracy: 0.8769, Loss: 0.1153
Epoch 214 Batch  110/269 - Train Accuracy: 0.8592, Validation Accuracy: 0.8730, Loss: 0.1118
Epoch 214 Batch  120/269 - Train Accuracy: 0.8716, Validation Accuracy: 0.8729, Loss: 0.1316
Epoch 214 Batch  130/269 - Train Accuracy: 0.8521, Validation Accuracy: 0.8746, Loss: 0.1259
Epoch 214 Batch  140/269 - Train Accuracy: 0.8628, Validation Accuracy: 0.8741, Loss: 0.1245
Epoch 214 Batch  150/269 - Train Accuracy: 0.8621, Validation Accuracy: 0.8625, Loss: 0.1248
Epoch 214 Batch  160/269 - Train Accuracy: 0.8733, Validation Accuracy: 0.8762, Loss: 0.1192
Epoch 214 Batch  170/269 - Train Accuracy: 0.8653, Validation Accuracy: 0.8733, Loss: 0.1115
Epoch 214 Batch  180/269 - Train Accuracy: 0.8887, Validation Accuracy: 0.8722, Loss: 0.1205
Epoch 214 Batch  190/269 - Train Accuracy: 0.8777, Validation Accuracy: 0.8738, Loss: 0.1184
Epoch 214 Batch  200/269 - Train Accuracy: 0.8619, Validation Accuracy: 0.8727, Loss: 0.1215
Epoch 214 Batch  210/269 - Train Accuracy: 0.8621, Validation Accuracy: 0.8725, Loss: 0.1204
Epoch 214 Batch  220/269 - Train Accuracy: 0.8695, Validation Accuracy: 0.8666, Loss: 0.1137
Epoch 214 Batch  230/269 - Train Accuracy: 0.8587, Validation Accuracy: 0.8738, Loss: 0.1181
Epoch 214 Batch  240/269 - Train Accuracy: 0.8735, Validation Accuracy: 0.8752, Loss: 0.1046
Epoch 214 Batch  250/269 - Train Accuracy: 0.8759, Validation Accuracy: 0.8692, Loss: 0.1095
Epoch 214 Batch  260/269 - Train Accuracy: 0.8598, Validation Accuracy: 0.8754, Loss: 0.1200
Epoch 215 Batch   10/269 - Train Accuracy: 0.8692, Validation Accuracy: 0.8689, Loss: 0.1061
Epoch 215 Batch   20/269 - Train Accuracy: 0.8621, Validation Accuracy: 0.8736, Loss: 0.1108
Epoch 215 Batch   30/269 - Train Accuracy: 0.8628, Validation Accuracy: 0.8774, Loss: 0.1099
Epoch 215 Batch   40/269 - Train Accuracy: 0.8524, Validation Accuracy: 0.8740, Loss: 0.1213
Epoch 215 Batch   50/269 - Train Accuracy: 0.8514, Validation Accuracy: 0.8732, Loss: 0.1288
Epoch 215 Batch   60/269 - Train Accuracy: 0.8740, Validation Accuracy: 0.8778, Loss: 0.1098
Epoch 215 Batch   70/269 - Train Accuracy: 0.8780, Validation Accuracy: 0.8751, Loss: 0.1198
Epoch 215 Batch   80/269 - Train Accuracy: 0.8792, Validation Accuracy: 0.8696, Loss: 0.1072
Epoch 215 Batch   90/269 - Train Accuracy: 0.8660, Validation Accuracy: 0.8710, Loss: 0.1161
Epoch 215 Batch  100/269 - Train Accuracy: 0.8836, Validation Accuracy: 0.8708, Loss: 0.1054
Epoch 215 Batch  110/269 - Train Accuracy: 0.8609, Validation Accuracy: 0.8725, Loss: 0.1198
Epoch 215 Batch  120/269 - Train Accuracy: 0.8715, Validation Accuracy: 0.8714, Loss: 0.1196
Epoch 215 Batch  130/269 - Train Accuracy: 0.8479, Validation Accuracy: 0.8742, Loss: 0.1187
Epoch 215 Batch  140/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8702, Loss: 0.1198
Epoch 215 Batch  150/269 - Train Accuracy: 0.8646, Validation Accuracy: 0.8666, Loss: 0.1194
Epoch 215 Batch  160/269 - Train Accuracy: 0.8708, Validation Accuracy: 0.8751, Loss: 0.1172
Epoch 215 Batch  170/269 - Train Accuracy: 0.8622, Validation Accuracy: 0.8732, Loss: 0.1102
Epoch 215 Batch  180/269 - Train Accuracy: 0.8859, Validation Accuracy: 0.8721, Loss: 0.1148
Epoch 215 Batch  190/269 - Train Accuracy: 0.8777, Validation Accuracy: 0.8749, Loss: 0.1200
Epoch 215 Batch  200/269 - Train Accuracy: 0.8554, Validation Accuracy: 0.8757, Loss: 0.1142
Epoch 215 Batch  210/269 - Train Accuracy: 0.8710, Validation Accuracy: 0.8775, Loss: 0.1127
Epoch 215 Batch  220/269 - Train Accuracy: 0.8742, Validation Accuracy: 0.8738, Loss: 0.1119
Epoch 215 Batch  230/269 - Train Accuracy: 0.8605, Validation Accuracy: 0.8734, Loss: 0.1130
Epoch 215 Batch  240/269 - Train Accuracy: 0.8745, Validation Accuracy: 0.8708, Loss: 0.1055
Epoch 215 Batch  250/269 - Train Accuracy: 0.8753, Validation Accuracy: 0.8742, Loss: 0.1088
Epoch 215 Batch  260/269 - Train Accuracy: 0.8634, Validation Accuracy: 0.8754, Loss: 0.1172
Epoch 216 Batch   10/269 - Train Accuracy: 0.8677, Validation Accuracy: 0.8676, Loss: 0.1097
Epoch 216 Batch   20/269 - Train Accuracy: 0.8584, Validation Accuracy: 0.8730, Loss: 0.1075
Epoch 216 Batch   30/269 - Train Accuracy: 0.8666, Validation Accuracy: 0.8734, Loss: 0.1126
Epoch 216 Batch   40/269 - Train Accuracy: 0.8532, Validation Accuracy: 0.8772, Loss: 0.1209
Epoch 216 Batch   50/269 - Train Accuracy: 0.8533, Validation Accuracy: 0.8752, Loss: 0.1290
Epoch 216 Batch   60/269 - Train Accuracy: 0.8732, Validation Accuracy: 0.8724, Loss: 0.1082
Epoch 216 Batch   70/269 - Train Accuracy: 0.8824, Validation Accuracy: 0.8724, Loss: 0.1087
Epoch 216 Batch   80/269 - Train Accuracy: 0.8736, Validation Accuracy: 0.8722, Loss: 0.1163
Epoch 216 Batch   90/269 - Train Accuracy: 0.8687, Validation Accuracy: 0.8679, Loss: 0.1230
Epoch 216 Batch  100/269 - Train Accuracy: 0.8805, Validation Accuracy: 0.8749, Loss: 0.1110
Epoch 216 Batch  110/269 - Train Accuracy: 0.8594, Validation Accuracy: 0.8766, Loss: 0.1163
Epoch 216 Batch  120/269 - Train Accuracy: 0.8686, Validation Accuracy: 0.8691, Loss: 0.1260
Epoch 216 Batch  130/269 - Train Accuracy: 0.8572, Validation Accuracy: 0.8698, Loss: 0.1189
Epoch 216 Batch  140/269 - Train Accuracy: 0.8603, Validation Accuracy: 0.8709, Loss: 0.1206
Epoch 216 Batch  150/269 - Train Accuracy: 0.8628, Validation Accuracy: 0.8738, Loss: 0.1161
Epoch 216 Batch  160/269 - Train Accuracy: 0.8775, Validation Accuracy: 0.8682, Loss: 0.1106
Epoch 216 Batch  170/269 - Train Accuracy: 0.8681, Validation Accuracy: 0.8780, Loss: 0.1148
Epoch 216 Batch  180/269 - Train Accuracy: 0.8876, Validation Accuracy: 0.8785, Loss: 0.1136
Epoch 216 Batch  190/269 - Train Accuracy: 0.8803, Validation Accuracy: 0.8776, Loss: 0.1102
Epoch 216 Batch  200/269 - Train Accuracy: 0.8654, Validation Accuracy: 0.8755, Loss: 0.1118
Epoch 216 Batch  210/269 - Train Accuracy: 0.8645, Validation Accuracy: 0.8717, Loss: 0.1107
Epoch 216 Batch  220/269 - Train Accuracy: 0.8722, Validation Accuracy: 0.8675, Loss: 0.1139
Epoch 216 Batch  230/269 - Train Accuracy: 0.8597, Validation Accuracy: 0.8746, Loss: 0.1109
Epoch 216 Batch  240/269 - Train Accuracy: 0.8820, Validation Accuracy: 0.8691, Loss: 0.1077
Epoch 216 Batch  250/269 - Train Accuracy: 0.8831, Validation Accuracy: 0.8792, Loss: 0.1178
Epoch 216 Batch  260/269 - Train Accuracy: 0.8639, Validation Accuracy: 0.8730, Loss: 0.1236
Epoch 217 Batch   10/269 - Train Accuracy: 0.8713, Validation Accuracy: 0.8714, Loss: 0.0992
Epoch 217 Batch   20/269 - Train Accuracy: 0.8632, Validation Accuracy: 0.8701, Loss: 0.1089
Epoch 217 Batch   30/269 - Train Accuracy: 0.8612, Validation Accuracy: 0.8777, Loss: 0.1030
Epoch 217 Batch   40/269 - Train Accuracy: 0.8559, Validation Accuracy: 0.8738, Loss: 0.1290
Epoch 217 Batch   50/269 - Train Accuracy: 0.8476, Validation Accuracy: 0.8751, Loss: 0.1271
Epoch 217 Batch   60/269 - Train Accuracy: 0.8751, Validation Accuracy: 0.8760, Loss: 0.0997
Epoch 217 Batch   70/269 - Train Accuracy: 0.8864, Validation Accuracy: 0.8754, Loss: 0.1196
Epoch 217 Batch   80/269 - Train Accuracy: 0.8749, Validation Accuracy: 0.8687, Loss: 0.1049
Epoch 217 Batch   90/269 - Train Accuracy: 0.8707, Validation Accuracy: 0.8685, Loss: 0.1242
Epoch 217 Batch  100/269 - Train Accuracy: 0.8866, Validation Accuracy: 0.8770, Loss: 0.1143
Epoch 217 Batch  110/269 - Train Accuracy: 0.8613, Validation Accuracy: 0.8722, Loss: 0.1139
Epoch 217 Batch  120/269 - Train Accuracy: 0.8701, Validation Accuracy: 0.8666, Loss: 0.1274
Epoch 217 Batch  130/269 - Train Accuracy: 0.8602, Validation Accuracy: 0.8715, Loss: 0.1186
Epoch 217 Batch  140/269 - Train Accuracy: 0.8614, Validation Accuracy: 0.8753, Loss: 0.1165
Epoch 217 Batch  150/269 - Train Accuracy: 0.8641, Validation Accuracy: 0.8696, Loss: 0.1193
Epoch 217 Batch  160/269 - Train Accuracy: 0.8767, Validation Accuracy: 0.8755, Loss: 0.1110
Epoch 217 Batch  170/269 - Train Accuracy: 0.8668, Validation Accuracy: 0.8716, Loss: 0.1092
Epoch 217 Batch  180/269 - Train Accuracy: 0.8878, Validation Accuracy: 0.8743, Loss: 0.1064
Epoch 217 Batch  190/269 - Train Accuracy: 0.8772, Validation Accuracy: 0.8757, Loss: 0.1206
Epoch 217 Batch  200/269 - Train Accuracy: 0.8627, Validation Accuracy: 0.8768, Loss: 0.1207
Epoch 217 Batch  210/269 - Train Accuracy: 0.8692, Validation Accuracy: 0.8788, Loss: 0.1190
Epoch 217 Batch  220/269 - Train Accuracy: 0.8708, Validation Accuracy: 0.8675, Loss: 0.1136
Epoch 217 Batch  230/269 - Train Accuracy: 0.8632, Validation Accuracy: 0.8707, Loss: 0.1149
Epoch 217 Batch  240/269 - Train Accuracy: 0.8749, Validation Accuracy: 0.8758, Loss: 0.1025
Epoch 217 Batch  250/269 - Train Accuracy: 0.8776, Validation Accuracy: 0.8759, Loss: 0.1094
Epoch 217 Batch  260/269 - Train Accuracy: 0.8583, Validation Accuracy: 0.8773, Loss: 0.1180
Epoch 218 Batch   10/269 - Train Accuracy: 0.8669, Validation Accuracy: 0.8650, Loss: 0.1090
Epoch 218 Batch   20/269 - Train Accuracy: 0.8574, Validation Accuracy: 0.8717, Loss: 0.1093
Epoch 218 Batch   30/269 - Train Accuracy: 0.8702, Validation Accuracy: 0.8777, Loss: 0.1094
Epoch 218 Batch   40/269 - Train Accuracy: 0.8486, Validation Accuracy: 0.8762, Loss: 0.1258
Epoch 218 Batch   50/269 - Train Accuracy: 0.8521, Validation Accuracy: 0.8691, Loss: 0.1285
Epoch 218 Batch   60/269 - Train Accuracy: 0.8761, Validation Accuracy: 0.8751, Loss: 0.0992
Epoch 218 Batch   70/269 - Train Accuracy: 0.8926, Validation Accuracy: 0.8767, Loss: 0.1184
Epoch 218 Batch   80/269 - Train Accuracy: 0.8751, Validation Accuracy: 0.8762, Loss: 0.1131
Epoch 218 Batch   90/269 - Train Accuracy: 0.8728, Validation Accuracy: 0.8727, Loss: 0.1210
Epoch 218 Batch  100/269 - Train Accuracy: 0.8811, Validation Accuracy: 0.8671, Loss: 0.1134
Epoch 218 Batch  110/269 - Train Accuracy: 0.8583, Validation Accuracy: 0.8693, Loss: 0.1102
Epoch 218 Batch  120/269 - Train Accuracy: 0.8707, Validation Accuracy: 0.8719, Loss: 0.1268
Epoch 218 Batch  130/269 - Train Accuracy: 0.8538, Validation Accuracy: 0.8713, Loss: 0.1187
Epoch 218 Batch  140/269 - Train Accuracy: 0.8573, Validation Accuracy: 0.8681, Loss: 0.1268
Epoch 218 Batch  150/269 - Train Accuracy: 0.8645, Validation Accuracy: 0.8723, Loss: 0.1198
Epoch 218 Batch  160/269 - Train Accuracy: 0.8789, Validation Accuracy: 0.8762, Loss: 0.1214
Epoch 218 Batch  170/269 - Train Accuracy: 0.8615, Validation Accuracy: 0.8659, Loss: 0.1142
Epoch 218 Batch  180/269 - Train Accuracy: 0.8882, Validation Accuracy: 0.8764, Loss: 0.1026
Epoch 218 Batch  190/269 - Train Accuracy: 0.8802, Validation Accuracy: 0.8733, Loss: 0.1058
Epoch 218 Batch  200/269 - Train Accuracy: 0.8641, Validation Accuracy: 0.8744, Loss: 0.1124
Epoch 218 Batch  210/269 - Train Accuracy: 0.8698, Validation Accuracy: 0.8751, Loss: 0.1138
Epoch 218 Batch  220/269 - Train Accuracy: 0.8706, Validation Accuracy: 0.8657, Loss: 0.1183
Epoch 218 Batch  230/269 - Train Accuracy: 0.8583, Validation Accuracy: 0.8721, Loss: 0.1171
Epoch 218 Batch  240/269 - Train Accuracy: 0.8792, Validation Accuracy: 0.8736, Loss: 0.1009
Epoch 218 Batch  250/269 - Train Accuracy: 0.8800, Validation Accuracy: 0.8782, Loss: 0.1142
Epoch 218 Batch  260/269 - Train Accuracy: 0.8506, Validation Accuracy: 0.8741, Loss: 0.1244
Epoch 219 Batch   10/269 - Train Accuracy: 0.8740, Validation Accuracy: 0.8663, Loss: 0.1127
Epoch 219 Batch   20/269 - Train Accuracy: 0.8547, Validation Accuracy: 0.8699, Loss: 0.1099
Epoch 219 Batch   30/269 - Train Accuracy: 0.8626, Validation Accuracy: 0.8755, Loss: 0.1051
Epoch 219 Batch   40/269 - Train Accuracy: 0.8568, Validation Accuracy: 0.8713, Loss: 0.1355
Epoch 219 Batch   50/269 - Train Accuracy: 0.8477, Validation Accuracy: 0.8726, Loss: 0.1281
Epoch 219 Batch   60/269 - Train Accuracy: 0.8749, Validation Accuracy: 0.8739, Loss: 0.1091
Epoch 219 Batch   70/269 - Train Accuracy: 0.8813, Validation Accuracy: 0.8725, Loss: 0.1139
Epoch 219 Batch   80/269 - Train Accuracy: 0.8789, Validation Accuracy: 0.8774, Loss: 0.1055
Epoch 219 Batch   90/269 - Train Accuracy: 0.8695, Validation Accuracy: 0.8701, Loss: 0.1159
Epoch 219 Batch  100/269 - Train Accuracy: 0.8814, Validation Accuracy: 0.8702, Loss: 0.1146
Epoch 219 Batch  110/269 - Train Accuracy: 0.8590, Validation Accuracy: 0.8721, Loss: 0.1152
Epoch 219 Batch  120/269 - Train Accuracy: 0.8659, Validation Accuracy: 0.8687, Loss: 0.1253
Epoch 219 Batch  130/269 - Train Accuracy: 0.8653, Validation Accuracy: 0.8692, Loss: 0.1198
Epoch 219 Batch  140/269 - Train Accuracy: 0.8582, Validation Accuracy: 0.8667, Loss: 0.1169
Epoch 219 Batch  150/269 - Train Accuracy: 0.8626, Validation Accuracy: 0.8711, Loss: 0.1150
Epoch 219 Batch  160/269 - Train Accuracy: 0.8770, Validation Accuracy: 0.8773, Loss: 0.1208
Epoch 219 Batch  170/269 - Train Accuracy: 0.8611, Validation Accuracy: 0.8770, Loss: 0.1052
Epoch 219 Batch  180/269 - Train Accuracy: 0.8855, Validation Accuracy: 0.8743, Loss: 0.1032
Epoch 219 Batch  190/269 - Train Accuracy: 0.8765, Validation Accuracy: 0.8774, Loss: 0.1092
Epoch 219 Batch  200/269 - Train Accuracy: 0.8573, Validation Accuracy: 0.8688, Loss: 0.1045
Epoch 219 Batch  210/269 - Train Accuracy: 0.8649, Validation Accuracy: 0.8739, Loss: 0.1183
Epoch 219 Batch  220/269 - Train Accuracy: 0.8672, Validation Accuracy: 0.8657, Loss: 0.1150
Epoch 219 Batch  230/269 - Train Accuracy: 0.8571, Validation Accuracy: 0.8707, Loss: 0.1231
Epoch 219 Batch  240/269 - Train Accuracy: 0.8749, Validation Accuracy: 0.8779, Loss: 0.1012
Epoch 219 Batch  250/269 - Train Accuracy: 0.8799, Validation Accuracy: 0.8762, Loss: 0.1154
Epoch 219 Batch  260/269 - Train Accuracy: 0.8620, Validation Accuracy: 0.8705, Loss: 0.1208
Epoch 220 Batch   10/269 - Train Accuracy: 0.8729, Validation Accuracy: 0.8673, Loss: 0.1054
Epoch 220 Batch   20/269 - Train Accuracy: 0.8645, Validation Accuracy: 0.8738, Loss: 0.1169
Epoch 220 Batch   30/269 - Train Accuracy: 0.8669, Validation Accuracy: 0.8756, Loss: 0.1098
Epoch 220 Batch   40/269 - Train Accuracy: 0.8550, Validation Accuracy: 0.8750, Loss: 0.1216
Epoch 220 Batch   50/269 - Train Accuracy: 0.8543, Validation Accuracy: 0.8780, Loss: 0.1290
Epoch 220 Batch   60/269 - Train Accuracy: 0.8770, Validation Accuracy: 0.8736, Loss: 0.0994
Epoch 220 Batch   70/269 - Train Accuracy: 0.8808, Validation Accuracy: 0.8744, Loss: 0.1088
Epoch 220 Batch   80/269 - Train Accuracy: 0.8729, Validation Accuracy: 0.8724, Loss: 0.1038
Epoch 220 Batch   90/269 - Train Accuracy: 0.8740, Validation Accuracy: 0.8722, Loss: 0.1284
Epoch 220 Batch  100/269 - Train Accuracy: 0.8761, Validation Accuracy: 0.8652, Loss: 0.1279
Epoch 220 Batch  110/269 - Train Accuracy: 0.8523, Validation Accuracy: 0.8723, Loss: 0.1347
Epoch 220 Batch  120/269 - Train Accuracy: 0.8699, Validation Accuracy: 0.8699, Loss: 0.1284
Epoch 220 Batch  130/269 - Train Accuracy: 0.8522, Validation Accuracy: 0.8741, Loss: 0.1348
Epoch 220 Batch  140/269 - Train Accuracy: 0.8609, Validation Accuracy: 0.8706, Loss: 0.1348
Epoch 220 Batch  150/269 - Train Accuracy: 0.8645, Validation Accuracy: 0.8770, Loss: 0.1118
Epoch 220 Batch  160/269 - Train Accuracy: 0.8686, Validation Accuracy: 0.8796, Loss: 0.1135
Epoch 220 Batch  170/269 - Train Accuracy: 0.8651, Validation Accuracy: 0.8757, Loss: 0.1118
Epoch 220 Batch  180/269 - Train Accuracy: 0.8830, Validation Accuracy: 0.8678, Loss: 0.1109
Epoch 220 Batch  190/269 - Train Accuracy: 0.8804, Validation Accuracy: 0.8730, Loss: 0.1082
Epoch 220 Batch  200/269 - Train Accuracy: 0.8673, Validation Accuracy: 0.8779, Loss: 0.1072
Epoch 220 Batch  210/269 - Train Accuracy: 0.8665, Validation Accuracy: 0.8725, Loss: 0.1118
Epoch 220 Batch  220/269 - Train Accuracy: 0.8677, Validation Accuracy: 0.8631, Loss: 0.1205
Epoch 220 Batch  230/269 - Train Accuracy: 0.8523, Validation Accuracy: 0.8743, Loss: 0.1072
Epoch 220 Batch  240/269 - Train Accuracy: 0.8720, Validation Accuracy: 0.8706, Loss: 0.0961
Epoch 220 Batch  250/269 - Train Accuracy: 0.8806, Validation Accuracy: 0.8746, Loss: 0.1209
Epoch 220 Batch  260/269 - Train Accuracy: 0.8578, Validation Accuracy: 0.8718, Loss: 0.1227
Epoch 221 Batch   10/269 - Train Accuracy: 0.8741, Validation Accuracy: 0.8763, Loss: 0.1072
Epoch 221 Batch   20/269 - Train Accuracy: 0.8574, Validation Accuracy: 0.8713, Loss: 0.1093
Epoch 221 Batch   30/269 - Train Accuracy: 0.8667, Validation Accuracy: 0.8747, Loss: 0.1153
Epoch 221 Batch   40/269 - Train Accuracy: 0.8505, Validation Accuracy: 0.8734, Loss: 0.1196
Epoch 221 Batch   50/269 - Train Accuracy: 0.8506, Validation Accuracy: 0.8691, Loss: 0.1357
Epoch 221 Batch   60/269 - Train Accuracy: 0.8781, Validation Accuracy: 0.8764, Loss: 0.1058
Epoch 221 Batch   70/269 - Train Accuracy: 0.8827, Validation Accuracy: 0.8747, Loss: 0.1068
Epoch 221 Batch   80/269 - Train Accuracy: 0.8686, Validation Accuracy: 0.8730, Loss: 0.1091
Epoch 221 Batch   90/269 - Train Accuracy: 0.8705, Validation Accuracy: 0.8702, Loss: 0.1163
Epoch 221 Batch  100/269 - Train Accuracy: 0.8801, Validation Accuracy: 0.8742, Loss: 0.1059
Epoch 221 Batch  110/269 - Train Accuracy: 0.8601, Validation Accuracy: 0.8702, Loss: 0.1103
Epoch 221 Batch  120/269 - Train Accuracy: 0.8738, Validation Accuracy: 0.8745, Loss: 0.1183
Epoch 221 Batch  130/269 - Train Accuracy: 0.8613, Validation Accuracy: 0.8770, Loss: 0.1310
Epoch 221 Batch  140/269 - Train Accuracy: 0.8584, Validation Accuracy: 0.8778, Loss: 0.1240
Epoch 221 Batch  150/269 - Train Accuracy: 0.8705, Validation Accuracy: 0.8691, Loss: 0.1167
Epoch 221 Batch  160/269 - Train Accuracy: 0.8757, Validation Accuracy: 0.8729, Loss: 0.1223
Epoch 221 Batch  170/269 - Train Accuracy: 0.8641, Validation Accuracy: 0.8712, Loss: 0.1042
Epoch 221 Batch  180/269 - Train Accuracy: 0.8897, Validation Accuracy: 0.8754, Loss: 0.1041
Epoch 221 Batch  190/269 - Train Accuracy: 0.8810, Validation Accuracy: 0.8769, Loss: 0.1037
Epoch 221 Batch  200/269 - Train Accuracy: 0.8574, Validation Accuracy: 0.8746, Loss: 0.1118
Epoch 221 Batch  210/269 - Train Accuracy: 0.8689, Validation Accuracy: 0.8732, Loss: 0.1162
Epoch 221 Batch  220/269 - Train Accuracy: 0.8732, Validation Accuracy: 0.8737, Loss: 0.1063
Epoch 221 Batch  230/269 - Train Accuracy: 0.8605, Validation Accuracy: 0.8786, Loss: 0.1182
Epoch 221 Batch  240/269 - Train Accuracy: 0.8758, Validation Accuracy: 0.8723, Loss: 0.1089
Epoch 221 Batch  250/269 - Train Accuracy: 0.8776, Validation Accuracy: 0.8744, Loss: 0.1130
Epoch 221 Batch  260/269 - Train Accuracy: 0.8604, Validation Accuracy: 0.8769, Loss: 0.1201
Epoch 222 Batch   10/269 - Train Accuracy: 0.8724, Validation Accuracy: 0.8723, Loss: 0.1007
Epoch 222 Batch   20/269 - Train Accuracy: 0.8636, Validation Accuracy: 0.8699, Loss: 0.1097
Epoch 222 Batch   30/269 - Train Accuracy: 0.8670, Validation Accuracy: 0.8759, Loss: 0.1075
Epoch 222 Batch   40/269 - Train Accuracy: 0.8525, Validation Accuracy: 0.8756, Loss: 0.1216
Epoch 222 Batch   50/269 - Train Accuracy: 0.8531, Validation Accuracy: 0.8752, Loss: 0.1265
Epoch 222 Batch   60/269 - Train Accuracy: 0.8761, Validation Accuracy: 0.8708, Loss: 0.1153
Epoch 222 Batch   70/269 - Train Accuracy: 0.8816, Validation Accuracy: 0.8771, Loss: 0.1117
Epoch 222 Batch   80/269 - Train Accuracy: 0.8695, Validation Accuracy: 0.8743, Loss: 0.1090
Epoch 222 Batch   90/269 - Train Accuracy: 0.8746, Validation Accuracy: 0.8714, Loss: 0.1188
Epoch 222 Batch  100/269 - Train Accuracy: 0.8814, Validation Accuracy: 0.8751, Loss: 0.1069
Epoch 222 Batch  110/269 - Train Accuracy: 0.8617, Validation Accuracy: 0.8701, Loss: 0.1178
Epoch 222 Batch  120/269 - Train Accuracy: 0.8735, Validation Accuracy: 0.8768, Loss: 0.1207
Epoch 222 Batch  130/269 - Train Accuracy: 0.8594, Validation Accuracy: 0.8739, Loss: 0.1209
Epoch 222 Batch  140/269 - Train Accuracy: 0.8571, Validation Accuracy: 0.8703, Loss: 0.1145
Epoch 222 Batch  150/269 - Train Accuracy: 0.8692, Validation Accuracy: 0.8738, Loss: 0.1150
Epoch 222 Batch  160/269 - Train Accuracy: 0.8793, Validation Accuracy: 0.8757, Loss: 0.1095
Epoch 222 Batch  170/269 - Train Accuracy: 0.8690, Validation Accuracy: 0.8796, Loss: 0.1126
Epoch 222 Batch  180/269 - Train Accuracy: 0.8846, Validation Accuracy: 0.8752, Loss: 0.1023
Epoch 222 Batch  190/269 - Train Accuracy: 0.8805, Validation Accuracy: 0.8730, Loss: 0.1129
Epoch 222 Batch  200/269 - Train Accuracy: 0.8617, Validation Accuracy: 0.8762, Loss: 0.1044
Epoch 222 Batch  210/269 - Train Accuracy: 0.8726, Validation Accuracy: 0.8716, Loss: 0.1141
Epoch 222 Batch  220/269 - Train Accuracy: 0.8699, Validation Accuracy: 0.8703, Loss: 0.1127
Epoch 222 Batch  230/269 - Train Accuracy: 0.8569, Validation Accuracy: 0.8737, Loss: 0.1113
Epoch 222 Batch  240/269 - Train Accuracy: 0.8693, Validation Accuracy: 0.8699, Loss: 0.1062
Epoch 222 Batch  250/269 - Train Accuracy: 0.8859, Validation Accuracy: 0.8801, Loss: 0.1139
Epoch 222 Batch  260/269 - Train Accuracy: 0.8545, Validation Accuracy: 0.8767, Loss: 0.1236
Epoch 223 Batch   10/269 - Train Accuracy: 0.8714, Validation Accuracy: 0.8739, Loss: 0.1120
Epoch 223 Batch   20/269 - Train Accuracy: 0.8666, Validation Accuracy: 0.8736, Loss: 0.1109
Epoch 223 Batch   30/269 - Train Accuracy: 0.8654, Validation Accuracy: 0.8755, Loss: 0.1025
Epoch 223 Batch   40/269 - Train Accuracy: 0.8509, Validation Accuracy: 0.8742, Loss: 0.1212
Epoch 223 Batch   50/269 - Train Accuracy: 0.8549, Validation Accuracy: 0.8762, Loss: 0.1192
Epoch 223 Batch   60/269 - Train Accuracy: 0.8757, Validation Accuracy: 0.8779, Loss: 0.1064
Epoch 223 Batch   70/269 - Train Accuracy: 0.8861, Validation Accuracy: 0.8780, Loss: 0.1146
Epoch 223 Batch   80/269 - Train Accuracy: 0.8756, Validation Accuracy: 0.8691, Loss: 0.1098
Epoch 223 Batch   90/269 - Train Accuracy: 0.8777, Validation Accuracy: 0.8690, Loss: 0.1198
Epoch 223 Batch  100/269 - Train Accuracy: 0.8851, Validation Accuracy: 0.8735, Loss: 0.1107
Epoch 223 Batch  110/269 - Train Accuracy: 0.8580, Validation Accuracy: 0.8755, Loss: 0.1111
Epoch 223 Batch  120/269 - Train Accuracy: 0.8719, Validation Accuracy: 0.8770, Loss: 0.1205
Epoch 223 Batch  130/269 - Train Accuracy: 0.8604, Validation Accuracy: 0.8727, Loss: 0.1131
Epoch 223 Batch  140/269 - Train Accuracy: 0.8610, Validation Accuracy: 0.8688, Loss: 0.1172
Epoch 223 Batch  150/269 - Train Accuracy: 0.8656, Validation Accuracy: 0.8734, Loss: 0.1226
Epoch 223 Batch  160/269 - Train Accuracy: 0.8755, Validation Accuracy: 0.8787, Loss: 0.1121
Epoch 223 Batch  170/269 - Train Accuracy: 0.8607, Validation Accuracy: 0.8803, Loss: 0.1063
Epoch 223 Batch  180/269 - Train Accuracy: 0.8915, Validation Accuracy: 0.8749, Loss: 0.1076
Epoch 223 Batch  190/269 - Train Accuracy: 0.8773, Validation Accuracy: 0.8777, Loss: 0.1055
Epoch 223 Batch  200/269 - Train Accuracy: 0.8587, Validation Accuracy: 0.8730, Loss: 0.1024
Epoch 223 Batch  210/269 - Train Accuracy: 0.8704, Validation Accuracy: 0.8748, Loss: 0.1125
Epoch 223 Batch  220/269 - Train Accuracy: 0.8762, Validation Accuracy: 0.8778, Loss: 0.1184
Epoch 223 Batch  230/269 - Train Accuracy: 0.8610, Validation Accuracy: 0.8708, Loss: 0.1116
Epoch 223 Batch  240/269 - Train Accuracy: 0.8775, Validation Accuracy: 0.8787, Loss: 0.0977
Epoch 223 Batch  250/269 - Train Accuracy: 0.8803, Validation Accuracy: 0.8771, Loss: 0.1116
Epoch 223 Batch  260/269 - Train Accuracy: 0.8615, Validation Accuracy: 0.8755, Loss: 0.1196
Epoch 224 Batch   10/269 - Train Accuracy: 0.8682, Validation Accuracy: 0.8698, Loss: 0.1078
Epoch 224 Batch   20/269 - Train Accuracy: 0.8581, Validation Accuracy: 0.8686, Loss: 0.1138
Epoch 224 Batch   30/269 - Train Accuracy: 0.8613, Validation Accuracy: 0.8754, Loss: 0.1033
Epoch 224 Batch   40/269 - Train Accuracy: 0.8591, Validation Accuracy: 0.8770, Loss: 0.1299
Epoch 224 Batch   50/269 - Train Accuracy: 0.8503, Validation Accuracy: 0.8749, Loss: 0.1192
Epoch 224 Batch   60/269 - Train Accuracy: 0.8763, Validation Accuracy: 0.8704, Loss: 0.1112
Epoch 224 Batch   70/269 - Train Accuracy: 0.8842, Validation Accuracy: 0.8781, Loss: 0.1207
Epoch 224 Batch   80/269 - Train Accuracy: 0.8696, Validation Accuracy: 0.8736, Loss: 0.1077
Epoch 224 Batch   90/269 - Train Accuracy: 0.8726, Validation Accuracy: 0.8727, Loss: 0.1316
Epoch 224 Batch  100/269 - Train Accuracy: 0.8824, Validation Accuracy: 0.8764, Loss: 0.1111
Epoch 224 Batch  110/269 - Train Accuracy: 0.8584, Validation Accuracy: 0.8706, Loss: 0.1174
Epoch 224 Batch  120/269 - Train Accuracy: 0.8720, Validation Accuracy: 0.8722, Loss: 0.1173
Epoch 224 Batch  130/269 - Train Accuracy: 0.8571, Validation Accuracy: 0.8720, Loss: 0.1188
Epoch 224 Batch  140/269 - Train Accuracy: 0.8561, Validation Accuracy: 0.8707, Loss: 0.1166
Epoch 224 Batch  150/269 - Train Accuracy: 0.8665, Validation Accuracy: 0.8724, Loss: 0.1179
Epoch 224 Batch  160/269 - Train Accuracy: 0.8786, Validation Accuracy: 0.8719, Loss: 0.1193
Epoch 224 Batch  170/269 - Train Accuracy: 0.8649, Validation Accuracy: 0.8691, Loss: 0.1068
Epoch 224 Batch  180/269 - Train Accuracy: 0.8836, Validation Accuracy: 0.8730, Loss: 0.0998
Epoch 224 Batch  190/269 - Train Accuracy: 0.8790, Validation Accuracy: 0.8795, Loss: 0.1105
Epoch 224 Batch  200/269 - Train Accuracy: 0.8608, Validation Accuracy: 0.8739, Loss: 0.1120
Epoch 224 Batch  210/269 - Train Accuracy: 0.8720, Validation Accuracy: 0.8724, Loss: 0.1109
Epoch 224 Batch  220/269 - Train Accuracy: 0.8659, Validation Accuracy: 0.8728, Loss: 0.1150
Epoch 224 Batch  230/269 - Train Accuracy: 0.8609, Validation Accuracy: 0.8745, Loss: 0.1099
Epoch 224 Batch  240/269 - Train Accuracy: 0.8710, Validation Accuracy: 0.8757, Loss: 0.1043
Epoch 224 Batch  250/269 - Train Accuracy: 0.8830, Validation Accuracy: 0.8741, Loss: 0.1077
Epoch 224 Batch  260/269 - Train Accuracy: 0.8580, Validation Accuracy: 0.8763, Loss: 0.1168
Epoch 225 Batch   10/269 - Train Accuracy: 0.8713, Validation Accuracy: 0.8690, Loss: 0.1056
Epoch 225 Batch   20/269 - Train Accuracy: 0.8636, Validation Accuracy: 0.8692, Loss: 0.1045
Epoch 225 Batch   30/269 - Train Accuracy: 0.8681, Validation Accuracy: 0.8776, Loss: 0.1061
Epoch 225 Batch   40/269 - Train Accuracy: 0.8572, Validation Accuracy: 0.8746, Loss: 0.1204
Epoch 225 Batch   50/269 - Train Accuracy: 0.8551, Validation Accuracy: 0.8683, Loss: 0.1206
Epoch 225 Batch   60/269 - Train Accuracy: 0.8764, Validation Accuracy: 0.8719, Loss: 0.1114
Epoch 225 Batch   70/269 - Train Accuracy: 0.8858, Validation Accuracy: 0.8698, Loss: 0.1221
Epoch 225 Batch   80/269 - Train Accuracy: 0.8792, Validation Accuracy: 0.8753, Loss: 0.1074
Epoch 225 Batch   90/269 - Train Accuracy: 0.8760, Validation Accuracy: 0.8722, Loss: 0.1203
Epoch 225 Batch  100/269 - Train Accuracy: 0.8825, Validation Accuracy: 0.8740, Loss: 0.1038
Epoch 225 Batch  110/269 - Train Accuracy: 0.8582, Validation Accuracy: 0.8730, Loss: 0.1119
Epoch 225 Batch  120/269 - Train Accuracy: 0.8670, Validation Accuracy: 0.8716, Loss: 0.1286
Epoch 225 Batch  130/269 - Train Accuracy: 0.8614, Validation Accuracy: 0.8754, Loss: 0.1184
Epoch 225 Batch  140/269 - Train Accuracy: 0.8611, Validation Accuracy: 0.8718, Loss: 0.1192
Epoch 225 Batch  150/269 - Train Accuracy: 0.8661, Validation Accuracy: 0.8723, Loss: 0.1181
Epoch 225 Batch  160/269 - Train Accuracy: 0.8748, Validation Accuracy: 0.8709, Loss: 0.1037
Epoch 225 Batch  170/269 - Train Accuracy: 0.8631, Validation Accuracy: 0.8741, Loss: 0.1051
Epoch 225 Batch  180/269 - Train Accuracy: 0.8827, Validation Accuracy: 0.8729, Loss: 0.1077
Epoch 225 Batch  190/269 - Train Accuracy: 0.8797, Validation Accuracy: 0.8758, Loss: 0.1172
Epoch 225 Batch  200/269 - Train Accuracy: 0.8643, Validation Accuracy: 0.8755, Loss: 0.1069
Epoch 225 Batch  210/269 - Train Accuracy: 0.8690, Validation Accuracy: 0.8688, Loss: 0.1106
Epoch 225 Batch  220/269 - Train Accuracy: 0.8742, Validation Accuracy: 0.8692, Loss: 0.1160
Epoch 225 Batch  230/269 - Train Accuracy: 0.8632, Validation Accuracy: 0.8667, Loss: 0.1361
Epoch 225 Batch  240/269 - Train Accuracy: 0.8811, Validation Accuracy: 0.8688, Loss: 0.1061
Epoch 225 Batch  250/269 - Train Accuracy: 0.8778, Validation Accuracy: 0.8726, Loss: 0.1138
Epoch 225 Batch  260/269 - Train Accuracy: 0.8557, Validation Accuracy: 0.8761, Loss: 0.1274
Epoch 226 Batch   10/269 - Train Accuracy: 0.8724, Validation Accuracy: 0.8714, Loss: 0.1028
Epoch 226 Batch   20/269 - Train Accuracy: 0.8658, Validation Accuracy: 0.8760, Loss: 0.1096
Epoch 226 Batch   30/269 - Train Accuracy: 0.8655, Validation Accuracy: 0.8743, Loss: 0.1077
Epoch 226 Batch   40/269 - Train Accuracy: 0.8586, Validation Accuracy: 0.8740, Loss: 0.1273
Epoch 226 Batch   50/269 - Train Accuracy: 0.8524, Validation Accuracy: 0.8744, Loss: 0.1233
Epoch 226 Batch   60/269 - Train Accuracy: 0.8754, Validation Accuracy: 0.8755, Loss: 0.1104
Epoch 226 Batch   70/269 - Train Accuracy: 0.8794, Validation Accuracy: 0.8783, Loss: 0.1046
Epoch 226 Batch   80/269 - Train Accuracy: 0.8659, Validation Accuracy: 0.8715, Loss: 0.1066
Epoch 226 Batch   90/269 - Train Accuracy: 0.8762, Validation Accuracy: 0.8722, Loss: 0.1195
Epoch 226 Batch  100/269 - Train Accuracy: 0.8854, Validation Accuracy: 0.8737, Loss: 0.1203
Epoch 226 Batch  110/269 - Train Accuracy: 0.8633, Validation Accuracy: 0.8786, Loss: 0.1112
Epoch 226 Batch  120/269 - Train Accuracy: 0.8730, Validation Accuracy: 0.8690, Loss: 0.1165
Epoch 226 Batch  130/269 - Train Accuracy: 0.8588, Validation Accuracy: 0.8766, Loss: 0.1084
Epoch 226 Batch  140/269 - Train Accuracy: 0.8557, Validation Accuracy: 0.8698, Loss: 0.1250
Epoch 226 Batch  150/269 - Train Accuracy: 0.8646, Validation Accuracy: 0.8731, Loss: 0.1240
Epoch 226 Batch  160/269 - Train Accuracy: 0.8724, Validation Accuracy: 0.8731, Loss: 0.1138
Epoch 226 Batch  170/269 - Train Accuracy: 0.8626, Validation Accuracy: 0.8732, Loss: 0.1101
Epoch 226 Batch  180/269 - Train Accuracy: 0.8885, Validation Accuracy: 0.8752, Loss: 0.1016
Epoch 226 Batch  190/269 - Train Accuracy: 0.8806, Validation Accuracy: 0.8751, Loss: 0.1099
Epoch 226 Batch  200/269 - Train Accuracy: 0.8625, Validation Accuracy: 0.8737, Loss: 0.1074
Epoch 226 Batch  210/269 - Train Accuracy: 0.8702, Validation Accuracy: 0.8745, Loss: 0.1147
Epoch 226 Batch  220/269 - Train Accuracy: 0.8664, Validation Accuracy: 0.8779, Loss: 0.1117
Epoch 226 Batch  230/269 - Train Accuracy: 0.8657, Validation Accuracy: 0.8718, Loss: 0.1036
Epoch 226 Batch  240/269 - Train Accuracy: 0.8764, Validation Accuracy: 0.8725, Loss: 0.1036
Epoch 226 Batch  250/269 - Train Accuracy: 0.8800, Validation Accuracy: 0.8783, Loss: 0.1050
Epoch 226 Batch  260/269 - Train Accuracy: 0.8643, Validation Accuracy: 0.8746, Loss: 0.1179
Epoch 227 Batch   10/269 - Train Accuracy: 0.8709, Validation Accuracy: 0.8692, Loss: 0.1084
Epoch 227 Batch   20/269 - Train Accuracy: 0.8646, Validation Accuracy: 0.8790, Loss: 0.1051
Epoch 227 Batch   30/269 - Train Accuracy: 0.8660, Validation Accuracy: 0.8817, Loss: 0.1094
Epoch 227 Batch   40/269 - Train Accuracy: 0.8511, Validation Accuracy: 0.8762, Loss: 0.1337
Epoch 227 Batch   50/269 - Train Accuracy: 0.8530, Validation Accuracy: 0.8753, Loss: 0.1255
Epoch 227 Batch   60/269 - Train Accuracy: 0.8804, Validation Accuracy: 0.8775, Loss: 0.1036
Epoch 227 Batch   70/269 - Train Accuracy: 0.8794, Validation Accuracy: 0.8730, Loss: 0.1172
Epoch 227 Batch   80/269 - Train Accuracy: 0.8743, Validation Accuracy: 0.8723, Loss: 0.1067
Epoch 227 Batch   90/269 - Train Accuracy: 0.8758, Validation Accuracy: 0.8700, Loss: 0.1219
Epoch 227 Batch  100/269 - Train Accuracy: 0.8854, Validation Accuracy: 0.8762, Loss: 0.1091
Epoch 227 Batch  110/269 - Train Accuracy: 0.8570, Validation Accuracy: 0.8738, Loss: 0.1117
Epoch 227 Batch  120/269 - Train Accuracy: 0.8619, Validation Accuracy: 0.8734, Loss: 0.1177
Epoch 227 Batch  130/269 - Train Accuracy: 0.8552, Validation Accuracy: 0.8697, Loss: 0.1152
Epoch 227 Batch  140/269 - Train Accuracy: 0.8627, Validation Accuracy: 0.8701, Loss: 0.1179
Epoch 227 Batch  150/269 - Train Accuracy: 0.8696, Validation Accuracy: 0.8702, Loss: 0.1053
Epoch 227 Batch  160/269 - Train Accuracy: 0.8753, Validation Accuracy: 0.8744, Loss: 0.1117
Epoch 227 Batch  170/269 - Train Accuracy: 0.8640, Validation Accuracy: 0.8741, Loss: 0.1052
Epoch 227 Batch  180/269 - Train Accuracy: 0.8877, Validation Accuracy: 0.8705, Loss: 0.1110
Epoch 227 Batch  190/269 - Train Accuracy: 0.8836, Validation Accuracy: 0.8751, Loss: 0.1043
Epoch 227 Batch  200/269 - Train Accuracy: 0.8623, Validation Accuracy: 0.8739, Loss: 0.1076
Epoch 227 Batch  210/269 - Train Accuracy: 0.8666, Validation Accuracy: 0.8691, Loss: 0.1114
Epoch 227 Batch  220/269 - Train Accuracy: 0.8714, Validation Accuracy: 0.8714, Loss: 0.1218
Epoch 227 Batch  230/269 - Train Accuracy: 0.8610, Validation Accuracy: 0.8690, Loss: 0.1093
Epoch 227 Batch  240/269 - Train Accuracy: 0.8764, Validation Accuracy: 0.8699, Loss: 0.1090
Epoch 227 Batch  250/269 - Train Accuracy: 0.8800, Validation Accuracy: 0.8769, Loss: 0.1038
Epoch 227 Batch  260/269 - Train Accuracy: 0.8571, Validation Accuracy: 0.8759, Loss: 0.1101
Epoch 228 Batch   10/269 - Train Accuracy: 0.8704, Validation Accuracy: 0.8706, Loss: 0.1095
Epoch 228 Batch   20/269 - Train Accuracy: 0.8618, Validation Accuracy: 0.8737, Loss: 0.1017
Epoch 228 Batch   30/269 - Train Accuracy: 0.8667, Validation Accuracy: 0.8749, Loss: 0.1125
Epoch 228 Batch   40/269 - Train Accuracy: 0.8524, Validation Accuracy: 0.8748, Loss: 0.1209
Epoch 228 Batch   50/269 - Train Accuracy: 0.8531, Validation Accuracy: 0.8731, Loss: 0.1272
Epoch 228 Batch   60/269 - Train Accuracy: 0.8768, Validation Accuracy: 0.8686, Loss: 0.1022
Epoch 228 Batch   70/269 - Train Accuracy: 0.8848, Validation Accuracy: 0.8733, Loss: 0.1139
Epoch 228 Batch   80/269 - Train Accuracy: 0.8767, Validation Accuracy: 0.8732, Loss: 0.1052
Epoch 228 Batch   90/269 - Train Accuracy: 0.8650, Validation Accuracy: 0.8690, Loss: 0.1208
Epoch 228 Batch  100/269 - Train Accuracy: 0.8847, Validation Accuracy: 0.8705, Loss: 0.1033
Epoch 228 Batch  110/269 - Train Accuracy: 0.8633, Validation Accuracy: 0.8742, Loss: 0.1150
Epoch 228 Batch  120/269 - Train Accuracy: 0.8628, Validation Accuracy: 0.8744, Loss: 0.1188
Epoch 228 Batch  130/269 - Train Accuracy: 0.8582, Validation Accuracy: 0.8724, Loss: 0.1156
Epoch 228 Batch  140/269 - Train Accuracy: 0.8619, Validation Accuracy: 0.8682, Loss: 0.1206
Epoch 228 Batch  150/269 - Train Accuracy: 0.8671, Validation Accuracy: 0.8727, Loss: 0.1115
Epoch 228 Batch  160/269 - Train Accuracy: 0.8793, Validation Accuracy: 0.8731, Loss: 0.1176
Epoch 228 Batch  170/269 - Train Accuracy: 0.8630, Validation Accuracy: 0.8752, Loss: 0.1136
Epoch 228 Batch  180/269 - Train Accuracy: 0.8872, Validation Accuracy: 0.8741, Loss: 0.1075
Epoch 228 Batch  190/269 - Train Accuracy: 0.8790, Validation Accuracy: 0.8750, Loss: 0.1038
Epoch 228 Batch  200/269 - Train Accuracy: 0.8576, Validation Accuracy: 0.8762, Loss: 0.1051
Epoch 228 Batch  210/269 - Train Accuracy: 0.8681, Validation Accuracy: 0.8673, Loss: 0.1121
Epoch 228 Batch  220/269 - Train Accuracy: 0.8681, Validation Accuracy: 0.8699, Loss: 0.1083
Epoch 228 Batch  230/269 - Train Accuracy: 0.8591, Validation Accuracy: 0.8755, Loss: 0.1042
Epoch 228 Batch  240/269 - Train Accuracy: 0.8775, Validation Accuracy: 0.8713, Loss: 0.1096
Epoch 228 Batch  250/269 - Train Accuracy: 0.8772, Validation Accuracy: 0.8784, Loss: 0.1019
Epoch 228 Batch  260/269 - Train Accuracy: 0.8587, Validation Accuracy: 0.8766, Loss: 0.1221
Epoch 229 Batch   10/269 - Train Accuracy: 0.8732, Validation Accuracy: 0.8699, Loss: 0.1054
Epoch 229 Batch   20/269 - Train Accuracy: 0.8664, Validation Accuracy: 0.8735, Loss: 0.1140
Epoch 229 Batch   30/269 - Train Accuracy: 0.8651, Validation Accuracy: 0.8754, Loss: 0.1047
Epoch 229 Batch   40/269 - Train Accuracy: 0.8558, Validation Accuracy: 0.8736, Loss: 0.1204
Epoch 229 Batch   50/269 - Train Accuracy: 0.8534, Validation Accuracy: 0.8726, Loss: 0.1151
Epoch 229 Batch   60/269 - Train Accuracy: 0.8763, Validation Accuracy: 0.8738, Loss: 0.1044
Epoch 229 Batch   70/269 - Train Accuracy: 0.8813, Validation Accuracy: 0.8770, Loss: 0.1099
Epoch 229 Batch   80/269 - Train Accuracy: 0.8706, Validation Accuracy: 0.8720, Loss: 0.1001
Epoch 229 Batch   90/269 - Train Accuracy: 0.8711, Validation Accuracy: 0.8735, Loss: 0.1160
Epoch 229 Batch  100/269 - Train Accuracy: 0.8841, Validation Accuracy: 0.8698, Loss: 0.1111
Epoch 229 Batch  110/269 - Train Accuracy: 0.8580, Validation Accuracy: 0.8752, Loss: 0.1204
Epoch 229 Batch  120/269 - Train Accuracy: 0.8679, Validation Accuracy: 0.8740, Loss: 0.1212
Epoch 229 Batch  130/269 - Train Accuracy: 0.8555, Validation Accuracy: 0.8729, Loss: 0.1171
Epoch 229 Batch  140/269 - Train Accuracy: 0.8634, Validation Accuracy: 0.8715, Loss: 0.1218
Epoch 229 Batch  150/269 - Train Accuracy: 0.8710, Validation Accuracy: 0.8679, Loss: 0.1022
Epoch 229 Batch  160/269 - Train Accuracy: 0.8764, Validation Accuracy: 0.8742, Loss: 0.1108
Epoch 229 Batch  170/269 - Train Accuracy: 0.8664, Validation Accuracy: 0.8702, Loss: 0.1157
Epoch 229 Batch  180/269 - Train Accuracy: 0.8880, Validation Accuracy: 0.8746, Loss: 0.1100
Epoch 229 Batch  190/269 - Train Accuracy: 0.8760, Validation Accuracy: 0.8772, Loss: 0.1155
Epoch 229 Batch  200/269 - Train Accuracy: 0.8652, Validation Accuracy: 0.8725, Loss: 0.1142
Epoch 229 Batch  210/269 - Train Accuracy: 0.8688, Validation Accuracy: 0.8714, Loss: 0.1095
Epoch 229 Batch  220/269 - Train Accuracy: 0.8681, Validation Accuracy: 0.8754, Loss: 0.1103
Epoch 229 Batch  230/269 - Train Accuracy: 0.8605, Validation Accuracy: 0.8755, Loss: 0.1104
Epoch 229 Batch  240/269 - Train Accuracy: 0.8778, Validation Accuracy: 0.8716, Loss: 0.0997
Epoch 229 Batch  250/269 - Train Accuracy: 0.8803, Validation Accuracy: 0.8751, Loss: 0.1063
Epoch 229 Batch  260/269 - Train Accuracy: 0.8605, Validation Accuracy: 0.8750, Loss: 0.1388
Epoch 230 Batch   10/269 - Train Accuracy: 0.8684, Validation Accuracy: 0.8691, Loss: 0.1083
Epoch 230 Batch   20/269 - Train Accuracy: 0.8651, Validation Accuracy: 0.8761, Loss: 0.0993
Epoch 230 Batch   30/269 - Train Accuracy: 0.8648, Validation Accuracy: 0.8734, Loss: 0.1086
Epoch 230 Batch   40/269 - Train Accuracy: 0.8534, Validation Accuracy: 0.8724, Loss: 0.1187
Epoch 230 Batch   50/269 - Train Accuracy: 0.8537, Validation Accuracy: 0.8788, Loss: 0.1165
Epoch 230 Batch   60/269 - Train Accuracy: 0.8770, Validation Accuracy: 0.8706, Loss: 0.1073
Epoch 230 Batch   70/269 - Train Accuracy: 0.8810, Validation Accuracy: 0.8768, Loss: 0.1128
Epoch 230 Batch   80/269 - Train Accuracy: 0.8756, Validation Accuracy: 0.8761, Loss: 0.1114
Epoch 230 Batch   90/269 - Train Accuracy: 0.8767, Validation Accuracy: 0.8705, Loss: 0.1213
Epoch 230 Batch  100/269 - Train Accuracy: 0.8776, Validation Accuracy: 0.8671, Loss: 0.1084
Epoch 230 Batch  110/269 - Train Accuracy: 0.8607, Validation Accuracy: 0.8732, Loss: 0.1073
Epoch 230 Batch  120/269 - Train Accuracy: 0.8701, Validation Accuracy: 0.8699, Loss: 0.1195
Epoch 230 Batch  130/269 - Train Accuracy: 0.8629, Validation Accuracy: 0.8730, Loss: 0.1210
Epoch 230 Batch  140/269 - Train Accuracy: 0.8610, Validation Accuracy: 0.8675, Loss: 0.1191
Epoch 230 Batch  150/269 - Train Accuracy: 0.8674, Validation Accuracy: 0.8716, Loss: 0.1127
Epoch 230 Batch  160/269 - Train Accuracy: 0.8814, Validation Accuracy: 0.8725, Loss: 0.1123
Epoch 230 Batch  170/269 - Train Accuracy: 0.8595, Validation Accuracy: 0.8714, Loss: 0.1024
Epoch 230 Batch  180/269 - Train Accuracy: 0.8890, Validation Accuracy: 0.8769, Loss: 0.0982
Epoch 230 Batch  190/269 - Train Accuracy: 0.8775, Validation Accuracy: 0.8801, Loss: 0.1072
Epoch 230 Batch  200/269 - Train Accuracy: 0.8651, Validation Accuracy: 0.8797, Loss: 0.1159
Epoch 230 Batch  210/269 - Train Accuracy: 0.8677, Validation Accuracy: 0.8730, Loss: 0.1155
Epoch 230 Batch  220/269 - Train Accuracy: 0.8722, Validation Accuracy: 0.8722, Loss: 0.1164
Epoch 230 Batch  230/269 - Train Accuracy: 0.8560, Validation Accuracy: 0.8749, Loss: 0.1060
Epoch 230 Batch  240/269 - Train Accuracy: 0.8788, Validation Accuracy: 0.8723, Loss: 0.1031
Epoch 230 Batch  250/269 - Train Accuracy: 0.8793, Validation Accuracy: 0.8778, Loss: 0.1130
Epoch 230 Batch  260/269 - Train Accuracy: 0.8562, Validation Accuracy: 0.8742, Loss: 0.1224
Epoch 231 Batch   10/269 - Train Accuracy: 0.8732, Validation Accuracy: 0.8699, Loss: 0.1004
Epoch 231 Batch   20/269 - Train Accuracy: 0.8577, Validation Accuracy: 0.8711, Loss: 0.1077
Epoch 231 Batch   30/269 - Train Accuracy: 0.8657, Validation Accuracy: 0.8744, Loss: 0.1014
Epoch 231 Batch   40/269 - Train Accuracy: 0.8540, Validation Accuracy: 0.8747, Loss: 0.1174
Epoch 231 Batch   50/269 - Train Accuracy: 0.8506, Validation Accuracy: 0.8771, Loss: 0.1224
Epoch 231 Batch   60/269 - Train Accuracy: 0.8724, Validation Accuracy: 0.8743, Loss: 0.1093
Epoch 231 Batch   70/269 - Train Accuracy: 0.8823, Validation Accuracy: 0.8756, Loss: 0.1088
Epoch 231 Batch   80/269 - Train Accuracy: 0.8696, Validation Accuracy: 0.8667, Loss: 0.1120
Epoch 231 Batch   90/269 - Train Accuracy: 0.8663, Validation Accuracy: 0.8749, Loss: 0.1196
Epoch 231 Batch  100/269 - Train Accuracy: 0.8850, Validation Accuracy: 0.8736, Loss: 0.1033
Epoch 231 Batch  110/269 - Train Accuracy: 0.8562, Validation Accuracy: 0.8730, Loss: 0.1140
Epoch 231 Batch  120/269 - Train Accuracy: 0.8695, Validation Accuracy: 0.8727, Loss: 0.1184
Epoch 231 Batch  130/269 - Train Accuracy: 0.8571, Validation Accuracy: 0.8824, Loss: 0.1209
Epoch 231 Batch  140/269 - Train Accuracy: 0.8648, Validation Accuracy: 0.8758, Loss: 0.1234
Epoch 231 Batch  150/269 - Train Accuracy: 0.8670, Validation Accuracy: 0.8709, Loss: 0.1145
Epoch 231 Batch  160/269 - Train Accuracy: 0.8787, Validation Accuracy: 0.8725, Loss: 0.1105
Epoch 231 Batch  170/269 - Train Accuracy: 0.8651, Validation Accuracy: 0.8749, Loss: 0.1151
Epoch 231 Batch  180/269 - Train Accuracy: 0.8914, Validation Accuracy: 0.8762, Loss: 0.1054
Epoch 231 Batch  190/269 - Train Accuracy: 0.8818, Validation Accuracy: 0.8727, Loss: 0.1142
Epoch 231 Batch  200/269 - Train Accuracy: 0.8654, Validation Accuracy: 0.8738, Loss: 0.1073
Epoch 231 Batch  210/269 - Train Accuracy: 0.8644, Validation Accuracy: 0.8740, Loss: 0.1153
Epoch 231 Batch  220/269 - Train Accuracy: 0.8704, Validation Accuracy: 0.8724, Loss: 0.1104
Epoch 231 Batch  230/269 - Train Accuracy: 0.8574, Validation Accuracy: 0.8784, Loss: 0.1203
Epoch 231 Batch  240/269 - Train Accuracy: 0.8745, Validation Accuracy: 0.8730, Loss: 0.0957
Epoch 231 Batch  250/269 - Train Accuracy: 0.8790, Validation Accuracy: 0.8762, Loss: 0.1141
Epoch 231 Batch  260/269 - Train Accuracy: 0.8618, Validation Accuracy: 0.8753, Loss: 0.1144
Epoch 232 Batch   10/269 - Train Accuracy: 0.8729, Validation Accuracy: 0.8702, Loss: 0.1067
Epoch 232 Batch   20/269 - Train Accuracy: 0.8653, Validation Accuracy: 0.8708, Loss: 0.1087
Epoch 232 Batch   30/269 - Train Accuracy: 0.8664, Validation Accuracy: 0.8729, Loss: 0.0997
Epoch 232 Batch   40/269 - Train Accuracy: 0.8537, Validation Accuracy: 0.8744, Loss: 0.1251
Epoch 232 Batch   50/269 - Train Accuracy: 0.8528, Validation Accuracy: 0.8697, Loss: 0.1172
Epoch 232 Batch   60/269 - Train Accuracy: 0.8765, Validation Accuracy: 0.8743, Loss: 0.1045
Epoch 232 Batch   70/269 - Train Accuracy: 0.8853, Validation Accuracy: 0.8762, Loss: 0.1100
Epoch 232 Batch   80/269 - Train Accuracy: 0.8708, Validation Accuracy: 0.8753, Loss: 0.1046
Epoch 232 Batch   90/269 - Train Accuracy: 0.8782, Validation Accuracy: 0.8789, Loss: 0.1230
Epoch 232 Batch  100/269 - Train Accuracy: 0.8883, Validation Accuracy: 0.8715, Loss: 0.1034
Epoch 232 Batch  110/269 - Train Accuracy: 0.8602, Validation Accuracy: 0.8730, Loss: 0.1228
Epoch 232 Batch  120/269 - Train Accuracy: 0.8709, Validation Accuracy: 0.8691, Loss: 0.1186
Epoch 232 Batch  130/269 - Train Accuracy: 0.8648, Validation Accuracy: 0.8775, Loss: 0.1185
Epoch 232 Batch  140/269 - Train Accuracy: 0.8636, Validation Accuracy: 0.8706, Loss: 0.1166
Epoch 232 Batch  150/269 - Train Accuracy: 0.8669, Validation Accuracy: 0.8735, Loss: 0.1146
Epoch 232 Batch  160/269 - Train Accuracy: 0.8799, Validation Accuracy: 0.8762, Loss: 0.1052
Epoch 232 Batch  170/269 - Train Accuracy: 0.8661, Validation Accuracy: 0.8770, Loss: 0.1033
Epoch 232 Batch  180/269 - Train Accuracy: 0.8904, Validation Accuracy: 0.8727, Loss: 0.1063
Epoch 232 Batch  190/269 - Train Accuracy: 0.8826, Validation Accuracy: 0.8744, Loss: 0.1083
Epoch 232 Batch  200/269 - Train Accuracy: 0.8562, Validation Accuracy: 0.8743, Loss: 0.1052
Epoch 232 Batch  210/269 - Train Accuracy: 0.8731, Validation Accuracy: 0.8770, Loss: 0.1097
Epoch 232 Batch  220/269 - Train Accuracy: 0.8739, Validation Accuracy: 0.8740, Loss: 0.1054
Epoch 232 Batch  230/269 - Train Accuracy: 0.8602, Validation Accuracy: 0.8732, Loss: 0.1119
Epoch 232 Batch  240/269 - Train Accuracy: 0.8744, Validation Accuracy: 0.8705, Loss: 0.0996
Epoch 232 Batch  250/269 - Train Accuracy: 0.8773, Validation Accuracy: 0.8724, Loss: 0.1035
Epoch 232 Batch  260/269 - Train Accuracy: 0.8535, Validation Accuracy: 0.8790, Loss: 0.1147
Epoch 233 Batch   10/269 - Train Accuracy: 0.8762, Validation Accuracy: 0.8749, Loss: 0.1046
Epoch 233 Batch   20/269 - Train Accuracy: 0.8631, Validation Accuracy: 0.8746, Loss: 0.1174
Epoch 233 Batch   30/269 - Train Accuracy: 0.8678, Validation Accuracy: 0.8754, Loss: 0.1003
Epoch 233 Batch   40/269 - Train Accuracy: 0.8603, Validation Accuracy: 0.8724, Loss: 0.1179
Epoch 233 Batch   50/269 - Train Accuracy: 0.8523, Validation Accuracy: 0.8704, Loss: 0.1212
Epoch 233 Batch   60/269 - Train Accuracy: 0.8770, Validation Accuracy: 0.8724, Loss: 0.1054
Epoch 233 Batch   70/269 - Train Accuracy: 0.8802, Validation Accuracy: 0.8713, Loss: 0.1128
Epoch 233 Batch   80/269 - Train Accuracy: 0.8751, Validation Accuracy: 0.8734, Loss: 0.1069
Epoch 233 Batch   90/269 - Train Accuracy: 0.8777, Validation Accuracy: 0.8743, Loss: 0.1179
Epoch 233 Batch  100/269 - Train Accuracy: 0.8838, Validation Accuracy: 0.8720, Loss: 0.1091
Epoch 233 Batch  110/269 - Train Accuracy: 0.8611, Validation Accuracy: 0.8714, Loss: 0.1101
Epoch 233 Batch  120/269 - Train Accuracy: 0.8768, Validation Accuracy: 0.8724, Loss: 0.1156
Epoch 233 Batch  130/269 - Train Accuracy: 0.8601, Validation Accuracy: 0.8778, Loss: 0.1103
Epoch 233 Batch  140/269 - Train Accuracy: 0.8618, Validation Accuracy: 0.8728, Loss: 0.1162
Epoch 233 Batch  150/269 - Train Accuracy: 0.8688, Validation Accuracy: 0.8738, Loss: 0.1084
Epoch 233 Batch  160/269 - Train Accuracy: 0.8751, Validation Accuracy: 0.8732, Loss: 0.1070
Epoch 233 Batch  170/269 - Train Accuracy: 0.8686, Validation Accuracy: 0.8783, Loss: 0.0998
Epoch 233 Batch  180/269 - Train Accuracy: 0.8872, Validation Accuracy: 0.8739, Loss: 0.1030
Epoch 233 Batch  190/269 - Train Accuracy: 0.8819, Validation Accuracy: 0.8759, Loss: 0.1096
Epoch 233 Batch  200/269 - Train Accuracy: 0.8564, Validation Accuracy: 0.8735, Loss: 0.1086
Epoch 233 Batch  210/269 - Train Accuracy: 0.8622, Validation Accuracy: 0.8684, Loss: 0.1104
Epoch 233 Batch  220/269 - Train Accuracy: 0.8693, Validation Accuracy: 0.8734, Loss: 0.1131
Epoch 233 Batch  230/269 - Train Accuracy: 0.8628, Validation Accuracy: 0.8681, Loss: 0.1106
Epoch 233 Batch  240/269 - Train Accuracy: 0.8764, Validation Accuracy: 0.8684, Loss: 0.0964
Epoch 233 Batch  250/269 - Train Accuracy: 0.8848, Validation Accuracy: 0.8770, Loss: 0.1008
Epoch 233 Batch  260/269 - Train Accuracy: 0.8593, Validation Accuracy: 0.8804, Loss: 0.1369
Epoch 234 Batch   10/269 - Train Accuracy: 0.8744, Validation Accuracy: 0.8675, Loss: 0.1066
Epoch 234 Batch   20/269 - Train Accuracy: 0.8610, Validation Accuracy: 0.8722, Loss: 0.1020
Epoch 234 Batch   30/269 - Train Accuracy: 0.8676, Validation Accuracy: 0.8714, Loss: 0.1147
Epoch 234 Batch   40/269 - Train Accuracy: 0.8550, Validation Accuracy: 0.8721, Loss: 0.1195
Epoch 234 Batch   50/269 - Train Accuracy: 0.8549, Validation Accuracy: 0.8715, Loss: 0.1188
Epoch 234 Batch   60/269 - Train Accuracy: 0.8794, Validation Accuracy: 0.8770, Loss: 0.1025
Epoch 234 Batch   70/269 - Train Accuracy: 0.8843, Validation Accuracy: 0.8726, Loss: 0.1098
Epoch 234 Batch   80/269 - Train Accuracy: 0.8714, Validation Accuracy: 0.8740, Loss: 0.1191
Epoch 234 Batch   90/269 - Train Accuracy: 0.8697, Validation Accuracy: 0.8710, Loss: 0.1188
Epoch 234 Batch  100/269 - Train Accuracy: 0.8852, Validation Accuracy: 0.8725, Loss: 0.1054
Epoch 234 Batch  110/269 - Train Accuracy: 0.8611, Validation Accuracy: 0.8731, Loss: 0.1069
Epoch 234 Batch  120/269 - Train Accuracy: 0.8709, Validation Accuracy: 0.8749, Loss: 0.1164
Epoch 234 Batch  130/269 - Train Accuracy: 0.8571, Validation Accuracy: 0.8781, Loss: 0.1158
Epoch 234 Batch  140/269 - Train Accuracy: 0.8604, Validation Accuracy: 0.8746, Loss: 0.1177
Epoch 234 Batch  150/269 - Train Accuracy: 0.8648, Validation Accuracy: 0.8722, Loss: 0.1227
Epoch 234 Batch  160/269 - Train Accuracy: 0.8733, Validation Accuracy: 0.8733, Loss: 0.1102
Epoch 234 Batch  170/269 - Train Accuracy: 0.8629, Validation Accuracy: 0.8742, Loss: 0.1102
Epoch 234 Batch  180/269 - Train Accuracy: 0.8855, Validation Accuracy: 0.8746, Loss: 0.1078
Epoch 234 Batch  190/269 - Train Accuracy: 0.8823, Validation Accuracy: 0.8781, Loss: 0.1111
Epoch 234 Batch  200/269 - Train Accuracy: 0.8614, Validation Accuracy: 0.8721, Loss: 0.1071
Epoch 234 Batch  210/269 - Train Accuracy: 0.8696, Validation Accuracy: 0.8806, Loss: 0.1059
Epoch 234 Batch  220/269 - Train Accuracy: 0.8716, Validation Accuracy: 0.8739, Loss: 0.1112
Epoch 234 Batch  230/269 - Train Accuracy: 0.8577, Validation Accuracy: 0.8701, Loss: 0.1077
Epoch 234 Batch  240/269 - Train Accuracy: 0.8832, Validation Accuracy: 0.8711, Loss: 0.0990
Epoch 234 Batch  250/269 - Train Accuracy: 0.8790, Validation Accuracy: 0.8780, Loss: 0.1055
Epoch 234 Batch  260/269 - Train Accuracy: 0.8601, Validation Accuracy: 0.8752, Loss: 0.1160
Epoch 235 Batch   10/269 - Train Accuracy: 0.8738, Validation Accuracy: 0.8688, Loss: 0.1026
Epoch 235 Batch   20/269 - Train Accuracy: 0.8641, Validation Accuracy: 0.8719, Loss: 0.1057
Epoch 235 Batch   30/269 - Train Accuracy: 0.8653, Validation Accuracy: 0.8765, Loss: 0.1075
Epoch 235 Batch   40/269 - Train Accuracy: 0.8560, Validation Accuracy: 0.8764, Loss: 0.1257
Epoch 235 Batch   50/269 - Train Accuracy: 0.8619, Validation Accuracy: 0.8784, Loss: 0.1296
Epoch 235 Batch   60/269 - Train Accuracy: 0.8815, Validation Accuracy: 0.8737, Loss: 0.1024
Epoch 235 Batch   70/269 - Train Accuracy: 0.8833, Validation Accuracy: 0.8776, Loss: 0.1173
Epoch 235 Batch   80/269 - Train Accuracy: 0.8760, Validation Accuracy: 0.8756, Loss: 0.1075
Epoch 235 Batch   90/269 - Train Accuracy: 0.8735, Validation Accuracy: 0.8726, Loss: 0.1142
Epoch 235 Batch  100/269 - Train Accuracy: 0.8839, Validation Accuracy: 0.8730, Loss: 0.1038
Epoch 235 Batch  110/269 - Train Accuracy: 0.8594, Validation Accuracy: 0.8770, Loss: 0.1182
Epoch 235 Batch  120/269 - Train Accuracy: 0.8706, Validation Accuracy: 0.8708, Loss: 0.1173
Epoch 235 Batch  130/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8754, Loss: 0.1139
Epoch 235 Batch  140/269 - Train Accuracy: 0.8617, Validation Accuracy: 0.8719, Loss: 0.1174
Epoch 235 Batch  150/269 - Train Accuracy: 0.8705, Validation Accuracy: 0.8767, Loss: 0.1143
Epoch 235 Batch  160/269 - Train Accuracy: 0.8783, Validation Accuracy: 0.8684, Loss: 0.1084
Epoch 235 Batch  170/269 - Train Accuracy: 0.8656, Validation Accuracy: 0.8742, Loss: 0.0967
Epoch 235 Batch  180/269 - Train Accuracy: 0.8844, Validation Accuracy: 0.8741, Loss: 0.1081
Epoch 235 Batch  190/269 - Train Accuracy: 0.8806, Validation Accuracy: 0.8721, Loss: 0.1090
Epoch 235 Batch  200/269 - Train Accuracy: 0.8632, Validation Accuracy: 0.8799, Loss: 0.1037
Epoch 235 Batch  210/269 - Train Accuracy: 0.8684, Validation Accuracy: 0.8778, Loss: 0.1101
Epoch 235 Batch  220/269 - Train Accuracy: 0.8681, Validation Accuracy: 0.8711, Loss: 0.1081
Epoch 235 Batch  230/269 - Train Accuracy: 0.8628, Validation Accuracy: 0.8764, Loss: 0.1104
Epoch 235 Batch  240/269 - Train Accuracy: 0.8768, Validation Accuracy: 0.8741, Loss: 0.0961
Epoch 235 Batch  250/269 - Train Accuracy: 0.8842, Validation Accuracy: 0.8774, Loss: 0.1013
Epoch 235 Batch  260/269 - Train Accuracy: 0.8614, Validation Accuracy: 0.8763, Loss: 0.1298
Epoch 236 Batch   10/269 - Train Accuracy: 0.8696, Validation Accuracy: 0.8750, Loss: 0.1045
Epoch 236 Batch   20/269 - Train Accuracy: 0.8638, Validation Accuracy: 0.8746, Loss: 0.1075
Epoch 236 Batch   30/269 - Train Accuracy: 0.8666, Validation Accuracy: 0.8740, Loss: 0.1050
Epoch 236 Batch   40/269 - Train Accuracy: 0.8579, Validation Accuracy: 0.8766, Loss: 0.1177
Epoch 236 Batch   50/269 - Train Accuracy: 0.8545, Validation Accuracy: 0.8756, Loss: 0.1214
Epoch 236 Batch   60/269 - Train Accuracy: 0.8735, Validation Accuracy: 0.8788, Loss: 0.0951
Epoch 236 Batch   70/269 - Train Accuracy: 0.8804, Validation Accuracy: 0.8785, Loss: 0.1074
Epoch 236 Batch   80/269 - Train Accuracy: 0.8778, Validation Accuracy: 0.8789, Loss: 0.1039
Epoch 236 Batch   90/269 - Train Accuracy: 0.8772, Validation Accuracy: 0.8751, Loss: 0.1191
Epoch 236 Batch  100/269 - Train Accuracy: 0.8836, Validation Accuracy: 0.8752, Loss: 0.1063
Epoch 236 Batch  110/269 - Train Accuracy: 0.8599, Validation Accuracy: 0.8738, Loss: 0.1204
Epoch 236 Batch  120/269 - Train Accuracy: 0.8700, Validation Accuracy: 0.8672, Loss: 0.1205
Epoch 236 Batch  130/269 - Train Accuracy: 0.8587, Validation Accuracy: 0.8724, Loss: 0.1156
Epoch 236 Batch  140/269 - Train Accuracy: 0.8630, Validation Accuracy: 0.8716, Loss: 0.1205
Epoch 236 Batch  150/269 - Train Accuracy: 0.8692, Validation Accuracy: 0.8762, Loss: 0.1094
Epoch 236 Batch  160/269 - Train Accuracy: 0.8768, Validation Accuracy: 0.8752, Loss: 0.1094
Epoch 236 Batch  170/269 - Train Accuracy: 0.8655, Validation Accuracy: 0.8742, Loss: 0.1130
Epoch 236 Batch  180/269 - Train Accuracy: 0.8883, Validation Accuracy: 0.8740, Loss: 0.1084
Epoch 236 Batch  190/269 - Train Accuracy: 0.8778, Validation Accuracy: 0.8802, Loss: 0.1052
Epoch 236 Batch  200/269 - Train Accuracy: 0.8675, Validation Accuracy: 0.8748, Loss: 0.1022
Epoch 236 Batch  210/269 - Train Accuracy: 0.8682, Validation Accuracy: 0.8719, Loss: 0.1070
Epoch 236 Batch  220/269 - Train Accuracy: 0.8720, Validation Accuracy: 0.8740, Loss: 0.1080
Epoch 236 Batch  230/269 - Train Accuracy: 0.8599, Validation Accuracy: 0.8756, Loss: 0.1082
Epoch 236 Batch  240/269 - Train Accuracy: 0.8846, Validation Accuracy: 0.8732, Loss: 0.0991
Epoch 236 Batch  250/269 - Train Accuracy: 0.8798, Validation Accuracy: 0.8811, Loss: 0.1058
Epoch 236 Batch  260/269 - Train Accuracy: 0.8604, Validation Accuracy: 0.8738, Loss: 0.1146
Epoch 237 Batch   10/269 - Train Accuracy: 0.8800, Validation Accuracy: 0.8754, Loss: 0.1049
Epoch 237 Batch   20/269 - Train Accuracy: 0.8654, Validation Accuracy: 0.8784, Loss: 0.0989
Epoch 237 Batch   30/269 - Train Accuracy: 0.8698, Validation Accuracy: 0.8750, Loss: 0.1006
Epoch 237 Batch   40/269 - Train Accuracy: 0.8602, Validation Accuracy: 0.8740, Loss: 0.1221
Epoch 237 Batch   50/269 - Train Accuracy: 0.8552, Validation Accuracy: 0.8763, Loss: 0.1253
Epoch 237 Batch   60/269 - Train Accuracy: 0.8791, Validation Accuracy: 0.8762, Loss: 0.1002
Epoch 237 Batch   70/269 - Train Accuracy: 0.8815, Validation Accuracy: 0.8738, Loss: 0.1102
Epoch 237 Batch   80/269 - Train Accuracy: 0.8758, Validation Accuracy: 0.8699, Loss: 0.1180
Epoch 237 Batch   90/269 - Train Accuracy: 0.8706, Validation Accuracy: 0.8694, Loss: 0.1133
Epoch 237 Batch  100/269 - Train Accuracy: 0.8878, Validation Accuracy: 0.8765, Loss: 0.1129
Epoch 237 Batch  110/269 - Train Accuracy: 0.8605, Validation Accuracy: 0.8730, Loss: 0.1182
Epoch 237 Batch  120/269 - Train Accuracy: 0.8705, Validation Accuracy: 0.8765, Loss: 0.1166
Epoch 237 Batch  130/269 - Train Accuracy: 0.8612, Validation Accuracy: 0.8762, Loss: 0.1263
Epoch 237 Batch  140/269 - Train Accuracy: 0.8614, Validation Accuracy: 0.8746, Loss: 0.1151
Epoch 237 Batch  150/269 - Train Accuracy: 0.8677, Validation Accuracy: 0.8728, Loss: 0.1066
Epoch 237 Batch  160/269 - Train Accuracy: 0.8784, Validation Accuracy: 0.8723, Loss: 0.1058
Epoch 237 Batch  170/269 - Train Accuracy: 0.8687, Validation Accuracy: 0.8762, Loss: 0.1056
Epoch 237 Batch  180/269 - Train Accuracy: 0.8859, Validation Accuracy: 0.8674, Loss: 0.1025
Epoch 237 Batch  190/269 - Train Accuracy: 0.8825, Validation Accuracy: 0.8784, Loss: 0.1050
Epoch 237 Batch  200/269 - Train Accuracy: 0.8669, Validation Accuracy: 0.8748, Loss: 0.1133
Epoch 237 Batch  210/269 - Train Accuracy: 0.8750, Validation Accuracy: 0.8784, Loss: 0.1152
Epoch 237 Batch  220/269 - Train Accuracy: 0.8749, Validation Accuracy: 0.8778, Loss: 0.0976
Epoch 237 Batch  230/269 - Train Accuracy: 0.8631, Validation Accuracy: 0.8735, Loss: 0.1066
Epoch 237 Batch  240/269 - Train Accuracy: 0.8836, Validation Accuracy: 0.8717, Loss: 0.0960
Epoch 237 Batch  250/269 - Train Accuracy: 0.8831, Validation Accuracy: 0.8818, Loss: 0.1035
Epoch 237 Batch  260/269 - Train Accuracy: 0.8597, Validation Accuracy: 0.8737, Loss: 0.1175
Epoch 238 Batch   10/269 - Train Accuracy: 0.8740, Validation Accuracy: 0.8692, Loss: 0.1021
Epoch 238 Batch   20/269 - Train Accuracy: 0.8665, Validation Accuracy: 0.8745, Loss: 0.1030
Epoch 238 Batch   30/269 - Train Accuracy: 0.8690, Validation Accuracy: 0.8768, Loss: 0.1115
Epoch 238 Batch   40/269 - Train Accuracy: 0.8593, Validation Accuracy: 0.8759, Loss: 0.1224
Epoch 238 Batch   50/269 - Train Accuracy: 0.8571, Validation Accuracy: 0.8757, Loss: 0.1143
Epoch 238 Batch   60/269 - Train Accuracy: 0.8780, Validation Accuracy: 0.8801, Loss: 0.0972
Epoch 238 Batch   70/269 - Train Accuracy: 0.8797, Validation Accuracy: 0.8776, Loss: 0.1101
Epoch 238 Batch   80/269 - Train Accuracy: 0.8738, Validation Accuracy: 0.8730, Loss: 0.1073
Epoch 238 Batch   90/269 - Train Accuracy: 0.8701, Validation Accuracy: 0.8714, Loss: 0.1182
Epoch 238 Batch  100/269 - Train Accuracy: 0.8861, Validation Accuracy: 0.8722, Loss: 0.1061
Epoch 238 Batch  110/269 - Train Accuracy: 0.8608, Validation Accuracy: 0.8747, Loss: 0.1082
Epoch 238 Batch  120/269 - Train Accuracy: 0.8702, Validation Accuracy: 0.8789, Loss: 0.1189
Epoch 238 Batch  130/269 - Train Accuracy: 0.8593, Validation Accuracy: 0.8696, Loss: 0.1058
Epoch 238 Batch  140/269 - Train Accuracy: 0.8637, Validation Accuracy: 0.8675, Loss: 0.1211
Epoch 238 Batch  150/269 - Train Accuracy: 0.8673, Validation Accuracy: 0.8726, Loss: 0.1170
Epoch 238 Batch  160/269 - Train Accuracy: 0.8748, Validation Accuracy: 0.8763, Loss: 0.1083
Epoch 238 Batch  170/269 - Train Accuracy: 0.8641, Validation Accuracy: 0.8798, Loss: 0.1060
Epoch 238 Batch  180/269 - Train Accuracy: 0.8947, Validation Accuracy: 0.8726, Loss: 0.1032
Epoch 238 Batch  190/269 - Train Accuracy: 0.8769, Validation Accuracy: 0.8756, Loss: 0.1088
Epoch 238 Batch  200/269 - Train Accuracy: 0.8619, Validation Accuracy: 0.8747, Loss: 0.1040
Epoch 238 Batch  210/269 - Train Accuracy: 0.8739, Validation Accuracy: 0.8767, Loss: 0.1075
Epoch 238 Batch  220/269 - Train Accuracy: 0.8706, Validation Accuracy: 0.8708, Loss: 0.1115
Epoch 238 Batch  230/269 - Train Accuracy: 0.8588, Validation Accuracy: 0.8729, Loss: 0.1073
Epoch 238 Batch  240/269 - Train Accuracy: 0.8787, Validation Accuracy: 0.8749, Loss: 0.0999
Epoch 238 Batch  250/269 - Train Accuracy: 0.8812, Validation Accuracy: 0.8722, Loss: 0.1025
Epoch 238 Batch  260/269 - Train Accuracy: 0.8629, Validation Accuracy: 0.8794, Loss: 0.1170
Epoch 239 Batch   10/269 - Train Accuracy: 0.8739, Validation Accuracy: 0.8714, Loss: 0.0970
Epoch 239 Batch   20/269 - Train Accuracy: 0.8625, Validation Accuracy: 0.8727, Loss: 0.1037
Epoch 239 Batch   30/269 - Train Accuracy: 0.8696, Validation Accuracy: 0.8719, Loss: 0.1037
Epoch 239 Batch   40/269 - Train Accuracy: 0.8613, Validation Accuracy: 0.8741, Loss: 0.1140
Epoch 239 Batch   50/269 - Train Accuracy: 0.8556, Validation Accuracy: 0.8748, Loss: 0.1171
Epoch 239 Batch   60/269 - Train Accuracy: 0.8756, Validation Accuracy: 0.8716, Loss: 0.1008
Epoch 239 Batch   70/269 - Train Accuracy: 0.8761, Validation Accuracy: 0.8754, Loss: 0.1097
Epoch 239 Batch   80/269 - Train Accuracy: 0.8701, Validation Accuracy: 0.8744, Loss: 0.1101
Epoch 239 Batch   90/269 - Train Accuracy: 0.8763, Validation Accuracy: 0.8732, Loss: 0.1135
Epoch 239 Batch  100/269 - Train Accuracy: 0.8870, Validation Accuracy: 0.8804, Loss: 0.1061
Epoch 239 Batch  110/269 - Train Accuracy: 0.8596, Validation Accuracy: 0.8680, Loss: 0.1088
Epoch 239 Batch  120/269 - Train Accuracy: 0.8722, Validation Accuracy: 0.8769, Loss: 0.1235
Epoch 239 Batch  130/269 - Train Accuracy: 0.8617, Validation Accuracy: 0.8741, Loss: 0.1123
Epoch 239 Batch  140/269 - Train Accuracy: 0.8628, Validation Accuracy: 0.8683, Loss: 0.1166
Epoch 239 Batch  150/269 - Train Accuracy: 0.8648, Validation Accuracy: 0.8738, Loss: 0.1178
Epoch 239 Batch  160/269 - Train Accuracy: 0.8836, Validation Accuracy: 0.8786, Loss: 0.1144
Epoch 239 Batch  170/269 - Train Accuracy: 0.8636, Validation Accuracy: 0.8718, Loss: 0.1073
Epoch 239 Batch  180/269 - Train Accuracy: 0.8891, Validation Accuracy: 0.8683, Loss: 0.1042
Epoch 239 Batch  190/269 - Train Accuracy: 0.8772, Validation Accuracy: 0.8751, Loss: 0.1042
Epoch 239 Batch  200/269 - Train Accuracy: 0.8656, Validation Accuracy: 0.8731, Loss: 0.1108
Epoch 239 Batch  210/269 - Train Accuracy: 0.8725, Validation Accuracy: 0.8723, Loss: 0.1127
Epoch 239 Batch  220/269 - Train Accuracy: 0.8692, Validation Accuracy: 0.8738, Loss: 0.1065
Epoch 239 Batch  230/269 - Train Accuracy: 0.8608, Validation Accuracy: 0.8742, Loss: 0.1130
Epoch 239 Batch  240/269 - Train Accuracy: 0.8725, Validation Accuracy: 0.8733, Loss: 0.0991
Epoch 239 Batch  250/269 - Train Accuracy: 0.8819, Validation Accuracy: 0.8766, Loss: 0.1002
Epoch 239 Batch  260/269 - Train Accuracy: 0.8583, Validation Accuracy: 0.8746, Loss: 0.1199
Epoch 240 Batch   10/269 - Train Accuracy: 0.8742, Validation Accuracy: 0.8786, Loss: 0.1091
Epoch 240 Batch   20/269 - Train Accuracy: 0.8610, Validation Accuracy: 0.8721, Loss: 0.1061
Epoch 240 Batch   30/269 - Train Accuracy: 0.8639, Validation Accuracy: 0.8762, Loss: 0.1043
Epoch 240 Batch   40/269 - Train Accuracy: 0.8521, Validation Accuracy: 0.8754, Loss: 0.1258
Epoch 240 Batch   50/269 - Train Accuracy: 0.8535, Validation Accuracy: 0.8749, Loss: 0.1234
Epoch 240 Batch   60/269 - Train Accuracy: 0.8746, Validation Accuracy: 0.8759, Loss: 0.0942
Epoch 240 Batch   70/269 - Train Accuracy: 0.8876, Validation Accuracy: 0.8714, Loss: 0.1175
Epoch 240 Batch   80/269 - Train Accuracy: 0.8740, Validation Accuracy: 0.8722, Loss: 0.1118
Epoch 240 Batch   90/269 - Train Accuracy: 0.8797, Validation Accuracy: 0.8698, Loss: 0.1196
Epoch 240 Batch  100/269 - Train Accuracy: 0.8831, Validation Accuracy: 0.8727, Loss: 0.1058
Epoch 240 Batch  110/269 - Train Accuracy: 0.8594, Validation Accuracy: 0.8712, Loss: 0.1105
Epoch 240 Batch  120/269 - Train Accuracy: 0.8702, Validation Accuracy: 0.8785, Loss: 0.1188
Epoch 240 Batch  130/269 - Train Accuracy: 0.8596, Validation Accuracy: 0.8747, Loss: 0.1088
Epoch 240 Batch  140/269 - Train Accuracy: 0.8615, Validation Accuracy: 0.8769, Loss: 0.1144
Epoch 240 Batch  150/269 - Train Accuracy: 0.8696, Validation Accuracy: 0.8740, Loss: 0.1172
Epoch 240 Batch  160/269 - Train Accuracy: 0.8771, Validation Accuracy: 0.8713, Loss: 0.1122
Epoch 240 Batch  170/269 - Train Accuracy: 0.8653, Validation Accuracy: 0.8742, Loss: 0.1034
Epoch 240 Batch  180/269 - Train Accuracy: 0.8877, Validation Accuracy: 0.8770, Loss: 0.0953
Epoch 240 Batch  190/269 - Train Accuracy: 0.8781, Validation Accuracy: 0.8781, Loss: 0.1124
Epoch 240 Batch  200/269 - Train Accuracy: 0.8630, Validation Accuracy: 0.8738, Loss: 0.1127
Epoch 240 Batch  210/269 - Train Accuracy: 0.8703, Validation Accuracy: 0.8813, Loss: 0.1030
Epoch 240 Batch  220/269 - Train Accuracy: 0.8728, Validation Accuracy: 0.8727, Loss: 0.1025
Epoch 240 Batch  230/269 - Train Accuracy: 0.8576, Validation Accuracy: 0.8746, Loss: 0.1067
Epoch 240 Batch  240/269 - Train Accuracy: 0.8766, Validation Accuracy: 0.8714, Loss: 0.0977
Epoch 240 Batch  250/269 - Train Accuracy: 0.8819, Validation Accuracy: 0.8788, Loss: 0.1139
Epoch 240 Batch  260/269 - Train Accuracy: 0.8628, Validation Accuracy: 0.8769, Loss: 0.1172
Epoch 241 Batch   10/269 - Train Accuracy: 0.8726, Validation Accuracy: 0.8772, Loss: 0.0998
Epoch 241 Batch   20/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8753, Loss: 0.1042
Epoch 241 Batch   30/269 - Train Accuracy: 0.8660, Validation Accuracy: 0.8792, Loss: 0.1028
Epoch 241 Batch   40/269 - Train Accuracy: 0.8561, Validation Accuracy: 0.8741, Loss: 0.1231
Epoch 241 Batch   50/269 - Train Accuracy: 0.8505, Validation Accuracy: 0.8715, Loss: 0.1195
Epoch 241 Batch   60/269 - Train Accuracy: 0.8768, Validation Accuracy: 0.8773, Loss: 0.1009
Epoch 241 Batch   70/269 - Train Accuracy: 0.8821, Validation Accuracy: 0.8737, Loss: 0.1038
Epoch 241 Batch   80/269 - Train Accuracy: 0.8748, Validation Accuracy: 0.8718, Loss: 0.1013
Epoch 241 Batch   90/269 - Train Accuracy: 0.8727, Validation Accuracy: 0.8748, Loss: 0.1090
Epoch 241 Batch  100/269 - Train Accuracy: 0.8805, Validation Accuracy: 0.8706, Loss: 0.1104
Epoch 241 Batch  110/269 - Train Accuracy: 0.8575, Validation Accuracy: 0.8712, Loss: 0.1070
Epoch 241 Batch  120/269 - Train Accuracy: 0.8678, Validation Accuracy: 0.8726, Loss: 0.1164
Epoch 241 Batch  130/269 - Train Accuracy: 0.8580, Validation Accuracy: 0.8754, Loss: 0.1113
Epoch 241 Batch  140/269 - Train Accuracy: 0.8637, Validation Accuracy: 0.8692, Loss: 0.1222
Epoch 241 Batch  150/269 - Train Accuracy: 0.8677, Validation Accuracy: 0.8699, Loss: 0.1138
Epoch 241 Batch  160/269 - Train Accuracy: 0.8776, Validation Accuracy: 0.8714, Loss: 0.1108
Epoch 241 Batch  170/269 - Train Accuracy: 0.8622, Validation Accuracy: 0.8742, Loss: 0.1086
Epoch 241 Batch  180/269 - Train Accuracy: 0.8874, Validation Accuracy: 0.8755, Loss: 0.1029
Epoch 241 Batch  190/269 - Train Accuracy: 0.8780, Validation Accuracy: 0.8724, Loss: 0.1090
Epoch 241 Batch  200/269 - Train Accuracy: 0.8613, Validation Accuracy: 0.8765, Loss: 0.1064
Epoch 241 Batch  210/269 - Train Accuracy: 0.8773, Validation Accuracy: 0.8761, Loss: 0.1095
Epoch 241 Batch  220/269 - Train Accuracy: 0.8715, Validation Accuracy: 0.8739, Loss: 0.1043
Epoch 241 Batch  230/269 - Train Accuracy: 0.8597, Validation Accuracy: 0.8790, Loss: 0.1112
Epoch 241 Batch  240/269 - Train Accuracy: 0.8780, Validation Accuracy: 0.8716, Loss: 0.0976
Epoch 241 Batch  250/269 - Train Accuracy: 0.8861, Validation Accuracy: 0.8757, Loss: 0.1020
Epoch 241 Batch  260/269 - Train Accuracy: 0.8616, Validation Accuracy: 0.8777, Loss: 0.1153
Epoch 242 Batch   10/269 - Train Accuracy: 0.8699, Validation Accuracy: 0.8731, Loss: 0.0924
Epoch 242 Batch   20/269 - Train Accuracy: 0.8639, Validation Accuracy: 0.8768, Loss: 0.1088
Epoch 242 Batch   30/269 - Train Accuracy: 0.8694, Validation Accuracy: 0.8778, Loss: 0.1095
Epoch 242 Batch   40/269 - Train Accuracy: 0.8586, Validation Accuracy: 0.8722, Loss: 0.1267
Epoch 242 Batch   50/269 - Train Accuracy: 0.8531, Validation Accuracy: 0.8761, Loss: 0.1166
Epoch 242 Batch   60/269 - Train Accuracy: 0.8790, Validation Accuracy: 0.8777, Loss: 0.0982
Epoch 242 Batch   70/269 - Train Accuracy: 0.8893, Validation Accuracy: 0.8776, Loss: 0.1065
Epoch 242 Batch   80/269 - Train Accuracy: 0.8788, Validation Accuracy: 0.8758, Loss: 0.1046
Epoch 242 Batch   90/269 - Train Accuracy: 0.8772, Validation Accuracy: 0.8738, Loss: 0.1193
Epoch 242 Batch  100/269 - Train Accuracy: 0.8850, Validation Accuracy: 0.8744, Loss: 0.1053
Epoch 242 Batch  110/269 - Train Accuracy: 0.8617, Validation Accuracy: 0.8755, Loss: 0.1084
Epoch 242 Batch  120/269 - Train Accuracy: 0.8764, Validation Accuracy: 0.8753, Loss: 0.1227
Epoch 242 Batch  130/269 - Train Accuracy: 0.8589, Validation Accuracy: 0.8792, Loss: 0.1116
Epoch 242 Batch  140/269 - Train Accuracy: 0.8655, Validation Accuracy: 0.8717, Loss: 0.1162
Epoch 242 Batch  150/269 - Train Accuracy: 0.8700, Validation Accuracy: 0.8713, Loss: 0.1085
Epoch 242 Batch  160/269 - Train Accuracy: 0.8819, Validation Accuracy: 0.8752, Loss: 0.1092
Epoch 242 Batch  170/269 - Train Accuracy: 0.8671, Validation Accuracy: 0.8749, Loss: 0.0998
Epoch 242 Batch  180/269 - Train Accuracy: 0.8894, Validation Accuracy: 0.8756, Loss: 0.1010
Epoch 242 Batch  190/269 - Train Accuracy: 0.8761, Validation Accuracy: 0.8717, Loss: 0.1091
Epoch 242 Batch  200/269 - Train Accuracy: 0.8672, Validation Accuracy: 0.8784, Loss: 0.1046
Epoch 242 Batch  210/269 - Train Accuracy: 0.8718, Validation Accuracy: 0.8760, Loss: 0.1150
Epoch 242 Batch  220/269 - Train Accuracy: 0.8694, Validation Accuracy: 0.8762, Loss: 0.1043
Epoch 242 Batch  230/269 - Train Accuracy: 0.8657, Validation Accuracy: 0.8772, Loss: 0.1042
Epoch 242 Batch  240/269 - Train Accuracy: 0.8805, Validation Accuracy: 0.8740, Loss: 0.0960
Epoch 242 Batch  250/269 - Train Accuracy: 0.8872, Validation Accuracy: 0.8802, Loss: 0.1100
Epoch 242 Batch  260/269 - Train Accuracy: 0.8603, Validation Accuracy: 0.8782, Loss: 0.1129
Epoch 243 Batch   10/269 - Train Accuracy: 0.8706, Validation Accuracy: 0.8712, Loss: 0.1033
Epoch 243 Batch   20/269 - Train Accuracy: 0.8650, Validation Accuracy: 0.8751, Loss: 0.1037
Epoch 243 Batch   30/269 - Train Accuracy: 0.8748, Validation Accuracy: 0.8747, Loss: 0.1054
Epoch 243 Batch   40/269 - Train Accuracy: 0.8576, Validation Accuracy: 0.8716, Loss: 0.1122
Epoch 243 Batch   50/269 - Train Accuracy: 0.8576, Validation Accuracy: 0.8695, Loss: 0.1171
Epoch 243 Batch   60/269 - Train Accuracy: 0.8746, Validation Accuracy: 0.8769, Loss: 0.1022
Epoch 243 Batch   70/269 - Train Accuracy: 0.8816, Validation Accuracy: 0.8744, Loss: 0.1094
Epoch 243 Batch   80/269 - Train Accuracy: 0.8733, Validation Accuracy: 0.8745, Loss: 0.1018
Epoch 243 Batch   90/269 - Train Accuracy: 0.8716, Validation Accuracy: 0.8730, Loss: 0.1040
Epoch 243 Batch  100/269 - Train Accuracy: 0.8882, Validation Accuracy: 0.8754, Loss: 0.1065
Epoch 243 Batch  110/269 - Train Accuracy: 0.8636, Validation Accuracy: 0.8674, Loss: 0.1185
Epoch 243 Batch  120/269 - Train Accuracy: 0.8768, Validation Accuracy: 0.8733, Loss: 0.1135
Epoch 243 Batch  130/269 - Train Accuracy: 0.8618, Validation Accuracy: 0.8718, Loss: 0.1165
Epoch 243 Batch  140/269 - Train Accuracy: 0.8608, Validation Accuracy: 0.8714, Loss: 0.1171
Epoch 243 Batch  150/269 - Train Accuracy: 0.8703, Validation Accuracy: 0.8699, Loss: 0.1080
Epoch 243 Batch  160/269 - Train Accuracy: 0.8802, Validation Accuracy: 0.8802, Loss: 0.1036
Epoch 243 Batch  170/269 - Train Accuracy: 0.8637, Validation Accuracy: 0.8709, Loss: 0.1030
Epoch 243 Batch  180/269 - Train Accuracy: 0.8891, Validation Accuracy: 0.8790, Loss: 0.1038
Epoch 243 Batch  190/269 - Train Accuracy: 0.8829, Validation Accuracy: 0.8747, Loss: 0.1083
Epoch 243 Batch  200/269 - Train Accuracy: 0.8607, Validation Accuracy: 0.8725, Loss: 0.1085
Epoch 243 Batch  210/269 - Train Accuracy: 0.8703, Validation Accuracy: 0.8734, Loss: 0.1119
Epoch 243 Batch  220/269 - Train Accuracy: 0.8700, Validation Accuracy: 0.8775, Loss: 0.1135
Epoch 243 Batch  230/269 - Train Accuracy: 0.8603, Validation Accuracy: 0.8735, Loss: 0.1182
Epoch 243 Batch  240/269 - Train Accuracy: 0.8821, Validation Accuracy: 0.8777, Loss: 0.1014
Epoch 243 Batch  250/269 - Train Accuracy: 0.8826, Validation Accuracy: 0.8817, Loss: 0.1085
Epoch 243 Batch  260/269 - Train Accuracy: 0.8618, Validation Accuracy: 0.8794, Loss: 0.1128
Epoch 244 Batch   10/269 - Train Accuracy: 0.8737, Validation Accuracy: 0.8685, Loss: 0.1021
Epoch 244 Batch   20/269 - Train Accuracy: 0.8630, Validation Accuracy: 0.8739, Loss: 0.1078
Epoch 244 Batch   30/269 - Train Accuracy: 0.8692, Validation Accuracy: 0.8711, Loss: 0.1050
Epoch 244 Batch   40/269 - Train Accuracy: 0.8571, Validation Accuracy: 0.8744, Loss: 0.1221
Epoch 244 Batch   50/269 - Train Accuracy: 0.8567, Validation Accuracy: 0.8796, Loss: 0.1179
Epoch 244 Batch   60/269 - Train Accuracy: 0.8770, Validation Accuracy: 0.8786, Loss: 0.1085
Epoch 244 Batch   70/269 - Train Accuracy: 0.8863, Validation Accuracy: 0.8754, Loss: 0.1099
Epoch 244 Batch   80/269 - Train Accuracy: 0.8769, Validation Accuracy: 0.8778, Loss: 0.1121
Epoch 244 Batch   90/269 - Train Accuracy: 0.8762, Validation Accuracy: 0.8681, Loss: 0.1067
Epoch 244 Batch  100/269 - Train Accuracy: 0.8879, Validation Accuracy: 0.8754, Loss: 0.1071
Epoch 244 Batch  110/269 - Train Accuracy: 0.8610, Validation Accuracy: 0.8722, Loss: 0.1084
Epoch 244 Batch  120/269 - Train Accuracy: 0.8668, Validation Accuracy: 0.8730, Loss: 0.1085
Epoch 244 Batch  130/269 - Train Accuracy: 0.8626, Validation Accuracy: 0.8754, Loss: 0.1186
Epoch 244 Batch  140/269 - Train Accuracy: 0.8610, Validation Accuracy: 0.8736, Loss: 0.1186
Epoch 244 Batch  150/269 - Train Accuracy: 0.8661, Validation Accuracy: 0.8731, Loss: 0.1173
Epoch 244 Batch  160/269 - Train Accuracy: 0.8802, Validation Accuracy: 0.8783, Loss: 0.0967
Epoch 244 Batch  170/269 - Train Accuracy: 0.8633, Validation Accuracy: 0.8758, Loss: 0.1073
Epoch 244 Batch  180/269 - Train Accuracy: 0.8916, Validation Accuracy: 0.8689, Loss: 0.1042
Epoch 244 Batch  190/269 - Train Accuracy: 0.8787, Validation Accuracy: 0.8783, Loss: 0.1066
Epoch 244 Batch  200/269 - Train Accuracy: 0.8689, Validation Accuracy: 0.8749, Loss: 0.1043
Epoch 244 Batch  210/269 - Train Accuracy: 0.8759, Validation Accuracy: 0.8755, Loss: 0.1029
Epoch 244 Batch  220/269 - Train Accuracy: 0.8700, Validation Accuracy: 0.8733, Loss: 0.1141
Epoch 244 Batch  230/269 - Train Accuracy: 0.8659, Validation Accuracy: 0.8755, Loss: 0.1078
Epoch 244 Batch  240/269 - Train Accuracy: 0.8722, Validation Accuracy: 0.8701, Loss: 0.0972
Epoch 244 Batch  250/269 - Train Accuracy: 0.8840, Validation Accuracy: 0.8745, Loss: 0.1087
Epoch 244 Batch  260/269 - Train Accuracy: 0.8622, Validation Accuracy: 0.8779, Loss: 0.1147
Epoch 245 Batch   10/269 - Train Accuracy: 0.8744, Validation Accuracy: 0.8677, Loss: 0.1029
Epoch 245 Batch   20/269 - Train Accuracy: 0.8615, Validation Accuracy: 0.8762, Loss: 0.1031
Epoch 245 Batch   30/269 - Train Accuracy: 0.8654, Validation Accuracy: 0.8776, Loss: 0.0999
Epoch 245 Batch   40/269 - Train Accuracy: 0.8543, Validation Accuracy: 0.8739, Loss: 0.1258
Epoch 245 Batch   50/269 - Train Accuracy: 0.8555, Validation Accuracy: 0.8716, Loss: 0.1129
Epoch 245 Batch   60/269 - Train Accuracy: 0.8764, Validation Accuracy: 0.8792, Loss: 0.1046
Epoch 245 Batch   70/269 - Train Accuracy: 0.8825, Validation Accuracy: 0.8732, Loss: 0.1121
Epoch 245 Batch   80/269 - Train Accuracy: 0.8742, Validation Accuracy: 0.8741, Loss: 0.1055
Epoch 245 Batch   90/269 - Train Accuracy: 0.8771, Validation Accuracy: 0.8754, Loss: 0.1197
Epoch 245 Batch  100/269 - Train Accuracy: 0.8872, Validation Accuracy: 0.8777, Loss: 0.1055
Epoch 245 Batch  110/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8751, Loss: 0.1135
Epoch 245 Batch  120/269 - Train Accuracy: 0.8745, Validation Accuracy: 0.8713, Loss: 0.1141
Epoch 245 Batch  130/269 - Train Accuracy: 0.8635, Validation Accuracy: 0.8717, Loss: 0.1107
Epoch 245 Batch  140/269 - Train Accuracy: 0.8577, Validation Accuracy: 0.8676, Loss: 0.1128
Epoch 245 Batch  150/269 - Train Accuracy: 0.8650, Validation Accuracy: 0.8735, Loss: 0.1177
Epoch 245 Batch  160/269 - Train Accuracy: 0.8804, Validation Accuracy: 0.8772, Loss: 0.1107
Epoch 245 Batch  170/269 - Train Accuracy: 0.8602, Validation Accuracy: 0.8644, Loss: 0.1108
Epoch 245 Batch  180/269 - Train Accuracy: 0.8853, Validation Accuracy: 0.8697, Loss: 0.1044
Epoch 245 Batch  190/269 - Train Accuracy: 0.8868, Validation Accuracy: 0.8778, Loss: 0.1052
Epoch 245 Batch  200/269 - Train Accuracy: 0.8605, Validation Accuracy: 0.8727, Loss: 0.1023
Epoch 245 Batch  210/269 - Train Accuracy: 0.8736, Validation Accuracy: 0.8801, Loss: 0.1095
Epoch 245 Batch  220/269 - Train Accuracy: 0.8706, Validation Accuracy: 0.8746, Loss: 0.1153
Epoch 245 Batch  230/269 - Train Accuracy: 0.8635, Validation Accuracy: 0.8770, Loss: 0.1155
Epoch 245 Batch  240/269 - Train Accuracy: 0.8772, Validation Accuracy: 0.8699, Loss: 0.1020
Epoch 245 Batch  250/269 - Train Accuracy: 0.8814, Validation Accuracy: 0.8721, Loss: 0.1065
Epoch 245 Batch  260/269 - Train Accuracy: 0.8640, Validation Accuracy: 0.8716, Loss: 0.1095
Epoch 246 Batch   10/269 - Train Accuracy: 0.8749, Validation Accuracy: 0.8721, Loss: 0.1076
Epoch 246 Batch   20/269 - Train Accuracy: 0.8702, Validation Accuracy: 0.8788, Loss: 0.0962
Epoch 246 Batch   30/269 - Train Accuracy: 0.8620, Validation Accuracy: 0.8736, Loss: 0.1026
Epoch 246 Batch   40/269 - Train Accuracy: 0.8599, Validation Accuracy: 0.8713, Loss: 0.1210
Epoch 246 Batch   50/269 - Train Accuracy: 0.8521, Validation Accuracy: 0.8678, Loss: 0.1180
Epoch 246 Batch   60/269 - Train Accuracy: 0.8807, Validation Accuracy: 0.8794, Loss: 0.1033
Epoch 246 Batch   70/269 - Train Accuracy: 0.8797, Validation Accuracy: 0.8718, Loss: 0.1156
Epoch 246 Batch   80/269 - Train Accuracy: 0.8728, Validation Accuracy: 0.8715, Loss: 0.1130
Epoch 246 Batch   90/269 - Train Accuracy: 0.8757, Validation Accuracy: 0.8701, Loss: 0.1216
Epoch 246 Batch  100/269 - Train Accuracy: 0.8830, Validation Accuracy: 0.8732, Loss: 0.1125
Epoch 246 Batch  110/269 - Train Accuracy: 0.8477, Validation Accuracy: 0.8579, Loss: 0.1275
Epoch 246 Batch  120/269 - Train Accuracy: 0.8600, Validation Accuracy: 0.8703, Loss: 0.1367
Epoch 246 Batch  130/269 - Train Accuracy: 0.8544, Validation Accuracy: 0.8698, Loss: 0.1170
Epoch 246 Batch  140/269 - Train Accuracy: 0.8604, Validation Accuracy: 0.8691, Loss: 0.1256
Epoch 246 Batch  150/269 - Train Accuracy: 0.8620, Validation Accuracy: 0.8673, Loss: 0.1157
Epoch 246 Batch  160/269 - Train Accuracy: 0.8804, Validation Accuracy: 0.8785, Loss: 0.1067
Epoch 246 Batch  170/269 - Train Accuracy: 0.8616, Validation Accuracy: 0.8727, Loss: 0.1083
Epoch 246 Batch  180/269 - Train Accuracy: 0.8901, Validation Accuracy: 0.8778, Loss: 0.1040
Epoch 246 Batch  190/269 - Train Accuracy: 0.8818, Validation Accuracy: 0.8763, Loss: 0.1085
Epoch 246 Batch  200/269 - Train Accuracy: 0.8620, Validation Accuracy: 0.8778, Loss: 0.0980
Epoch 246 Batch  210/269 - Train Accuracy: 0.8716, Validation Accuracy: 0.8737, Loss: 0.1052
Epoch 246 Batch  220/269 - Train Accuracy: 0.8683, Validation Accuracy: 0.8709, Loss: 0.1096
Epoch 246 Batch  230/269 - Train Accuracy: 0.8631, Validation Accuracy: 0.8804, Loss: 0.1087
Epoch 246 Batch  240/269 - Train Accuracy: 0.8820, Validation Accuracy: 0.8775, Loss: 0.0939
Epoch 246 Batch  250/269 - Train Accuracy: 0.8814, Validation Accuracy: 0.8798, Loss: 0.1031
Epoch 246 Batch  260/269 - Train Accuracy: 0.8569, Validation Accuracy: 0.8786, Loss: 0.1175
Epoch 247 Batch   10/269 - Train Accuracy: 0.8714, Validation Accuracy: 0.8737, Loss: 0.0995
Epoch 247 Batch   20/269 - Train Accuracy: 0.8656, Validation Accuracy: 0.8754, Loss: 0.1087
Epoch 247 Batch   30/269 - Train Accuracy: 0.8681, Validation Accuracy: 0.8731, Loss: 0.1061
Epoch 247 Batch   40/269 - Train Accuracy: 0.8592, Validation Accuracy: 0.8701, Loss: 0.1165
Epoch 247 Batch   50/269 - Train Accuracy: 0.8568, Validation Accuracy: 0.8811, Loss: 0.1290
Epoch 247 Batch   60/269 - Train Accuracy: 0.8793, Validation Accuracy: 0.8807, Loss: 0.1019
Epoch 247 Batch   70/269 - Train Accuracy: 0.8835, Validation Accuracy: 0.8737, Loss: 0.1094
Epoch 247 Batch   80/269 - Train Accuracy: 0.8774, Validation Accuracy: 0.8754, Loss: 0.0998
Epoch 247 Batch   90/269 - Train Accuracy: 0.8774, Validation Accuracy: 0.8759, Loss: 0.1096
Epoch 247 Batch  100/269 - Train Accuracy: 0.8823, Validation Accuracy: 0.8729, Loss: 0.1005
Epoch 247 Batch  110/269 - Train Accuracy: 0.8555, Validation Accuracy: 0.8751, Loss: 0.1047
Epoch 247 Batch  120/269 - Train Accuracy: 0.8687, Validation Accuracy: 0.8734, Loss: 0.1098
Epoch 247 Batch  130/269 - Train Accuracy: 0.8653, Validation Accuracy: 0.8757, Loss: 0.1209
Epoch 247 Batch  140/269 - Train Accuracy: 0.8646, Validation Accuracy: 0.8731, Loss: 0.1125
Epoch 247 Batch  150/269 - Train Accuracy: 0.8677, Validation Accuracy: 0.8699, Loss: 0.1109
Epoch 247 Batch  160/269 - Train Accuracy: 0.8816, Validation Accuracy: 0.8755, Loss: 0.1078
Epoch 247 Batch  170/269 - Train Accuracy: 0.8644, Validation Accuracy: 0.8767, Loss: 0.1071
Epoch 247 Batch  180/269 - Train Accuracy: 0.8844, Validation Accuracy: 0.8759, Loss: 0.0993
Epoch 247 Batch  190/269 - Train Accuracy: 0.8856, Validation Accuracy: 0.8756, Loss: 0.1066
Epoch 247 Batch  200/269 - Train Accuracy: 0.8641, Validation Accuracy: 0.8809, Loss: 0.1026
Epoch 247 Batch  210/269 - Train Accuracy: 0.8707, Validation Accuracy: 0.8813, Loss: 0.1111
Epoch 247 Batch  220/269 - Train Accuracy: 0.8706, Validation Accuracy: 0.8743, Loss: 0.1073
Epoch 247 Batch  230/269 - Train Accuracy: 0.8629, Validation Accuracy: 0.8762, Loss: 0.1068
Epoch 247 Batch  240/269 - Train Accuracy: 0.8802, Validation Accuracy: 0.8772, Loss: 0.1019
Epoch 247 Batch  250/269 - Train Accuracy: 0.8816, Validation Accuracy: 0.8717, Loss: 0.1069
Epoch 247 Batch  260/269 - Train Accuracy: 0.8611, Validation Accuracy: 0.8781, Loss: 0.1237
Epoch 248 Batch   10/269 - Train Accuracy: 0.8759, Validation Accuracy: 0.8755, Loss: 0.0990
Epoch 248 Batch   20/269 - Train Accuracy: 0.8640, Validation Accuracy: 0.8739, Loss: 0.1036
Epoch 248 Batch   30/269 - Train Accuracy: 0.8493, Validation Accuracy: 0.8596, Loss: 0.1234
Epoch 248 Batch   40/269 - Train Accuracy: 0.8430, Validation Accuracy: 0.8625, Loss: 0.1511
Epoch 248 Batch   50/269 - Train Accuracy: 0.8490, Validation Accuracy: 0.8629, Loss: 0.1312
Epoch 248 Batch   60/269 - Train Accuracy: 0.8794, Validation Accuracy: 0.8784, Loss: 0.1018
Epoch 248 Batch   70/269 - Train Accuracy: 0.8810, Validation Accuracy: 0.8802, Loss: 0.1079
Epoch 248 Batch   80/269 - Train Accuracy: 0.8723, Validation Accuracy: 0.8736, Loss: 0.1024
Epoch 248 Batch   90/269 - Train Accuracy: 0.8760, Validation Accuracy: 0.8756, Loss: 0.1138
Epoch 248 Batch  100/269 - Train Accuracy: 0.8824, Validation Accuracy: 0.8746, Loss: 0.1076
Epoch 248 Batch  110/269 - Train Accuracy: 0.8651, Validation Accuracy: 0.8701, Loss: 0.1124
Epoch 248 Batch  120/269 - Train Accuracy: 0.8700, Validation Accuracy: 0.8723, Loss: 0.1182
Epoch 248 Batch  130/269 - Train Accuracy: 0.8591, Validation Accuracy: 0.8734, Loss: 0.1079
Epoch 248 Batch  140/269 - Train Accuracy: 0.8634, Validation Accuracy: 0.8687, Loss: 0.1114
Epoch 248 Batch  150/269 - Train Accuracy: 0.8734, Validation Accuracy: 0.8736, Loss: 0.1137
Epoch 248 Batch  160/269 - Train Accuracy: 0.8820, Validation Accuracy: 0.8797, Loss: 0.1151
Epoch 248 Batch  170/269 - Train Accuracy: 0.8612, Validation Accuracy: 0.8746, Loss: 0.1030
Epoch 248 Batch  180/269 - Train Accuracy: 0.8863, Validation Accuracy: 0.8756, Loss: 0.1017
Epoch 248 Batch  190/269 - Train Accuracy: 0.8792, Validation Accuracy: 0.8784, Loss: 0.1113
Epoch 248 Batch  200/269 - Train Accuracy: 0.8618, Validation Accuracy: 0.8802, Loss: 0.1045
Epoch 248 Batch  210/269 - Train Accuracy: 0.8781, Validation Accuracy: 0.8718, Loss: 0.1123
Epoch 248 Batch  220/269 - Train Accuracy: 0.8737, Validation Accuracy: 0.8738, Loss: 0.1175
Epoch 248 Batch  230/269 - Train Accuracy: 0.8625, Validation Accuracy: 0.8797, Loss: 0.1171
Epoch 248 Batch  240/269 - Train Accuracy: 0.8725, Validation Accuracy: 0.8688, Loss: 0.0984
Epoch 248 Batch  250/269 - Train Accuracy: 0.8835, Validation Accuracy: 0.8724, Loss: 0.1074
Epoch 248 Batch  260/269 - Train Accuracy: 0.8579, Validation Accuracy: 0.8772, Loss: 0.1153
Epoch 249 Batch   10/269 - Train Accuracy: 0.8744, Validation Accuracy: 0.8745, Loss: 0.1037
Epoch 249 Batch   20/269 - Train Accuracy: 0.8595, Validation Accuracy: 0.8754, Loss: 0.1024
Epoch 249 Batch   30/269 - Train Accuracy: 0.8671, Validation Accuracy: 0.8810, Loss: 0.0943
Epoch 249 Batch   40/269 - Train Accuracy: 0.8535, Validation Accuracy: 0.8766, Loss: 0.1172
Epoch 249 Batch   50/269 - Train Accuracy: 0.8558, Validation Accuracy: 0.8760, Loss: 0.1173
Epoch 249 Batch   60/269 - Train Accuracy: 0.8784, Validation Accuracy: 0.8789, Loss: 0.0999
Epoch 249 Batch   70/269 - Train Accuracy: 0.8826, Validation Accuracy: 0.8772, Loss: 0.1111
Epoch 249 Batch   80/269 - Train Accuracy: 0.8708, Validation Accuracy: 0.8722, Loss: 0.1000
Epoch 249 Batch   90/269 - Train Accuracy: 0.8737, Validation Accuracy: 0.8744, Loss: 0.1119
Epoch 249 Batch  100/269 - Train Accuracy: 0.8822, Validation Accuracy: 0.8728, Loss: 0.1047
Epoch 249 Batch  110/269 - Train Accuracy: 0.8611, Validation Accuracy: 0.8757, Loss: 0.1089
Epoch 249 Batch  120/269 - Train Accuracy: 0.8775, Validation Accuracy: 0.8707, Loss: 0.1098
Epoch 249 Batch  130/269 - Train Accuracy: 0.8625, Validation Accuracy: 0.8761, Loss: 0.1172
Epoch 249 Batch  140/269 - Train Accuracy: 0.8610, Validation Accuracy: 0.8792, Loss: 0.1106
Epoch 249 Batch  150/269 - Train Accuracy: 0.8671, Validation Accuracy: 0.8746, Loss: 0.1113
Epoch 249 Batch  160/269 - Train Accuracy: 0.8773, Validation Accuracy: 0.8752, Loss: 0.1258
Epoch 249 Batch  170/269 - Train Accuracy: 0.8659, Validation Accuracy: 0.8807, Loss: 0.1006
Epoch 249 Batch  180/269 - Train Accuracy: 0.8918, Validation Accuracy: 0.8780, Loss: 0.1001
Epoch 249 Batch  190/269 - Train Accuracy: 0.8833, Validation Accuracy: 0.8710, Loss: 0.1054
Epoch 249 Batch  200/269 - Train Accuracy: 0.8558, Validation Accuracy: 0.8777, Loss: 0.1062
Epoch 249 Batch  210/269 - Train Accuracy: 0.8728, Validation Accuracy: 0.8802, Loss: 0.1039
Epoch 249 Batch  220/269 - Train Accuracy: 0.8716, Validation Accuracy: 0.8764, Loss: 0.1034
Epoch 249 Batch  230/269 - Train Accuracy: 0.8677, Validation Accuracy: 0.8722, Loss: 0.1070
Epoch 249 Batch  240/269 - Train Accuracy: 0.8806, Validation Accuracy: 0.8738, Loss: 0.0983
Epoch 249 Batch  250/269 - Train Accuracy: 0.8880, Validation Accuracy: 0.8776, Loss: 0.1010
Epoch 249 Batch  260/269 - Train Accuracy: 0.8607, Validation Accuracy: 0.8838, Loss: 0.1181
Epoch 250 Batch   10/269 - Train Accuracy: 0.8652, Validation Accuracy: 0.8697, Loss: 0.0962
Epoch 250 Batch   20/269 - Train Accuracy: 0.8586, Validation Accuracy: 0.8751, Loss: 0.0987
Epoch 250 Batch   30/269 - Train Accuracy: 0.8660, Validation Accuracy: 0.8770, Loss: 0.1045
Epoch 250 Batch   40/269 - Train Accuracy: 0.8551, Validation Accuracy: 0.8762, Loss: 0.1172
Epoch 250 Batch   50/269 - Train Accuracy: 0.8541, Validation Accuracy: 0.8734, Loss: 0.1166
Epoch 250 Batch   60/269 - Train Accuracy: 0.8756, Validation Accuracy: 0.8811, Loss: 0.0960
Epoch 250 Batch   70/269 - Train Accuracy: 0.8890, Validation Accuracy: 0.8731, Loss: 0.1048
Epoch 250 Batch   80/269 - Train Accuracy: 0.8764, Validation Accuracy: 0.8745, Loss: 0.1038
Epoch 250 Batch   90/269 - Train Accuracy: 0.8748, Validation Accuracy: 0.8740, Loss: 0.1153
Epoch 250 Batch  100/269 - Train Accuracy: 0.8864, Validation Accuracy: 0.8742, Loss: 0.1101
Epoch 250 Batch  110/269 - Train Accuracy: 0.8594, Validation Accuracy: 0.8751, Loss: 0.1224
Epoch 250 Batch  120/269 - Train Accuracy: 0.8720, Validation Accuracy: 0.8740, Loss: 0.1205
Epoch 250 Batch  130/269 - Train Accuracy: 0.8613, Validation Accuracy: 0.8764, Loss: 0.1189
Epoch 250 Batch  140/269 - Train Accuracy: 0.8677, Validation Accuracy: 0.8750, Loss: 0.1112
Epoch 250 Batch  150/269 - Train Accuracy: 0.8703, Validation Accuracy: 0.8694, Loss: 0.1083
Epoch 250 Batch  160/269 - Train Accuracy: 0.8836, Validation Accuracy: 0.8777, Loss: 0.1045
Epoch 250 Batch  170/269 - Train Accuracy: 0.8669, Validation Accuracy: 0.8802, Loss: 0.0985
Epoch 250 Batch  180/269 - Train Accuracy: 0.8852, Validation Accuracy: 0.8777, Loss: 0.1054
Epoch 250 Batch  190/269 - Train Accuracy: 0.8846, Validation Accuracy: 0.8816, Loss: 0.0997
Epoch 250 Batch  200/269 - Train Accuracy: 0.8627, Validation Accuracy: 0.8780, Loss: 0.1038
Epoch 250 Batch  210/269 - Train Accuracy: 0.8711, Validation Accuracy: 0.8752, Loss: 0.1029
Epoch 250 Batch  220/269 - Train Accuracy: 0.8725, Validation Accuracy: 0.8699, Loss: 0.1093
Epoch 250 Batch  230/269 - Train Accuracy: 0.8674, Validation Accuracy: 0.8699, Loss: 0.1006
Epoch 250 Batch  240/269 - Train Accuracy: 0.8791, Validation Accuracy: 0.8738, Loss: 0.0927
Epoch 250 Batch  250/269 - Train Accuracy: 0.8796, Validation Accuracy: 0.8802, Loss: 0.1033
Epoch 250 Batch  260/269 - Train Accuracy: 0.8595, Validation Accuracy: 0.8746, Loss: 0.1144
Epoch 251 Batch   10/269 - Train Accuracy: 0.8680, Validation Accuracy: 0.8718, Loss: 0.1043
Epoch 251 Batch   20/269 - Train Accuracy: 0.8643, Validation Accuracy: 0.8712, Loss: 0.1057
Epoch 251 Batch   30/269 - Train Accuracy: 0.8671, Validation Accuracy: 0.8760, Loss: 0.1076
Epoch 251 Batch   40/269 - Train Accuracy: 0.8529, Validation Accuracy: 0.8764, Loss: 0.1348
Epoch 251 Batch   50/269 - Train Accuracy: 0.8566, Validation Accuracy: 0.8765, Loss: 0.1162
Epoch 251 Batch   60/269 - Train Accuracy: 0.8835, Validation Accuracy: 0.8807, Loss: 0.0999
Epoch 251 Batch   70/269 - Train Accuracy: 0.8833, Validation Accuracy: 0.8760, Loss: 0.1037
Epoch 251 Batch   80/269 - Train Accuracy: 0.8780, Validation Accuracy: 0.8692, Loss: 0.1004
Epoch 251 Batch   90/269 - Train Accuracy: 0.8759, Validation Accuracy: 0.8790, Loss: 0.1086
Epoch 251 Batch  100/269 - Train Accuracy: 0.8845, Validation Accuracy: 0.8744, Loss: 0.1046
Epoch 251 Batch  110/269 - Train Accuracy: 0.8585, Validation Accuracy: 0.8775, Loss: 0.1124
Epoch 251 Batch  120/269 - Train Accuracy: 0.8771, Validation Accuracy: 0.8786, Loss: 0.1251
Epoch 251 Batch  130/269 - Train Accuracy: 0.8572, Validation Accuracy: 0.8714, Loss: 0.1039
Epoch 251 Batch  140/269 - Train Accuracy: 0.8628, Validation Accuracy: 0.8720, Loss: 0.1150
Epoch 251 Batch  150/269 - Train Accuracy: 0.8697, Validation Accuracy: 0.8729, Loss: 0.1118
Epoch 251 Batch  160/269 - Train Accuracy: 0.8773, Validation Accuracy: 0.8762, Loss: 0.1097
Epoch 251 Batch  170/269 - Train Accuracy: 0.8626, Validation Accuracy: 0.8770, Loss: 0.1091
Epoch 251 Batch  180/269 - Train Accuracy: 0.8910, Validation Accuracy: 0.8687, Loss: 0.1001
Epoch 251 Batch  190/269 - Train Accuracy: 0.8779, Validation Accuracy: 0.8742, Loss: 0.1140
Epoch 251 Batch  200/269 - Train Accuracy: 0.8603, Validation Accuracy: 0.8755, Loss: 0.1121
Epoch 251 Batch  210/269 - Train Accuracy: 0.8741, Validation Accuracy: 0.8740, Loss: 0.1130
Epoch 251 Batch  220/269 - Train Accuracy: 0.8691, Validation Accuracy: 0.8692, Loss: 0.1028
Epoch 251 Batch  230/269 - Train Accuracy: 0.8649, Validation Accuracy: 0.8746, Loss: 0.1032
Epoch 251 Batch  240/269 - Train Accuracy: 0.8810, Validation Accuracy: 0.8699, Loss: 0.0988
Epoch 251 Batch  250/269 - Train Accuracy: 0.8816, Validation Accuracy: 0.8756, Loss: 0.1230
Epoch 251 Batch  260/269 - Train Accuracy: 0.8498, Validation Accuracy: 0.8744, Loss: 0.1161
Epoch 252 Batch   10/269 - Train Accuracy: 0.8650, Validation Accuracy: 0.8668, Loss: 0.1006
Epoch 252 Batch   20/269 - Train Accuracy: 0.8622, Validation Accuracy: 0.8717, Loss: 0.1141
Epoch 252 Batch   30/269 - Train Accuracy: 0.8658, Validation Accuracy: 0.8779, Loss: 0.1112
Epoch 252 Batch   40/269 - Train Accuracy: 0.8543, Validation Accuracy: 0.8753, Loss: 0.1285
Epoch 252 Batch   50/269 - Train Accuracy: 0.8555, Validation Accuracy: 0.8738, Loss: 0.1231
Epoch 252 Batch   60/269 - Train Accuracy: 0.8754, Validation Accuracy: 0.8775, Loss: 0.1031
Epoch 252 Batch   70/269 - Train Accuracy: 0.8832, Validation Accuracy: 0.8773, Loss: 0.1054
Epoch 252 Batch   80/269 - Train Accuracy: 0.8797, Validation Accuracy: 0.8746, Loss: 0.1043
Epoch 252 Batch   90/269 - Train Accuracy: 0.8762, Validation Accuracy: 0.8734, Loss: 0.1174
Epoch 252 Batch  100/269 - Train Accuracy: 0.8847, Validation Accuracy: 0.8756, Loss: 0.1085
Epoch 252 Batch  110/269 - Train Accuracy: 0.8598, Validation Accuracy: 0.8714, Loss: 0.1026
Epoch 252 Batch  120/269 - Train Accuracy: 0.8711, Validation Accuracy: 0.8747, Loss: 0.1264
Epoch 252 Batch  130/269 - Train Accuracy: 0.8641, Validation Accuracy: 0.8756, Loss: 0.1161
Epoch 252 Batch  140/269 - Train Accuracy: 0.8646, Validation Accuracy: 0.8746, Loss: 0.1192
Epoch 252 Batch  150/269 - Train Accuracy: 0.8708, Validation Accuracy: 0.8744, Loss: 0.1031
Epoch 252 Batch  160/269 - Train Accuracy: 0.8758, Validation Accuracy: 0.8737, Loss: 0.1131
Epoch 252 Batch  170/269 - Train Accuracy: 0.8658, Validation Accuracy: 0.8798, Loss: 0.1084
Epoch 252 Batch  180/269 - Train Accuracy: 0.8909, Validation Accuracy: 0.8747, Loss: 0.1012
Epoch 252 Batch  190/269 - Train Accuracy: 0.8803, Validation Accuracy: 0.8808, Loss: 0.1123
Epoch 252 Batch  200/269 - Train Accuracy: 0.8634, Validation Accuracy: 0.8799, Loss: 0.1094
Epoch 252 Batch  210/269 - Train Accuracy: 0.8698, Validation Accuracy: 0.8735, Loss: 0.1080
Epoch 252 Batch  220/269 - Train Accuracy: 0.8683, Validation Accuracy: 0.8777, Loss: 0.1070
Epoch 252 Batch  230/269 - Train Accuracy: 0.8641, Validation Accuracy: 0.8762, Loss: 0.1196
Epoch 252 Batch  240/269 - Train Accuracy: 0.8783, Validation Accuracy: 0.8738, Loss: 0.0893
Epoch 252 Batch  250/269 - Train Accuracy: 0.8854, Validation Accuracy: 0.8762, Loss: 0.0959
Epoch 252 Batch  260/269 - Train Accuracy: 0.8637, Validation Accuracy: 0.8793, Loss: 0.1131
Epoch 253 Batch   10/269 - Train Accuracy: 0.8739, Validation Accuracy: 0.8771, Loss: 0.0961
Epoch 253 Batch   20/269 - Train Accuracy: 0.8626, Validation Accuracy: 0.8748, Loss: 0.1083
Epoch 253 Batch   30/269 - Train Accuracy: 0.8683, Validation Accuracy: 0.8716, Loss: 0.1044
Epoch 253 Batch   40/269 - Train Accuracy: 0.8574, Validation Accuracy: 0.8732, Loss: 0.1108
Epoch 253 Batch   50/269 - Train Accuracy: 0.8547, Validation Accuracy: 0.8781, Loss: 0.1200
Epoch 253 Batch   60/269 - Train Accuracy: 0.8810, Validation Accuracy: 0.8752, Loss: 0.0944
Epoch 253 Batch   70/269 - Train Accuracy: 0.8732, Validation Accuracy: 0.8745, Loss: 0.1017
Epoch 253 Batch   80/269 - Train Accuracy: 0.8730, Validation Accuracy: 0.8685, Loss: 0.1023
Epoch 253 Batch   90/269 - Train Accuracy: 0.8765, Validation Accuracy: 0.8755, Loss: 0.1363
Epoch 253 Batch  100/269 - Train Accuracy: 0.8867, Validation Accuracy: 0.8789, Loss: 0.1071
Epoch 253 Batch  110/269 - Train Accuracy: 0.8554, Validation Accuracy: 0.8754, Loss: 0.1042
Epoch 253 Batch  120/269 - Train Accuracy: 0.8709, Validation Accuracy: 0.8733, Loss: 0.1125
Epoch 253 Batch  130/269 - Train Accuracy: 0.8596, Validation Accuracy: 0.8703, Loss: 0.1206
Epoch 253 Batch  140/269 - Train Accuracy: 0.8646, Validation Accuracy: 0.8667, Loss: 0.1273
Epoch 253 Batch  150/269 - Train Accuracy: 0.8671, Validation Accuracy: 0.8692, Loss: 0.1195
Epoch 253 Batch  160/269 - Train Accuracy: 0.8776, Validation Accuracy: 0.8643, Loss: 0.1124
Epoch 253 Batch  170/269 - Train Accuracy: 0.8594, Validation Accuracy: 0.8695, Loss: 0.1128
Epoch 253 Batch  180/269 - Train Accuracy: 0.8839, Validation Accuracy: 0.8715, Loss: 0.0978
Epoch 253 Batch  190/269 - Train Accuracy: 0.8852, Validation Accuracy: 0.8796, Loss: 0.1049
Epoch 253 Batch  200/269 - Train Accuracy: 0.8647, Validation Accuracy: 0.8793, Loss: 0.1042
Epoch 253 Batch  210/269 - Train Accuracy: 0.8729, Validation Accuracy: 0.8746, Loss: 0.1106
Epoch 253 Batch  220/269 - Train Accuracy: 0.8722, Validation Accuracy: 0.8724, Loss: 0.1063
Epoch 253 Batch  230/269 - Train Accuracy: 0.8593, Validation Accuracy: 0.8717, Loss: 0.1270
Epoch 253 Batch  240/269 - Train Accuracy: 0.8832, Validation Accuracy: 0.8687, Loss: 0.0975
Epoch 253 Batch  250/269 - Train Accuracy: 0.8827, Validation Accuracy: 0.8754, Loss: 0.1033
Epoch 253 Batch  260/269 - Train Accuracy: 0.8575, Validation Accuracy: 0.8805, Loss: 0.1152
Epoch 254 Batch   10/269 - Train Accuracy: 0.8663, Validation Accuracy: 0.8719, Loss: 0.1041
Epoch 254 Batch   20/269 - Train Accuracy: 0.8634, Validation Accuracy: 0.8754, Loss: 0.1041
Epoch 254 Batch   30/269 - Train Accuracy: 0.8613, Validation Accuracy: 0.8767, Loss: 0.1029
Epoch 254 Batch   40/269 - Train Accuracy: 0.8585, Validation Accuracy: 0.8755, Loss: 0.1172
Epoch 254 Batch   50/269 - Train Accuracy: 0.8521, Validation Accuracy: 0.8729, Loss: 0.1185
Epoch 254 Batch   60/269 - Train Accuracy: 0.8825, Validation Accuracy: 0.8773, Loss: 0.1000
Epoch 254 Batch   70/269 - Train Accuracy: 0.8837, Validation Accuracy: 0.8805, Loss: 0.1121
Epoch 254 Batch   80/269 - Train Accuracy: 0.8800, Validation Accuracy: 0.8731, Loss: 0.1041
Epoch 254 Batch   90/269 - Train Accuracy: 0.8767, Validation Accuracy: 0.8708, Loss: 0.1171
Epoch 254 Batch  100/269 - Train Accuracy: 0.8873, Validation Accuracy: 0.8733, Loss: 0.1004
Epoch 254 Batch  110/269 - Train Accuracy: 0.8640, Validation Accuracy: 0.8738, Loss: 0.1046
Epoch 254 Batch  120/269 - Train Accuracy: 0.8740, Validation Accuracy: 0.8728, Loss: 0.1078
Epoch 254 Batch  130/269 - Train Accuracy: 0.8623, Validation Accuracy: 0.8766, Loss: 0.1157
Epoch 254 Batch  140/269 - Train Accuracy: 0.8578, Validation Accuracy: 0.8688, Loss: 0.1117
Epoch 254 Batch  150/269 - Train Accuracy: 0.8693, Validation Accuracy: 0.8762, Loss: 0.1040
Epoch 254 Batch  160/269 - Train Accuracy: 0.8811, Validation Accuracy: 0.8759, Loss: 0.1030
Epoch 254 Batch  170/269 - Train Accuracy: 0.8680, Validation Accuracy: 0.8786, Loss: 0.1011
Epoch 254 Batch  180/269 - Train Accuracy: 0.8949, Validation Accuracy: 0.8722, Loss: 0.1005
Epoch 254 Batch  190/269 - Train Accuracy: 0.8849, Validation Accuracy: 0.8742, Loss: 0.1067
Epoch 254 Batch  200/269 - Train Accuracy: 0.8610, Validation Accuracy: 0.8736, Loss: 0.0951
Epoch 254 Batch  210/269 - Train Accuracy: 0.8738, Validation Accuracy: 0.8786, Loss: 0.1099
Epoch 254 Batch  220/269 - Train Accuracy: 0.8734, Validation Accuracy: 0.8728, Loss: 0.1033
Epoch 254 Batch  230/269 - Train Accuracy: 0.8686, Validation Accuracy: 0.8768, Loss: 0.0995
Epoch 254 Batch  240/269 - Train Accuracy: 0.8774, Validation Accuracy: 0.8717, Loss: 0.1008
Epoch 254 Batch  250/269 - Train Accuracy: 0.8819, Validation Accuracy: 0.8807, Loss: 0.0983
Epoch 254 Batch  260/269 - Train Accuracy: 0.8616, Validation Accuracy: 0.8733, Loss: 0.1120
Epoch 255 Batch   10/269 - Train Accuracy: 0.8707, Validation Accuracy: 0.8715, Loss: 0.1096
Epoch 255 Batch   20/269 - Train Accuracy: 0.8679, Validation Accuracy: 0.8761, Loss: 0.1017
Epoch 255 Batch   30/269 - Train Accuracy: 0.8674, Validation Accuracy: 0.8732, Loss: 0.0992
Epoch 255 Batch   40/269 - Train Accuracy: 0.8543, Validation Accuracy: 0.8701, Loss: 0.1129
Epoch 255 Batch   50/269 - Train Accuracy: 0.8591, Validation Accuracy: 0.8713, Loss: 0.1180
Epoch 255 Batch   60/269 - Train Accuracy: 0.8812, Validation Accuracy: 0.8763, Loss: 0.0900
Epoch 255 Batch   70/269 - Train Accuracy: 0.8830, Validation Accuracy: 0.8774, Loss: 0.1001
Epoch 255 Batch   80/269 - Train Accuracy: 0.8764, Validation Accuracy: 0.8736, Loss: 0.1018
Epoch 255 Batch   90/269 - Train Accuracy: 0.8754, Validation Accuracy: 0.8754, Loss: 0.1206
Epoch 255 Batch  100/269 - Train Accuracy: 0.8820, Validation Accuracy: 0.8727, Loss: 0.0955
Epoch 255 Batch  110/269 - Train Accuracy: 0.8583, Validation Accuracy: 0.8724, Loss: 0.1050
Epoch 255 Batch  120/269 - Train Accuracy: 0.8740, Validation Accuracy: 0.8734, Loss: 0.1160
Epoch 255 Batch  130/269 - Train Accuracy: 0.8632, Validation Accuracy: 0.8761, Loss: 0.1133
Epoch 255 Batch  140/269 - Train Accuracy: 0.8588, Validation Accuracy: 0.8769, Loss: 0.1160
Epoch 255 Batch  150/269 - Train Accuracy: 0.8678, Validation Accuracy: 0.8789, Loss: 0.1039
Epoch 255 Batch  160/269 - Train Accuracy: 0.8815, Validation Accuracy: 0.8730, Loss: 0.1033
Epoch 255 Batch  170/269 - Train Accuracy: 0.8661, Validation Accuracy: 0.8697, Loss: 0.1064
Epoch 255 Batch  180/269 - Train Accuracy: 0.8883, Validation Accuracy: 0.8769, Loss: 0.0927
Epoch 255 Batch  190/269 - Train Accuracy: 0.8818, Validation Accuracy: 0.8730, Loss: 0.1068
Epoch 255 Batch  200/269 - Train Accuracy: 0.8649, Validation Accuracy: 0.8740, Loss: 0.1001
Epoch 255 Batch  210/269 - Train Accuracy: 0.8720, Validation Accuracy: 0.8788, Loss: 0.1154
Epoch 255 Batch  220/269 - Train Accuracy: 0.8727, Validation Accuracy: 0.8747, Loss: 0.1090
Epoch 255 Batch  230/269 - Train Accuracy: 0.8633, Validation Accuracy: 0.8684, Loss: 0.1079
Epoch 255 Batch  240/269 - Train Accuracy: 0.8840, Validation Accuracy: 0.8739, Loss: 0.1039
Epoch 255 Batch  250/269 - Train Accuracy: 0.8853, Validation Accuracy: 0.8778, Loss: 0.1081
Epoch 255 Batch  260/269 - Train Accuracy: 0.8587, Validation Accuracy: 0.8747, Loss: 0.1102
Epoch 256 Batch   10/269 - Train Accuracy: 0.8659, Validation Accuracy: 0.8668, Loss: 0.1051
Epoch 256 Batch   20/269 - Train Accuracy: 0.8643, Validation Accuracy: 0.8732, Loss: 0.0982
Epoch 256 Batch   30/269 - Train Accuracy: 0.8652, Validation Accuracy: 0.8789, Loss: 0.1046
Epoch 256 Batch   40/269 - Train Accuracy: 0.8556, Validation Accuracy: 0.8751, Loss: 0.1070
Epoch 256 Batch   50/269 - Train Accuracy: 0.8614, Validation Accuracy: 0.8801, Loss: 0.1140
Epoch 256 Batch   60/269 - Train Accuracy: 0.8766, Validation Accuracy: 0.8792, Loss: 0.0938
Epoch 256 Batch   70/269 - Train Accuracy: 0.8850, Validation Accuracy: 0.8759, Loss: 0.1150
Epoch 256 Batch   80/269 - Train Accuracy: 0.8734, Validation Accuracy: 0.8774, Loss: 0.1245
Epoch 256 Batch   90/269 - Train Accuracy: 0.8766, Validation Accuracy: 0.8750, Loss: 0.1126
Epoch 256 Batch  100/269 - Train Accuracy: 0.8879, Validation Accuracy: 0.8821, Loss: 0.1081
Epoch 256 Batch  110/269 - Train Accuracy: 0.8623, Validation Accuracy: 0.8744, Loss: 0.1021
Epoch 256 Batch  120/269 - Train Accuracy: 0.8780, Validation Accuracy: 0.8700, Loss: 0.1253
Epoch 256 Batch  130/269 - Train Accuracy: 0.8625, Validation Accuracy: 0.8766, Loss: 0.1052
Epoch 256 Batch  140/269 - Train Accuracy: 0.8623, Validation Accuracy: 0.8715, Loss: 0.1145
Epoch 256 Batch  150/269 - Train Accuracy: 0.8673, Validation Accuracy: 0.8814, Loss: 0.1079
Epoch 256 Batch  160/269 - Train Accuracy: 0.8722, Validation Accuracy: 0.8778, Loss: 0.1235
Epoch 256 Batch  170/269 - Train Accuracy: 0.8590, Validation Accuracy: 0.8735, Loss: 0.1064
Epoch 256 Batch  180/269 - Train Accuracy: 0.8899, Validation Accuracy: 0.8672, Loss: 0.1001
Epoch 256 Batch  190/269 - Train Accuracy: 0.8783, Validation Accuracy: 0.8808, Loss: 0.1106
Epoch 256 Batch  200/269 - Train Accuracy: 0.8562, Validation Accuracy: 0.8783, Loss: 0.1061
Epoch 256 Batch  210/269 - Train Accuracy: 0.8724, Validation Accuracy: 0.8705, Loss: 0.1075
Epoch 256 Batch  220/269 - Train Accuracy: 0.8704, Validation Accuracy: 0.8744, Loss: 0.1121
Epoch 256 Batch  230/269 - Train Accuracy: 0.8584, Validation Accuracy: 0.8759, Loss: 0.1049
Epoch 256 Batch  240/269 - Train Accuracy: 0.8827, Validation Accuracy: 0.8722, Loss: 0.0996
Epoch 256 Batch  250/269 - Train Accuracy: 0.8867, Validation Accuracy: 0.8809, Loss: 0.1074
Epoch 256 Batch  260/269 - Train Accuracy: 0.8585, Validation Accuracy: 0.8753, Loss: 0.1108
Epoch 257 Batch   10/269 - Train Accuracy: 0.8713, Validation Accuracy: 0.8723, Loss: 0.0998
Epoch 257 Batch   20/269 - Train Accuracy: 0.8628, Validation Accuracy: 0.8714, Loss: 0.1026
Epoch 257 Batch   30/269 - Train Accuracy: 0.8651, Validation Accuracy: 0.8739, Loss: 0.1038
Epoch 257 Batch   40/269 - Train Accuracy: 0.8549, Validation Accuracy: 0.8746, Loss: 0.1145
Epoch 257 Batch   50/269 - Train Accuracy: 0.8542, Validation Accuracy: 0.8752, Loss: 0.1207
Epoch 257 Batch   60/269 - Train Accuracy: 0.8843, Validation Accuracy: 0.8751, Loss: 0.0892
Epoch 257 Batch   70/269 - Train Accuracy: 0.8794, Validation Accuracy: 0.8740, Loss: 0.1046
Epoch 257 Batch   80/269 - Train Accuracy: 0.8783, Validation Accuracy: 0.8730, Loss: 0.1046
Epoch 257 Batch   90/269 - Train Accuracy: 0.8731, Validation Accuracy: 0.8688, Loss: 0.1186
Epoch 257 Batch  100/269 - Train Accuracy: 0.8828, Validation Accuracy: 0.8711, Loss: 0.1013
Epoch 257 Batch  110/269 - Train Accuracy: 0.8584, Validation Accuracy: 0.8678, Loss: 0.1102
Epoch 257 Batch  120/269 - Train Accuracy: 0.8757, Validation Accuracy: 0.8738, Loss: 0.1176
Epoch 257 Batch  130/269 - Train Accuracy: 0.8625, Validation Accuracy: 0.8665, Loss: 0.1086
Epoch 257 Batch  140/269 - Train Accuracy: 0.8590, Validation Accuracy: 0.8734, Loss: 0.1164
Epoch 257 Batch  150/269 - Train Accuracy: 0.8661, Validation Accuracy: 0.8722, Loss: 0.1185
Epoch 257 Batch  160/269 - Train Accuracy: 0.8757, Validation Accuracy: 0.8705, Loss: 0.1050
Epoch 257 Batch  170/269 - Train Accuracy: 0.8587, Validation Accuracy: 0.8683, Loss: 0.0985
Epoch 257 Batch  180/269 - Train Accuracy: 0.8883, Validation Accuracy: 0.8702, Loss: 0.0975
Epoch 257 Batch  190/269 - Train Accuracy: 0.8783, Validation Accuracy: 0.8778, Loss: 0.1046
Epoch 257 Batch  200/269 - Train Accuracy: 0.8651, Validation Accuracy: 0.8756, Loss: 0.1004
Epoch 257 Batch  210/269 - Train Accuracy: 0.8700, Validation Accuracy: 0.8766, Loss: 0.1052
Epoch 257 Batch  220/269 - Train Accuracy: 0.8681, Validation Accuracy: 0.8770, Loss: 0.1115
Epoch 257 Batch  230/269 - Train Accuracy: 0.8640, Validation Accuracy: 0.8791, Loss: 0.1108
Epoch 257 Batch  240/269 - Train Accuracy: 0.8806, Validation Accuracy: 0.8768, Loss: 0.0949
Epoch 257 Batch  250/269 - Train Accuracy: 0.8854, Validation Accuracy: 0.8816, Loss: 0.1011
Epoch 257 Batch  260/269 - Train Accuracy: 0.8621, Validation Accuracy: 0.8797, Loss: 0.1180
Epoch 258 Batch   10/269 - Train Accuracy: 0.8755, Validation Accuracy: 0.8717, Loss: 0.1011
Epoch 258 Batch   20/269 - Train Accuracy: 0.8654, Validation Accuracy: 0.8729, Loss: 0.1061
Epoch 258 Batch   30/269 - Train Accuracy: 0.8662, Validation Accuracy: 0.8753, Loss: 0.1080
Epoch 258 Batch   40/269 - Train Accuracy: 0.8562, Validation Accuracy: 0.8717, Loss: 0.1176
Epoch 258 Batch   50/269 - Train Accuracy: 0.8565, Validation Accuracy: 0.8756, Loss: 0.1147
Epoch 258 Batch   60/269 - Train Accuracy: 0.8802, Validation Accuracy: 0.8770, Loss: 0.0916
Epoch 258 Batch   70/269 - Train Accuracy: 0.8842, Validation Accuracy: 0.8746, Loss: 0.1090
Epoch 258 Batch   80/269 - Train Accuracy: 0.8792, Validation Accuracy: 0.8732, Loss: 0.1003
Epoch 258 Batch   90/269 - Train Accuracy: 0.8727, Validation Accuracy: 0.8713, Loss: 0.1155
Epoch 258 Batch  100/269 - Train Accuracy: 0.8846, Validation Accuracy: 0.8794, Loss: 0.1038
Epoch 258 Batch  110/269 - Train Accuracy: 0.8565, Validation Accuracy: 0.8770, Loss: 0.1048
Epoch 258 Batch  120/269 - Train Accuracy: 0.8711, Validation Accuracy: 0.8695, Loss: 0.1143
Epoch 258 Batch  130/269 - Train Accuracy: 0.8600, Validation Accuracy: 0.8807, Loss: 0.1114
Epoch 258 Batch  140/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8798, Loss: 0.1050
Epoch 258 Batch  150/269 - Train Accuracy: 0.8768, Validation Accuracy: 0.8744, Loss: 0.1095
Epoch 258 Batch  160/269 - Train Accuracy: 0.8778, Validation Accuracy: 0.8746, Loss: 0.1069
Epoch 258 Batch  170/269 - Train Accuracy: 0.8669, Validation Accuracy: 0.8745, Loss: 0.0980
Epoch 258 Batch  180/269 - Train Accuracy: 0.8914, Validation Accuracy: 0.8784, Loss: 0.0962
Epoch 258 Batch  190/269 - Train Accuracy: 0.8839, Validation Accuracy: 0.8770, Loss: 0.1115
Epoch 258 Batch  200/269 - Train Accuracy: 0.8633, Validation Accuracy: 0.8805, Loss: 0.0968
Epoch 258 Batch  210/269 - Train Accuracy: 0.8755, Validation Accuracy: 0.8787, Loss: 0.1017
Epoch 258 Batch  220/269 - Train Accuracy: 0.8706, Validation Accuracy: 0.8748, Loss: 0.0950
Epoch 258 Batch  230/269 - Train Accuracy: 0.8677, Validation Accuracy: 0.8784, Loss: 0.1037
Epoch 258 Batch  240/269 - Train Accuracy: 0.8818, Validation Accuracy: 0.8748, Loss: 0.0911
Epoch 258 Batch  250/269 - Train Accuracy: 0.8865, Validation Accuracy: 0.8769, Loss: 0.1002
Epoch 258 Batch  260/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8778, Loss: 0.1207
Epoch 259 Batch   10/269 - Train Accuracy: 0.8761, Validation Accuracy: 0.8760, Loss: 0.1006
Epoch 259 Batch   20/269 - Train Accuracy: 0.8701, Validation Accuracy: 0.8795, Loss: 0.1032
Epoch 259 Batch   30/269 - Train Accuracy: 0.8647, Validation Accuracy: 0.8789, Loss: 0.0971
Epoch 259 Batch   40/269 - Train Accuracy: 0.8586, Validation Accuracy: 0.8722, Loss: 0.1194
Epoch 259 Batch   50/269 - Train Accuracy: 0.8545, Validation Accuracy: 0.8768, Loss: 0.1138
Epoch 259 Batch   60/269 - Train Accuracy: 0.8809, Validation Accuracy: 0.8733, Loss: 0.0998
Epoch 259 Batch   70/269 - Train Accuracy: 0.8857, Validation Accuracy: 0.8801, Loss: 0.1099
Epoch 259 Batch   80/269 - Train Accuracy: 0.8815, Validation Accuracy: 0.8767, Loss: 0.1040
Epoch 259 Batch   90/269 - Train Accuracy: 0.8771, Validation Accuracy: 0.8777, Loss: 0.1136
Epoch 259 Batch  100/269 - Train Accuracy: 0.8858, Validation Accuracy: 0.8774, Loss: 0.1120
Epoch 259 Batch  110/269 - Train Accuracy: 0.8638, Validation Accuracy: 0.8720, Loss: 0.1080
Epoch 259 Batch  120/269 - Train Accuracy: 0.8767, Validation Accuracy: 0.8750, Loss: 0.1276
Epoch 259 Batch  130/269 - Train Accuracy: 0.8623, Validation Accuracy: 0.8726, Loss: 0.1182
Epoch 259 Batch  140/269 - Train Accuracy: 0.8613, Validation Accuracy: 0.8782, Loss: 0.1192
Epoch 259 Batch  150/269 - Train Accuracy: 0.8727, Validation Accuracy: 0.8760, Loss: 0.1067
Epoch 259 Batch  160/269 - Train Accuracy: 0.8866, Validation Accuracy: 0.8814, Loss: 0.0985
Epoch 259 Batch  170/269 - Train Accuracy: 0.8693, Validation Accuracy: 0.8755, Loss: 0.0996
Epoch 259 Batch  180/269 - Train Accuracy: 0.8867, Validation Accuracy: 0.8735, Loss: 0.0986
Epoch 259 Batch  190/269 - Train Accuracy: 0.8819, Validation Accuracy: 0.8813, Loss: 0.1049
Epoch 259 Batch  200/269 - Train Accuracy: 0.8558, Validation Accuracy: 0.8716, Loss: 0.1059
Epoch 259 Batch  210/269 - Train Accuracy: 0.8721, Validation Accuracy: 0.8764, Loss: 0.1020
Epoch 259 Batch  220/269 - Train Accuracy: 0.8713, Validation Accuracy: 0.8752, Loss: 0.1128
Epoch 259 Batch  230/269 - Train Accuracy: 0.8646, Validation Accuracy: 0.8829, Loss: 0.1051
Epoch 259 Batch  240/269 - Train Accuracy: 0.8829, Validation Accuracy: 0.8771, Loss: 0.0924
Epoch 259 Batch  250/269 - Train Accuracy: 0.8898, Validation Accuracy: 0.8784, Loss: 0.1033
Epoch 259 Batch  260/269 - Train Accuracy: 0.8585, Validation Accuracy: 0.8769, Loss: 0.1070
Epoch 260 Batch   10/269 - Train Accuracy: 0.8756, Validation Accuracy: 0.8746, Loss: 0.1082
Epoch 260 Batch   20/269 - Train Accuracy: 0.8574, Validation Accuracy: 0.8760, Loss: 0.1008
Epoch 260 Batch   30/269 - Train Accuracy: 0.8692, Validation Accuracy: 0.8791, Loss: 0.1038
Epoch 260 Batch   40/269 - Train Accuracy: 0.8583, Validation Accuracy: 0.8755, Loss: 0.1147
Epoch 260 Batch   50/269 - Train Accuracy: 0.8592, Validation Accuracy: 0.8746, Loss: 0.1188
Epoch 260 Batch   60/269 - Train Accuracy: 0.8820, Validation Accuracy: 0.8771, Loss: 0.1141
Epoch 260 Batch   70/269 - Train Accuracy: 0.8763, Validation Accuracy: 0.8767, Loss: 0.1028
Epoch 260 Batch   80/269 - Train Accuracy: 0.8767, Validation Accuracy: 0.8751, Loss: 0.1005
Epoch 260 Batch   90/269 - Train Accuracy: 0.8711, Validation Accuracy: 0.8810, Loss: 0.1105
Epoch 260 Batch  100/269 - Train Accuracy: 0.8837, Validation Accuracy: 0.8786, Loss: 0.1072
Epoch 260 Batch  110/269 - Train Accuracy: 0.8666, Validation Accuracy: 0.8811, Loss: 0.1073
Epoch 260 Batch  120/269 - Train Accuracy: 0.8751, Validation Accuracy: 0.8715, Loss: 0.1166
Epoch 260 Batch  130/269 - Train Accuracy: 0.8586, Validation Accuracy: 0.8720, Loss: 0.1086
Epoch 260 Batch  140/269 - Train Accuracy: 0.8658, Validation Accuracy: 0.8695, Loss: 0.1285
Epoch 260 Batch  150/269 - Train Accuracy: 0.8704, Validation Accuracy: 0.8769, Loss: 0.1096
Epoch 260 Batch  160/269 - Train Accuracy: 0.8800, Validation Accuracy: 0.8714, Loss: 0.1024
Epoch 260 Batch  170/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8678, Loss: 0.1088
Epoch 260 Batch  180/269 - Train Accuracy: 0.8919, Validation Accuracy: 0.8785, Loss: 0.0974
Epoch 260 Batch  190/269 - Train Accuracy: 0.8823, Validation Accuracy: 0.8736, Loss: 0.1011
Epoch 260 Batch  200/269 - Train Accuracy: 0.8615, Validation Accuracy: 0.8798, Loss: 0.1001
Epoch 260 Batch  210/269 - Train Accuracy: 0.8771, Validation Accuracy: 0.8748, Loss: 0.1008
Epoch 260 Batch  220/269 - Train Accuracy: 0.8720, Validation Accuracy: 0.8722, Loss: 0.1052
Epoch 260 Batch  230/269 - Train Accuracy: 0.8583, Validation Accuracy: 0.8797, Loss: 0.1011
Epoch 260 Batch  240/269 - Train Accuracy: 0.8773, Validation Accuracy: 0.8665, Loss: 0.0959
Epoch 260 Batch  250/269 - Train Accuracy: 0.8804, Validation Accuracy: 0.8746, Loss: 0.1017
Epoch 260 Batch  260/269 - Train Accuracy: 0.8613, Validation Accuracy: 0.8770, Loss: 0.1134
Epoch 261 Batch   10/269 - Train Accuracy: 0.8751, Validation Accuracy: 0.8717, Loss: 0.0985
Epoch 261 Batch   20/269 - Train Accuracy: 0.8651, Validation Accuracy: 0.8727, Loss: 0.1003
Epoch 261 Batch   30/269 - Train Accuracy: 0.8667, Validation Accuracy: 0.8754, Loss: 0.1004
Epoch 261 Batch   40/269 - Train Accuracy: 0.8546, Validation Accuracy: 0.8768, Loss: 0.1122
Epoch 261 Batch   50/269 - Train Accuracy: 0.8579, Validation Accuracy: 0.8796, Loss: 0.1217
Epoch 261 Batch   60/269 - Train Accuracy: 0.8857, Validation Accuracy: 0.8726, Loss: 0.0991
Epoch 261 Batch   70/269 - Train Accuracy: 0.8761, Validation Accuracy: 0.8707, Loss: 0.1037
Epoch 261 Batch   80/269 - Train Accuracy: 0.8786, Validation Accuracy: 0.8747, Loss: 0.1001
Epoch 261 Batch   90/269 - Train Accuracy: 0.8776, Validation Accuracy: 0.8733, Loss: 0.1148
Epoch 261 Batch  100/269 - Train Accuracy: 0.8819, Validation Accuracy: 0.8705, Loss: 0.1085
Epoch 261 Batch  110/269 - Train Accuracy: 0.8620, Validation Accuracy: 0.8725, Loss: 0.1017
Epoch 261 Batch  120/269 - Train Accuracy: 0.8744, Validation Accuracy: 0.8731, Loss: 0.1121
Epoch 261 Batch  130/269 - Train Accuracy: 0.8609, Validation Accuracy: 0.8782, Loss: 0.1035
Epoch 261 Batch  140/269 - Train Accuracy: 0.8627, Validation Accuracy: 0.8744, Loss: 0.1097
Epoch 261 Batch  150/269 - Train Accuracy: 0.8712, Validation Accuracy: 0.8733, Loss: 0.1172
Epoch 261 Batch  160/269 - Train Accuracy: 0.8789, Validation Accuracy: 0.8738, Loss: 0.1040
Epoch 261 Batch  170/269 - Train Accuracy: 0.8676, Validation Accuracy: 0.8731, Loss: 0.1024
Epoch 261 Batch  180/269 - Train Accuracy: 0.8907, Validation Accuracy: 0.8754, Loss: 0.1032
Epoch 261 Batch  190/269 - Train Accuracy: 0.8815, Validation Accuracy: 0.8720, Loss: 0.1033
Epoch 261 Batch  200/269 - Train Accuracy: 0.8541, Validation Accuracy: 0.8798, Loss: 0.0943
Epoch 261 Batch  210/269 - Train Accuracy: 0.8720, Validation Accuracy: 0.8868, Loss: 0.1030
Epoch 261 Batch  220/269 - Train Accuracy: 0.8698, Validation Accuracy: 0.8746, Loss: 0.1128
Epoch 261 Batch  230/269 - Train Accuracy: 0.8683, Validation Accuracy: 0.8778, Loss: 0.0992
Epoch 261 Batch  240/269 - Train Accuracy: 0.8835, Validation Accuracy: 0.8761, Loss: 0.0949
Epoch 261 Batch  250/269 - Train Accuracy: 0.8854, Validation Accuracy: 0.8815, Loss: 0.1023
Epoch 261 Batch  260/269 - Train Accuracy: 0.8634, Validation Accuracy: 0.8787, Loss: 0.1121
Epoch 262 Batch   10/269 - Train Accuracy: 0.8719, Validation Accuracy: 0.8715, Loss: 0.1050
Epoch 262 Batch   20/269 - Train Accuracy: 0.8622, Validation Accuracy: 0.8724, Loss: 0.1033
Epoch 262 Batch   30/269 - Train Accuracy: 0.8632, Validation Accuracy: 0.8775, Loss: 0.1019
Epoch 262 Batch   40/269 - Train Accuracy: 0.8603, Validation Accuracy: 0.8755, Loss: 0.1237
Epoch 262 Batch   50/269 - Train Accuracy: 0.8544, Validation Accuracy: 0.8760, Loss: 0.1197
Epoch 262 Batch   60/269 - Train Accuracy: 0.8817, Validation Accuracy: 0.8819, Loss: 0.0938
Epoch 262 Batch   70/269 - Train Accuracy: 0.8782, Validation Accuracy: 0.8712, Loss: 0.1074
Epoch 262 Batch   80/269 - Train Accuracy: 0.8697, Validation Accuracy: 0.8726, Loss: 0.1052
Epoch 262 Batch   90/269 - Train Accuracy: 0.8813, Validation Accuracy: 0.8748, Loss: 0.1124
Epoch 262 Batch  100/269 - Train Accuracy: 0.8850, Validation Accuracy: 0.8762, Loss: 0.0990
Epoch 262 Batch  110/269 - Train Accuracy: 0.8632, Validation Accuracy: 0.8737, Loss: 0.1095
Epoch 262 Batch  120/269 - Train Accuracy: 0.8722, Validation Accuracy: 0.8762, Loss: 0.1123
Epoch 262 Batch  130/269 - Train Accuracy: 0.8674, Validation Accuracy: 0.8817, Loss: 0.1124
Epoch 262 Batch  140/269 - Train Accuracy: 0.8647, Validation Accuracy: 0.8740, Loss: 0.1172
Epoch 262 Batch  150/269 - Train Accuracy: 0.8669, Validation Accuracy: 0.8740, Loss: 0.1043
Epoch 262 Batch  160/269 - Train Accuracy: 0.8821, Validation Accuracy: 0.8771, Loss: 0.1056
Epoch 262 Batch  170/269 - Train Accuracy: 0.8666, Validation Accuracy: 0.8756, Loss: 0.1033
Epoch 262 Batch  180/269 - Train Accuracy: 0.8889, Validation Accuracy: 0.8721, Loss: 0.0994
Epoch 262 Batch  190/269 - Train Accuracy: 0.8806, Validation Accuracy: 0.8800, Loss: 0.1136
Epoch 262 Batch  200/269 - Train Accuracy: 0.8585, Validation Accuracy: 0.8800, Loss: 0.0947
Epoch 262 Batch  210/269 - Train Accuracy: 0.8692, Validation Accuracy: 0.8748, Loss: 0.1087
Epoch 262 Batch  220/269 - Train Accuracy: 0.8744, Validation Accuracy: 0.8715, Loss: 0.1020
Epoch 262 Batch  230/269 - Train Accuracy: 0.8609, Validation Accuracy: 0.8782, Loss: 0.1029
Epoch 262 Batch  240/269 - Train Accuracy: 0.8742, Validation Accuracy: 0.8727, Loss: 0.0934
Epoch 262 Batch  250/269 - Train Accuracy: 0.8815, Validation Accuracy: 0.8775, Loss: 0.1047
Epoch 262 Batch  260/269 - Train Accuracy: 0.8590, Validation Accuracy: 0.8706, Loss: 0.1126
Epoch 263 Batch   10/269 - Train Accuracy: 0.8720, Validation Accuracy: 0.8650, Loss: 0.0944
Epoch 263 Batch   20/269 - Train Accuracy: 0.8682, Validation Accuracy: 0.8730, Loss: 0.1018
Epoch 263 Batch   30/269 - Train Accuracy: 0.8655, Validation Accuracy: 0.8714, Loss: 0.1034
Epoch 263 Batch   40/269 - Train Accuracy: 0.8566, Validation Accuracy: 0.8728, Loss: 0.1150
Epoch 263 Batch   50/269 - Train Accuracy: 0.8594, Validation Accuracy: 0.8753, Loss: 0.1163
Epoch 263 Batch   60/269 - Train Accuracy: 0.8790, Validation Accuracy: 0.8778, Loss: 0.0940
Epoch 263 Batch   70/269 - Train Accuracy: 0.8811, Validation Accuracy: 0.8768, Loss: 0.1089
Epoch 263 Batch   80/269 - Train Accuracy: 0.8737, Validation Accuracy: 0.8706, Loss: 0.1098
Epoch 263 Batch   90/269 - Train Accuracy: 0.8754, Validation Accuracy: 0.8773, Loss: 0.1160
Epoch 263 Batch  100/269 - Train Accuracy: 0.8901, Validation Accuracy: 0.8786, Loss: 0.0990
Epoch 263 Batch  110/269 - Train Accuracy: 0.8621, Validation Accuracy: 0.8750, Loss: 0.1056
Epoch 263 Batch  120/269 - Train Accuracy: 0.8697, Validation Accuracy: 0.8714, Loss: 0.1190
Epoch 263 Batch  130/269 - Train Accuracy: 0.8663, Validation Accuracy: 0.8778, Loss: 0.1052
Epoch 263 Batch  140/269 - Train Accuracy: 0.8615, Validation Accuracy: 0.8770, Loss: 0.1081
Epoch 263 Batch  150/269 - Train Accuracy: 0.8715, Validation Accuracy: 0.8746, Loss: 0.1048
Epoch 263 Batch  160/269 - Train Accuracy: 0.8769, Validation Accuracy: 0.8750, Loss: 0.1096
Epoch 263 Batch  170/269 - Train Accuracy: 0.8605, Validation Accuracy: 0.8686, Loss: 0.1027
Epoch 263 Batch  180/269 - Train Accuracy: 0.8932, Validation Accuracy: 0.8770, Loss: 0.0967
Epoch 263 Batch  190/269 - Train Accuracy: 0.8783, Validation Accuracy: 0.8748, Loss: 0.1038
Epoch 263 Batch  200/269 - Train Accuracy: 0.8577, Validation Accuracy: 0.8765, Loss: 0.0942
Epoch 263 Batch  210/269 - Train Accuracy: 0.8750, Validation Accuracy: 0.8722, Loss: 0.0985
Epoch 263 Batch  220/269 - Train Accuracy: 0.8716, Validation Accuracy: 0.8762, Loss: 0.1082
Epoch 263 Batch  230/269 - Train Accuracy: 0.8671, Validation Accuracy: 0.8759, Loss: 0.0989
Epoch 263 Batch  240/269 - Train Accuracy: 0.8792, Validation Accuracy: 0.8770, Loss: 0.0970
Epoch 263 Batch  250/269 - Train Accuracy: 0.8824, Validation Accuracy: 0.8801, Loss: 0.0986
Epoch 263 Batch  260/269 - Train Accuracy: 0.8585, Validation Accuracy: 0.8817, Loss: 0.1092
Epoch 264 Batch   10/269 - Train Accuracy: 0.8756, Validation Accuracy: 0.8694, Loss: 0.0951
Epoch 264 Batch   20/269 - Train Accuracy: 0.8618, Validation Accuracy: 0.8743, Loss: 0.1025
Epoch 264 Batch   30/269 - Train Accuracy: 0.8713, Validation Accuracy: 0.8774, Loss: 0.1017
Epoch 264 Batch   40/269 - Train Accuracy: 0.8499, Validation Accuracy: 0.8736, Loss: 0.1084
Epoch 264 Batch   50/269 - Train Accuracy: 0.8602, Validation Accuracy: 0.8730, Loss: 0.1175
Epoch 264 Batch   60/269 - Train Accuracy: 0.8794, Validation Accuracy: 0.8830, Loss: 0.1087
Epoch 264 Batch   70/269 - Train Accuracy: 0.8854, Validation Accuracy: 0.8772, Loss: 0.1011
Epoch 264 Batch   80/269 - Train Accuracy: 0.8748, Validation Accuracy: 0.8775, Loss: 0.1019
Epoch 264 Batch   90/269 - Train Accuracy: 0.8796, Validation Accuracy: 0.8754, Loss: 0.1276
Epoch 264 Batch  100/269 - Train Accuracy: 0.8886, Validation Accuracy: 0.8732, Loss: 0.0995
Epoch 264 Batch  110/269 - Train Accuracy: 0.8636, Validation Accuracy: 0.8741, Loss: 0.1131
Epoch 264 Batch  120/269 - Train Accuracy: 0.8721, Validation Accuracy: 0.8743, Loss: 0.1150
Epoch 264 Batch  130/269 - Train Accuracy: 0.8607, Validation Accuracy: 0.8715, Loss: 0.1136
Epoch 264 Batch  140/269 - Train Accuracy: 0.8599, Validation Accuracy: 0.8698, Loss: 0.1116
Epoch 264 Batch  150/269 - Train Accuracy: 0.8669, Validation Accuracy: 0.8721, Loss: 0.1017
Epoch 264 Batch  160/269 - Train Accuracy: 0.8794, Validation Accuracy: 0.8765, Loss: 0.1064
Epoch 264 Batch  170/269 - Train Accuracy: 0.8642, Validation Accuracy: 0.8732, Loss: 0.1052
Epoch 264 Batch  180/269 - Train Accuracy: 0.8922, Validation Accuracy: 0.8761, Loss: 0.1000
Epoch 264 Batch  190/269 - Train Accuracy: 0.8880, Validation Accuracy: 0.8758, Loss: 0.1268
Epoch 264 Batch  200/269 - Train Accuracy: 0.8605, Validation Accuracy: 0.8801, Loss: 0.0987
Epoch 264 Batch  210/269 - Train Accuracy: 0.8760, Validation Accuracy: 0.8759, Loss: 0.1037
Epoch 264 Batch  220/269 - Train Accuracy: 0.8735, Validation Accuracy: 0.8724, Loss: 0.1136
Epoch 264 Batch  230/269 - Train Accuracy: 0.8610, Validation Accuracy: 0.8754, Loss: 0.0967
Epoch 264 Batch  240/269 - Train Accuracy: 0.8795, Validation Accuracy: 0.8752, Loss: 0.0993
Epoch 264 Batch  250/269 - Train Accuracy: 0.8842, Validation Accuracy: 0.8801, Loss: 0.0953
Epoch 264 Batch  260/269 - Train Accuracy: 0.8619, Validation Accuracy: 0.8809, Loss: 0.1076
Epoch 265 Batch   10/269 - Train Accuracy: 0.8707, Validation Accuracy: 0.8749, Loss: 0.0961
Epoch 265 Batch   20/269 - Train Accuracy: 0.8649, Validation Accuracy: 0.8733, Loss: 0.1179
Epoch 265 Batch   30/269 - Train Accuracy: 0.8638, Validation Accuracy: 0.8740, Loss: 0.0991
Epoch 265 Batch   40/269 - Train Accuracy: 0.8564, Validation Accuracy: 0.8724, Loss: 0.1137
Epoch 265 Batch   50/269 - Train Accuracy: 0.8596, Validation Accuracy: 0.8797, Loss: 0.1116
Epoch 265 Batch   60/269 - Train Accuracy: 0.8808, Validation Accuracy: 0.8770, Loss: 0.0891
Epoch 265 Batch   70/269 - Train Accuracy: 0.8899, Validation Accuracy: 0.8797, Loss: 0.1041
Epoch 265 Batch   80/269 - Train Accuracy: 0.8769, Validation Accuracy: 0.8796, Loss: 0.1011
Epoch 265 Batch   90/269 - Train Accuracy: 0.8713, Validation Accuracy: 0.8746, Loss: 0.1123
Epoch 265 Batch  100/269 - Train Accuracy: 0.8857, Validation Accuracy: 0.8762, Loss: 0.1028
Epoch 265 Batch  110/269 - Train Accuracy: 0.8579, Validation Accuracy: 0.8699, Loss: 0.1081
Epoch 265 Batch  120/269 - Train Accuracy: 0.8735, Validation Accuracy: 0.8685, Loss: 0.1131
Epoch 265 Batch  130/269 - Train Accuracy: 0.8593, Validation Accuracy: 0.8714, Loss: 0.1107
Epoch 265 Batch  140/269 - Train Accuracy: 0.8611, Validation Accuracy: 0.8706, Loss: 0.1072
Epoch 265 Batch  150/269 - Train Accuracy: 0.8689, Validation Accuracy: 0.8735, Loss: 0.1026
Epoch 265 Batch  160/269 - Train Accuracy: 0.8692, Validation Accuracy: 0.8724, Loss: 0.1118
Epoch 265 Batch  170/269 - Train Accuracy: 0.8650, Validation Accuracy: 0.8759, Loss: 0.1119
Epoch 265 Batch  180/269 - Train Accuracy: 0.8947, Validation Accuracy: 0.8691, Loss: 0.1137
Epoch 265 Batch  190/269 - Train Accuracy: 0.8813, Validation Accuracy: 0.8748, Loss: 0.0971
Epoch 265 Batch  200/269 - Train Accuracy: 0.8660, Validation Accuracy: 0.8743, Loss: 0.1048
Epoch 265 Batch  210/269 - Train Accuracy: 0.8667, Validation Accuracy: 0.8758, Loss: 0.0986
Epoch 265 Batch  220/269 - Train Accuracy: 0.8712, Validation Accuracy: 0.8730, Loss: 0.1006
Epoch 265 Batch  230/269 - Train Accuracy: 0.8690, Validation Accuracy: 0.8807, Loss: 0.1021
Epoch 265 Batch  240/269 - Train Accuracy: 0.8780, Validation Accuracy: 0.8762, Loss: 0.0931
Epoch 265 Batch  250/269 - Train Accuracy: 0.8862, Validation Accuracy: 0.8820, Loss: 0.1064
Epoch 265 Batch  260/269 - Train Accuracy: 0.8679, Validation Accuracy: 0.8757, Loss: 0.1156
Epoch 266 Batch   10/269 - Train Accuracy: 0.8748, Validation Accuracy: 0.8748, Loss: 0.0989
Epoch 266 Batch   20/269 - Train Accuracy: 0.8655, Validation Accuracy: 0.8726, Loss: 0.0945
Epoch 266 Batch   30/269 - Train Accuracy: 0.8654, Validation Accuracy: 0.8761, Loss: 0.0961
Epoch 266 Batch   40/269 - Train Accuracy: 0.8521, Validation Accuracy: 0.8745, Loss: 0.1176
Epoch 266 Batch   50/269 - Train Accuracy: 0.8551, Validation Accuracy: 0.8744, Loss: 0.1160
Epoch 266 Batch   60/269 - Train Accuracy: 0.8823, Validation Accuracy: 0.8747, Loss: 0.0982
Epoch 266 Batch   70/269 - Train Accuracy: 0.8763, Validation Accuracy: 0.8801, Loss: 0.1071
Epoch 266 Batch   80/269 - Train Accuracy: 0.8787, Validation Accuracy: 0.8745, Loss: 0.1074
Epoch 266 Batch   90/269 - Train Accuracy: 0.8779, Validation Accuracy: 0.8730, Loss: 0.1130
Epoch 266 Batch  100/269 - Train Accuracy: 0.8896, Validation Accuracy: 0.8845, Loss: 0.1005
Epoch 266 Batch  110/269 - Train Accuracy: 0.8587, Validation Accuracy: 0.8672, Loss: 0.1076
Epoch 266 Batch  120/269 - Train Accuracy: 0.8757, Validation Accuracy: 0.8763, Loss: 0.1179
Epoch 266 Batch  130/269 - Train Accuracy: 0.8551, Validation Accuracy: 0.8738, Loss: 0.1082
Epoch 266 Batch  140/269 - Train Accuracy: 0.8660, Validation Accuracy: 0.8764, Loss: 0.1129
Epoch 266 Batch  150/269 - Train Accuracy: 0.8721, Validation Accuracy: 0.8703, Loss: 0.1064
Epoch 266 Batch  160/269 - Train Accuracy: 0.8828, Validation Accuracy: 0.8762, Loss: 0.1039
Epoch 266 Batch  170/269 - Train Accuracy: 0.8608, Validation Accuracy: 0.8763, Loss: 0.1035
Epoch 266 Batch  180/269 - Train Accuracy: 0.8942, Validation Accuracy: 0.8770, Loss: 0.0966
Epoch 266 Batch  190/269 - Train Accuracy: 0.8835, Validation Accuracy: 0.8812, Loss: 0.0970
Epoch 266 Batch  200/269 - Train Accuracy: 0.8584, Validation Accuracy: 0.8754, Loss: 0.1030
Epoch 266 Batch  210/269 - Train Accuracy: 0.8754, Validation Accuracy: 0.8754, Loss: 0.1066
Epoch 266 Batch  220/269 - Train Accuracy: 0.8711, Validation Accuracy: 0.8745, Loss: 0.1028
Epoch 266 Batch  230/269 - Train Accuracy: 0.8730, Validation Accuracy: 0.8791, Loss: 0.1022
Epoch 266 Batch  240/269 - Train Accuracy: 0.8809, Validation Accuracy: 0.8761, Loss: 0.0930
Epoch 266 Batch  250/269 - Train Accuracy: 0.8827, Validation Accuracy: 0.8803, Loss: 0.1149
Epoch 266 Batch  260/269 - Train Accuracy: 0.8634, Validation Accuracy: 0.8826, Loss: 0.1142
Epoch 267 Batch   10/269 - Train Accuracy: 0.8748, Validation Accuracy: 0.8747, Loss: 0.1004
Epoch 267 Batch   20/269 - Train Accuracy: 0.8674, Validation Accuracy: 0.8796, Loss: 0.1033
Epoch 267 Batch   30/269 - Train Accuracy: 0.8688, Validation Accuracy: 0.8767, Loss: 0.0960
Epoch 267 Batch   40/269 - Train Accuracy: 0.8536, Validation Accuracy: 0.8751, Loss: 0.1199
Epoch 267 Batch   50/269 - Train Accuracy: 0.8579, Validation Accuracy: 0.8804, Loss: 0.1160
Epoch 267 Batch   60/269 - Train Accuracy: 0.8862, Validation Accuracy: 0.8751, Loss: 0.1033
Epoch 267 Batch   70/269 - Train Accuracy: 0.8841, Validation Accuracy: 0.8808, Loss: 0.1254
Epoch 267 Batch   80/269 - Train Accuracy: 0.8724, Validation Accuracy: 0.8820, Loss: 0.1064
Epoch 267 Batch   90/269 - Train Accuracy: 0.8734, Validation Accuracy: 0.8779, Loss: 0.1153
Epoch 267 Batch  100/269 - Train Accuracy: 0.8826, Validation Accuracy: 0.8781, Loss: 0.1101
Epoch 267 Batch  110/269 - Train Accuracy: 0.8597, Validation Accuracy: 0.8759, Loss: 0.1071
Epoch 267 Batch  120/269 - Train Accuracy: 0.8681, Validation Accuracy: 0.8751, Loss: 0.1126
Epoch 267 Batch  130/269 - Train Accuracy: 0.8656, Validation Accuracy: 0.8753, Loss: 0.1233
Epoch 267 Batch  140/269 - Train Accuracy: 0.8594, Validation Accuracy: 0.8762, Loss: 0.1142
Epoch 267 Batch  150/269 - Train Accuracy: 0.8714, Validation Accuracy: 0.8741, Loss: 0.1078
Epoch 267 Batch  160/269 - Train Accuracy: 0.8834, Validation Accuracy: 0.8810, Loss: 0.1109
Epoch 267 Batch  170/269 - Train Accuracy: 0.8643, Validation Accuracy: 0.8813, Loss: 0.1051
Epoch 267 Batch  180/269 - Train Accuracy: 0.8896, Validation Accuracy: 0.8788, Loss: 0.1060
Epoch 267 Batch  190/269 - Train Accuracy: 0.8781, Validation Accuracy: 0.8725, Loss: 0.1049
Epoch 267 Batch  200/269 - Train Accuracy: 0.8635, Validation Accuracy: 0.8828, Loss: 0.0938
Epoch 267 Batch  210/269 - Train Accuracy: 0.8739, Validation Accuracy: 0.8782, Loss: 0.0966
Epoch 267 Batch  220/269 - Train Accuracy: 0.8747, Validation Accuracy: 0.8704, Loss: 0.0996
Epoch 267 Batch  230/269 - Train Accuracy: 0.8653, Validation Accuracy: 0.8781, Loss: 0.1004
Epoch 267 Batch  240/269 - Train Accuracy: 0.8775, Validation Accuracy: 0.8764, Loss: 0.0902
Epoch 267 Batch  250/269 - Train Accuracy: 0.8803, Validation Accuracy: 0.8735, Loss: 0.0937
Epoch 267 Batch  260/269 - Train Accuracy: 0.8635, Validation Accuracy: 0.8786, Loss: 0.1077
Epoch 268 Batch   10/269 - Train Accuracy: 0.8746, Validation Accuracy: 0.8712, Loss: 0.0949
Epoch 268 Batch   20/269 - Train Accuracy: 0.8677, Validation Accuracy: 0.8781, Loss: 0.1007
Epoch 268 Batch   30/269 - Train Accuracy: 0.8686, Validation Accuracy: 0.8722, Loss: 0.0975
Epoch 268 Batch   40/269 - Train Accuracy: 0.8577, Validation Accuracy: 0.8773, Loss: 0.1171
Epoch 268 Batch   50/269 - Train Accuracy: 0.8582, Validation Accuracy: 0.8765, Loss: 0.1087
Epoch 268 Batch   60/269 - Train Accuracy: 0.8794, Validation Accuracy: 0.8790, Loss: 0.0930
Epoch 268 Batch   70/269 - Train Accuracy: 0.8779, Validation Accuracy: 0.8792, Loss: 0.1094
Epoch 268 Batch   80/269 - Train Accuracy: 0.8810, Validation Accuracy: 0.8731, Loss: 0.1023
Epoch 268 Batch   90/269 - Train Accuracy: 0.8704, Validation Accuracy: 0.8701, Loss: 0.1131
Epoch 268 Batch  100/269 - Train Accuracy: 0.8842, Validation Accuracy: 0.8752, Loss: 0.1087
Epoch 268 Batch  110/269 - Train Accuracy: 0.8617, Validation Accuracy: 0.8821, Loss: 0.1078
Epoch 268 Batch  120/269 - Train Accuracy: 0.8661, Validation Accuracy: 0.8715, Loss: 0.1106
Epoch 268 Batch  130/269 - Train Accuracy: 0.8543, Validation Accuracy: 0.8748, Loss: 0.1065
Epoch 268 Batch  140/269 - Train Accuracy: 0.8615, Validation Accuracy: 0.8672, Loss: 0.1201
Epoch 268 Batch  150/269 - Train Accuracy: 0.8727, Validation Accuracy: 0.8719, Loss: 0.1078
Epoch 268 Batch  160/269 - Train Accuracy: 0.8813, Validation Accuracy: 0.8733, Loss: 0.1062
Epoch 268 Batch  170/269 - Train Accuracy: 0.8668, Validation Accuracy: 0.8774, Loss: 0.0946
Epoch 268 Batch  180/269 - Train Accuracy: 0.8944, Validation Accuracy: 0.8742, Loss: 0.0952
Epoch 268 Batch  190/269 - Train Accuracy: 0.8837, Validation Accuracy: 0.8735, Loss: 0.0987
Epoch 268 Batch  200/269 - Train Accuracy: 0.8589, Validation Accuracy: 0.8736, Loss: 0.0994
Epoch 268 Batch  210/269 - Train Accuracy: 0.8789, Validation Accuracy: 0.8821, Loss: 0.1037
Epoch 268 Batch  220/269 - Train Accuracy: 0.8785, Validation Accuracy: 0.8745, Loss: 0.1018
Epoch 268 Batch  230/269 - Train Accuracy: 0.8584, Validation Accuracy: 0.8747, Loss: 0.0974
Epoch 268 Batch  240/269 - Train Accuracy: 0.8798, Validation Accuracy: 0.8787, Loss: 0.0936
Epoch 268 Batch  250/269 - Train Accuracy: 0.8797, Validation Accuracy: 0.8807, Loss: 0.1033
Epoch 268 Batch  260/269 - Train Accuracy: 0.8623, Validation Accuracy: 0.8759, Loss: 0.1049
Epoch 269 Batch   10/269 - Train Accuracy: 0.8709, Validation Accuracy: 0.8725, Loss: 0.1000
Epoch 269 Batch   20/269 - Train Accuracy: 0.8641, Validation Accuracy: 0.8755, Loss: 0.1010
Epoch 269 Batch   30/269 - Train Accuracy: 0.8743, Validation Accuracy: 0.8754, Loss: 0.0993
Epoch 269 Batch   40/269 - Train Accuracy: 0.8571, Validation Accuracy: 0.8788, Loss: 0.1138
Epoch 269 Batch   50/269 - Train Accuracy: 0.8636, Validation Accuracy: 0.8717, Loss: 0.1134
Epoch 269 Batch   60/269 - Train Accuracy: 0.8838, Validation Accuracy: 0.8774, Loss: 0.0977
Epoch 269 Batch   70/269 - Train Accuracy: 0.8790, Validation Accuracy: 0.8751, Loss: 0.1039
Epoch 269 Batch   80/269 - Train Accuracy: 0.8810, Validation Accuracy: 0.8751, Loss: 0.1016
Epoch 269 Batch   90/269 - Train Accuracy: 0.8748, Validation Accuracy: 0.8738, Loss: 0.1039
Epoch 269 Batch  100/269 - Train Accuracy: 0.8903, Validation Accuracy: 0.8732, Loss: 0.0941
Epoch 269 Batch  110/269 - Train Accuracy: 0.8669, Validation Accuracy: 0.8822, Loss: 0.1040
Epoch 269 Batch  120/269 - Train Accuracy: 0.8703, Validation Accuracy: 0.8735, Loss: 0.1156
Epoch 269 Batch  130/269 - Train Accuracy: 0.8657, Validation Accuracy: 0.8722, Loss: 0.1071
Epoch 269 Batch  140/269 - Train Accuracy: 0.8641, Validation Accuracy: 0.8713, Loss: 0.1061
Epoch 269 Batch  150/269 - Train Accuracy: 0.8730, Validation Accuracy: 0.8693, Loss: 0.1001
Epoch 269 Batch  160/269 - Train Accuracy: 0.8761, Validation Accuracy: 0.8751, Loss: 0.0990
Epoch 269 Batch  170/269 - Train Accuracy: 0.8602, Validation Accuracy: 0.8765, Loss: 0.0967
Epoch 269 Batch  180/269 - Train Accuracy: 0.8937, Validation Accuracy: 0.8746, Loss: 0.1134
Epoch 269 Batch  190/269 - Train Accuracy: 0.8798, Validation Accuracy: 0.8784, Loss: 0.1021
Epoch 269 Batch  200/269 - Train Accuracy: 0.8604, Validation Accuracy: 0.8731, Loss: 0.1013
Epoch 269 Batch  210/269 - Train Accuracy: 0.8762, Validation Accuracy: 0.8748, Loss: 0.0975
Epoch 269 Batch  220/269 - Train Accuracy: 0.8704, Validation Accuracy: 0.8747, Loss: 0.1041
Epoch 269 Batch  230/269 - Train Accuracy: 0.8683, Validation Accuracy: 0.8814, Loss: 0.1009
Epoch 269 Batch  240/269 - Train Accuracy: 0.8817, Validation Accuracy: 0.8711, Loss: 0.0866
Epoch 269 Batch  250/269 - Train Accuracy: 0.8840, Validation Accuracy: 0.8763, Loss: 0.1044
Epoch 269 Batch  260/269 - Train Accuracy: 0.8596, Validation Accuracy: 0.8763, Loss: 0.1074
Epoch 270 Batch   10/269 - Train Accuracy: 0.8746, Validation Accuracy: 0.8803, Loss: 0.0992
Epoch 270 Batch   20/269 - Train Accuracy: 0.8663, Validation Accuracy: 0.8735, Loss: 0.0990
Epoch 270 Batch   30/269 - Train Accuracy: 0.8716, Validation Accuracy: 0.8756, Loss: 0.0996
Epoch 270 Batch   40/269 - Train Accuracy: 0.8572, Validation Accuracy: 0.8729, Loss: 0.1190
Epoch 270 Batch   50/269 - Train Accuracy: 0.8588, Validation Accuracy: 0.8786, Loss: 0.1277
Epoch 270 Batch   60/269 - Train Accuracy: 0.8846, Validation Accuracy: 0.8794, Loss: 0.1012
Epoch 270 Batch   70/269 - Train Accuracy: 0.8830, Validation Accuracy: 0.8732, Loss: 0.1111
Epoch 270 Batch   80/269 - Train Accuracy: 0.8806, Validation Accuracy: 0.8721, Loss: 0.1018
Epoch 270 Batch   90/269 - Train Accuracy: 0.8747, Validation Accuracy: 0.8762, Loss: 0.1128
Epoch 270 Batch  100/269 - Train Accuracy: 0.8838, Validation Accuracy: 0.8784, Loss: 0.0929
Epoch 270 Batch  110/269 - Train Accuracy: 0.8605, Validation Accuracy: 0.8770, Loss: 0.1000
Epoch 270 Batch  120/269 - Train Accuracy: 0.8765, Validation Accuracy: 0.8683, Loss: 0.1091
Epoch 270 Batch  130/269 - Train Accuracy: 0.8647, Validation Accuracy: 0.8747, Loss: 0.1115
Epoch 270 Batch  140/269 - Train Accuracy: 0.8614, Validation Accuracy: 0.8722, Loss: 0.1097
Epoch 270 Batch  150/269 - Train Accuracy: 0.8676, Validation Accuracy: 0.8683, Loss: 0.1086
Epoch 270 Batch  160/269 - Train Accuracy: 0.8815, Validation Accuracy: 0.8753, Loss: 0.1116
Epoch 270 Batch  170/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8722, Loss: 0.0958
Epoch 270 Batch  180/269 - Train Accuracy: 0.8829, Validation Accuracy: 0.8693, Loss: 0.0878
Epoch 270 Batch  190/269 - Train Accuracy: 0.8802, Validation Accuracy: 0.8738, Loss: 0.0985
Epoch 270 Batch  200/269 - Train Accuracy: 0.8667, Validation Accuracy: 0.8740, Loss: 0.1005
Epoch 270 Batch  210/269 - Train Accuracy: 0.8738, Validation Accuracy: 0.8867, Loss: 0.1106
Epoch 270 Batch  220/269 - Train Accuracy: 0.8731, Validation Accuracy: 0.8762, Loss: 0.1016
Epoch 270 Batch  230/269 - Train Accuracy: 0.8663, Validation Accuracy: 0.8703, Loss: 0.0987
Epoch 270 Batch  240/269 - Train Accuracy: 0.8796, Validation Accuracy: 0.8780, Loss: 0.0868
Epoch 270 Batch  250/269 - Train Accuracy: 0.8863, Validation Accuracy: 0.8787, Loss: 0.1014
Epoch 270 Batch  260/269 - Train Accuracy: 0.8616, Validation Accuracy: 0.8770, Loss: 0.1083
Epoch 271 Batch   10/269 - Train Accuracy: 0.8727, Validation Accuracy: 0.8725, Loss: 0.0938
Epoch 271 Batch   20/269 - Train Accuracy: 0.8633, Validation Accuracy: 0.8733, Loss: 0.1017
Epoch 271 Batch   30/269 - Train Accuracy: 0.8680, Validation Accuracy: 0.8755, Loss: 0.0969
Epoch 271 Batch   40/269 - Train Accuracy: 0.8527, Validation Accuracy: 0.8768, Loss: 0.1097
Epoch 271 Batch   50/269 - Train Accuracy: 0.8525, Validation Accuracy: 0.8765, Loss: 0.1216
Epoch 271 Batch   60/269 - Train Accuracy: 0.8792, Validation Accuracy: 0.8801, Loss: 0.1016
Epoch 271 Batch   70/269 - Train Accuracy: 0.8747, Validation Accuracy: 0.8748, Loss: 0.1074
Epoch 271 Batch   80/269 - Train Accuracy: 0.8770, Validation Accuracy: 0.8756, Loss: 0.1034
Epoch 271 Batch   90/269 - Train Accuracy: 0.8762, Validation Accuracy: 0.8783, Loss: 0.1207
Epoch 271 Batch  100/269 - Train Accuracy: 0.8842, Validation Accuracy: 0.8749, Loss: 0.1020
Epoch 271 Batch  110/269 - Train Accuracy: 0.8680, Validation Accuracy: 0.8738, Loss: 0.1071
Epoch 271 Batch  120/269 - Train Accuracy: 0.8771, Validation Accuracy: 0.8704, Loss: 0.1143
Epoch 271 Batch  130/269 - Train Accuracy: 0.8608, Validation Accuracy: 0.8720, Loss: 0.1085
Epoch 271 Batch  140/269 - Train Accuracy: 0.8645, Validation Accuracy: 0.8702, Loss: 0.1091
Epoch 271 Batch  150/269 - Train Accuracy: 0.8713, Validation Accuracy: 0.8761, Loss: 0.1066
Epoch 271 Batch  160/269 - Train Accuracy: 0.8849, Validation Accuracy: 0.8740, Loss: 0.1092
Epoch 271 Batch  170/269 - Train Accuracy: 0.8638, Validation Accuracy: 0.8734, Loss: 0.1019
Epoch 271 Batch  180/269 - Train Accuracy: 0.8841, Validation Accuracy: 0.8662, Loss: 0.0971
Epoch 271 Batch  190/269 - Train Accuracy: 0.8834, Validation Accuracy: 0.8778, Loss: 0.0982
Epoch 271 Batch  200/269 - Train Accuracy: 0.8607, Validation Accuracy: 0.8740, Loss: 0.1038
Epoch 271 Batch  210/269 - Train Accuracy: 0.8796, Validation Accuracy: 0.8798, Loss: 0.1051
Epoch 271 Batch  220/269 - Train Accuracy: 0.8730, Validation Accuracy: 0.8727, Loss: 0.0972
Epoch 271 Batch  230/269 - Train Accuracy: 0.8684, Validation Accuracy: 0.8748, Loss: 0.1036
Epoch 271 Batch  240/269 - Train Accuracy: 0.8758, Validation Accuracy: 0.8732, Loss: 0.0936
Epoch 271 Batch  250/269 - Train Accuracy: 0.8766, Validation Accuracy: 0.8720, Loss: 0.0985
Epoch 271 Batch  260/269 - Train Accuracy: 0.8621, Validation Accuracy: 0.8784, Loss: 0.1020
Epoch 272 Batch   10/269 - Train Accuracy: 0.8740, Validation Accuracy: 0.8714, Loss: 0.0911
Epoch 272 Batch   20/269 - Train Accuracy: 0.8560, Validation Accuracy: 0.8686, Loss: 0.0981
Epoch 272 Batch   30/269 - Train Accuracy: 0.8704, Validation Accuracy: 0.8721, Loss: 0.0913
Epoch 272 Batch   40/269 - Train Accuracy: 0.8562, Validation Accuracy: 0.8759, Loss: 0.1073
Epoch 272 Batch   50/269 - Train Accuracy: 0.8619, Validation Accuracy: 0.8806, Loss: 0.1087
Epoch 272 Batch   60/269 - Train Accuracy: 0.8813, Validation Accuracy: 0.8746, Loss: 0.0943
Epoch 272 Batch   70/269 - Train Accuracy: 0.8867, Validation Accuracy: 0.8761, Loss: 0.0959
Epoch 272 Batch   80/269 - Train Accuracy: 0.8743, Validation Accuracy: 0.8814, Loss: 0.1054
Epoch 272 Batch   90/269 - Train Accuracy: 0.8736, Validation Accuracy: 0.8739, Loss: 0.1011
Epoch 272 Batch  100/269 - Train Accuracy: 0.8857, Validation Accuracy: 0.8801, Loss: 0.1014
Epoch 272 Batch  110/269 - Train Accuracy: 0.8694, Validation Accuracy: 0.8710, Loss: 0.1063
Epoch 272 Batch  120/269 - Train Accuracy: 0.8735, Validation Accuracy: 0.8762, Loss: 0.1088
Epoch 272 Batch  130/269 - Train Accuracy: 0.8578, Validation Accuracy: 0.8674, Loss: 0.1089
Epoch 272 Batch  140/269 - Train Accuracy: 0.8679, Validation Accuracy: 0.8710, Loss: 0.1057
Epoch 272 Batch  150/269 - Train Accuracy: 0.8743, Validation Accuracy: 0.8740, Loss: 0.1004
Epoch 272 Batch  160/269 - Train Accuracy: 0.8820, Validation Accuracy: 0.8726, Loss: 0.1042
Epoch 272 Batch  170/269 - Train Accuracy: 0.8656, Validation Accuracy: 0.8739, Loss: 0.0973
Epoch 272 Batch  180/269 - Train Accuracy: 0.8964, Validation Accuracy: 0.8769, Loss: 0.0950
Epoch 272 Batch  190/269 - Train Accuracy: 0.8816, Validation Accuracy: 0.8738, Loss: 0.1023
Epoch 272 Batch  200/269 - Train Accuracy: 0.8646, Validation Accuracy: 0.8754, Loss: 0.1032
Epoch 272 Batch  210/269 - Train Accuracy: 0.8713, Validation Accuracy: 0.8738, Loss: 0.0988
Epoch 272 Batch  220/269 - Train Accuracy: 0.8638, Validation Accuracy: 0.8652, Loss: 0.1771
Epoch 272 Batch  230/269 - Train Accuracy: 0.8630, Validation Accuracy: 0.8706, Loss: 0.1350
Epoch 272 Batch  240/269 - Train Accuracy: 0.8785, Validation Accuracy: 0.8730, Loss: 0.1001
Epoch 272 Batch  250/269 - Train Accuracy: 0.8780, Validation Accuracy: 0.8770, Loss: 0.1076
Epoch 272 Batch  260/269 - Train Accuracy: 0.8611, Validation Accuracy: 0.8758, Loss: 0.1179
Epoch 273 Batch   10/269 - Train Accuracy: 0.8770, Validation Accuracy: 0.8729, Loss: 0.0950
Epoch 273 Batch   20/269 - Train Accuracy: 0.8643, Validation Accuracy: 0.8736, Loss: 0.1047
Epoch 273 Batch   30/269 - Train Accuracy: 0.8650, Validation Accuracy: 0.8694, Loss: 0.0945
Epoch 273 Batch   40/269 - Train Accuracy: 0.8597, Validation Accuracy: 0.8716, Loss: 0.1191
Epoch 273 Batch   50/269 - Train Accuracy: 0.8621, Validation Accuracy: 0.8762, Loss: 0.1217
Epoch 273 Batch   60/269 - Train Accuracy: 0.8837, Validation Accuracy: 0.8797, Loss: 0.0911
Epoch 273 Batch   70/269 - Train Accuracy: 0.8797, Validation Accuracy: 0.8737, Loss: 0.1064
Epoch 273 Batch   80/269 - Train Accuracy: 0.8755, Validation Accuracy: 0.8731, Loss: 0.1023
Epoch 273 Batch   90/269 - Train Accuracy: 0.8805, Validation Accuracy: 0.8738, Loss: 0.1166
Epoch 273 Batch  100/269 - Train Accuracy: 0.8827, Validation Accuracy: 0.8670, Loss: 0.0952
Epoch 273 Batch  110/269 - Train Accuracy: 0.8599, Validation Accuracy: 0.8778, Loss: 0.1088
Epoch 273 Batch  120/269 - Train Accuracy: 0.8783, Validation Accuracy: 0.8732, Loss: 0.1152
Epoch 273 Batch  130/269 - Train Accuracy: 0.8598, Validation Accuracy: 0.8728, Loss: 0.1115
Epoch 273 Batch  140/269 - Train Accuracy: 0.8623, Validation Accuracy: 0.8671, Loss: 0.1090
Epoch 273 Batch  150/269 - Train Accuracy: 0.8744, Validation Accuracy: 0.8686, Loss: 0.1130
Epoch 273 Batch  160/269 - Train Accuracy: 0.8791, Validation Accuracy: 0.8700, Loss: 0.1057
Epoch 273 Batch  170/269 - Train Accuracy: 0.8644, Validation Accuracy: 0.8690, Loss: 0.1041
Epoch 273 Batch  180/269 - Train Accuracy: 0.8900, Validation Accuracy: 0.8693, Loss: 0.1003
Epoch 273 Batch  190/269 - Train Accuracy: 0.8800, Validation Accuracy: 0.8758, Loss: 0.1057
Epoch 273 Batch  200/269 - Train Accuracy: 0.8669, Validation Accuracy: 0.8760, Loss: 0.1009
Epoch 273 Batch  210/269 - Train Accuracy: 0.8759, Validation Accuracy: 0.8806, Loss: 0.1012
Epoch 273 Batch  220/269 - Train Accuracy: 0.8705, Validation Accuracy: 0.8722, Loss: 0.1057
Epoch 273 Batch  230/269 - Train Accuracy: 0.8689, Validation Accuracy: 0.8739, Loss: 0.1004
Epoch 273 Batch  240/269 - Train Accuracy: 0.8761, Validation Accuracy: 0.8730, Loss: 0.0943
Epoch 273 Batch  250/269 - Train Accuracy: 0.8804, Validation Accuracy: 0.8790, Loss: 0.0989
Epoch 273 Batch  260/269 - Train Accuracy: 0.8618, Validation Accuracy: 0.8727, Loss: 0.1084
Epoch 274 Batch   10/269 - Train Accuracy: 0.8742, Validation Accuracy: 0.8747, Loss: 0.1035
Epoch 274 Batch   20/269 - Train Accuracy: 0.8662, Validation Accuracy: 0.8655, Loss: 0.1023
Epoch 274 Batch   30/269 - Train Accuracy: 0.8626, Validation Accuracy: 0.8730, Loss: 0.0987
Epoch 274 Batch   40/269 - Train Accuracy: 0.8556, Validation Accuracy: 0.8739, Loss: 0.1111
Epoch 274 Batch   50/269 - Train Accuracy: 0.8573, Validation Accuracy: 0.8792, Loss: 0.1089
Epoch 274 Batch   60/269 - Train Accuracy: 0.8794, Validation Accuracy: 0.8803, Loss: 0.0940
Epoch 274 Batch   70/269 - Train Accuracy: 0.8792, Validation Accuracy: 0.8708, Loss: 0.1053
Epoch 274 Batch   80/269 - Train Accuracy: 0.8739, Validation Accuracy: 0.8724, Loss: 0.1082
Epoch 274 Batch   90/269 - Train Accuracy: 0.8744, Validation Accuracy: 0.8647, Loss: 0.1140
Epoch 274 Batch  100/269 - Train Accuracy: 0.8809, Validation Accuracy: 0.8765, Loss: 0.1031
Epoch 274 Batch  110/269 - Train Accuracy: 0.8589, Validation Accuracy: 0.8722, Loss: 0.1129
Epoch 274 Batch  120/269 - Train Accuracy: 0.8776, Validation Accuracy: 0.8710, Loss: 0.1150
Epoch 274 Batch  130/269 - Train Accuracy: 0.8591, Validation Accuracy: 0.8758, Loss: 0.1030
Epoch 274 Batch  140/269 - Train Accuracy: 0.8631, Validation Accuracy: 0.8765, Loss: 0.1092
Epoch 274 Batch  150/269 - Train Accuracy: 0.8737, Validation Accuracy: 0.8698, Loss: 0.1115
Epoch 274 Batch  160/269 - Train Accuracy: 0.8812, Validation Accuracy: 0.8740, Loss: 0.1044
Epoch 274 Batch  170/269 - Train Accuracy: 0.8647, Validation Accuracy: 0.8697, Loss: 0.1076
Epoch 274 Batch  180/269 - Train Accuracy: 0.8888, Validation Accuracy: 0.8736, Loss: 0.0954
Epoch 274 Batch  190/269 - Train Accuracy: 0.8802, Validation Accuracy: 0.8799, Loss: 0.1037
Epoch 274 Batch  200/269 - Train Accuracy: 0.8687, Validation Accuracy: 0.8762, Loss: 0.0982
Epoch 274 Batch  210/269 - Train Accuracy: 0.8705, Validation Accuracy: 0.8794, Loss: 0.1093
Epoch 274 Batch  220/269 - Train Accuracy: 0.8760, Validation Accuracy: 0.8698, Loss: 0.1056
Epoch 274 Batch  230/269 - Train Accuracy: 0.8659, Validation Accuracy: 0.8761, Loss: 0.1021
Epoch 274 Batch  240/269 - Train Accuracy: 0.8803, Validation Accuracy: 0.8733, Loss: 0.0941
Epoch 274 Batch  250/269 - Train Accuracy: 0.8770, Validation Accuracy: 0.8816, Loss: 0.1129
Epoch 274 Batch  260/269 - Train Accuracy: 0.8657, Validation Accuracy: 0.8762, Loss: 0.1100
Epoch 275 Batch   10/269 - Train Accuracy: 0.8722, Validation Accuracy: 0.8730, Loss: 0.0892
Epoch 275 Batch   20/269 - Train Accuracy: 0.8630, Validation Accuracy: 0.8762, Loss: 0.0966
Epoch 275 Batch   30/269 - Train Accuracy: 0.8636, Validation Accuracy: 0.8772, Loss: 0.0994
Epoch 275 Batch   40/269 - Train Accuracy: 0.8462, Validation Accuracy: 0.8778, Loss: 0.1177
Epoch 275 Batch   50/269 - Train Accuracy: 0.8614, Validation Accuracy: 0.8755, Loss: 0.1121
Epoch 275 Batch   60/269 - Train Accuracy: 0.8828, Validation Accuracy: 0.8773, Loss: 0.0943
Epoch 275 Batch   70/269 - Train Accuracy: 0.8790, Validation Accuracy: 0.8803, Loss: 0.1015
Epoch 275 Batch   80/269 - Train Accuracy: 0.8752, Validation Accuracy: 0.8794, Loss: 0.0977
Epoch 275 Batch   90/269 - Train Accuracy: 0.8778, Validation Accuracy: 0.8728, Loss: 0.1112
Epoch 275 Batch  100/269 - Train Accuracy: 0.8881, Validation Accuracy: 0.8764, Loss: 0.1035
Epoch 275 Batch  110/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8743, Loss: 0.1038
Epoch 275 Batch  120/269 - Train Accuracy: 0.8747, Validation Accuracy: 0.8689, Loss: 0.1087
Epoch 275 Batch  130/269 - Train Accuracy: 0.8592, Validation Accuracy: 0.8771, Loss: 0.1076
Epoch 275 Batch  140/269 - Train Accuracy: 0.8581, Validation Accuracy: 0.8733, Loss: 0.1048
Epoch 275 Batch  150/269 - Train Accuracy: 0.8718, Validation Accuracy: 0.8805, Loss: 0.1012
Epoch 275 Batch  160/269 - Train Accuracy: 0.8877, Validation Accuracy: 0.8834, Loss: 0.1053
Epoch 275 Batch  170/269 - Train Accuracy: 0.8663, Validation Accuracy: 0.8788, Loss: 0.0992
Epoch 275 Batch  180/269 - Train Accuracy: 0.8897, Validation Accuracy: 0.8715, Loss: 0.0935
Epoch 275 Batch  190/269 - Train Accuracy: 0.8749, Validation Accuracy: 0.8655, Loss: 0.1052
Epoch 275 Batch  200/269 - Train Accuracy: 0.8646, Validation Accuracy: 0.8809, Loss: 0.1042
Epoch 275 Batch  210/269 - Train Accuracy: 0.8776, Validation Accuracy: 0.8757, Loss: 0.1055
Epoch 275 Batch  220/269 - Train Accuracy: 0.8737, Validation Accuracy: 0.8742, Loss: 0.0998
Epoch 275 Batch  230/269 - Train Accuracy: 0.8690, Validation Accuracy: 0.8777, Loss: 0.1008
Epoch 275 Batch  240/269 - Train Accuracy: 0.8766, Validation Accuracy: 0.8713, Loss: 0.0868
Epoch 275 Batch  250/269 - Train Accuracy: 0.8832, Validation Accuracy: 0.8768, Loss: 0.0959
Epoch 275 Batch  260/269 - Train Accuracy: 0.8626, Validation Accuracy: 0.8809, Loss: 0.1075
Epoch 276 Batch   10/269 - Train Accuracy: 0.8732, Validation Accuracy: 0.8729, Loss: 0.0941
Epoch 276 Batch   20/269 - Train Accuracy: 0.8620, Validation Accuracy: 0.8718, Loss: 0.1098
Epoch 276 Batch   30/269 - Train Accuracy: 0.8724, Validation Accuracy: 0.8806, Loss: 0.0964
Epoch 276 Batch   40/269 - Train Accuracy: 0.8541, Validation Accuracy: 0.8712, Loss: 0.1037
Epoch 276 Batch   50/269 - Train Accuracy: 0.8570, Validation Accuracy: 0.8730, Loss: 0.1153
Epoch 276 Batch   60/269 - Train Accuracy: 0.8814, Validation Accuracy: 0.8794, Loss: 0.1033
Epoch 276 Batch   70/269 - Train Accuracy: 0.8753, Validation Accuracy: 0.8743, Loss: 0.0954
Epoch 276 Batch   80/269 - Train Accuracy: 0.8803, Validation Accuracy: 0.8754, Loss: 0.0990
Epoch 276 Batch   90/269 - Train Accuracy: 0.8793, Validation Accuracy: 0.8738, Loss: 0.1041
Epoch 276 Batch  100/269 - Train Accuracy: 0.8816, Validation Accuracy: 0.8679, Loss: 0.0993
Epoch 276 Batch  110/269 - Train Accuracy: 0.8691, Validation Accuracy: 0.8795, Loss: 0.1098
Epoch 276 Batch  120/269 - Train Accuracy: 0.8751, Validation Accuracy: 0.8707, Loss: 0.1189
Epoch 276 Batch  130/269 - Train Accuracy: 0.8574, Validation Accuracy: 0.8716, Loss: 0.1077
Epoch 276 Batch  140/269 - Train Accuracy: 0.8667, Validation Accuracy: 0.8754, Loss: 0.1110
Epoch 276 Batch  150/269 - Train Accuracy: 0.8759, Validation Accuracy: 0.8722, Loss: 0.1018
Epoch 276 Batch  160/269 - Train Accuracy: 0.8843, Validation Accuracy: 0.8770, Loss: 0.1041
Epoch 276 Batch  170/269 - Train Accuracy: 0.8622, Validation Accuracy: 0.8806, Loss: 0.0992
Epoch 276 Batch  180/269 - Train Accuracy: 0.8853, Validation Accuracy: 0.8790, Loss: 0.0908
Epoch 276 Batch  190/269 - Train Accuracy: 0.8798, Validation Accuracy: 0.8818, Loss: 0.0963
Epoch 276 Batch  200/269 - Train Accuracy: 0.8565, Validation Accuracy: 0.8817, Loss: 0.0883
Epoch 276 Batch  210/269 - Train Accuracy: 0.8752, Validation Accuracy: 0.8802, Loss: 0.1030
Epoch 276 Batch  220/269 - Train Accuracy: 0.8746, Validation Accuracy: 0.8765, Loss: 0.1033
Epoch 276 Batch  230/269 - Train Accuracy: 0.8703, Validation Accuracy: 0.8788, Loss: 0.0980
Epoch 276 Batch  240/269 - Train Accuracy: 0.8771, Validation Accuracy: 0.8740, Loss: 0.0881
Epoch 276 Batch  250/269 - Train Accuracy: 0.8902, Validation Accuracy: 0.8834, Loss: 0.1010
Epoch 276 Batch  260/269 - Train Accuracy: 0.8600, Validation Accuracy: 0.8743, Loss: 0.1094
Epoch 277 Batch   10/269 - Train Accuracy: 0.8746, Validation Accuracy: 0.8737, Loss: 0.0975
Epoch 277 Batch   20/269 - Train Accuracy: 0.8758, Validation Accuracy: 0.8725, Loss: 0.0998
Epoch 277 Batch   30/269 - Train Accuracy: 0.8659, Validation Accuracy: 0.8762, Loss: 0.0991
Epoch 277 Batch   40/269 - Train Accuracy: 0.8556, Validation Accuracy: 0.8761, Loss: 0.1092
Epoch 277 Batch   50/269 - Train Accuracy: 0.8590, Validation Accuracy: 0.8722, Loss: 0.1092
Epoch 277 Batch   60/269 - Train Accuracy: 0.8865, Validation Accuracy: 0.8788, Loss: 0.0951
Epoch 277 Batch   70/269 - Train Accuracy: 0.8813, Validation Accuracy: 0.8738, Loss: 0.1058
Epoch 277 Batch   80/269 - Train Accuracy: 0.8831, Validation Accuracy: 0.8766, Loss: 0.1058
Epoch 277 Batch   90/269 - Train Accuracy: 0.8773, Validation Accuracy: 0.8742, Loss: 0.1001
Epoch 277 Batch  100/269 - Train Accuracy: 0.8876, Validation Accuracy: 0.8842, Loss: 0.1003
Epoch 277 Batch  110/269 - Train Accuracy: 0.8666, Validation Accuracy: 0.8730, Loss: 0.1114
Epoch 277 Batch  120/269 - Train Accuracy: 0.8805, Validation Accuracy: 0.8794, Loss: 0.1176
Epoch 277 Batch  130/269 - Train Accuracy: 0.8609, Validation Accuracy: 0.8738, Loss: 0.1054
Epoch 277 Batch  140/269 - Train Accuracy: 0.8643, Validation Accuracy: 0.8762, Loss: 0.1069
Epoch 277 Batch  150/269 - Train Accuracy: 0.8732, Validation Accuracy: 0.8741, Loss: 0.1034
Epoch 277 Batch  160/269 - Train Accuracy: 0.8803, Validation Accuracy: 0.8725, Loss: 0.1028
Epoch 277 Batch  170/269 - Train Accuracy: 0.8597, Validation Accuracy: 0.8782, Loss: 0.0948
Epoch 277 Batch  180/269 - Train Accuracy: 0.8909, Validation Accuracy: 0.8788, Loss: 0.0986
Epoch 277 Batch  190/269 - Train Accuracy: 0.8826, Validation Accuracy: 0.8782, Loss: 0.1003
Epoch 277 Batch  200/269 - Train Accuracy: 0.8627, Validation Accuracy: 0.8777, Loss: 0.0952
Epoch 277 Batch  210/269 - Train Accuracy: 0.8772, Validation Accuracy: 0.8752, Loss: 0.1029
Epoch 277 Batch  220/269 - Train Accuracy: 0.8747, Validation Accuracy: 0.8748, Loss: 0.0973
Epoch 277 Batch  230/269 - Train Accuracy: 0.8611, Validation Accuracy: 0.8810, Loss: 0.1026
Epoch 277 Batch  240/269 - Train Accuracy: 0.8818, Validation Accuracy: 0.8746, Loss: 0.0910
Epoch 277 Batch  250/269 - Train Accuracy: 0.8861, Validation Accuracy: 0.8739, Loss: 0.1006
Epoch 277 Batch  260/269 - Train Accuracy: 0.8614, Validation Accuracy: 0.8810, Loss: 0.1212
Epoch 278 Batch   10/269 - Train Accuracy: 0.8741, Validation Accuracy: 0.8704, Loss: 0.0929
Epoch 278 Batch   20/269 - Train Accuracy: 0.8637, Validation Accuracy: 0.8770, Loss: 0.0969
Epoch 278 Batch   30/269 - Train Accuracy: 0.8652, Validation Accuracy: 0.8819, Loss: 0.0969
Epoch 278 Batch   40/269 - Train Accuracy: 0.8555, Validation Accuracy: 0.8769, Loss: 0.1169
Epoch 278 Batch   50/269 - Train Accuracy: 0.8607, Validation Accuracy: 0.8794, Loss: 0.1074
Epoch 278 Batch   60/269 - Train Accuracy: 0.8835, Validation Accuracy: 0.8780, Loss: 0.0952
Epoch 278 Batch   70/269 - Train Accuracy: 0.8863, Validation Accuracy: 0.8786, Loss: 0.0999
Epoch 278 Batch   80/269 - Train Accuracy: 0.8815, Validation Accuracy: 0.8781, Loss: 0.0993
Epoch 278 Batch   90/269 - Train Accuracy: 0.8763, Validation Accuracy: 0.8745, Loss: 0.1095
Epoch 278 Batch  100/269 - Train Accuracy: 0.8815, Validation Accuracy: 0.8786, Loss: 0.1012
Epoch 278 Batch  110/269 - Train Accuracy: 0.8676, Validation Accuracy: 0.8760, Loss: 0.1034
Epoch 278 Batch  120/269 - Train Accuracy: 0.8724, Validation Accuracy: 0.8777, Loss: 0.1146
Epoch 278 Batch  130/269 - Train Accuracy: 0.8651, Validation Accuracy: 0.8763, Loss: 0.1080
Epoch 278 Batch  140/269 - Train Accuracy: 0.8593, Validation Accuracy: 0.8754, Loss: 0.1047
Epoch 278 Batch  150/269 - Train Accuracy: 0.8717, Validation Accuracy: 0.8743, Loss: 0.1083
Epoch 278 Batch  160/269 - Train Accuracy: 0.8773, Validation Accuracy: 0.8801, Loss: 0.0972
Epoch 278 Batch  170/269 - Train Accuracy: 0.8662, Validation Accuracy: 0.8788, Loss: 0.0988
Epoch 278 Batch  180/269 - Train Accuracy: 0.8903, Validation Accuracy: 0.8781, Loss: 0.0924
Epoch 278 Batch  190/269 - Train Accuracy: 0.8840, Validation Accuracy: 0.8772, Loss: 0.0970
Epoch 278 Batch  200/269 - Train Accuracy: 0.8661, Validation Accuracy: 0.8772, Loss: 0.1006
Epoch 278 Batch  210/269 - Train Accuracy: 0.8765, Validation Accuracy: 0.8726, Loss: 0.1020
Epoch 278 Batch  220/269 - Train Accuracy: 0.8699, Validation Accuracy: 0.8745, Loss: 0.0944
Epoch 278 Batch  230/269 - Train Accuracy: 0.8682, Validation Accuracy: 0.8779, Loss: 0.1085
Epoch 278 Batch  240/269 - Train Accuracy: 0.8836, Validation Accuracy: 0.8746, Loss: 0.0921
Epoch 278 Batch  250/269 - Train Accuracy: 0.8802, Validation Accuracy: 0.8794, Loss: 0.0957
Epoch 278 Batch  260/269 - Train Accuracy: 0.8683, Validation Accuracy: 0.8754, Loss: 0.1139
Epoch 279 Batch   10/269 - Train Accuracy: 0.8740, Validation Accuracy: 0.8702, Loss: 0.0956
Epoch 279 Batch   20/269 - Train Accuracy: 0.8646, Validation Accuracy: 0.8696, Loss: 0.1050
Epoch 279 Batch   30/269 - Train Accuracy: 0.8629, Validation Accuracy: 0.8741, Loss: 0.0957
Epoch 279 Batch   40/269 - Train Accuracy: 0.8534, Validation Accuracy: 0.8710, Loss: 0.1071
Epoch 279 Batch   50/269 - Train Accuracy: 0.8552, Validation Accuracy: 0.8761, Loss: 0.1076
Epoch 279 Batch   60/269 - Train Accuracy: 0.8830, Validation Accuracy: 0.8793, Loss: 0.0922
Epoch 279 Batch   70/269 - Train Accuracy: 0.8823, Validation Accuracy: 0.8773, Loss: 0.1019
Epoch 279 Batch   80/269 - Train Accuracy: 0.8815, Validation Accuracy: 0.8754, Loss: 0.1031
Epoch 279 Batch   90/269 - Train Accuracy: 0.8686, Validation Accuracy: 0.8684, Loss: 0.1371
Epoch 279 Batch  100/269 - Train Accuracy: 0.8799, Validation Accuracy: 0.8704, Loss: 0.1123
Epoch 279 Batch  110/269 - Train Accuracy: 0.8607, Validation Accuracy: 0.8659, Loss: 0.1100
Epoch 279 Batch  120/269 - Train Accuracy: 0.8697, Validation Accuracy: 0.8704, Loss: 0.1203
Epoch 279 Batch  130/269 - Train Accuracy: 0.8579, Validation Accuracy: 0.8803, Loss: 0.1126
Epoch 279 Batch  140/269 - Train Accuracy: 0.8621, Validation Accuracy: 0.8743, Loss: 0.1141
Epoch 279 Batch  150/269 - Train Accuracy: 0.8682, Validation Accuracy: 0.8716, Loss: 0.1071
Epoch 279 Batch  160/269 - Train Accuracy: 0.8818, Validation Accuracy: 0.8715, Loss: 0.1067
Epoch 279 Batch  170/269 - Train Accuracy: 0.8618, Validation Accuracy: 0.8763, Loss: 0.0963
Epoch 279 Batch  180/269 - Train Accuracy: 0.8892, Validation Accuracy: 0.8714, Loss: 0.0887
Epoch 279 Batch  190/269 - Train Accuracy: 0.8804, Validation Accuracy: 0.8794, Loss: 0.1044
Epoch 279 Batch  200/269 - Train Accuracy: 0.8619, Validation Accuracy: 0.8775, Loss: 0.1032
Epoch 279 Batch  210/269 - Train Accuracy: 0.8709, Validation Accuracy: 0.8743, Loss: 0.0998
Epoch 279 Batch  220/269 - Train Accuracy: 0.8714, Validation Accuracy: 0.8721, Loss: 0.0997
Epoch 279 Batch  230/269 - Train Accuracy: 0.8634, Validation Accuracy: 0.8797, Loss: 0.1017
Epoch 279 Batch  240/269 - Train Accuracy: 0.8798, Validation Accuracy: 0.8770, Loss: 0.0886
Epoch 279 Batch  250/269 - Train Accuracy: 0.8788, Validation Accuracy: 0.8788, Loss: 0.1192
Epoch 279 Batch  260/269 - Train Accuracy: 0.8645, Validation Accuracy: 0.8781, Loss: 0.1120
Epoch 280 Batch   10/269 - Train Accuracy: 0.8724, Validation Accuracy: 0.8698, Loss: 0.0904
Epoch 280 Batch   20/269 - Train Accuracy: 0.8639, Validation Accuracy: 0.8762, Loss: 0.1041
Epoch 280 Batch   30/269 - Train Accuracy: 0.8669, Validation Accuracy: 0.8801, Loss: 0.1014
Epoch 280 Batch   40/269 - Train Accuracy: 0.8542, Validation Accuracy: 0.8844, Loss: 0.1161
Epoch 280 Batch   50/269 - Train Accuracy: 0.8578, Validation Accuracy: 0.8725, Loss: 0.1067
Epoch 280 Batch   60/269 - Train Accuracy: 0.8849, Validation Accuracy: 0.8761, Loss: 0.0924
Epoch 280 Batch   70/269 - Train Accuracy: 0.8796, Validation Accuracy: 0.8725, Loss: 0.1083
Epoch 280 Batch   80/269 - Train Accuracy: 0.8783, Validation Accuracy: 0.8788, Loss: 0.0994
Epoch 280 Batch   90/269 - Train Accuracy: 0.8792, Validation Accuracy: 0.8778, Loss: 0.1046
Epoch 280 Batch  100/269 - Train Accuracy: 0.8878, Validation Accuracy: 0.8752, Loss: 0.0972
Epoch 280 Batch  110/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8722, Loss: 0.1091
Epoch 280 Batch  120/269 - Train Accuracy: 0.8724, Validation Accuracy: 0.8679, Loss: 0.1166
Epoch 280 Batch  130/269 - Train Accuracy: 0.8643, Validation Accuracy: 0.8746, Loss: 0.1048
Epoch 280 Batch  140/269 - Train Accuracy: 0.8672, Validation Accuracy: 0.8675, Loss: 0.1140
Epoch 280 Batch  150/269 - Train Accuracy: 0.8759, Validation Accuracy: 0.8710, Loss: 0.1005
Epoch 280 Batch  160/269 - Train Accuracy: 0.8845, Validation Accuracy: 0.8781, Loss: 0.1085
Epoch 280 Batch  170/269 - Train Accuracy: 0.8596, Validation Accuracy: 0.8763, Loss: 0.0926
Epoch 280 Batch  180/269 - Train Accuracy: 0.8884, Validation Accuracy: 0.8754, Loss: 0.0970
Epoch 280 Batch  190/269 - Train Accuracy: 0.8802, Validation Accuracy: 0.8784, Loss: 0.0992
Epoch 280 Batch  200/269 - Train Accuracy: 0.8660, Validation Accuracy: 0.8730, Loss: 0.1099
Epoch 280 Batch  210/269 - Train Accuracy: 0.8728, Validation Accuracy: 0.8705, Loss: 0.1057
Epoch 280 Batch  220/269 - Train Accuracy: 0.8794, Validation Accuracy: 0.8754, Loss: 0.0995
Epoch 280 Batch  230/269 - Train Accuracy: 0.8582, Validation Accuracy: 0.8723, Loss: 0.0974
Epoch 280 Batch  240/269 - Train Accuracy: 0.8717, Validation Accuracy: 0.8729, Loss: 0.0948
Epoch 280 Batch  250/269 - Train Accuracy: 0.8772, Validation Accuracy: 0.8734, Loss: 0.1011
Epoch 280 Batch  260/269 - Train Accuracy: 0.8596, Validation Accuracy: 0.8751, Loss: 0.1082
Epoch 281 Batch   10/269 - Train Accuracy: 0.8708, Validation Accuracy: 0.8681, Loss: 0.0930
Epoch 281 Batch   20/269 - Train Accuracy: 0.8640, Validation Accuracy: 0.8768, Loss: 0.1041
Epoch 281 Batch   30/269 - Train Accuracy: 0.8676, Validation Accuracy: 0.8741, Loss: 0.0976
Epoch 281 Batch   40/269 - Train Accuracy: 0.8576, Validation Accuracy: 0.8731, Loss: 0.1166
Epoch 281 Batch   50/269 - Train Accuracy: 0.8577, Validation Accuracy: 0.8726, Loss: 0.1267
Epoch 281 Batch   60/269 - Train Accuracy: 0.8827, Validation Accuracy: 0.8800, Loss: 0.1014
Epoch 281 Batch   70/269 - Train Accuracy: 0.8827, Validation Accuracy: 0.8775, Loss: 0.0918
Epoch 281 Batch   80/269 - Train Accuracy: 0.8806, Validation Accuracy: 0.8721, Loss: 0.0981
Epoch 281 Batch   90/269 - Train Accuracy: 0.8772, Validation Accuracy: 0.8729, Loss: 0.1021
Epoch 281 Batch  100/269 - Train Accuracy: 0.8879, Validation Accuracy: 0.8749, Loss: 0.0993
Epoch 281 Batch  110/269 - Train Accuracy: 0.8645, Validation Accuracy: 0.8699, Loss: 0.1093
Epoch 281 Batch  120/269 - Train Accuracy: 0.8703, Validation Accuracy: 0.8698, Loss: 0.1019
Epoch 281 Batch  130/269 - Train Accuracy: 0.8646, Validation Accuracy: 0.8742, Loss: 0.1030
Epoch 281 Batch  140/269 - Train Accuracy: 0.8677, Validation Accuracy: 0.8755, Loss: 0.1218
Epoch 281 Batch  150/269 - Train Accuracy: 0.8704, Validation Accuracy: 0.8719, Loss: 0.1045
Epoch 281 Batch  160/269 - Train Accuracy: 0.8803, Validation Accuracy: 0.8722, Loss: 0.1003
Epoch 281 Batch  170/269 - Train Accuracy: 0.8585, Validation Accuracy: 0.8731, Loss: 0.1124
Epoch 281 Batch  180/269 - Train Accuracy: 0.8918, Validation Accuracy: 0.8706, Loss: 0.0930
Epoch 281 Batch  190/269 - Train Accuracy: 0.8821, Validation Accuracy: 0.8746, Loss: 0.1032
Epoch 281 Batch  200/269 - Train Accuracy: 0.8577, Validation Accuracy: 0.8738, Loss: 0.1000
Epoch 281 Batch  210/269 - Train Accuracy: 0.8714, Validation Accuracy: 0.8764, Loss: 0.0990
Epoch 281 Batch  220/269 - Train Accuracy: 0.8707, Validation Accuracy: 0.8703, Loss: 0.1075
Epoch 281 Batch  230/269 - Train Accuracy: 0.8650, Validation Accuracy: 0.8802, Loss: 0.0954
Epoch 281 Batch  240/269 - Train Accuracy: 0.8815, Validation Accuracy: 0.8694, Loss: 0.0862
Epoch 281 Batch  250/269 - Train Accuracy: 0.8831, Validation Accuracy: 0.8775, Loss: 0.1016
Epoch 281 Batch  260/269 - Train Accuracy: 0.8623, Validation Accuracy: 0.8825, Loss: 0.1169
Epoch 282 Batch   10/269 - Train Accuracy: 0.8716, Validation Accuracy: 0.8694, Loss: 0.1065
Epoch 282 Batch   20/269 - Train Accuracy: 0.8684, Validation Accuracy: 0.8728, Loss: 0.0948
Epoch 282 Batch   30/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8792, Loss: 0.0986
Epoch 282 Batch   40/269 - Train Accuracy: 0.8524, Validation Accuracy: 0.8749, Loss: 0.1079
Epoch 282 Batch   50/269 - Train Accuracy: 0.8547, Validation Accuracy: 0.8736, Loss: 0.1089
Epoch 282 Batch   60/269 - Train Accuracy: 0.8801, Validation Accuracy: 0.8719, Loss: 0.0955
Epoch 282 Batch   70/269 - Train Accuracy: 0.8856, Validation Accuracy: 0.8729, Loss: 0.1050
Epoch 282 Batch   80/269 - Train Accuracy: 0.8796, Validation Accuracy: 0.8785, Loss: 0.1015
Epoch 282 Batch   90/269 - Train Accuracy: 0.8773, Validation Accuracy: 0.8714, Loss: 0.1093
Epoch 282 Batch  100/269 - Train Accuracy: 0.8872, Validation Accuracy: 0.8706, Loss: 0.1004
Epoch 282 Batch  110/269 - Train Accuracy: 0.8672, Validation Accuracy: 0.8731, Loss: 0.1035
Epoch 282 Batch  120/269 - Train Accuracy: 0.8658, Validation Accuracy: 0.8705, Loss: 0.1120
Epoch 282 Batch  130/269 - Train Accuracy: 0.8555, Validation Accuracy: 0.8703, Loss: 0.1027
Epoch 282 Batch  140/269 - Train Accuracy: 0.8614, Validation Accuracy: 0.8763, Loss: 0.1084
Epoch 282 Batch  150/269 - Train Accuracy: 0.8758, Validation Accuracy: 0.8742, Loss: 0.1057
Epoch 282 Batch  160/269 - Train Accuracy: 0.8878, Validation Accuracy: 0.8825, Loss: 0.1053
Epoch 282 Batch  170/269 - Train Accuracy: 0.8651, Validation Accuracy: 0.8736, Loss: 0.1023
Epoch 282 Batch  180/269 - Train Accuracy: 0.8917, Validation Accuracy: 0.8768, Loss: 0.0924
Epoch 282 Batch  190/269 - Train Accuracy: 0.8841, Validation Accuracy: 0.8739, Loss: 0.1053
Epoch 282 Batch  200/269 - Train Accuracy: 0.8631, Validation Accuracy: 0.8769, Loss: 0.0969
Epoch 282 Batch  210/269 - Train Accuracy: 0.8743, Validation Accuracy: 0.8779, Loss: 0.1058
Epoch 282 Batch  220/269 - Train Accuracy: 0.8731, Validation Accuracy: 0.8751, Loss: 0.0986
Epoch 282 Batch  230/269 - Train Accuracy: 0.8670, Validation Accuracy: 0.8813, Loss: 0.0999
Epoch 282 Batch  240/269 - Train Accuracy: 0.8792, Validation Accuracy: 0.8728, Loss: 0.0920
Epoch 282 Batch  250/269 - Train Accuracy: 0.8828, Validation Accuracy: 0.8756, Loss: 0.0957
Epoch 282 Batch  260/269 - Train Accuracy: 0.8684, Validation Accuracy: 0.8755, Loss: 0.1072
Epoch 283 Batch   10/269 - Train Accuracy: 0.8747, Validation Accuracy: 0.8730, Loss: 0.0888
Epoch 283 Batch   20/269 - Train Accuracy: 0.8632, Validation Accuracy: 0.8724, Loss: 0.1007
Epoch 283 Batch   30/269 - Train Accuracy: 0.8651, Validation Accuracy: 0.8695, Loss: 0.0935
Epoch 283 Batch   40/269 - Train Accuracy: 0.8555, Validation Accuracy: 0.8702, Loss: 0.1153
Epoch 283 Batch   50/269 - Train Accuracy: 0.8589, Validation Accuracy: 0.8761, Loss: 0.1178
Epoch 283 Batch   60/269 - Train Accuracy: 0.8813, Validation Accuracy: 0.8712, Loss: 0.0907
Epoch 283 Batch   70/269 - Train Accuracy: 0.8775, Validation Accuracy: 0.8691, Loss: 0.0994
Epoch 283 Batch   80/269 - Train Accuracy: 0.8746, Validation Accuracy: 0.8769, Loss: 0.0948
Epoch 283 Batch   90/269 - Train Accuracy: 0.8768, Validation Accuracy: 0.8726, Loss: 0.1016
Epoch 283 Batch  100/269 - Train Accuracy: 0.8854, Validation Accuracy: 0.8754, Loss: 0.1167
Epoch 283 Batch  110/269 - Train Accuracy: 0.8677, Validation Accuracy: 0.8706, Loss: 0.1041
Epoch 283 Batch  120/269 - Train Accuracy: 0.8695, Validation Accuracy: 0.8707, Loss: 0.1124
Epoch 283 Batch  130/269 - Train Accuracy: 0.8631, Validation Accuracy: 0.8703, Loss: 0.1186
Epoch 283 Batch  140/269 - Train Accuracy: 0.8653, Validation Accuracy: 0.8727, Loss: 0.1048
Epoch 283 Batch  150/269 - Train Accuracy: 0.8706, Validation Accuracy: 0.8717, Loss: 0.1020
Epoch 283 Batch  160/269 - Train Accuracy: 0.8834, Validation Accuracy: 0.8762, Loss: 0.0976
Epoch 283 Batch  170/269 - Train Accuracy: 0.8662, Validation Accuracy: 0.8759, Loss: 0.0981
Epoch 283 Batch  180/269 - Train Accuracy: 0.8868, Validation Accuracy: 0.8702, Loss: 0.1041
Epoch 283 Batch  190/269 - Train Accuracy: 0.8837, Validation Accuracy: 0.8823, Loss: 0.1032
Epoch 283 Batch  200/269 - Train Accuracy: 0.8635, Validation Accuracy: 0.8722, Loss: 0.0984
Epoch 283 Batch  210/269 - Train Accuracy: 0.8749, Validation Accuracy: 0.8737, Loss: 0.1059
Epoch 283 Batch  220/269 - Train Accuracy: 0.8735, Validation Accuracy: 0.8662, Loss: 0.1014
Epoch 283 Batch  230/269 - Train Accuracy: 0.8723, Validation Accuracy: 0.8798, Loss: 0.1054
Epoch 283 Batch  240/269 - Train Accuracy: 0.8796, Validation Accuracy: 0.8730, Loss: 0.0918
Epoch 283 Batch  250/269 - Train Accuracy: 0.8840, Validation Accuracy: 0.8805, Loss: 0.0978
Epoch 283 Batch  260/269 - Train Accuracy: 0.8652, Validation Accuracy: 0.8760, Loss: 0.1106
Epoch 284 Batch   10/269 - Train Accuracy: 0.8770, Validation Accuracy: 0.8741, Loss: 0.0934
Epoch 284 Batch   20/269 - Train Accuracy: 0.8710, Validation Accuracy: 0.8743, Loss: 0.0969
Epoch 284 Batch   30/269 - Train Accuracy: 0.8712, Validation Accuracy: 0.8754, Loss: 0.0958
Epoch 284 Batch   40/269 - Train Accuracy: 0.8523, Validation Accuracy: 0.8721, Loss: 0.1191
Epoch 284 Batch   50/269 - Train Accuracy: 0.8558, Validation Accuracy: 0.8735, Loss: 0.1123
Epoch 284 Batch   60/269 - Train Accuracy: 0.8829, Validation Accuracy: 0.8752, Loss: 0.0911
Epoch 284 Batch   70/269 - Train Accuracy: 0.8844, Validation Accuracy: 0.8693, Loss: 0.1043
Epoch 284 Batch   80/269 - Train Accuracy: 0.8747, Validation Accuracy: 0.8754, Loss: 0.1050
Epoch 284 Batch   90/269 - Train Accuracy: 0.8783, Validation Accuracy: 0.8731, Loss: 0.1073
Epoch 284 Batch  100/269 - Train Accuracy: 0.8829, Validation Accuracy: 0.8751, Loss: 0.0988
Epoch 284 Batch  110/269 - Train Accuracy: 0.8616, Validation Accuracy: 0.8709, Loss: 0.1011
Epoch 284 Batch  120/269 - Train Accuracy: 0.8772, Validation Accuracy: 0.8705, Loss: 0.1001
Epoch 284 Batch  130/269 - Train Accuracy: 0.8635, Validation Accuracy: 0.8727, Loss: 0.1010
Epoch 284 Batch  140/269 - Train Accuracy: 0.8639, Validation Accuracy: 0.8778, Loss: 0.1065
Epoch 284 Batch  150/269 - Train Accuracy: 0.8663, Validation Accuracy: 0.8734, Loss: 0.1064
Epoch 284 Batch  160/269 - Train Accuracy: 0.8797, Validation Accuracy: 0.8769, Loss: 0.0999
Epoch 284 Batch  170/269 - Train Accuracy: 0.8676, Validation Accuracy: 0.8754, Loss: 0.0925
Epoch 284 Batch  180/269 - Train Accuracy: 0.8915, Validation Accuracy: 0.8709, Loss: 0.0941
Epoch 284 Batch  190/269 - Train Accuracy: 0.8840, Validation Accuracy: 0.8731, Loss: 0.0971
Epoch 284 Batch  200/269 - Train Accuracy: 0.8604, Validation Accuracy: 0.8739, Loss: 0.1012
Epoch 284 Batch  210/269 - Train Accuracy: 0.8674, Validation Accuracy: 0.8650, Loss: 0.1054
Epoch 284 Batch  220/269 - Train Accuracy: 0.8714, Validation Accuracy: 0.8738, Loss: 0.0991
Epoch 284 Batch  230/269 - Train Accuracy: 0.8734, Validation Accuracy: 0.8773, Loss: 0.1014
Epoch 284 Batch  240/269 - Train Accuracy: 0.8781, Validation Accuracy: 0.8677, Loss: 0.0842
Epoch 284 Batch  250/269 - Train Accuracy: 0.8813, Validation Accuracy: 0.8753, Loss: 0.0914
Epoch 284 Batch  260/269 - Train Accuracy: 0.8633, Validation Accuracy: 0.8756, Loss: 0.1055
Epoch 285 Batch   10/269 - Train Accuracy: 0.8733, Validation Accuracy: 0.8730, Loss: 0.0909
Epoch 285 Batch   20/269 - Train Accuracy: 0.8644, Validation Accuracy: 0.8712, Loss: 0.1010
Epoch 285 Batch   30/269 - Train Accuracy: 0.8650, Validation Accuracy: 0.8752, Loss: 0.1012
Epoch 285 Batch   40/269 - Train Accuracy: 0.8585, Validation Accuracy: 0.8696, Loss: 0.1066
Epoch 285 Batch   50/269 - Train Accuracy: 0.8601, Validation Accuracy: 0.8713, Loss: 0.1116
Epoch 285 Batch   60/269 - Train Accuracy: 0.8860, Validation Accuracy: 0.8770, Loss: 0.0908
Epoch 285 Batch   70/269 - Train Accuracy: 0.8756, Validation Accuracy: 0.8763, Loss: 0.1071
Epoch 285 Batch   80/269 - Train Accuracy: 0.8783, Validation Accuracy: 0.8772, Loss: 0.0963
Epoch 285 Batch   90/269 - Train Accuracy: 0.8814, Validation Accuracy: 0.8726, Loss: 0.1051
Epoch 285 Batch  100/269 - Train Accuracy: 0.8852, Validation Accuracy: 0.8749, Loss: 0.0978
Epoch 285 Batch  110/269 - Train Accuracy: 0.8683, Validation Accuracy: 0.8761, Loss: 0.1035
Epoch 285 Batch  120/269 - Train Accuracy: 0.8709, Validation Accuracy: 0.8721, Loss: 0.1083
Epoch 285 Batch  130/269 - Train Accuracy: 0.8561, Validation Accuracy: 0.8669, Loss: 0.1019
Epoch 285 Batch  140/269 - Train Accuracy: 0.8616, Validation Accuracy: 0.8688, Loss: 0.1035
Epoch 285 Batch  150/269 - Train Accuracy: 0.8735, Validation Accuracy: 0.8717, Loss: 0.1051
Epoch 285 Batch  160/269 - Train Accuracy: 0.8800, Validation Accuracy: 0.8720, Loss: 0.0990
Epoch 285 Batch  170/269 - Train Accuracy: 0.8627, Validation Accuracy: 0.8794, Loss: 0.0970
Epoch 285 Batch  180/269 - Train Accuracy: 0.8916, Validation Accuracy: 0.8721, Loss: 0.0973
Epoch 285 Batch  190/269 - Train Accuracy: 0.8821, Validation Accuracy: 0.8751, Loss: 0.0991
Epoch 285 Batch  200/269 - Train Accuracy: 0.8655, Validation Accuracy: 0.8739, Loss: 0.0927
Epoch 285 Batch  210/269 - Train Accuracy: 0.8765, Validation Accuracy: 0.8774, Loss: 0.1021
Epoch 285 Batch  220/269 - Train Accuracy: 0.8778, Validation Accuracy: 0.8706, Loss: 0.0966
Epoch 285 Batch  230/269 - Train Accuracy: 0.8655, Validation Accuracy: 0.8716, Loss: 0.0966
Epoch 285 Batch  240/269 - Train Accuracy: 0.8826, Validation Accuracy: 0.8746, Loss: 0.0904
Epoch 285 Batch  250/269 - Train Accuracy: 0.8834, Validation Accuracy: 0.8759, Loss: 0.0992
Epoch 285 Batch  260/269 - Train Accuracy: 0.8638, Validation Accuracy: 0.8786, Loss: 0.1014
Epoch 286 Batch   10/269 - Train Accuracy: 0.8761, Validation Accuracy: 0.8647, Loss: 0.0939
Epoch 286 Batch   20/269 - Train Accuracy: 0.8668, Validation Accuracy: 0.8711, Loss: 0.0990
Epoch 286 Batch   30/269 - Train Accuracy: 0.8703, Validation Accuracy: 0.8752, Loss: 0.0980
Epoch 286 Batch   40/269 - Train Accuracy: 0.8562, Validation Accuracy: 0.8676, Loss: 0.1107
Epoch 286 Batch   50/269 - Train Accuracy: 0.8576, Validation Accuracy: 0.8692, Loss: 0.1121
Epoch 286 Batch   60/269 - Train Accuracy: 0.8735, Validation Accuracy: 0.8740, Loss: 0.0922
Epoch 286 Batch   70/269 - Train Accuracy: 0.8826, Validation Accuracy: 0.8738, Loss: 0.0937
Epoch 286 Batch   80/269 - Train Accuracy: 0.8713, Validation Accuracy: 0.8707, Loss: 0.1219
Epoch 286 Batch   90/269 - Train Accuracy: 0.8683, Validation Accuracy: 0.8708, Loss: 0.1164
Epoch 286 Batch  100/269 - Train Accuracy: 0.8824, Validation Accuracy: 0.8770, Loss: 0.0959
Epoch 286 Batch  110/269 - Train Accuracy: 0.8593, Validation Accuracy: 0.8788, Loss: 0.1181
Epoch 286 Batch  120/269 - Train Accuracy: 0.8720, Validation Accuracy: 0.8710, Loss: 0.1025
Epoch 286 Batch  130/269 - Train Accuracy: 0.8572, Validation Accuracy: 0.8778, Loss: 0.1029
Epoch 286 Batch  140/269 - Train Accuracy: 0.8656, Validation Accuracy: 0.8706, Loss: 0.1029
Epoch 286 Batch  150/269 - Train Accuracy: 0.8733, Validation Accuracy: 0.8777, Loss: 0.0988
Epoch 286 Batch  160/269 - Train Accuracy: 0.8831, Validation Accuracy: 0.8752, Loss: 0.1065
Epoch 286 Batch  170/269 - Train Accuracy: 0.8640, Validation Accuracy: 0.8727, Loss: 0.0936
Epoch 286 Batch  180/269 - Train Accuracy: 0.8832, Validation Accuracy: 0.8677, Loss: 0.0933
Epoch 286 Batch  190/269 - Train Accuracy: 0.8833, Validation Accuracy: 0.8745, Loss: 0.1017
Epoch 286 Batch  200/269 - Train Accuracy: 0.8657, Validation Accuracy: 0.8787, Loss: 0.0936
Epoch 286 Batch  210/269 - Train Accuracy: 0.8723, Validation Accuracy: 0.8751, Loss: 0.0979
Epoch 286 Batch  220/269 - Train Accuracy: 0.8679, Validation Accuracy: 0.8703, Loss: 0.1000
Epoch 286 Batch  230/269 - Train Accuracy: 0.8682, Validation Accuracy: 0.8818, Loss: 0.1047
Epoch 286 Batch  240/269 - Train Accuracy: 0.8760, Validation Accuracy: 0.8696, Loss: 0.0888
Epoch 286 Batch  250/269 - Train Accuracy: 0.8840, Validation Accuracy: 0.8806, Loss: 0.1049
Epoch 286 Batch  260/269 - Train Accuracy: 0.8644, Validation Accuracy: 0.8777, Loss: 0.1015
Epoch 287 Batch   10/269 - Train Accuracy: 0.8739, Validation Accuracy: 0.8702, Loss: 0.0994
Epoch 287 Batch   20/269 - Train Accuracy: 0.8609, Validation Accuracy: 0.8761, Loss: 0.0972
Epoch 287 Batch   30/269 - Train Accuracy: 0.8727, Validation Accuracy: 0.8804, Loss: 0.0951
Epoch 287 Batch   40/269 - Train Accuracy: 0.8554, Validation Accuracy: 0.8745, Loss: 0.1084
Epoch 287 Batch   50/269 - Train Accuracy: 0.8593, Validation Accuracy: 0.8766, Loss: 0.1101
Epoch 287 Batch   60/269 - Train Accuracy: 0.8885, Validation Accuracy: 0.8740, Loss: 0.0898
Epoch 287 Batch   70/269 - Train Accuracy: 0.8802, Validation Accuracy: 0.8719, Loss: 0.1006
Epoch 287 Batch   80/269 - Train Accuracy: 0.8786, Validation Accuracy: 0.8798, Loss: 0.1029
Epoch 287 Batch   90/269 - Train Accuracy: 0.8752, Validation Accuracy: 0.8724, Loss: 0.1068
Epoch 287 Batch  100/269 - Train Accuracy: 0.8902, Validation Accuracy: 0.8751, Loss: 0.0991
Epoch 287 Batch  110/269 - Train Accuracy: 0.8674, Validation Accuracy: 0.8725, Loss: 0.1056
Epoch 287 Batch  120/269 - Train Accuracy: 0.8747, Validation Accuracy: 0.8734, Loss: 0.1056
Epoch 287 Batch  130/269 - Train Accuracy: 0.8579, Validation Accuracy: 0.8746, Loss: 0.1072
Epoch 287 Batch  140/269 - Train Accuracy: 0.8627, Validation Accuracy: 0.8759, Loss: 0.1004
Epoch 287 Batch  150/269 - Train Accuracy: 0.8712, Validation Accuracy: 0.8710, Loss: 0.1078
Epoch 287 Batch  160/269 - Train Accuracy: 0.8820, Validation Accuracy: 0.8699, Loss: 0.1012
Epoch 287 Batch  170/269 - Train Accuracy: 0.8686, Validation Accuracy: 0.8763, Loss: 0.0990
Epoch 287 Batch  180/269 - Train Accuracy: 0.8930, Validation Accuracy: 0.8747, Loss: 0.0941
Epoch 287 Batch  190/269 - Train Accuracy: 0.8783, Validation Accuracy: 0.8860, Loss: 0.0997
Epoch 287 Batch  200/269 - Train Accuracy: 0.8610, Validation Accuracy: 0.8776, Loss: 0.0933
Epoch 287 Batch  210/269 - Train Accuracy: 0.8660, Validation Accuracy: 0.8784, Loss: 0.1069
Epoch 287 Batch  220/269 - Train Accuracy: 0.8749, Validation Accuracy: 0.8711, Loss: 0.0917
Epoch 287 Batch  230/269 - Train Accuracy: 0.8687, Validation Accuracy: 0.8794, Loss: 0.0943
Epoch 287 Batch  240/269 - Train Accuracy: 0.8837, Validation Accuracy: 0.8736, Loss: 0.0876
Epoch 287 Batch  250/269 - Train Accuracy: 0.8806, Validation Accuracy: 0.8714, Loss: 0.0916
Epoch 287 Batch  260/269 - Train Accuracy: 0.8657, Validation Accuracy: 0.8764, Loss: 0.1090
Epoch 288 Batch   10/269 - Train Accuracy: 0.8727, Validation Accuracy: 0.8680, Loss: 0.0932
Epoch 288 Batch   20/269 - Train Accuracy: 0.8521, Validation Accuracy: 0.8702, Loss: 0.0972
Epoch 288 Batch   30/269 - Train Accuracy: 0.8681, Validation Accuracy: 0.8762, Loss: 0.0932
Epoch 288 Batch   40/269 - Train Accuracy: 0.8573, Validation Accuracy: 0.8728, Loss: 0.1077
Epoch 288 Batch   50/269 - Train Accuracy: 0.8552, Validation Accuracy: 0.8734, Loss: 0.1044
Epoch 288 Batch   60/269 - Train Accuracy: 0.8895, Validation Accuracy: 0.8790, Loss: 0.0916
Epoch 288 Batch   70/269 - Train Accuracy: 0.8770, Validation Accuracy: 0.8731, Loss: 0.1025
Epoch 288 Batch   80/269 - Train Accuracy: 0.8824, Validation Accuracy: 0.8752, Loss: 0.0978
Epoch 288 Batch   90/269 - Train Accuracy: 0.8755, Validation Accuracy: 0.8744, Loss: 0.0997
Epoch 288 Batch  100/269 - Train Accuracy: 0.8838, Validation Accuracy: 0.8706, Loss: 0.0913
Epoch 288 Batch  110/269 - Train Accuracy: 0.8623, Validation Accuracy: 0.8679, Loss: 0.1136
Epoch 288 Batch  120/269 - Train Accuracy: 0.8776, Validation Accuracy: 0.8720, Loss: 0.1023
Epoch 288 Batch  130/269 - Train Accuracy: 0.8645, Validation Accuracy: 0.8707, Loss: 0.1067
Epoch 288 Batch  140/269 - Train Accuracy: 0.8705, Validation Accuracy: 0.8741, Loss: 0.1035
Epoch 288 Batch  150/269 - Train Accuracy: 0.8736, Validation Accuracy: 0.8703, Loss: 0.1021
Epoch 288 Batch  160/269 - Train Accuracy: 0.8839, Validation Accuracy: 0.8712, Loss: 0.1018
Epoch 288 Batch  170/269 - Train Accuracy: 0.8614, Validation Accuracy: 0.8770, Loss: 0.0973
Epoch 288 Batch  180/269 - Train Accuracy: 0.8930, Validation Accuracy: 0.8760, Loss: 0.0941
Epoch 288 Batch  190/269 - Train Accuracy: 0.8816, Validation Accuracy: 0.8770, Loss: 0.0905
Epoch 288 Batch  200/269 - Train Accuracy: 0.8579, Validation Accuracy: 0.8757, Loss: 0.1024
Epoch 288 Batch  210/269 - Train Accuracy: 0.8718, Validation Accuracy: 0.8798, Loss: 0.0983
Epoch 288 Batch  220/269 - Train Accuracy: 0.8777, Validation Accuracy: 0.8716, Loss: 0.0950
Epoch 288 Batch  230/269 - Train Accuracy: 0.8708, Validation Accuracy: 0.8747, Loss: 0.0944
Epoch 288 Batch  240/269 - Train Accuracy: 0.8806, Validation Accuracy: 0.8703, Loss: 0.0844
Epoch 288 Batch  250/269 - Train Accuracy: 0.8815, Validation Accuracy: 0.8750, Loss: 0.0962
Epoch 288 Batch  260/269 - Train Accuracy: 0.8629, Validation Accuracy: 0.8785, Loss: 0.1087
Epoch 289 Batch   10/269 - Train Accuracy: 0.8808, Validation Accuracy: 0.8691, Loss: 0.0933
Epoch 289 Batch   20/269 - Train Accuracy: 0.8609, Validation Accuracy: 0.8715, Loss: 0.1071
Epoch 289 Batch   30/269 - Train Accuracy: 0.8659, Validation Accuracy: 0.8722, Loss: 0.0904
Epoch 289 Batch   40/269 - Train Accuracy: 0.8521, Validation Accuracy: 0.8716, Loss: 0.1160
Epoch 289 Batch   50/269 - Train Accuracy: 0.8569, Validation Accuracy: 0.8713, Loss: 0.1023
Epoch 289 Batch   60/269 - Train Accuracy: 0.8874, Validation Accuracy: 0.8740, Loss: 0.0889
Epoch 289 Batch   70/269 - Train Accuracy: 0.8858, Validation Accuracy: 0.8721, Loss: 0.1000
Epoch 289 Batch   80/269 - Train Accuracy: 0.8813, Validation Accuracy: 0.8754, Loss: 0.0914
Epoch 289 Batch   90/269 - Train Accuracy: 0.8738, Validation Accuracy: 0.8724, Loss: 0.1057
Epoch 289 Batch  100/269 - Train Accuracy: 0.8818, Validation Accuracy: 0.8733, Loss: 0.1007
Epoch 289 Batch  110/269 - Train Accuracy: 0.8627, Validation Accuracy: 0.8713, Loss: 0.1043
Epoch 289 Batch  120/269 - Train Accuracy: 0.8731, Validation Accuracy: 0.8671, Loss: 0.1099
Epoch 289 Batch  130/269 - Train Accuracy: 0.8596, Validation Accuracy: 0.8709, Loss: 0.1136
Epoch 289 Batch  140/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8703, Loss: 0.1074
Epoch 289 Batch  150/269 - Train Accuracy: 0.8706, Validation Accuracy: 0.8714, Loss: 0.1051
Epoch 289 Batch  160/269 - Train Accuracy: 0.8786, Validation Accuracy: 0.8749, Loss: 0.1000
Epoch 289 Batch  170/269 - Train Accuracy: 0.8657, Validation Accuracy: 0.8724, Loss: 0.1024
Epoch 289 Batch  180/269 - Train Accuracy: 0.8916, Validation Accuracy: 0.8691, Loss: 0.0985
Epoch 289 Batch  190/269 - Train Accuracy: 0.8839, Validation Accuracy: 0.8716, Loss: 0.0943
Epoch 289 Batch  200/269 - Train Accuracy: 0.8604, Validation Accuracy: 0.8805, Loss: 0.1009
Epoch 289 Batch  210/269 - Train Accuracy: 0.8718, Validation Accuracy: 0.8735, Loss: 0.1029
Epoch 289 Batch  220/269 - Train Accuracy: 0.8726, Validation Accuracy: 0.8730, Loss: 0.0982
Epoch 289 Batch  230/269 - Train Accuracy: 0.8634, Validation Accuracy: 0.8715, Loss: 0.0983
Epoch 289 Batch  240/269 - Train Accuracy: 0.8770, Validation Accuracy: 0.8742, Loss: 0.0874
Epoch 289 Batch  250/269 - Train Accuracy: 0.8809, Validation Accuracy: 0.8701, Loss: 0.0972
Epoch 289 Batch  260/269 - Train Accuracy: 0.8557, Validation Accuracy: 0.8708, Loss: 0.1078
Epoch 290 Batch   10/269 - Train Accuracy: 0.8805, Validation Accuracy: 0.8726, Loss: 0.0900
Epoch 290 Batch   20/269 - Train Accuracy: 0.8631, Validation Accuracy: 0.8643, Loss: 0.1015
Epoch 290 Batch   30/269 - Train Accuracy: 0.8657, Validation Accuracy: 0.8695, Loss: 0.1018
Epoch 290 Batch   40/269 - Train Accuracy: 0.8555, Validation Accuracy: 0.8758, Loss: 0.1150
Epoch 290 Batch   50/269 - Train Accuracy: 0.8568, Validation Accuracy: 0.8695, Loss: 0.1090
Epoch 290 Batch   60/269 - Train Accuracy: 0.8865, Validation Accuracy: 0.8739, Loss: 0.0999
Epoch 290 Batch   70/269 - Train Accuracy: 0.8779, Validation Accuracy: 0.8719, Loss: 0.1023
Epoch 290 Batch   80/269 - Train Accuracy: 0.8800, Validation Accuracy: 0.8742, Loss: 0.0950
Epoch 290 Batch   90/269 - Train Accuracy: 0.8720, Validation Accuracy: 0.8762, Loss: 0.0972
Epoch 290 Batch  100/269 - Train Accuracy: 0.8845, Validation Accuracy: 0.8685, Loss: 0.0994
Epoch 290 Batch  110/269 - Train Accuracy: 0.8655, Validation Accuracy: 0.8714, Loss: 0.1020
Epoch 290 Batch  120/269 - Train Accuracy: 0.8729, Validation Accuracy: 0.8733, Loss: 0.1033
Epoch 290 Batch  130/269 - Train Accuracy: 0.8623, Validation Accuracy: 0.8727, Loss: 0.1015
Epoch 290 Batch  140/269 - Train Accuracy: 0.8680, Validation Accuracy: 0.8690, Loss: 0.1032
Epoch 290 Batch  150/269 - Train Accuracy: 0.8730, Validation Accuracy: 0.8757, Loss: 0.0972
Epoch 290 Batch  160/269 - Train Accuracy: 0.8841, Validation Accuracy: 0.8750, Loss: 0.1066
Epoch 290 Batch  170/269 - Train Accuracy: 0.8627, Validation Accuracy: 0.8727, Loss: 0.0968
Epoch 290 Batch  180/269 - Train Accuracy: 0.8855, Validation Accuracy: 0.8688, Loss: 0.0974
Epoch 290 Batch  190/269 - Train Accuracy: 0.8775, Validation Accuracy: 0.8726, Loss: 0.1017
Epoch 290 Batch  200/269 - Train Accuracy: 0.8688, Validation Accuracy: 0.8755, Loss: 0.0971
Epoch 290 Batch  210/269 - Train Accuracy: 0.8768, Validation Accuracy: 0.8730, Loss: 0.1051
Epoch 290 Batch  220/269 - Train Accuracy: 0.8722, Validation Accuracy: 0.8712, Loss: 0.0989
Epoch 290 Batch  230/269 - Train Accuracy: 0.8645, Validation Accuracy: 0.8753, Loss: 0.1022
Epoch 290 Batch  240/269 - Train Accuracy: 0.8775, Validation Accuracy: 0.8742, Loss: 0.0856
Epoch 290 Batch  250/269 - Train Accuracy: 0.8704, Validation Accuracy: 0.8628, Loss: 0.1145
Epoch 290 Batch  260/269 - Train Accuracy: 0.8552, Validation Accuracy: 0.8675, Loss: 0.1142
Epoch 291 Batch   10/269 - Train Accuracy: 0.8639, Validation Accuracy: 0.8612, Loss: 0.1060
Epoch 291 Batch   20/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8755, Loss: 0.1027
Epoch 291 Batch   30/269 - Train Accuracy: 0.8676, Validation Accuracy: 0.8701, Loss: 0.0996
Epoch 291 Batch   40/269 - Train Accuracy: 0.8543, Validation Accuracy: 0.8725, Loss: 0.1184
Epoch 291 Batch   50/269 - Train Accuracy: 0.8585, Validation Accuracy: 0.8720, Loss: 0.1031
Epoch 291 Batch   60/269 - Train Accuracy: 0.8817, Validation Accuracy: 0.8776, Loss: 0.0953
Epoch 291 Batch   70/269 - Train Accuracy: 0.8784, Validation Accuracy: 0.8653, Loss: 0.0942
Epoch 291 Batch   80/269 - Train Accuracy: 0.8730, Validation Accuracy: 0.8714, Loss: 0.0978
Epoch 291 Batch   90/269 - Train Accuracy: 0.8768, Validation Accuracy: 0.8678, Loss: 0.1024
Epoch 291 Batch  100/269 - Train Accuracy: 0.8876, Validation Accuracy: 0.8731, Loss: 0.0976
Epoch 291 Batch  110/269 - Train Accuracy: 0.8613, Validation Accuracy: 0.8701, Loss: 0.0980
Epoch 291 Batch  120/269 - Train Accuracy: 0.8728, Validation Accuracy: 0.8741, Loss: 0.1111
Epoch 291 Batch  130/269 - Train Accuracy: 0.8608, Validation Accuracy: 0.8743, Loss: 0.1029
Epoch 291 Batch  140/269 - Train Accuracy: 0.8690, Validation Accuracy: 0.8722, Loss: 0.1065
Epoch 291 Batch  150/269 - Train Accuracy: 0.8727, Validation Accuracy: 0.8699, Loss: 0.0972
Epoch 291 Batch  160/269 - Train Accuracy: 0.8829, Validation Accuracy: 0.8761, Loss: 0.1052
Epoch 291 Batch  170/269 - Train Accuracy: 0.8658, Validation Accuracy: 0.8737, Loss: 0.0917
Epoch 291 Batch  180/269 - Train Accuracy: 0.8893, Validation Accuracy: 0.8724, Loss: 0.0885
Epoch 291 Batch  190/269 - Train Accuracy: 0.8823, Validation Accuracy: 0.8760, Loss: 0.0935
Epoch 291 Batch  200/269 - Train Accuracy: 0.8671, Validation Accuracy: 0.8712, Loss: 0.1070
Epoch 291 Batch  210/269 - Train Accuracy: 0.8697, Validation Accuracy: 0.8740, Loss: 0.1091
Epoch 291 Batch  220/269 - Train Accuracy: 0.8683, Validation Accuracy: 0.8723, Loss: 0.0965
Epoch 291 Batch  230/269 - Train Accuracy: 0.8715, Validation Accuracy: 0.8770, Loss: 0.0981
Epoch 291 Batch  240/269 - Train Accuracy: 0.8803, Validation Accuracy: 0.8807, Loss: 0.0865
Epoch 291 Batch  250/269 - Train Accuracy: 0.8845, Validation Accuracy: 0.8759, Loss: 0.1074
Epoch 291 Batch  260/269 - Train Accuracy: 0.8630, Validation Accuracy: 0.8822, Loss: 0.1095
Epoch 292 Batch   10/269 - Train Accuracy: 0.8834, Validation Accuracy: 0.8778, Loss: 0.0974
Epoch 292 Batch   20/269 - Train Accuracy: 0.8673, Validation Accuracy: 0.8743, Loss: 0.0986
Epoch 292 Batch   30/269 - Train Accuracy: 0.8690, Validation Accuracy: 0.8782, Loss: 0.0962
Epoch 292 Batch   40/269 - Train Accuracy: 0.8548, Validation Accuracy: 0.8741, Loss: 0.1014
Epoch 292 Batch   50/269 - Train Accuracy: 0.8606, Validation Accuracy: 0.8739, Loss: 0.1013
Epoch 292 Batch   60/269 - Train Accuracy: 0.8911, Validation Accuracy: 0.8764, Loss: 0.0905
Epoch 292 Batch   70/269 - Train Accuracy: 0.8794, Validation Accuracy: 0.8760, Loss: 0.1059
Epoch 292 Batch   80/269 - Train Accuracy: 0.8745, Validation Accuracy: 0.8772, Loss: 0.1015
Epoch 292 Batch   90/269 - Train Accuracy: 0.8751, Validation Accuracy: 0.8727, Loss: 0.1117
Epoch 292 Batch  100/269 - Train Accuracy: 0.8840, Validation Accuracy: 0.8706, Loss: 0.0974
Epoch 292 Batch  110/269 - Train Accuracy: 0.8646, Validation Accuracy: 0.8777, Loss: 0.1070
Epoch 292 Batch  120/269 - Train Accuracy: 0.8741, Validation Accuracy: 0.8711, Loss: 0.1050
Epoch 292 Batch  130/269 - Train Accuracy: 0.8655, Validation Accuracy: 0.8747, Loss: 0.1050
Epoch 292 Batch  140/269 - Train Accuracy: 0.8690, Validation Accuracy: 0.8771, Loss: 0.1050
Epoch 292 Batch  150/269 - Train Accuracy: 0.8721, Validation Accuracy: 0.8721, Loss: 0.1025
Epoch 292 Batch  160/269 - Train Accuracy: 0.8787, Validation Accuracy: 0.8750, Loss: 0.0944
Epoch 292 Batch  170/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8678, Loss: 0.0973
Epoch 292 Batch  180/269 - Train Accuracy: 0.8890, Validation Accuracy: 0.8704, Loss: 0.0940
Epoch 292 Batch  190/269 - Train Accuracy: 0.8877, Validation Accuracy: 0.8745, Loss: 0.0889
Epoch 292 Batch  200/269 - Train Accuracy: 0.8605, Validation Accuracy: 0.8781, Loss: 0.0984
Epoch 292 Batch  210/269 - Train Accuracy: 0.8754, Validation Accuracy: 0.8741, Loss: 0.0962
Epoch 292 Batch  220/269 - Train Accuracy: 0.8790, Validation Accuracy: 0.8745, Loss: 0.0969
Epoch 292 Batch  230/269 - Train Accuracy: 0.8669, Validation Accuracy: 0.8807, Loss: 0.0952
Epoch 292 Batch  240/269 - Train Accuracy: 0.8774, Validation Accuracy: 0.8699, Loss: 0.0912
Epoch 292 Batch  250/269 - Train Accuracy: 0.8856, Validation Accuracy: 0.8722, Loss: 0.0975
Epoch 292 Batch  260/269 - Train Accuracy: 0.8615, Validation Accuracy: 0.8758, Loss: 0.1061
Epoch 293 Batch   10/269 - Train Accuracy: 0.8750, Validation Accuracy: 0.8772, Loss: 0.0879
Epoch 293 Batch   20/269 - Train Accuracy: 0.8629, Validation Accuracy: 0.8681, Loss: 0.0911
Epoch 293 Batch   30/269 - Train Accuracy: 0.8668, Validation Accuracy: 0.8816, Loss: 0.0942
Epoch 293 Batch   40/269 - Train Accuracy: 0.8509, Validation Accuracy: 0.8737, Loss: 0.1077
Epoch 293 Batch   50/269 - Train Accuracy: 0.8576, Validation Accuracy: 0.8737, Loss: 0.1175
Epoch 293 Batch   60/269 - Train Accuracy: 0.8873, Validation Accuracy: 0.8759, Loss: 0.0924
Epoch 293 Batch   70/269 - Train Accuracy: 0.8771, Validation Accuracy: 0.8722, Loss: 0.0995
Epoch 293 Batch   80/269 - Train Accuracy: 0.8812, Validation Accuracy: 0.8764, Loss: 0.0964
Epoch 293 Batch   90/269 - Train Accuracy: 0.8778, Validation Accuracy: 0.8699, Loss: 0.1136
Epoch 293 Batch  100/269 - Train Accuracy: 0.8787, Validation Accuracy: 0.8757, Loss: 0.0946
Epoch 293 Batch  110/269 - Train Accuracy: 0.8631, Validation Accuracy: 0.8726, Loss: 0.0988
Epoch 293 Batch  120/269 - Train Accuracy: 0.8700, Validation Accuracy: 0.8675, Loss: 0.1027
Epoch 293 Batch  130/269 - Train Accuracy: 0.8613, Validation Accuracy: 0.8689, Loss: 0.1050
Epoch 293 Batch  140/269 - Train Accuracy: 0.8661, Validation Accuracy: 0.8774, Loss: 0.1073
Epoch 293 Batch  150/269 - Train Accuracy: 0.8748, Validation Accuracy: 0.8693, Loss: 0.0956
Epoch 293 Batch  160/269 - Train Accuracy: 0.8854, Validation Accuracy: 0.8675, Loss: 0.1045
Epoch 293 Batch  170/269 - Train Accuracy: 0.8606, Validation Accuracy: 0.8710, Loss: 0.0910
Epoch 293 Batch  180/269 - Train Accuracy: 0.8876, Validation Accuracy: 0.8662, Loss: 0.0951
Epoch 293 Batch  190/269 - Train Accuracy: 0.8757, Validation Accuracy: 0.8714, Loss: 0.0993
Epoch 293 Batch  200/269 - Train Accuracy: 0.8629, Validation Accuracy: 0.8740, Loss: 0.0985
Epoch 293 Batch  210/269 - Train Accuracy: 0.8675, Validation Accuracy: 0.8715, Loss: 0.0948
Epoch 293 Batch  220/269 - Train Accuracy: 0.8741, Validation Accuracy: 0.8655, Loss: 0.1056
Epoch 293 Batch  230/269 - Train Accuracy: 0.8743, Validation Accuracy: 0.8716, Loss: 0.0994
Epoch 293 Batch  240/269 - Train Accuracy: 0.8803, Validation Accuracy: 0.8754, Loss: 0.0903
Epoch 293 Batch  250/269 - Train Accuracy: 0.8853, Validation Accuracy: 0.8790, Loss: 0.1005
Epoch 293 Batch  260/269 - Train Accuracy: 0.8621, Validation Accuracy: 0.8723, Loss: 0.1053
Epoch 294 Batch   10/269 - Train Accuracy: 0.8736, Validation Accuracy: 0.8708, Loss: 0.0911
Epoch 294 Batch   20/269 - Train Accuracy: 0.8616, Validation Accuracy: 0.8762, Loss: 0.0990
Epoch 294 Batch   30/269 - Train Accuracy: 0.8693, Validation Accuracy: 0.8748, Loss: 0.0993
Epoch 294 Batch   40/269 - Train Accuracy: 0.8539, Validation Accuracy: 0.8744, Loss: 0.1165
Epoch 294 Batch   50/269 - Train Accuracy: 0.8592, Validation Accuracy: 0.8748, Loss: 0.1095
Epoch 294 Batch   60/269 - Train Accuracy: 0.8786, Validation Accuracy: 0.8748, Loss: 0.0941
Epoch 294 Batch   70/269 - Train Accuracy: 0.8791, Validation Accuracy: 0.8732, Loss: 0.0948
Epoch 294 Batch   80/269 - Train Accuracy: 0.8784, Validation Accuracy: 0.8788, Loss: 0.1050
Epoch 294 Batch   90/269 - Train Accuracy: 0.8783, Validation Accuracy: 0.8699, Loss: 0.0991
Epoch 294 Batch  100/269 - Train Accuracy: 0.8824, Validation Accuracy: 0.8667, Loss: 0.0906
Epoch 294 Batch  110/269 - Train Accuracy: 0.8539, Validation Accuracy: 0.8670, Loss: 0.1060
Epoch 294 Batch  120/269 - Train Accuracy: 0.8729, Validation Accuracy: 0.8717, Loss: 0.1056
Epoch 294 Batch  130/269 - Train Accuracy: 0.8587, Validation Accuracy: 0.8771, Loss: 0.0990
Epoch 294 Batch  140/269 - Train Accuracy: 0.8601, Validation Accuracy: 0.8648, Loss: 0.1051
Epoch 294 Batch  150/269 - Train Accuracy: 0.8705, Validation Accuracy: 0.8733, Loss: 0.0974
Epoch 294 Batch  160/269 - Train Accuracy: 0.8781, Validation Accuracy: 0.8675, Loss: 0.1068
Epoch 294 Batch  170/269 - Train Accuracy: 0.8583, Validation Accuracy: 0.8673, Loss: 0.0946
Epoch 294 Batch  180/269 - Train Accuracy: 0.8874, Validation Accuracy: 0.8683, Loss: 0.0930
Epoch 294 Batch  190/269 - Train Accuracy: 0.8822, Validation Accuracy: 0.8723, Loss: 0.0961
Epoch 294 Batch  200/269 - Train Accuracy: 0.8634, Validation Accuracy: 0.8738, Loss: 0.0939
Epoch 294 Batch  210/269 - Train Accuracy: 0.8704, Validation Accuracy: 0.8744, Loss: 0.1025
Epoch 294 Batch  220/269 - Train Accuracy: 0.8783, Validation Accuracy: 0.8739, Loss: 0.1008
Epoch 294 Batch  230/269 - Train Accuracy: 0.8749, Validation Accuracy: 0.8808, Loss: 0.0968
Epoch 294 Batch  240/269 - Train Accuracy: 0.8794, Validation Accuracy: 0.8700, Loss: 0.0883
Epoch 294 Batch  250/269 - Train Accuracy: 0.8799, Validation Accuracy: 0.8692, Loss: 0.0944
Epoch 294 Batch  260/269 - Train Accuracy: 0.8608, Validation Accuracy: 0.8699, Loss: 0.1074
Epoch 295 Batch   10/269 - Train Accuracy: 0.8758, Validation Accuracy: 0.8724, Loss: 0.0948
Epoch 295 Batch   20/269 - Train Accuracy: 0.8629, Validation Accuracy: 0.8689, Loss: 0.0981
Epoch 295 Batch   30/269 - Train Accuracy: 0.8657, Validation Accuracy: 0.8746, Loss: 0.0931
Epoch 295 Batch   40/269 - Train Accuracy: 0.8537, Validation Accuracy: 0.8732, Loss: 0.1060
Epoch 295 Batch   50/269 - Train Accuracy: 0.8522, Validation Accuracy: 0.8678, Loss: 0.1177
Epoch 295 Batch   60/269 - Train Accuracy: 0.8864, Validation Accuracy: 0.8787, Loss: 0.0963
Epoch 295 Batch   70/269 - Train Accuracy: 0.8811, Validation Accuracy: 0.8718, Loss: 0.1017
Epoch 295 Batch   80/269 - Train Accuracy: 0.8789, Validation Accuracy: 0.8722, Loss: 0.1053
Epoch 295 Batch   90/269 - Train Accuracy: 0.8800, Validation Accuracy: 0.8701, Loss: 0.1070
Epoch 295 Batch  100/269 - Train Accuracy: 0.8828, Validation Accuracy: 0.8783, Loss: 0.0975
Epoch 295 Batch  110/269 - Train Accuracy: 0.8677, Validation Accuracy: 0.8722, Loss: 0.1027
Epoch 295 Batch  120/269 - Train Accuracy: 0.8714, Validation Accuracy: 0.8704, Loss: 0.1098
Epoch 295 Batch  130/269 - Train Accuracy: 0.8581, Validation Accuracy: 0.8722, Loss: 0.1023
Epoch 295 Batch  140/269 - Train Accuracy: 0.8689, Validation Accuracy: 0.8772, Loss: 0.1124
Epoch 295 Batch  150/269 - Train Accuracy: 0.8738, Validation Accuracy: 0.8774, Loss: 0.0960
Epoch 295 Batch  160/269 - Train Accuracy: 0.8797, Validation Accuracy: 0.8757, Loss: 0.0961
Epoch 295 Batch  170/269 - Train Accuracy: 0.8661, Validation Accuracy: 0.8767, Loss: 0.0989
Epoch 295 Batch  180/269 - Train Accuracy: 0.8885, Validation Accuracy: 0.8749, Loss: 0.0943
Epoch 295 Batch  190/269 - Train Accuracy: 0.8827, Validation Accuracy: 0.8719, Loss: 0.1064
Epoch 295 Batch  200/269 - Train Accuracy: 0.8567, Validation Accuracy: 0.8643, Loss: 0.1076
Epoch 295 Batch  210/269 - Train Accuracy: 0.8764, Validation Accuracy: 0.8803, Loss: 0.0932
Epoch 295 Batch  220/269 - Train Accuracy: 0.8762, Validation Accuracy: 0.8697, Loss: 0.0905
Epoch 295 Batch  230/269 - Train Accuracy: 0.8641, Validation Accuracy: 0.8741, Loss: 0.0928
Epoch 295 Batch  240/269 - Train Accuracy: 0.8831, Validation Accuracy: 0.8770, Loss: 0.0798
Epoch 295 Batch  250/269 - Train Accuracy: 0.8819, Validation Accuracy: 0.8730, Loss: 0.0974
Epoch 295 Batch  260/269 - Train Accuracy: 0.8633, Validation Accuracy: 0.8746, Loss: 0.1041
Epoch 296 Batch   10/269 - Train Accuracy: 0.8723, Validation Accuracy: 0.8635, Loss: 0.0991
Epoch 296 Batch   20/269 - Train Accuracy: 0.8646, Validation Accuracy: 0.8631, Loss: 0.0873
Epoch 296 Batch   30/269 - Train Accuracy: 0.8660, Validation Accuracy: 0.8792, Loss: 0.0976
Epoch 296 Batch   40/269 - Train Accuracy: 0.8532, Validation Accuracy: 0.8710, Loss: 0.1145
Epoch 296 Batch   50/269 - Train Accuracy: 0.8553, Validation Accuracy: 0.8730, Loss: 0.1050
Epoch 296 Batch   60/269 - Train Accuracy: 0.8835, Validation Accuracy: 0.8744, Loss: 0.0858
Epoch 296 Batch   70/269 - Train Accuracy: 0.8873, Validation Accuracy: 0.8704, Loss: 0.0982
Epoch 296 Batch   80/269 - Train Accuracy: 0.8831, Validation Accuracy: 0.8786, Loss: 0.0960
Epoch 296 Batch   90/269 - Train Accuracy: 0.8744, Validation Accuracy: 0.8672, Loss: 0.1025
Epoch 296 Batch  100/269 - Train Accuracy: 0.8854, Validation Accuracy: 0.8709, Loss: 0.0975
Epoch 296 Batch  110/269 - Train Accuracy: 0.8597, Validation Accuracy: 0.8735, Loss: 0.1035
Epoch 296 Batch  120/269 - Train Accuracy: 0.8742, Validation Accuracy: 0.8700, Loss: 0.1083
Epoch 296 Batch  130/269 - Train Accuracy: 0.8615, Validation Accuracy: 0.8730, Loss: 0.0995
Epoch 296 Batch  140/269 - Train Accuracy: 0.8678, Validation Accuracy: 0.8785, Loss: 0.1072
Epoch 296 Batch  150/269 - Train Accuracy: 0.8713, Validation Accuracy: 0.8729, Loss: 0.1037
Epoch 296 Batch  160/269 - Train Accuracy: 0.8847, Validation Accuracy: 0.8753, Loss: 0.0943
Epoch 296 Batch  170/269 - Train Accuracy: 0.8628, Validation Accuracy: 0.8742, Loss: 0.0921
Epoch 296 Batch  180/269 - Train Accuracy: 0.8876, Validation Accuracy: 0.8653, Loss: 0.0896
Epoch 296 Batch  190/269 - Train Accuracy: 0.8847, Validation Accuracy: 0.8726, Loss: 0.0915
Epoch 296 Batch  200/269 - Train Accuracy: 0.8658, Validation Accuracy: 0.8736, Loss: 0.0971
Epoch 296 Batch  210/269 - Train Accuracy: 0.8721, Validation Accuracy: 0.8730, Loss: 0.1030
Epoch 296 Batch  220/269 - Train Accuracy: 0.8745, Validation Accuracy: 0.8781, Loss: 0.0953
Epoch 296 Batch  230/269 - Train Accuracy: 0.8719, Validation Accuracy: 0.8767, Loss: 0.0920
Epoch 296 Batch  240/269 - Train Accuracy: 0.8748, Validation Accuracy: 0.8715, Loss: 0.0905
Epoch 296 Batch  250/269 - Train Accuracy: 0.8778, Validation Accuracy: 0.8718, Loss: 0.1099
Epoch 296 Batch  260/269 - Train Accuracy: 0.8578, Validation Accuracy: 0.8704, Loss: 0.1035
Epoch 297 Batch   10/269 - Train Accuracy: 0.8767, Validation Accuracy: 0.8722, Loss: 0.0899
Epoch 297 Batch   20/269 - Train Accuracy: 0.8623, Validation Accuracy: 0.8746, Loss: 0.1013
Epoch 297 Batch   30/269 - Train Accuracy: 0.8625, Validation Accuracy: 0.8697, Loss: 0.0954
Epoch 297 Batch   40/269 - Train Accuracy: 0.8588, Validation Accuracy: 0.8710, Loss: 0.1030
Epoch 297 Batch   50/269 - Train Accuracy: 0.8627, Validation Accuracy: 0.8728, Loss: 0.1071
Epoch 297 Batch   60/269 - Train Accuracy: 0.8884, Validation Accuracy: 0.8754, Loss: 0.0918
Epoch 297 Batch   70/269 - Train Accuracy: 0.8757, Validation Accuracy: 0.8741, Loss: 0.0978
Epoch 297 Batch   80/269 - Train Accuracy: 0.8744, Validation Accuracy: 0.8752, Loss: 0.0981
Epoch 297 Batch   90/269 - Train Accuracy: 0.8711, Validation Accuracy: 0.8708, Loss: 0.1086
Epoch 297 Batch  100/269 - Train Accuracy: 0.8783, Validation Accuracy: 0.8706, Loss: 0.0960
Epoch 297 Batch  110/269 - Train Accuracy: 0.8572, Validation Accuracy: 0.8761, Loss: 0.1002
Epoch 297 Batch  120/269 - Train Accuracy: 0.8729, Validation Accuracy: 0.8700, Loss: 0.1091
Epoch 297 Batch  130/269 - Train Accuracy: 0.8613, Validation Accuracy: 0.8739, Loss: 0.1069
Epoch 297 Batch  140/269 - Train Accuracy: 0.8683, Validation Accuracy: 0.8695, Loss: 0.1052
Epoch 297 Batch  150/269 - Train Accuracy: 0.8684, Validation Accuracy: 0.8727, Loss: 0.1014
Epoch 297 Batch  160/269 - Train Accuracy: 0.8863, Validation Accuracy: 0.8743, Loss: 0.1024
Epoch 297 Batch  170/269 - Train Accuracy: 0.8638, Validation Accuracy: 0.8762, Loss: 0.0940
Epoch 297 Batch  180/269 - Train Accuracy: 0.8867, Validation Accuracy: 0.8736, Loss: 0.0919
Epoch 297 Batch  190/269 - Train Accuracy: 0.8867, Validation Accuracy: 0.8685, Loss: 0.0941
Epoch 297 Batch  200/269 - Train Accuracy: 0.8640, Validation Accuracy: 0.8737, Loss: 0.0924
Epoch 297 Batch  210/269 - Train Accuracy: 0.8767, Validation Accuracy: 0.8738, Loss: 0.0964
Epoch 297 Batch  220/269 - Train Accuracy: 0.8703, Validation Accuracy: 0.8692, Loss: 0.0976
Epoch 297 Batch  230/269 - Train Accuracy: 0.8642, Validation Accuracy: 0.8757, Loss: 0.1030
Epoch 297 Batch  240/269 - Train Accuracy: 0.8854, Validation Accuracy: 0.8743, Loss: 0.0835
Epoch 297 Batch  250/269 - Train Accuracy: 0.8782, Validation Accuracy: 0.8773, Loss: 0.1019
Epoch 297 Batch  260/269 - Train Accuracy: 0.8687, Validation Accuracy: 0.8768, Loss: 0.1088
Epoch 298 Batch   10/269 - Train Accuracy: 0.8715, Validation Accuracy: 0.8656, Loss: 0.0897
Epoch 298 Batch   20/269 - Train Accuracy: 0.8630, Validation Accuracy: 0.8767, Loss: 0.0974
Epoch 298 Batch   30/269 - Train Accuracy: 0.8683, Validation Accuracy: 0.8683, Loss: 0.0950
Epoch 298 Batch   40/269 - Train Accuracy: 0.8581, Validation Accuracy: 0.8780, Loss: 0.1178
Epoch 298 Batch   50/269 - Train Accuracy: 0.8490, Validation Accuracy: 0.8750, Loss: 0.1116
Epoch 298 Batch   60/269 - Train Accuracy: 0.8825, Validation Accuracy: 0.8706, Loss: 0.0962
Epoch 298 Batch   70/269 - Train Accuracy: 0.8819, Validation Accuracy: 0.8746, Loss: 0.1008
Epoch 298 Batch   80/269 - Train Accuracy: 0.8791, Validation Accuracy: 0.8730, Loss: 0.1008
Epoch 298 Batch   90/269 - Train Accuracy: 0.8795, Validation Accuracy: 0.8717, Loss: 0.1073
Epoch 298 Batch  100/269 - Train Accuracy: 0.8817, Validation Accuracy: 0.8709, Loss: 0.0947
Epoch 298 Batch  110/269 - Train Accuracy: 0.8627, Validation Accuracy: 0.8682, Loss: 0.1140
Epoch 298 Batch  120/269 - Train Accuracy: 0.8697, Validation Accuracy: 0.8751, Loss: 0.1111
Epoch 298 Batch  130/269 - Train Accuracy: 0.8619, Validation Accuracy: 0.8707, Loss: 0.0976
Epoch 298 Batch  140/269 - Train Accuracy: 0.8670, Validation Accuracy: 0.8744, Loss: 0.0996
Epoch 298 Batch  150/269 - Train Accuracy: 0.8721, Validation Accuracy: 0.8675, Loss: 0.0994
Epoch 298 Batch  160/269 - Train Accuracy: 0.8844, Validation Accuracy: 0.8738, Loss: 0.0989
Epoch 298 Batch  170/269 - Train Accuracy: 0.8562, Validation Accuracy: 0.8683, Loss: 0.0999
Epoch 298 Batch  180/269 - Train Accuracy: 0.8931, Validation Accuracy: 0.8681, Loss: 0.0930
Epoch 298 Batch  190/269 - Train Accuracy: 0.8864, Validation Accuracy: 0.8723, Loss: 0.1037
Epoch 298 Batch  200/269 - Train Accuracy: 0.8657, Validation Accuracy: 0.8758, Loss: 0.0998
Epoch 298 Batch  210/269 - Train Accuracy: 0.8760, Validation Accuracy: 0.8750, Loss: 0.0985
Epoch 298 Batch  220/269 - Train Accuracy: 0.8774, Validation Accuracy: 0.8732, Loss: 0.0944
Epoch 298 Batch  230/269 - Train Accuracy: 0.8654, Validation Accuracy: 0.8742, Loss: 0.0993
Epoch 298 Batch  240/269 - Train Accuracy: 0.8787, Validation Accuracy: 0.8735, Loss: 0.0848
Epoch 298 Batch  250/269 - Train Accuracy: 0.8834, Validation Accuracy: 0.8746, Loss: 0.0947
Epoch 298 Batch  260/269 - Train Accuracy: 0.8642, Validation Accuracy: 0.8770, Loss: 0.1031
Epoch 299 Batch   10/269 - Train Accuracy: 0.8682, Validation Accuracy: 0.8708, Loss: 0.0915
Epoch 299 Batch   20/269 - Train Accuracy: 0.8563, Validation Accuracy: 0.8636, Loss: 0.0982
Epoch 299 Batch   30/269 - Train Accuracy: 0.8605, Validation Accuracy: 0.8727, Loss: 0.0976
Epoch 299 Batch   40/269 - Train Accuracy: 0.8566, Validation Accuracy: 0.8764, Loss: 0.1065
Epoch 299 Batch   50/269 - Train Accuracy: 0.8600, Validation Accuracy: 0.8765, Loss: 0.1161
Epoch 299 Batch   60/269 - Train Accuracy: 0.8843, Validation Accuracy: 0.8724, Loss: 0.0880
Epoch 299 Batch   70/269 - Train Accuracy: 0.8821, Validation Accuracy: 0.8747, Loss: 0.0950
Epoch 299 Batch   80/269 - Train Accuracy: 0.8715, Validation Accuracy: 0.8700, Loss: 0.1004
Epoch 299 Batch   90/269 - Train Accuracy: 0.8799, Validation Accuracy: 0.8699, Loss: 0.1074
Epoch 299 Batch  100/269 - Train Accuracy: 0.8847, Validation Accuracy: 0.8684, Loss: 0.0944
Epoch 299 Batch  110/269 - Train Accuracy: 0.8637, Validation Accuracy: 0.8724, Loss: 0.0989
Epoch 299 Batch  120/269 - Train Accuracy: 0.8758, Validation Accuracy: 0.8649, Loss: 0.1242
Epoch 299 Batch  130/269 - Train Accuracy: 0.8553, Validation Accuracy: 0.8635, Loss: 0.1027
Epoch 299 Batch  140/269 - Train Accuracy: 0.8660, Validation Accuracy: 0.8699, Loss: 0.1007
Epoch 299 Batch  150/269 - Train Accuracy: 0.8707, Validation Accuracy: 0.8730, Loss: 0.1013
Epoch 299 Batch  160/269 - Train Accuracy: 0.8850, Validation Accuracy: 0.8707, Loss: 0.0999
Epoch 299 Batch  170/269 - Train Accuracy: 0.8678, Validation Accuracy: 0.8709, Loss: 0.0983
Epoch 299 Batch  180/269 - Train Accuracy: 0.8873, Validation Accuracy: 0.8698, Loss: 0.0861
Epoch 299 Batch  190/269 - Train Accuracy: 0.8781, Validation Accuracy: 0.8746, Loss: 0.1014
Epoch 299 Batch  200/269 - Train Accuracy: 0.8600, Validation Accuracy: 0.8787, Loss: 0.1098
Epoch 299 Batch  210/269 - Train Accuracy: 0.8730, Validation Accuracy: 0.8803, Loss: 0.0959
Epoch 299 Batch  220/269 - Train Accuracy: 0.8708, Validation Accuracy: 0.8710, Loss: 0.0929
Epoch 299 Batch  230/269 - Train Accuracy: 0.8641, Validation Accuracy: 0.8766, Loss: 0.1051
Epoch 299 Batch  240/269 - Train Accuracy: 0.8783, Validation Accuracy: 0.8765, Loss: 0.0976
Epoch 299 Batch  250/269 - Train Accuracy: 0.8800, Validation Accuracy: 0.8746, Loss: 0.1002
Epoch 299 Batch  260/269 - Train Accuracy: 0.8634, Validation Accuracy: 0.8705, Loss: 0.1219
Model Trained and Saved
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Save-Parameters">Save Parameters<a class="anchor-link" href="#Save-Parameters">&#182;</a></h3><p>Save the <code>batch_size</code> and <code>save_path</code> parameters for inference.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[22]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="c1"># Save parameters for checkpoint</span>
<span class="n">helper</span><span class="o">.</span><span class="n">save_params</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Checkpoint">Checkpoint<a class="anchor-link" href="#Checkpoint">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[23]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">helper</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="k">as</span> <span class="nn">tests</span>

<span class="n">_</span><span class="p">,</span> <span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">),</span> <span class="p">(</span><span class="n">source_int_to_vocab</span><span class="p">,</span> <span class="n">target_int_to_vocab</span><span class="p">)</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess</span><span class="p">()</span>
<span class="n">load_path</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_params</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Sentence-to-Sequence">Sentence to Sequence<a class="anchor-link" href="#Sentence-to-Sequence">&#182;</a></h2><p>To feed a sentence into the model for translation, you first need to preprocess it.  Implement the function <code>sentence_to_seq()</code> to preprocess new sentences.</p>
<ul>
<li>Convert the sentence to lowercase</li>
<li>Convert words into ids using <code>vocab_to_int</code><ul>
<li>Convert words not in the vocabulary, to the <code>&lt;UNK&gt;</code> word id.</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[24]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">sentence_to_seq</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">vocab_to_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert a sentence to a sequence of ids</span>
<span class="sd">    :param sentence: String</span>
<span class="sd">    :param vocab_to_int: Dictionary to go from the words to an id</span>
<span class="sd">    :return: List of word ids</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">list_of_word_ids</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
    
    <span class="c1"># convert sentence to lowercase</span>
    <span class="n">lower_case_sentence</span> <span class="o">=</span> <span class="n">sentence</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">lower_case_sentence</span><span class="p">)</span>
    
    <span class="c1"># convert words into ids using vocab_to_int</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">lower_case_sentence</span><span class="o">.</span><span class="n">split</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">vocab_to_int</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">list_of_word_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">vocab_to_int</span><span class="p">[</span><span class="n">word</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">list_of_word_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;UNK&gt;&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">list_of_word_ids</span><span class="p">)</span>
                                
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_sentence_to_seq</span><span class="p">(</span><span class="n">sentence_to_seq</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>this is a test sentence
Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Translate">Translate<a class="anchor-link" href="#Translate">&#182;</a></h2><p>This will translate <code>translate_sentence</code> from English to French.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[25]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">translate_sentence</span> <span class="o">=</span> <span class="s1">&#39;he saw a old yellow truck .&#39;</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">translate_sentence</span> <span class="o">=</span> <span class="n">sentence_to_seq</span><span class="p">(</span><span class="n">translate_sentence</span><span class="p">,</span> <span class="n">source_vocab_to_int</span><span class="p">)</span>

<span class="n">loaded_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">loaded_graph</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="c1"># Load saved model</span>
    <span class="n">loader</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">import_meta_graph</span><span class="p">(</span><span class="n">load_path</span> <span class="o">+</span> <span class="s1">&#39;.meta&#39;</span><span class="p">)</span>
    <span class="n">loader</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">load_path</span><span class="p">)</span>

    <span class="n">input_data</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;input:0&#39;</span><span class="p">)</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;predictions:0&#39;</span><span class="p">)</span>
    <span class="n">target_sequence_length</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;target_sequence_length:0&#39;</span><span class="p">)</span>
    <span class="n">source_sequence_length</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;source_sequence_length:0&#39;</span><span class="p">)</span>
    <span class="n">keep_prob</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;keep_prob:0&#39;</span><span class="p">)</span>

    <span class="n">translate_logits</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="p">[</span><span class="n">translate_sentence</span><span class="p">]</span><span class="o">*</span><span class="n">batch_size</span><span class="p">,</span>
                                         <span class="n">target_sequence_length</span><span class="p">:</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">translate_sentence</span><span class="p">)</span><span class="o">*</span><span class="mi">2</span><span class="p">]</span><span class="o">*</span><span class="n">batch_size</span><span class="p">,</span>
                                         <span class="n">source_sequence_length</span><span class="p">:</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">translate_sentence</span><span class="p">)]</span><span class="o">*</span><span class="n">batch_size</span><span class="p">,</span>
                                         <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})[</span><span class="mi">0</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Input&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  Word Ids:      </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">translate_sentence</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  English Words: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">([</span><span class="n">source_int_to_vocab</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">translate_sentence</span><span class="p">]))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Prediction&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  Word Ids:      </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">translate_logits</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  French Words: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">target_int_to_vocab</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">translate_logits</span><span class="p">])))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>he saw a old yellow truck .
INFO:tensorflow:Restoring parameters from checkpoints/dev
Input
  Word Ids:      [190, 25, 202, 93, 197, 56, 215]
  English Words: [&#39;he&#39;, &#39;saw&#39;, &#39;a&#39;, &#39;old&#39;, &#39;yellow&#39;, &#39;truck&#39;, &#39;.&#39;]

Prediction
  Word Ids:      [211, 183, 262, 303, 53, 356, 197, 1]
  French Words: poire  chaude est brillante leur ? &lt;EOS&gt;
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Imperfect-Translation">Imperfect Translation<a class="anchor-link" href="#Imperfect-Translation">&#182;</a></h2><p>You might notice that some sentences translate better than others.  Since the dataset you're using only has a vocabulary of 227 English words of the thousands that you use, you're only going to see good results using these words.  For this project, you don't need a perfect translation. However, if you want to create a better translation model, you'll need better data.</p>
<p>You can train on the <a href="http://www.statmt.org/wmt10/training-giga-fren.tar">WMT10 French-English corpus</a>.  This dataset has more vocabulary and richer in topics discussed.  However, this will take you days to train, so make sure you've a GPU and the neural network is performing well on dataset we provided.  Just make sure you play with the WMT10 corpus after you've submitted this project.</p>
<h2 id="Submitting-This-Project">Submitting This Project<a class="anchor-link" href="#Submitting-This-Project">&#182;</a></h2><p>When submitting this project, make sure to run all the cells before saving the notebook. Save the notebook file as "dlnd_language_translation.ipynb" and save it as a HTML file under "File" -&gt; "Download as". Include the "helper.py" and "problem_unittests.py" files in your submission.</p>

</div>
</div>
</div>
    </div>
  </div>
</body>

 


</html>
